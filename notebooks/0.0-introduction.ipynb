{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; background-color: #0A6EBD; font-family: 'Trebuchet MS', Arial, sans-serif; color: white; padding: 20px; font-size: 40px; font-weight: bold; border-radius: 0 0 0 0; box-shadow: 0px 6px 8px rgba(0, 0, 0, 0.2);\">\n",
    "  Analyzing about Data Science Channels on Youtube\n",
    "  \n",
    "  @ FIT-HCMUS, VNU-HCM ðŸ“Œ\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; background-color: #5A96E3; font-family: 'Trebuchet MS', Arial, sans-serif; color: white; padding: 20px; font-size: 40px; font-weight: bold; border-radius: 0 0 0 0; box-shadow: 0px 6px 8px rgba(0, 0, 0, 0.2);\">\n",
    "  A brief introduction to the project\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why we choose this topic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YouTube stands out as a widely embraced platform for video consumption, seamlessly integrating into our daily routines. Whether for entertainment, education, or staying informed with the latest news, YouTube has become an integral part of our lives. As students specializing in Data Science, we aspire to seamlessly incorporate Data Science topics into our daily existence by leveraging YouTube videos. Thus, our decision was made to delve into an analysis of Data Science channels on YouTube. Exploring their operational dynamics, thematic focuses, and conducting comprehensive comparisons will empower us to identify the most fitting channels. This strategic approach aims to seamlessly integrate Data Science content into our daily lives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can we collect data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F\n",
    "Initially, we conducted research to identify popular Data Science channels on the internet, selecting some based on personal preferences. Subsequently, we obtained the channel IDs using [this website](https://www.streamweasels.com/tools/youtube-channel-id-and-user-id-convertor/). \n",
    "\n",
    "Next, utilizing these channel IDs, we made requests to the Youtube Data API v3 to retrieve all video IDs associated with these channels.\n",
    "\n",
    "Following that, we utilized the video IDs to send additional requests to the Youtube Data API v3, acquiring detailed information about each video. Subsequently, we stored this information in a CSV file.\n",
    "\n",
    "Lastly, we employed the video IDs once more to send requests to the Youtube Data API v3, this time retrieving all the comments for these videos. The comments were then stored in a separate CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Members"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- 21120504 _ Nguyá»…n PhÆ°Æ¡ng Nam: 21120504@student.hcmus.edu.vn\n",
    "- 21120516 _ VÃµ BÃ¡ HoÃ ng Nháº¥t: 21120516@student.hcmus.edu.vn\n",
    "- 21120529 _ Nguyá»…n Gia PhÃºc: 21120529@student.hcmus.edu.vn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up your coding environment with Anaconda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you should [download and install Anaconda](https://www.anaconda.com/download) for your operating systems. Then, starting install your development environment using ```requirements.txt```. \n",
    "\n",
    "**Note**: Suppose that you want to use Python 3.9, I built this requirement packages list base on Python 3.9. So if you want to install these packages in other Python version, please check all packages again via command ```conda search -c conda-forge -f  <package name>``` to verify the version of each package and change it in ```requirements.txt``` file. \n",
    "\n",
    "```bash\n",
    "# create conda virtual environment\n",
    "conda create --name min_ds-env python=3.9 -y\n",
    "\n",
    "# activate created conda virtual environment\n",
    "conda activate min_ds-env\n",
    "\n",
    "# install dependencies\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laboratory structure explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab project structure is built under the [Cookiecutter Data Science](https://github.com/drivendata/cookiecutter-data-science) - A logical, reasonably standardized, but flexible project structure for doing and sharing data science work. \n",
    "\n",
    "```\n",
    "â”œâ”€â”€ LICENSE-CC-BY-NC-ND-4.0.md\n",
    "â”œâ”€â”€ min_ds-env.yml\n",
    "â”œâ”€â”€ Makefile                 <- Makefile with commands like `make data` or `make train`\n",
    "â”œâ”€â”€ README.md                <- The top-level README for developers using this project.\n",
    "â”œâ”€â”€ data\n",
    "â”‚   â”œâ”€â”€ external             <- Data from third party sources.\n",
    "â”‚   â”œâ”€â”€ interim              <- Intermediate data that has been transformed.\n",
    "â”‚   â”œâ”€â”€ processed            <- The final, canonical data sets for modeling.\n",
    "â”‚   â””â”€â”€ raw                  <- The original, immutable data dump.\n",
    "â”‚\n",
    "â”‚\n",
    "â”œâ”€â”€ models                   <- Trained and serialized models, model predictions, or model summaries\n",
    "â”‚\n",
    "â”œâ”€â”€ notebooks                <- Jupyter notebooks. Naming convention is a number (for ordering),\n",
    "â”‚                               the creator's initials, and a short `-` delimited description, e.g.\n",
    "â”‚                               `1.0-initial-data-exploration`.\n",
    "â”‚\n",
    "â”œâ”€â”€ references                <- Data dictionaries, manuals, and all other explanatory materials.\n",
    "â”‚\n",
    "â”œâ”€â”€ reports                   <- Generated analysis as HTML, PDF, LaTeX, etc. or your written by template such as https://github.com/Wandmalfarbe/pandoc-latex-template\n",
    "â”‚   â””â”€â”€ figures               <- Generated graphics and figures to be used in reporting\n",
    "â”‚\n",
    "â”œâ”€â”€ requirements.txt          <- The requirements file for reproducing the analysis environment\n",
    "â”‚\n",
    "â”œâ”€â”€ src                       <- Source code for use in this project.\n",
    "â”‚   â”œâ”€â”€ __init__.py           <- Makes src a Python module\n",
    "â”‚   â”‚\n",
    "â”‚   â”œâ”€â”€ data_module           <- Scripts to download or generate data\n",
    "â”‚   â”‚   â””â”€â”€ make_dataset.py\n",
    "â”‚   â”‚\n",
    "â”‚   â”œâ”€â”€ features_module       <- Scripts to turn raw data into features for modeling\n",
    "â”‚   â”‚   â””â”€â”€ build_features.py\n",
    "â”‚   â”‚\n",
    "â”‚   â”œâ”€â”€ models_module         <- Scripts to train models and then use trained models to make\n",
    "â”‚   â”‚   â”‚                        predictions\n",
    "â”‚   â”‚   â”œâ”€â”€ predict_model.py\n",
    "â”‚   â”‚   â””â”€â”€ train_model.py\n",
    "â”‚   â”‚\n",
    "â”‚   â””â”€â”€ visualization_module  <- Scripts to create exploratory and results oriented visualizations\n",
    "â”‚       â””â”€â”€ visualize.py\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
