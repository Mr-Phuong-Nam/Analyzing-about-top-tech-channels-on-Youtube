Comment_id,author,Reply_for,Type,video_id,total_reply,like_count,published_at,textdisplay,updatedat
Ugw5fySq5NxfwgCuFhB4AaABAg,@AiexpertRajivVerma,,1,H_8ZVRRtiIA,0,0,2023-12-11T01:11:19Z,Sir thank you love love üíï‚ù§Ô∏è‚ù§‚ù§Ô∏è‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§ you for free these courses as I belong from India but don&#39;t have money to buy these Coursera course but it is really helpful for poor people in India or around the world who are interested in ai but can afford but yeah Andrew sir really appreciate your works ‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§,2023-12-11T01:11:19Z
Ugw_73FC0tI1B6PW9nh4AaABAg,@hamasali8764,,1,bZwkaVnhEo4,0,0,2023-07-27T16:54:52Z,Best Oneüéâ,2023-07-27T16:54:52Z
Ugx1qnyHmXF9-BjhIWR4AaABAg,@R0H00,,1,hkOosfWxBK4,0,1,2023-11-18T02:51:01Z,"Hi, I&#39;m a clinician who is working in the digital health/ informatics space. Can you please let me know, what role I can play the AI space (which I&#39;m interested to dig) apart from hardcore Data Science?",2023-11-18T02:51:01Z
UgyNZvEu-Ht9ZlLwOXp4AaABAg,@nitinsnoisepollution6293,,1,hkOosfWxBK4,0,0,2023-11-17T20:39:13Z,Superb üéâ‚ù§,2023-11-17T20:39:13Z
UgzAxiiLaxyBHEcRw0R4AaABAg,@REDBONDYT,,1,Fxq6vjJwX3o,0,1,2023-07-30T12:36:13Z,Very informative üòÉüò∫,2023-07-30T12:36:13Z
UgxyNjLNOVNw0c-EGXF4AaABAg,@erikgarcia6141,,1,Ee8EOWWGJ7U,0,0,2023-07-31T06:54:32Z,"How cool the lab, i&#39;m from Bogota",2023-07-31T06:54:32Z
UgyIcXszWKIz5H-kE8F4AaABAg,@zouhirelmezraoui1336,,1,AmlhNK9_I4o,0,1,2023-11-15T22:21:49Z,üíñüëÜüíñüéìüéìüéìüëâüëÜüëà,2023-11-15T22:21:49Z
Ugy7H_HsdoSC3akc9cV4AaABAg,@Raw-L,,1,Z8GILwqeSXE,0,1,2023-09-22T08:28:57Z,Is there an AI for evil Course? I am asking of course for a friendüòÖ!üà≤,2023-09-22T08:28:57Z
UgwZvlRNNYXFmK7z8yd4AaABAg,@taptyaagtandav,,1,Z8GILwqeSXE,0,2,2023-09-09T14:23:09Z,Love you Sir ‚ù§‚ù§‚ù§‚ù§,2023-09-09T14:23:09Z
UgyZPR-7aaoR5nrcgDJ4AaABAg,@musicanbeat,,1,Z8GILwqeSXE,0,2,2023-09-08T10:14:56Z,Thank you so much sir for such a great contribution you are doing for all youths and all people interested in learning these thingsüôè‚ú®,2023-09-08T10:14:56Z
Ugyvu2cI0GMd7ey7mGh4AaABAg,@muhammadasif9963,,1,Z8GILwqeSXE,0,3,2023-09-08T05:47:05Z,"Thank you so much Andrew Ng, for doing a great job for Community, providing a great platform for Deep learning, Large Language Models, and Generative AI, the field where all are learners.üòá",2023-09-08T05:47:05Z
Ugw_P10vaPKls4YrPH54AaABAg,@davidmerwin0077,,1,Z8GILwqeSXE,0,1,2023-09-07T16:54:12Z,‚ù§,2023-09-07T16:54:12Z
Ugy0bGctOrbSkRXaYRJ4AaABAg,@zouhirelmezraoui1336,,1,Z8GILwqeSXE,0,0,2023-09-07T16:13:49Z,üíñüëÜüíñüéìüéìüéìüëâüëÜüëàüî≠üî≠üî≠üåçüåçüåç‚õÖ‚õÖ‚õÖüíªüíªüíªüëäüëäüëäüå¥üå¥üå¥üêôüêôüêôüèÑüèÑüèÑ,2023-09-07T16:13:49Z
Ugxfe9KrWVYeFO_oPjV4AaABAg,@dianefay,,1,4xYos-CvkIY,0,0,2023-09-21T09:16:41Z,Promo sm üòâ,2023-09-21T09:16:41Z
UgxSgcokDDUws4Huuyx4AaABAg,@abbaskhan-db9rz,,1,4xYos-CvkIY,1,0,2023-09-03T06:36:26Z,Thank you for providing this open access short course but i have a question do we get any certification for this course ?<br>Maybe paid one ?,2023-09-03T06:36:26Z
UgxSgcokDDUws4Huuyx4AaABAg.9uB_KQOVIo49uKrJrJAQNK,@Deeplearningai,UgxSgcokDDUws4Huuyx4AaABAg,2,4xYos-CvkIY,0,0,2023-09-06T21:06:48Z,"Not at this time, but thanks for your comment!",2023-09-06T21:06:48Z
UgyUrVce7wabIOI9ov94AaABAg,@josephz82,,1,4xYos-CvkIY,0,1,2023-08-31T08:22:36Z,can anyone point me to the folder &quot;plugins-sk&quot;?,2023-08-31T08:22:36Z
Ugw8GgvR9kVJI-BJuWh4AaABAg,@aiopenknowledge,,1,4xYos-CvkIY,0,0,2023-08-30T16:37:14Z,Hello! I&#39;m interested in your video.,2023-08-30T16:37:14Z
UgxWdLjitTCQUieSnyl4AaABAg,@VenkatesanVenkat-fd4hg,,1,4xYos-CvkIY,0,0,2023-08-30T09:02:28Z,I am expecting finetuning LLM  related course using qlora and discussions on quantizations like GGML &amp; UL...Also on multimodal....that will be great.,2023-08-30T09:02:28Z
UgxJTz2ESwdPsHyNbpV4AaABAg,@taptyaagtandav,,1,4xYos-CvkIY,0,3,2023-08-30T07:56:52Z,More Courses Needed From Microsoft üôèüôèüôèüôèüôèüôèüôèüôèüôèüôè,2023-08-30T07:56:52Z
UgwEoH7C72LFzcBDEsJ4AaABAg,@basitbhai6314,,1,4xYos-CvkIY,0,0,2023-08-30T05:10:28Z,please sir chatbot development course  of  everything which I can  make  chatbot for any business needs,2023-08-30T05:10:28Z
UgwShEJ4dscpzjO0tZp4AaABAg,@ra_XOr,,1,4xYos-CvkIY,2,3,2023-08-30T01:32:11Z,These short courses are outstanding!! I can&#39;t recommend them enough! üíúüíú. Thank you for the great contribution to the ML community!!,2023-08-30T01:32:11Z
UgwShEJ4dscpzjO0tZp4AaABAg.9u0jKZKnvxA9u0y1MCCE3W,@geekyprogrammer4831,UgwShEJ4dscpzjO0tZp4AaABAg,2,4xYos-CvkIY,0,1,2023-08-30T03:40:37Z,sorry to say they are not as good as Andrews Machine Learning and Deep Learning courses. People on YouTube have explained much better than them,2023-08-30T03:40:37Z
UgwShEJ4dscpzjO0tZp4AaABAg.9u0jKZKnvxA9u1XR7bNGRA,@VenkatesanVenkat-fd4hg,UgwShEJ4dscpzjO0tZp4AaABAg,2,4xYos-CvkIY,0,1,2023-08-30T08:58:43Z,"Yes, the course is not good enough by senior data scientist.",2023-08-30T08:58:43Z
UgzyW5JUpf1WJlDQOkx4AaABAg,@ilovefangfang123,,1,Sh4n0uk-NHk,0,1,2023-11-02T09:05:09Z,Two years later I‚Äôll join cohere!,2023-11-02T09:05:09Z
UgybmJ-BSTV8hFe4hax4AaABAg,@melttherhythm,,1,Sh4n0uk-NHk,0,2,2023-08-16T17:31:57Z,"Thank you for the course, joining!",2023-08-16T17:31:57Z
UgwJMfcdx_toCIgNOEd4AaABAg,@nishantbundela,,1,Sh4n0uk-NHk,0,2,2023-08-16T15:46:59Z,Thank you for these courses :),2023-08-16T15:46:59Z
UgzXR-VVqvyFxgqNSFJ4AaABAg,@MatijaGrcic,,1,Sh4n0uk-NHk,0,2,2023-08-16T06:52:25Z,"So far I&#39;ve enjoyed all the LLM courses you&#39;ve published, looking forward to this one.",2023-08-16T06:52:25Z
Ugwauw1RK7GjreXRq154AaABAg,@transylvanian2411,,1,Sh4n0uk-NHk,2,2,2023-08-16T06:05:45Z,‚ùóÔ∏èü§ìüìñ Study Group for those who wana study together.,2023-08-16T06:05:45Z
Ugwauw1RK7GjreXRq154AaABAg.9tTAW0FciRU9tUP-Knozs7,@melttherhythm,Ugwauw1RK7GjreXRq154AaABAg,2,Sh4n0uk-NHk,0,0,2023-08-16T17:31:36Z,how to join üòÄ,2023-08-16T17:31:36Z
Ugwauw1RK7GjreXRq154AaABAg.9tTAW0FciRU9tURoh68O-Y,@visionxgaming4027,Ugwauw1RK7GjreXRq154AaABAg,2,Sh4n0uk-NHk,0,0,2023-08-16T17:56:13Z,Yes but how to join,2023-08-16T17:56:13Z
UgxgPnYvHYaWPVFp6sF4AaABAg,@divyeshrajpura6627,,1,Sh4n0uk-NHk,1,3,2023-08-06T05:37:23Z,"@DeepLearningAI, Thank you so much for interesting courses. Can you suggest on where could I find the link for this course?",2023-08-06T05:37:23Z
UgxgPnYvHYaWPVFp6sF4AaABAg.9t3NJTAj2E89tU2qJmQGwl,@Deeplearningai,UgxgPnYvHYaWPVFp6sF4AaABAg,2,Sh4n0uk-NHk,0,0,2023-08-16T14:18:00Z,"Hi @divyeshrajpura6627!<br><br>You can find more info and enroll here: <a href=""https://bit.ly/3OLOEzo"">https://bit.ly/3OLOEzo</a>",2023-08-16T14:18:00Z
UgwhA0znCah9ffW5fsx4AaABAg,@RajuRaju-md5oc,,1,UHFTY0B718s,0,0,2023-08-04T08:43:43Z,Website untouched bta rha hai,2023-08-04T08:43:43Z
Ugza4tiJHf8QWroomil4AaABAg,@zouhirelmezraoui1336,,1,UHFTY0B718s,0,0,2023-08-02T18:11:42Z,üíñüëÜüíñüéìüéìüéìüëâüëÜüëà,2023-08-02T18:11:42Z
UgwBvQ9AthE3p1gT0UF4AaABAg,@ARDSKiComedy,,1,UHFTY0B718s,0,0,2023-08-02T13:05:40Z,Thank you so much for your help üòä,2023-08-02T13:05:40Z
UgxKJlgSSnoqYef3dGZ4AaABAg,@umarfarooque3687,,1,UHFTY0B718s,0,0,2023-08-02T08:25:55Z,combination of beauty and brain ü§©,2023-08-02T08:25:55Z
UgxyHreEDJug1-lj1vR4AaABAg,@user-cj4uh6ss9u,,1,UHFTY0B718s,0,0,2023-08-02T08:20:35Z,Nice,2023-08-02T08:20:35Z
UgxDmHJIrwuGAY1L_bB4AaABAg,@codingquiz,,1,UHFTY0B718s,0,0,2023-08-02T08:06:41Z,great,2023-08-02T08:06:41Z
Ugxyl1B4BT3VmbNE4jt4AaABAg,@20y06h,,1,UHFTY0B718s,3,2,2023-08-02T07:52:05Z,I&#39;m confused about whether I should be taking ML&amp;AI or CSE,2023-08-02T07:52:05Z
Ugxyl1B4BT3VmbNE4jt4AaABAg.9suJYYQaA749suPhzgQeYH,@ujtyhbfgtfsdxz,Ugxyl1B4BT3VmbNE4jt4AaABAg,2,UHFTY0B718s,0,1,2023-08-02T08:45:56Z,CSE.,2023-08-02T08:45:56Z
Ugxyl1B4BT3VmbNE4jt4AaABAg.9suJYYQaA749swG0I8Bxn9,@tahirnaeem4208,Ugxyl1B4BT3VmbNE4jt4AaABAg,2,UHFTY0B718s,0,1,2023-08-03T01:59:40Z,CSE,2023-08-03T01:59:40Z
Ugxyl1B4BT3VmbNE4jt4AaABAg.9suJYYQaA749t1LbNREmq2,@MrGramatix,Ugxyl1B4BT3VmbNE4jt4AaABAg,2,UHFTY0B718s,0,2,2023-08-05T10:44:00Z,"CSE is the foundation, if you have strong foundation you can learn and move to any new streams",2023-08-05T10:44:00Z
UgwlNAupGbD31t1bC_14AaABAg,@ikurious,,1,UHFTY0B718s,0,0,2023-08-02T07:36:14Z,Cool!,2023-08-02T07:36:14Z
Ugz5PnDsW4HCXiDdujF4AaABAg,@sheikhakbar2067,,1,4fkqXdcTmGk,0,0,2023-08-02T13:59:59Z,Thanks a lot for making it free!,2023-08-02T13:59:59Z
UgyorqE5mVttI9n1ob54AaABAg,@fgfanta,,1,4fkqXdcTmGk,0,1,2023-07-26T16:36:27Z,The missing course! Not anymore!,2023-07-26T16:36:39Z
UgyXhypDXJMq6Ime0yV4AaABAg,@Andreas-gh6is,,1,4fkqXdcTmGk,0,1,2023-07-26T14:38:46Z,"I played around with Gradio a little... It&#39;s not all bad, I guess. But the state management is very tricky and that limits what you can do with it. I had also hoped I could use the table widgets for data exploration, but the widget is also quite limited. And you can&#39;t have a background process updating things in the UI, as far as I can see.",2023-07-26T14:38:46Z
UgxIyjZ3GcB1pUgoEoN4AaABAg,@sandip9691,,1,3CHB3_Q6GkA,1,0,2023-07-24T16:18:10Z,Can anyone share cource link?,2023-07-24T16:18:10Z
UgxIyjZ3GcB1pUgoEoN4AaABAg.9sZ2JFgVXj69sgCJo7QgFu,@Deeplearningai,UgxIyjZ3GcB1pUgoEoN4AaABAg,2,3CHB3_Q6GkA,0,0,2023-07-27T20:19:32Z,"<a href=""https://www.coursera.org/learn/generative-ai-with-llms"">https://www.coursera.org/learn/generative-ai-with-llms</a> :)",2023-07-27T20:19:32Z
Ugzc6c_2WElBnbWkNqh4AaABAg,@TheSiddhartha2u,,1,3CHB3_Q6GkA,0,0,2023-07-12T12:14:14Z,Enrolled and Completed Week 1 ‚ù§,2023-07-12T12:14:14Z
Ugw1beR_nJgHbK68OWh4AaABAg,@SantoshKumar-jm4oo,,1,3CHB3_Q6GkA,0,0,2023-07-11T17:01:40Z,why is his left side face of drooping?,2023-07-11T17:01:40Z
UgxCird8ce_T7xwFrgV4AaABAg,@MatijaGrcic,,1,3CHB3_Q6GkA,0,2,2023-06-28T22:54:13Z,"Enrolled, looking forward to it.",2023-06-28T22:54:13Z
UgyEYa_HnZi8gf0zUMJ4AaABAg,@TheLummen.,,1,3CHB3_Q6GkA,0,0,2023-06-28T21:50:18Z,Love it ! <br>Let&#39;s go !,2023-06-28T21:50:18Z
UgzNRyQJOb1Do5vg2DN4AaABAg,@rombohnallavan1861,,1,3CHB3_Q6GkA,2,3,2023-06-28T20:14:39Z,"I prefer google cloud. Having worked on AI for 10 years and benefited mostly from google innovation, I prefer google cloud over aws",2023-06-28T20:15:07Z
UgzNRyQJOb1Do5vg2DN4AaABAg.9rWWhg9GtKg9rXic7vMugt,@snowsnow5069,UgzNRyQJOb1Do5vg2DN4AaABAg,2,3CHB3_Q6GkA,0,1,2023-06-29T07:26:44Z,"Yes, AWS fees are incredibly high. We ended up building our own server with an API to LLMs",2023-06-29T07:26:44Z
UgzNRyQJOb1Do5vg2DN4AaABAg.9rWWhg9GtKg9s-bd6NSm_K,@friendzenterkolkata,UgzNRyQJOb1Do5vg2DN4AaABAg,2,3CHB3_Q6GkA,0,1,2023-07-10T22:02:55Z,"Google Cloud is easier to understand, faster to deploy and in general, a better Cloud Platform than AWS.",2023-07-10T22:02:55Z
Ugz0nD9MNv-Y8sTJWBl4AaABAg,@zouhirelmezraoui1336,,1,3CHB3_Q6GkA,0,0,2023-06-28T17:51:24Z,üíñüëÜüíñüéìüéìüéìüëâüëÜüëàüî≠üî≠üî≠üåçüåçüåç‚õÖ‚õÖ‚õÖüíªüíªüíªüëäüëäüëäüå¥üå¥üå¥üêôüêôüêôüèÑüèÑüèÑ,2023-06-28T17:51:24Z
UgzcOWCDRO6i_aOU8o94AaABAg,@nataliameira2283,,1,3CHB3_Q6GkA,0,0,2023-06-28T16:00:36Z,üò±üò±üò±,2023-06-28T16:00:36Z
UgxcOeCTnM6FtfbBOCh4AaABAg,@chiragsharma9430,,1,3CHB3_Q6GkA,0,1,2023-06-28T15:56:15Z,Is it paid or free?,2023-06-28T15:56:15Z
Ugzw9ZbHGFSCgIFj32t4AaABAg,@TheSiddhartha2u,,1,3CHB3_Q6GkA,0,1,2023-06-28T15:50:01Z,Waiting for this ‚ù§,2023-06-28T15:50:01Z
UgwqwKddnef2AWAM4cd4AaABAg,@prasenjit19,,1,BunESRhYhec,0,0,2023-07-17T18:14:03Z,Who is coming after saw the Sandeep maheshwari show,2023-07-17T18:14:03Z
UgxxWsBL6p9OUCMpTa14AaABAg,@rohitmotivates,,1,BunESRhYhec,0,0,2023-07-17T17:19:37Z,Can you provide these corours in hind or Hinglish language please,2023-07-17T17:19:37Z
UgyMmMFH6-UzTb5lRVp4AaABAg,@aabhash.01,,1,BunESRhYhec,0,0,2023-06-10T17:41:37Z,thumbs up emoji,2023-06-10T17:41:37Z
UgyOAJ2nupqggriQ4vV4AaABAg,@mishrr,,1,BunESRhYhec,0,0,2023-06-02T03:07:05Z,Thank you professor,2023-06-02T03:07:05Z
UgyX0ipgPAIS0KdfCIp4AaABAg,@hongbo-wei,,1,BunESRhYhec,0,1,2023-06-01T05:31:37Z,"Really glad to see Prof. Andrew and Isa, thank you both for bringing this course. I believe it will help me building a better carrer.",2023-06-01T05:31:37Z
Ugwea_TSomr-EDhON8B4AaABAg,@ahtashamilyas1572,,1,BunESRhYhec,0,0,2023-06-01T05:14:03Z,Should we need OpenAI subscription(for tokens) for this course?,2023-06-01T05:14:03Z
UgyaAJs6MtRiMIVqULl4AaABAg,@zouhirelmezraoui1336,,1,BunESRhYhec,0,0,2023-06-01T00:46:32Z,Thanks you,2023-06-01T00:46:32Z
Ugy76S_SXg5VbgRqprB4AaABAg,@zouhirelmezraoui1336,,1,BunESRhYhec,0,1,2023-06-01T00:45:44Z,Andrew is Doctor AIüíñüëÜüíñüéìüéìüéìüëâüëÜüëà,2023-06-01T00:45:44Z
UgzsPrA90_7L8Z1S6XV4AaABAg,@zouhirelmezraoui1336,,1,BunESRhYhec,0,0,2023-06-01T00:44:20Z,üíñüëÜüíñüéìüéìüéìüëâüëÜüëà,2023-06-01T00:44:20Z
UgyWv30IWXQjNSKCeuR4AaABAg,@jopadjr,,1,BunESRhYhec,0,0,2023-05-31T23:34:48Z,110th...Thanks Andrew and Isa!,2023-05-31T23:34:48Z
UgwivA783BtEpTlHHY54AaABAg,@HassanAli-tv6fc,,1,BunESRhYhec,0,0,2023-05-31T18:23:09Z,thanks alot,2023-05-31T18:23:09Z
UgwxsYifvMUuxPiVQFh4AaABAg,@LearningWorldChatGPT,,1,BunESRhYhec,0,0,2023-05-31T18:11:55Z,"Thank you very much DeepLearningAI <a href=""about:invalid#zCSafez""></a>!",2023-05-31T18:11:55Z
UgyLJh1DVDV4idJREyl4AaABAg,@chiragsharma9430,,1,BunESRhYhec,0,1,2023-05-31T16:39:00Z,Again thank you Andrew and Isa for bringing this course.,2023-05-31T16:39:00Z
UgzlmI786l9hyf8S5El4AaABAg,@surkewrasoul4711,,1,BunESRhYhec,0,0,2023-05-31T16:23:37Z,is Dr Andrew winking at he&#39;s viewers or is he just like that normally. Just curious.,2023-05-31T16:23:37Z
UgwEj_0gsYaoZlxWQ114AaABAg,@homesinlaguna,,1,BunESRhYhec,0,0,2023-05-31T16:19:52Z,Thank you for this,2023-05-31T16:19:52Z
Ugy67zRefdEYI3JypPZ4AaABAg,@tanvirmahtab5931,,1,jFo_gDOOusk,0,0,2023-10-15T20:16:43Z,Why is he talking like an AI,2023-10-15T20:16:43Z
Ugyo4s6a9K1XN3kSPZF4AaABAg,@habibmrad8116,,1,jFo_gDOOusk,0,2,2023-07-07T09:25:24Z,Andrew NG is one of the most powerful Hero in AI that put his signature over the next 100 years from now,2023-07-07T09:25:24Z
UgyBdYaNeMFnOKdnsVF4AaABAg,@deeplearningpartnership,,1,jFo_gDOOusk,0,1,2023-06-24T12:22:28Z,Cool.,2023-06-24T12:22:28Z
Ugz9kOehUhBAkGxkpdd4AaABAg,@UsmanKhan-tb7ll,,1,jFo_gDOOusk,0,3,2023-06-14T19:07:42Z,When will it be released ?<br>And where ?,2023-06-14T19:07:42Z
UgygKpwFpsWC5m4OH794AaABAg,@user-vg8hn3up1h,,1,jFo_gDOOusk,1,5,2023-06-01T12:53:32Z,"so, will you upload all the courses here? or just this one? since  your website there  is not chinese",2023-06-01T12:53:32Z
UgygKpwFpsWC5m4OH794AaABAg.9qQCl9jA0am9qlVVWy5ToN,@vinsonwong9282,UgygKpwFpsWC5m4OH794AaABAg,2,jFo_gDOOusk,0,0,2023-06-10T04:40:34Z,+1,2023-06-10T04:40:34Z
UgzowIiaJbGsxNbpOjZ4AaABAg,@zouhirelmezraoui1336,,1,jFo_gDOOusk,0,1,2023-06-01T00:43:02Z,Thanks you DoctorüíñüëÜüíñüéìüéìüéìüëâüëÜüëà,2023-06-01T00:43:02Z
Ugzth99hgSXwTgma3Rt4AaABAg,@TheSiddhartha2u,,1,obdVesVsGQI,0,0,2023-07-15T20:46:26Z,Thank You for this nice course. Why this course is not available in Coursera  ?,2023-07-15T20:47:05Z
Ugyqx8bzSfEjQHHhVIl4AaABAg,@tjeanneret,,1,obdVesVsGQI,0,0,2023-06-01T11:43:50Z,"Euh, √† votre avis, comment la chaleur du soleil nous parvient-elle ? Ne serait-ce pas par des rayons infrarouges, une &quot;lumi√®re&quot; que nous ne percevons pas directement par nos yeux ?",2023-06-01T11:43:50Z
UgzEOR801p8mAjEjhNl4AaABAg,@TECHNONEXUS,,1,obdVesVsGQI,0,14,2023-06-01T02:58:14Z,We all would like to have a whole specialization on Diffusion Model. Please create it.,2023-06-01T02:58:14Z
UgzqZgTffNYsKi0nYhR4AaABAg,@fgfanta,,1,obdVesVsGQI,0,0,2023-06-01T01:35:41Z,You are on a streak! Thank you!,2023-06-01T01:35:41Z
UgzTRm5GSHYOdMoB7qN4AaABAg,@zouhirelmezraoui1336,,1,obdVesVsGQI,0,0,2023-06-01T00:38:59Z,Good learning,2023-06-01T00:38:59Z
Ugw1c4uSsJWBZE7OODZ4AaABAg,@zouhirelmezraoui1336,,1,obdVesVsGQI,0,0,2023-06-01T00:38:20Z,Thanks you very very much,2023-06-01T00:38:20Z
UgwafOVfop48qW0EYX14AaABAg,@zouhirelmezraoui1336,,1,obdVesVsGQI,0,0,2023-06-01T00:37:15Z,üíñüëÜüíñüéìüéìüéìüëâüëÜüëàüî≠üî≠üî≠üåçüåçüåç‚õÖ‚õÖ‚õÖüíªüíªüíªüëäüëäüëäüå¥üå¥üå¥üêôüêôüêôüèÑüèÑüèÑ,2023-06-01T00:37:15Z
UgzcLtpJnz2gpIvlOUZ4AaABAg,@user-gi8yv4qh2h,,1,H4YK_7MAckk,0,0,2023-12-07T10:25:12Z,ADorable beauty with you‚ù§‚ù§‚ù§‚ù§‚ù§,2023-12-07T10:25:12Z
Ugyl2S8zsFPeM3t5mNR4AaABAg,@okoteteprogress3483,,1,H4YK_7MAckk,0,0,2023-11-29T13:26:10Z,"Hello, good day to you. I&#39;m currently following through on your course, its amazing. But am currently having some issues without any assistance currently. Pls i need your help",2023-11-29T13:26:10Z
UgwMV1U18P_U6hC3mJx4AaABAg,@teja11052,,1,H4YK_7MAckk,0,0,2023-10-23T02:13:17Z,This is only for learning or can also provide certificate after completing the course ?,2023-10-23T02:13:17Z
UgzsyPf_aachLOywLpZ4AaABAg,@vaishnavidesai4717,,1,H4YK_7MAckk,0,1,2023-09-27T09:47:15Z,"Hey i am grateful for the knowledge gained by u Andrew NG sir, but i dont know how to download certification of your prompt engineer course&#39;",2023-09-27T09:47:15Z
UgzDQX-gxCq9OdVl3fd4AaABAg,@MrJiazi,,1,H4YK_7MAckk,0,0,2023-09-19T09:36:20Z,"thank you so so much for putting it out for free ! we should have a community of folks that are leaning this - LMK if anyone is interested, so we could discuss &amp; exchange notes, ideas !",2023-09-19T09:36:20Z
UgzGijTGB0uVcca0aXh4AaABAg,@mr.digi.supporterr7708,,1,H4YK_7MAckk,0,0,2023-09-12T02:28:49Z,Sandeep maheshwari sir ki Jo bhi video dekh kar aya like karo‚ù§,2023-09-12T02:28:49Z
UgxB0Y6kj0X2jOuzsOV4AaABAg,@samdarshivikramsingh1766,,1,H4YK_7MAckk,0,0,2023-09-01T10:29:31Z,Can we get a certificate also for this course?,2023-09-01T10:29:31Z
UgwYsr5MJn4t932a6Cd4AaABAg,@ericschlosser2773,,1,H4YK_7MAckk,0,0,2023-08-29T20:58:08Z,"I really enjoyed this course and learned a lot, but when I tried running the code snippets from the lessons in a VSCode notebook it started having all kind of weird errors. At first things ran fine, then when I tried to enter chat responses into the text input box random keystrokes would trigger VSCode shortcuts (&#39;a&#39; would jump the cursor and open a new cell above the chat cell, etc...). Now it&#39;s telling me, &quot;TypeError: standalone_docs_json_and_render_items() takes 1 positional argument but 2 were given&quot; This only happens in VSCode; the code runs fine in Jupyter notebooks through Anaconda. I&#39;m thinking maybe Ipywidgets or panels doesn&#39;t play well with VSCode, but it&#39;s weird and I&#39;m wondering if anyone else has experienced something similar and found a workaround.",2023-08-29T20:58:08Z
UgzaxbfhYX4zdnChagp4AaABAg,@prashantlamba,,1,H4YK_7MAckk,0,1,2023-08-24T12:52:18Z,I have completed the course but I have no idea about developing. So can anyone please tell me how to use this course knowledge to create applications.,2023-08-24T12:52:18Z
UgzSCkQ32Y3xZGtSEEh4AaABAg,@syedjameelahmed66,,1,H4YK_7MAckk,0,0,2023-08-24T11:16:18Z,I have zero knowledge about coding and have never done programming.  Can this course help me build applications.,2023-08-24T11:16:18Z
UgzyhCv2AWHmDcRFL5V4AaABAg,@shivbhakhti,,1,H4YK_7MAckk,0,0,2023-08-05T04:59:21Z,This course doesn&#39;t provide certificate,2023-08-05T04:59:21Z
UgylTlKtC5DjAsEGtEh4AaABAg,@saylithakur4786,,1,H4YK_7MAckk,0,0,2023-07-29T04:46:38Z,Anyone here after SM&#39;s video,2023-07-29T04:46:38Z
Ugy0pOhdM8T0AsuYEK94AaABAg,@Eater_Beater,,1,H4YK_7MAckk,0,0,2023-07-28T03:52:01Z,Is it only for developers?,2023-07-28T03:52:01Z
UgzDA1QubYa83h3sYpV4AaABAg,@ankanpradhan854,,1,H4YK_7MAckk,0,0,2023-07-26T19:25:44Z,Provide any certificate?,2023-07-26T19:25:44Z
UgxLOvqGGdid9dWvPzd4AaABAg,@bharatiyagyan6500,,1,H4YK_7MAckk,0,1,2023-07-19T16:25:02Z,I have come here after watching Sandeep Maheshwari video.,2023-07-19T16:25:02Z
UgwEKmNDkbFR4pa7qqZ4AaABAg,@dubbingtadka5055,,1,H4YK_7MAckk,0,6,2023-07-18T08:50:00Z,Kon kon sandeep maheshwari k show k baad yaha aya h ‚û°Ô∏èüñêÔ∏è,2023-07-18T08:50:00Z
UgzQni_u62AqTk5PUsZ4AaABAg,@Abhishek_yadavw,,1,H4YK_7MAckk,1,2,2023-07-18T07:35:12Z,Who is here after watching Sandeep Maheshwariüéâ,2023-07-18T07:35:12Z
UgzQni_u62AqTk5PUsZ4AaABAg.9sIeggK-1dU9spVjAAUpnA,@movieclipsshortfilm3765,UgzQni_u62AqTk5PUsZ4AaABAg,2,H4YK_7MAckk,0,0,2023-07-31T11:02:19Z,Me,2023-07-31T11:02:19Z
Ugx1afeCJ-ZHehymTRB4AaABAg,@souravshil7507,,1,H4YK_7MAckk,0,0,2023-07-18T04:15:22Z,Thank you ‚ù§‚ù§‚ù§,2023-07-18T04:15:22Z
Ugyd4dhQUCXGzQJn4-F4AaABAg,@sarthaksingla_,,1,H4YK_7MAckk,1,5,2023-07-17T18:59:52Z,Kon kon Sandeep mashwari ki video dekh k aya hai yha pa?,2023-07-17T18:59:52Z
Ugyd4dhQUCXGzQJn4-F4AaABAg.9sHJFYJYHxU9sICcQm2VlH,@merapunjabanimation,Ugyd4dhQUCXGzQJn4-F4AaABAg,2,H4YK_7MAckk,0,0,2023-07-18T03:21:12Z,Me,2023-07-18T03:21:12Z
Ugyea4vvHTRq6CcyKwR4AaABAg,@jeetshah6554,,1,H4YK_7MAckk,0,1,2023-07-17T18:01:48Z,Who is here from Sandeep Maheshwari video?,2023-07-17T18:01:48Z
UgwZr47XSuXFjWJrnr14AaABAg,@surajlohar8753,,1,H4YK_7MAckk,0,0,2023-07-17T16:12:33Z,Love from üá≥üáµ,2023-07-17T16:12:33Z
Ugw-3_GVMIsf5MWUfSF4AaABAg,@shemkipruto4394,,1,H4YK_7MAckk,0,0,2023-07-10T17:03:43Z,He is talking in low tones like its a secret he is sharing,2023-07-10T17:03:43Z
UgwJqQDngqF9_XqqRrJ4AaABAg,@promptrevolution,,1,H4YK_7MAckk,0,0,2023-07-05T07:23:27Z,nice üëç,2023-07-05T07:23:27Z
UgxxSOKHo9tmT1FnOM94AaABAg,@migueldlima4005,,1,H4YK_7MAckk,0,0,2023-07-03T23:17:13Z,Is there any way to translate to Spanish audio this course ? It‚Äôs interesting but very technical for me.  I‚Äôm trying to learn how to use it in my area,2023-07-03T23:17:13Z
UgysIwJIZUtK4jEn6yR4AaABAg,@moularaoul643,,1,H4YK_7MAckk,0,1,2023-06-30T19:54:27Z,Thank you so much!,2023-06-30T19:54:27Z
UgzDy4QnhYKHzXZLZZZ4AaABAg,@webbot1083,,1,H4YK_7MAckk,0,0,2023-06-29T03:24:24Z,"I&#39;m not a developer, but I keep coming back to watch this vid, because the female in the vid (Isa) is mesmerizing to me! She is maybe the most beautiful woman I think I&#39;ve ever seen. I know she is super-intelligent, but her beauty has me captivated. Wow!!!",2023-06-29T03:24:24Z
Ugwj_I7LKNLHL1c6jyZ4AaABAg,@hernanduquelsky3007,,1,H4YK_7MAckk,0,1,2023-06-27T20:25:46Z,"it&#39;s a pity they don&#39;t put the videos here on youtube, the transcription doesn&#39;t let you follow the course fluently and understand it well.",2023-06-27T20:25:46Z
UgyWiVxMGf8tr6aQndh4AaABAg,@jean-michelbendaci2564,,1,H4YK_7MAckk,0,0,2023-06-24T20:11:05Z,Hello Andrew GN FF Le√≠ followed,2023-06-24T20:11:05Z
UgyUCuUbn45jlVYKu5B4AaABAg,@jean-michelbendaci2564,,1,H4YK_7MAckk,0,0,2023-06-12T17:28:09Z,Sexual harassment on LinkedIn.,2023-06-12T17:28:09Z
UgyA8S4gdoaAiRmIO2h4AaABAg,@muhammadidrees42,,1,H4YK_7MAckk,0,0,2023-06-03T09:37:49Z,When I click &#39;Learn for free&#39; the page never opens!,2023-06-03T09:37:49Z
Ugw-Gumj0CX2IuyE3op4AaABAg,@mishrr,,1,H4YK_7MAckk,0,0,2023-06-02T03:06:33Z,You are the best Professor.,2023-06-02T03:06:33Z
UgxUob-USIAuc1SGAmx4AaABAg,@jeffclark9477,,1,H4YK_7MAckk,0,0,2023-06-02T00:08:41Z,I love isa,2023-06-02T00:08:41Z
Ugz1fQ8LVpcl4ndKtMd4AaABAg,@Jirayu.Kaewprateep,,1,H4YK_7MAckk,0,0,2023-05-24T16:48:44Z,"üì∫üí¨ We can build text output by expanding text input and transforming it,  language models, and prompting.<br>ü•∫üí¨ In some applications before language models apply to create words or sentences Grammarly, it interferes with an updated word or remark that is different from the pre-created language model but that will be nice if the new word is automatically sorted by favorite and updated language model at the same time use it.<br>ü•∫üí¨ I think more than use with prompting when input is data it can create of target mapping format date sample 4 bits data to 8 bits for packages types and other applications do not limits to only prompting in text or voice.<br>ü•∫üí¨ I took one of the course and now I am waiting for myself ready to take another course that is interesting for me.",2023-05-24T16:49:33Z
UgxYJ1p4awaGUiPAxQx4AaABAg,@massa100,,1,H4YK_7MAckk,1,4,2023-05-23T01:59:35Z,"Thanks to you both! Expertise at best and not those other fancy YouTubers with clickbaits‚Ä¶ I‚Äôve joined the course, well done !",2023-05-23T01:59:35Z
UgxYJ1p4awaGUiPAxQx4AaABAg.9q1rlas_egw9sIsq8QUXko,@layeksandeep,UgxYJ1p4awaGUiPAxQx4AaABAg,2,H4YK_7MAckk,0,0,2023-07-18T09:38:48Z,Bro in course they are teaching from some others platforms why not CHATGPT/ Google bard ? Can I use there example in CHATGPT,2023-07-18T09:38:48Z
UgyzGuOzuSBrZFGJLmZ4AaABAg,@user-gb2oi1ic1p,,1,H4YK_7MAckk,0,0,2023-05-22T17:43:17Z,Where can I find the course pls?,2023-05-22T17:43:17Z
Ugz_Kh3IuvN4L_JRnlF4AaABAg,@nothing9259,,1,H4YK_7MAckk,0,0,2023-05-20T06:21:15Z,All money making schemes. No knowledge.,2023-05-20T06:21:15Z
UgyfHHfZf88kVKTrihd4AaABAg,@vamangori5635,,1,H4YK_7MAckk,2,0,2023-05-18T14:52:33Z,Its a high quality course and im glad that i have this opportunity to learn it from the experts <br>But i only have one query<br>I didn&#39;t get certificate for the compilation of the course is there any ?? <br>If it isn&#39;t can you please provide it <br>Im very heartful for that if you give me certificate for that <br>Thank you,2023-05-18T14:52:33Z
UgyfHHfZf88kVKTrihd4AaABAg.9prNFdGXSBD9sjpasrluzM,@se_a_53_sahilkhane9,UgyfHHfZf88kVKTrihd4AaABAg,2,H4YK_7MAckk,0,0,2023-07-29T06:09:15Z,Heyy... I am also having same query do you get certificate or not...,2023-07-29T06:09:15Z
UgyfHHfZf88kVKTrihd4AaABAg.9prNFdGXSBD9tnVmYj7ced,@prashantlamba,UgyfHHfZf88kVKTrihd4AaABAg,2,H4YK_7MAckk,0,0,2023-08-24T12:55:42Z,I have completed the course but I have no idea about developing. So can anyone please tell me how to use this course knowledge to create applications.,2023-08-24T12:55:42Z
UgyTfSrccfojODMtqlh4AaABAg,@YourWayOut101,,1,H4YK_7MAckk,0,0,2023-05-18T00:52:22Z,I thought this is the course.,2023-05-18T00:52:22Z
Ugw9Rdv91bVOpW6mC3F4AaABAg,@AdlejandroP,,1,H4YK_7MAckk,0,0,2023-05-16T15:24:54Z,I feel all the answers where made with chat gpt,2023-05-16T15:24:54Z
UgxIv4IaU_eoSW7Fh6V4AaABAg,@digigoliath,,1,H4YK_7MAckk,0,1,2023-05-15T07:21:10Z,‚ù§‚ù§ wonderful,2023-05-15T07:21:10Z
UgyeYnlmqG8XEfPKBKZ4AaABAg,@ChinaFeastStream,,1,H4YK_7MAckk,0,1,2023-05-13T14:15:28Z,"Great Course! Thanks, Andrew",2023-05-13T14:15:28Z
UgyYAp7cImqDv2IzTJh4AaABAg,@unpolish,,1,H4YK_7MAckk,0,1,2023-05-12T11:01:27Z,Doing it right now! Thanks for the opportunity!,2023-05-12T11:01:27Z
UgxJsr3WHv41338fXx54AaABAg,@thanhquachable,,1,H4YK_7MAckk,4,3,2023-05-11T10:46:53Z,"I just finished this course, high-quality and practical materials, highly recommended ‚ù§",2023-05-11T10:46:53Z
UgxJsr3WHv41338fXx54AaABAg.9pZu_7pt1v59p_RZ-gK2ae,@korinadavila8346,UgxJsr3WHv41338fXx54AaABAg,2,H4YK_7MAckk,0,0,2023-05-11T15:43:49Z,Donde lo viste??? Pasas el link,2023-05-11T15:43:49Z
UgxJsr3WHv41338fXx54AaABAg.9pZu_7pt1v59t1Rg1vOn-q,@SYETC200_SuyashSingh,UgxJsr3WHv41338fXx54AaABAg,2,H4YK_7MAckk,0,1,2023-08-05T11:37:04Z,did u get certificate,2023-08-05T11:37:04Z
UgxJsr3WHv41338fXx54AaABAg.9pZu_7pt1v59t1SwMYKwXX,@thanhquachable,UgxJsr3WHv41338fXx54AaABAg,2,H4YK_7MAckk,0,1,2023-08-05T11:48:02Z,"@@SYETC200_SuyashSingh no I couldn&#39;t care less about getting a certificate, I am too busy applying what I learn and building my app to get a certificate (which is not worth much in the market).üòÇ",2023-08-05T11:48:02Z
UgxJsr3WHv41338fXx54AaABAg.9pZu_7pt1v59tnVbY51SBz,@prashantlamba,UgxJsr3WHv41338fXx54AaABAg,2,H4YK_7MAckk,0,1,2023-08-24T12:54:11Z,I have completed the course but I have no idea about developing. So can anyone please tell me how to use this course knowledge to create applications.,2023-08-24T12:54:11Z
UgyRSFH3Qz7PNDpiXeB4AaABAg,@Yagyaansh,,1,g7dv-Lnuor4,0,0,2023-05-19T13:34:59Z,There is a need for Ng to upgrade his mic. The voice is so high treble,2023-05-19T13:34:59Z
UgxDG-L9fbQ0-YRF0TB4AaABAg,@SaffatUllah,,1,g7dv-Lnuor4,0,2,2023-05-13T19:36:27Z,"I‚Äôm a complete beginner in this field, but AI really excites me. I know Professor Ng says that this is a beginner friendly program, but to anyone who has done this course or is currently doing it: do you think it‚Äôs easy enough for a complete noob?",2023-05-13T19:36:27Z
Ugzvud0xgxQtc7_khz54AaABAg,@MilciadesAndrion,,1,g7dv-Lnuor4,0,0,2023-05-06T04:42:56Z,"I previously took a course with you and found it to be very inspiring. The course allowed me to learn about concepts that were previously unknown to me, and I appreciate you sharing your knowledge. Thank you for the opportunity to learn and grow under your instruction.",2023-05-06T04:42:56Z
UgxgwuHUvlt09UNrhRB4AaABAg,@TheAero,,1,g7dv-Lnuor4,0,0,2023-04-25T07:40:21Z,I am working on finishing all the AI related specilizations from DeepLearningAI. Feel I can build all around skills on different topics as well as get certified and make a portfolio through the assignments.,2023-04-25T07:40:21Z
UgxbCOLAzDC8TMa6fVN4AaABAg,@aycone7230,,1,g7dv-Lnuor4,0,0,2023-04-05T09:46:23Z,"i would like to enroll to original course, where can i find it? I don&#39;t mind more math.",2023-04-05T09:47:17Z
UgzPc7HEcO7YQM4ULEt4AaABAg,@mathman1475,,1,g7dv-Lnuor4,0,1,2023-03-19T13:29:47Z,I took the previous version and enjoyed the math portion.  I hope they kept optional  modules for the math portions.,2023-03-19T13:29:47Z
Ugwtpn3mf7mfybVEhLx4AaABAg,@neoblackcyptron,,1,g7dv-Lnuor4,0,4,2023-03-18T16:29:39Z,"Prof.Andrew&#39;s course on Machine Learning which I took back in 2018, inspired and changed my life, thanks to that, today I am finishing a degree in Robotics, and AI,  using machine learning with computer vision on a robotics project. All this was possible only because i took his course back in 2018 which transformed my life.",2023-03-18T16:29:39Z
Ugz6hxLHHqBHzq72meB4AaABAg,@yaartera1062,,1,g7dv-Lnuor4,0,1,2023-03-16T23:52:21Z,course 3 of your specialization &#39;mathematics for machine learning and data science&#39; does not have any content to access.,2023-03-16T23:52:21Z
UgyzM99AMoCGKMFbDsB4AaABAg,@roadto200million,,1,g7dv-Lnuor4,0,1,2023-03-14T13:06:37Z,"So when you go to Coursera there is a button Enroll for free, but when you click it it asks to start a 7 day trial and after that you need to pay $49 per month. Is this a free or paid course and is there any way to access it for free, at least lectures if not assignments.",2023-03-14T13:06:37Z
UgzAOEBC27_cMk9MOeJ4AaABAg,@brand_blitz,,1,g7dv-Lnuor4,0,1,2023-03-14T07:44:13Z,The course I absolutely recommend everyone who are into machine learning,2023-03-14T07:44:13Z
UgywKXWtpGq_ZHAmD3V4AaABAg,@hecnehecneyev470,,1,g7dv-Lnuor4,0,0,2023-03-11T20:02:29Z,It would be better if it was free. I am asked for card information.,2023-03-11T20:02:29Z
Ugwz1A0WrWnatw4MsVJ4AaABAg,@MrBemnet1,,1,g7dv-Lnuor4,0,1,2023-03-11T16:57:59Z,"You will be disappointed when you find out ML code is tiny part of ML system. Unless you find your self in a mature organization that have data engineers  ,software engineers ,devops people you would you can&#39;t see fruits of your your model.",2023-03-11T16:58:16Z
UgyJ3Jy0lqvspJF81uh4AaABAg,@brianaichlmayr,,1,g7dv-Lnuor4,0,7,2023-03-11T14:22:34Z,"The math sections kicked my butt and I was not able to complete this course originally, I am happy it has been reevaluated and will look towards taking this course again!",2023-03-11T14:22:34Z
UgyLf4QjZAQHX-RL5lB4AaABAg,@mykun8737,,1,g7dv-Lnuor4,3,1,2023-03-11T05:22:45Z,Could you please remake the specialization  deep learning?,2023-03-11T05:22:45Z
UgyLf4QjZAQHX-RL5lB4AaABAg.9n6FzjzxDGn9nN0QeIutD1,@commencater,UgyLf4QjZAQHX-RL5lB4AaABAg,2,g7dv-Lnuor4,0,0,2023-03-17T17:33:49Z,When did you did this specialization? In the website it&#39;s written they updated it on April 2021.,2023-03-17T17:33:49Z
UgyLf4QjZAQHX-RL5lB4AaABAg.9n6FzjzxDGn9nN3dNgs9FJ,@mykun8737,UgyLf4QjZAQHX-RL5lB4AaABAg,2,g7dv-Lnuor4,0,0,2023-03-17T18:01:55Z,"@@commencater the course is too old, it&#39;s been released for almost 10 years",2023-03-17T18:01:55Z
UgyLf4QjZAQHX-RL5lB4AaABAg.9n6FzjzxDGn9nNxwRju_0N,@commencater,UgyLf4QjZAQHX-RL5lB4AaABAg,2,g7dv-Lnuor4,0,0,2023-03-18T02:22:35Z,"@@mykun8737 Okay. I haven&#39;t done it, but in their website they says they updated it with including Python lessons.",2023-03-18T02:23:05Z
UgyvpZaOSXfE7SH5Fgd4AaABAg,@hongbo-wei,,1,g7dv-Lnuor4,1,10,2023-03-10T14:23:07Z,"Thank you, Prof. Andrew. I&#39;ve completed the first two parts of the specialization. Now I&#39;m doing the third part. I&#39;ll keep learning, and I hope I can be an AI engineer within a few years.",2023-03-10T14:23:07Z
UgyvpZaOSXfE7SH5Fgd4AaABAg.9n4e1d66D6H9nFQJdbH9Ts,@wafflecat711,UgyvpZaOSXfE7SH5Fgd4AaABAg,2,g7dv-Lnuor4,0,1,2023-03-14T18:46:08Z,"We can start the course at anytime, right?",2023-03-14T18:46:08Z
Ugz0NdIpWvwkQR1QRB94AaABAg,@waitwhat9669,,1,g7dv-Lnuor4,0,1,2023-03-10T09:07:47Z,is it free?,2023-03-10T09:07:47Z
Ugww3p8mfKSddm0Pejl4AaABAg,@jorgeabraham3414,,1,g7dv-Lnuor4,3,3,2023-03-10T01:38:51Z,"I took the Specialization and is really great content. It is really a total upgrade over the old ML course and even over the DL specialization,  I say it in terms of production of course, the DL Spec deserves a full re work or update, because the video quality sucks... in this ML specialization everything is shiny and visually engaging, I hope the DL Spec receives the same treatment",2023-03-10T01:38:51Z
Ugww3p8mfKSddm0Pejl4AaABAg.9n3H_1rOVS_9nN0W45MEn9,@commencater,Ugww3p8mfKSddm0Pejl4AaABAg,2,g7dv-Lnuor4,0,0,2023-03-17T17:34:34Z,When did you do this specialization? In the website it&#39;s written they updated it on April 2021.,2023-03-17T17:34:34Z
Ugww3p8mfKSddm0Pejl4AaABAg.9n3H_1rOVS_9nN4Z6nJDC5,@jorgeabraham3414,Ugww3p8mfKSddm0Pejl4AaABAg,2,g7dv-Lnuor4,0,0,2023-03-17T18:09:56Z,"@@commencater The ML one? I just finished a couple of months ago and I just started the DL, I&#39;m just in the first course",2023-03-17T18:09:56Z
Ugww3p8mfKSddm0Pejl4AaABAg.9n3H_1rOVS_9nNxlCPPzdZ,@commencater,Ugww3p8mfKSddm0Pejl4AaABAg,2,g7dv-Lnuor4,0,0,2023-03-18T02:21:03Z,@@jorgeabraham3414 DL. I wish to attend it in future. They last updated it in 2021 as per website.,2023-03-18T02:21:03Z
UgxdP8GurKqecy6lMXx4AaABAg,@TheHomeAlone66,,1,g7dv-Lnuor4,0,5,2023-03-09T19:13:19Z,Thank you for your dedications on helping the people take stairs professor.,2023-03-09T19:13:19Z
UgyQ1dL2_pZscjSKNId4AaABAg,@abdulwahabkhan1086,,1,g7dv-Lnuor4,2,40,2023-03-09T13:45:18Z,I completed this specialization 3 months ago. I can not express enough how beautiful this specialization is. I would totally recommend it.,2023-03-09T13:45:18Z
UgyQ1dL2_pZscjSKNId4AaABAg.9n2-usih3ea9yOo_FkRXOu,@syedarrafi4213,UgyQ1dL2_pZscjSKNId4AaABAg,2,g7dv-Lnuor4,0,0,2023-12-16T20:05:21Z,Can you apply for jobs after finishing this course? I mean does the course offer that much learning?,2023-12-16T20:05:21Z
UgyQ1dL2_pZscjSKNId4AaABAg.9n2-usih3ea9yOvbohiWfR,@abdulwahabkhan1086,UgyQ1dL2_pZscjSKNId4AaABAg,2,g7dv-Lnuor4,0,1,2023-12-16T21:06:52Z,"@syedarrafi4213¬†Not at all. The courses are meant to give fundamental knowledge. Job acquisition depends on the practical skillset. But if you want to get started, this ML Specialization is top-notch, and I highly recommend it.",2023-12-16T21:06:52Z
UgxyArFGeFNxQHD4L_J4AaABAg,@adityarajora7219,,1,g7dv-Lnuor4,7,3,2023-03-09T05:02:10Z,Do MS first..else there are no jobs.,2023-03-09T05:02:10Z
UgxyArFGeFNxQHD4L_J4AaABAg.9n142JtsQfP9nO9nRgDzyc,@rashedulkabir6227,UgxyArFGeFNxQHD4L_J4AaABAg,2,g7dv-Lnuor4,0,0,2023-03-18T04:14:57Z,Many people with no MS have their software engineering jobs.,2023-03-18T04:14:57Z
UgxyArFGeFNxQHD4L_J4AaABAg.9n142JtsQfP9nR_5v-F5E5,@adityarajora7219,UgxyArFGeFNxQHD4L_J4AaABAg,2,g7dv-Lnuor4,0,1,2023-03-19T12:02:32Z,"@@rashedulkabir6227 Yeah, But no ML jobs.",2023-03-19T12:02:32Z
UgxyArFGeFNxQHD4L_J4AaABAg.9n142JtsQfP9nvZVEOpxAy,@Ai-Future,UgxyArFGeFNxQHD4L_J4AaABAg,2,g7dv-Lnuor4,0,0,2023-03-31T12:53:42Z,@@adityarajora7219 what is the cause of jobs shortage?,2023-03-31T12:53:42Z
UgxyArFGeFNxQHD4L_J4AaABAg.9n142JtsQfP9nvyr0qyrO7,@adityarajora7219,UgxyArFGeFNxQHD4L_J4AaABAg,2,g7dv-Lnuor4,0,0,2023-03-31T16:44:00Z,"@@Ai-Future no job shortage, this field just requires higher studies!",2023-03-31T16:44:00Z
UgxyArFGeFNxQHD4L_J4AaABAg.9n142JtsQfP9r5-sWQFq0R,@fintech1378,UgxyArFGeFNxQHD4L_J4AaABAg,2,g7dv-Lnuor4,0,0,2023-06-18T03:48:17Z,Master?,2023-06-18T03:48:17Z
UgydrRcE1E5FXoS-vlF4AaABAg,@eni4ever,,1,g7dv-Lnuor4,0,2,2023-03-09T00:46:57Z,Andrew is IMMORTAL! Q.E.D.,2023-03-09T00:46:57Z
Ugx4OemJUD2BmJQuVbF4AaABAg,@ostensibly531,,1,g7dv-Lnuor4,3,20,2023-03-08T23:32:37Z,Hadn&#39;t this existed for YEARS on Coursera?,2023-03-08T23:32:37Z
Ugx4OemJUD2BmJQuVbF4AaABAg.9n0UKXzFKvs9n0xLhp4alO,@madhavgupta4490,Ugx4OemJUD2BmJQuVbF4AaABAg,2,g7dv-Lnuor4,0,1,2023-03-09T03:54:54Z,It did,2023-03-09T03:54:54Z
Ugx4OemJUD2BmJQuVbF4AaABAg.9n0UKXzFKvs9n1oyBj7NBX,@rohithpokala,Ugx4OemJUD2BmJQuVbF4AaABAg,2,g7dv-Lnuor4,0,6,2023-03-09T12:00:54Z,No. This is new. It is based on python. But is created in 2022,2023-03-09T12:00:54Z
Ugx4OemJUD2BmJQuVbF4AaABAg.9n0UKXzFKvs9nb-ibOF0u5,@subirdas0,Ugx4OemJUD2BmJQuVbF4AaABAg,2,g7dv-Lnuor4,0,0,2023-03-23T13:16:17Z,More visuals to aid maybe? Larger audience it seems.,2023-03-23T13:16:17Z
UgyLjsXQJFFk1seYqmZ4AaABAg,@omsingh4319,,1,g7dv-Lnuor4,0,1,2023-03-08T20:35:54Z,Excellent,2023-03-08T20:35:54Z
UgwS383hpwZszhRVwxl4AaABAg,@rameshkumaran,,1,g7dv-Lnuor4,0,2,2023-03-08T18:44:59Z,Brilliant.. Excellent.. Fantastic.. Superb.. to bring an already awesome course with less math seasoning..,2023-03-08T18:44:59Z
UgzKAQWZ7gNrAnKW4Xh4AaABAg,@jhogrute,,1,g7dv-Lnuor4,0,3,2023-03-08T17:52:04Z,he was amazing in ip man,2023-03-08T17:52:04Z
UgxWPafhtDXPOO4dhZt4AaABAg,@NoNTr1v1aL,,1,g7dv-Lnuor4,0,2,2023-03-08T17:35:59Z,Absolutely amazing!,2023-03-08T17:35:59Z
Ugyx3q3syzKvZkaZoP54AaABAg,@abdielerosadosanchez1256,,1,g7dv-Lnuor4,1,3,2023-03-08T17:07:54Z,"Wait, I&#39;m currently doing the machine learning specialization in Coursera. I have completed two courses and am nearly done with the third. Is this the same thing?",2023-03-08T17:07:54Z
Ugyx3q3syzKvZkaZoP54AaABAg.9n-nIs-WlCX9n1VChHmy3R,@rajavelks6861,Ugyx3q3syzKvZkaZoP54AaABAg,2,g7dv-Lnuor4,0,0,2023-03-09T08:59:31Z,Yes,2023-03-09T08:59:31Z
Ugw-BKff-qVX0btXAXB4AaABAg,@viewview6687,,1,g7dv-Lnuor4,0,1,2023-03-08T17:04:29Z,You are my best teacher !!!,2023-03-08T17:04:29Z
UgzVbuDmTrVlLTAnHKl4AaABAg,@kitulinokitulino3360,,1,g7dv-Lnuor4,0,1,2023-03-08T16:54:40Z,Amazing üôÇ,2023-03-08T16:54:40Z
Ugxh5_LfQimN-JPFhXt4AaABAg,@gacem213,,1,g7dv-Lnuor4,8,13,2022-06-17T00:48:34Z,"I would have hoped it was free like the previous one, as someone from a developing country I cannot afford this, unfortunately. However, this course looks really exciting!",2022-06-17T00:48:34Z
Ugxh5_LfQimN-JPFhXt4AaABAg.9cMGN-mmrbN9j7PLDdHN1D,@Sk-pl5zo,Ugxh5_LfQimN-JPFhXt4AaABAg,2,g7dv-Lnuor4,0,0,2022-12-02T05:58:07Z,can you please enlighten me on where I can find his previous course that you were talking about?,2022-12-02T05:58:07Z
Ugxh5_LfQimN-JPFhXt4AaABAg.9cMGN-mmrbN9l_euBK3e7R,@dunno418,Ugxh5_LfQimN-JPFhXt4AaABAg,2,g7dv-Lnuor4,0,9,2023-02-01T07:43:36Z,"you can, coursera has option provide financial aid(100% free), also you can still access to the lectures but not assignments",2023-02-01T07:43:36Z
Ugxh5_LfQimN-JPFhXt4AaABAg.9cMGN-mmrbN9laeeEQKe4A,@gacem213,Ugxh5_LfQimN-JPFhXt4AaABAg,2,g7dv-Lnuor4,0,2,2023-02-01T17:00:40Z,"@@dunno418 thank you very much, I have since discovered the audit functionality üòÜ",2023-02-01T17:00:40Z
Ugxh5_LfQimN-JPFhXt4AaABAg.9cMGN-mmrbN9laf9aA1Uhd,@dunno418,Ugxh5_LfQimN-JPFhXt4AaABAg,2,g7dv-Lnuor4,0,1,2023-02-01T17:05:05Z,@@gacem213 yay!,2023-02-01T17:05:05Z
Ugxh5_LfQimN-JPFhXt4AaABAg.9cMGN-mmrbN9n-p-7AuLBk,@niazhimselfangels,Ugxh5_LfQimN-JPFhXt4AaABAg,2,g7dv-Lnuor4,0,1,2023-03-08T17:22:41Z,Please try applying for financial aid. Before I had my first job Coursera was generous enough to provide financial aid and certifications for which I&#39;m forever thankful to them!,2023-03-08T17:22:41Z
UgzYYqj1NSG19uB8cJp4AaABAg,@LuisBotteri,,1,rt0uNjjBya4,0,0,2023-09-26T04:50:11Z,"Does anyone know if I need to know Python to take these classes? I mean, I don&#39;t know if the examples require having access to the program or using somehow this programming language.",2023-09-26T04:50:11Z
UgwHZiitCcJJKTsULLt4AaABAg,@ryan-tabar,,1,rt0uNjjBya4,0,1,2023-08-07T01:54:53Z,Currently doing this course! It‚Äôs a lot of fun!,2023-08-07T01:54:53Z
UgzgzbNaw0QQpuRn5dp4AaABAg,@shabazgaming3541,,1,rt0uNjjBya4,2,0,2023-05-14T06:29:04Z,Koi iska assignment bhej dey solve krke plz ü•∫ü•∫,2023-05-14T06:29:04Z
UgzgzbNaw0QQpuRn5dp4AaABAg.9pgASVeCl099uRxtmYMP_C,@user-mj5lj5lu8z,UgzgzbNaw0QQpuRn5dp4AaABAg,2,rt0uNjjBya4,0,0,2023-09-09T15:18:57Z,"thoda mehnat karle , bhai!",2023-09-09T15:18:57Z
UgzgzbNaw0QQpuRn5dp4AaABAg.9pgASVeCl099yYsrq8e70x,@AnkanNayak-qz7cx,UgzgzbNaw0QQpuRn5dp4AaABAg,2,rt0uNjjBya4,0,0,2023-12-20T17:55:15Z,"@@user-mj5lj5lu8z vai mene paisa deke nahi liya , only watching and learning from video , can you provide the lock ones (labs), can we connect if possible",2023-12-20T17:55:32Z
UgzpdlgA1L0hs_tqPbF4AaABAg,@dongan5046,,1,rt0uNjjBya4,3,0,2023-03-24T03:08:15Z,I am waiting to start the third one.,2023-03-24T03:08:15Z
UgzpdlgA1L0hs_tqPbF4AaABAg.9ncUw3z6Toc9om4Nh0tMUw,@Unknown-ey4yh,UgzpdlgA1L0hs_tqPbF4AaABAg,2,rt0uNjjBya4,0,0,2023-04-21T17:00:01Z,When it will come?,2023-04-21T17:00:01Z
UgzpdlgA1L0hs_tqPbF4AaABAg.9ncUw3z6Toc9orGstTQiCv,@mht-cetmaths3630,UgzpdlgA1L0hs_tqPbF4AaABAg,2,rt0uNjjBya4,0,0,2023-04-23T17:25:29Z,"me too, any updates???",2023-04-23T17:25:29Z
UgzpdlgA1L0hs_tqPbF4AaABAg.9ncUw3z6Toc9os499wvxkF,@dongan5046,UgzpdlgA1L0hs_tqPbF4AaABAg,2,rt0uNjjBya4,0,1,2023-04-24T00:53:29Z,I don‚Äôt know. It just keeps delaying.,2023-04-24T00:53:29Z
UgxhEoFZ7KlmTYFRXQ14AaABAg,@jorgebetancourt2610,,1,rt0uNjjBya4,0,5,2023-02-02T06:54:44Z,I‚Äôm enrolled in the course in coursera. Very good math refresher.,2023-02-02T06:54:44Z
Ugy-OqyyKW_yd2-Ug9t4AaABAg,@iam_mausam,,1,rt0uNjjBya4,0,3,2023-02-01T05:36:06Z,magic happens ü§©,2023-02-01T05:36:06Z
UgzBhS87LM9yrbZu0yp4AaABAg,@ibnaaburaed,,1,rt0uNjjBya4,0,8,2023-01-31T16:40:00Z,Thank you <br><br>I have gone through some chapters of Luis‚Äôs  book in Machine Learning .. I found it very useful and easy to grisp by the methods Luis applied and his clear presentation. Thus I believe this course will be very useful as well ‚Ä¶,2023-01-31T16:40:00Z
UgzgzRFimPioKJ7yqXx4AaABAg,@shravan6457,,1,rt0uNjjBya4,0,6,2023-01-25T21:50:18Z,It is exciting to see the excitement in Luis üòä. Thank you so much Luis ‚ù§,2023-01-25T21:50:18Z
Ugwm6serKJwfjEu0U054AaABAg,@RajdeepBorgohainRajdeep,,1,rt0uNjjBya4,0,6,2023-01-25T19:26:03Z,One of the best person to learn from Luis Serrano,2023-01-25T19:26:03Z
UgwOwzOWaBXNhbyiZDp4AaABAg,@goutamgarai6632,,1,rt0uNjjBya4,0,10,2023-01-25T06:52:27Z,I was waiting for this courseüòÄ,2023-01-25T06:52:27Z
UgzzQIY-7YSztjGeSM94AaABAg,@VenkatesanVenkat-fd4hg,,1,Z5HurHL2fWc,0,1,2023-12-13T14:37:04Z,"Superr, will take this valuable course...",2023-12-13T14:37:04Z
UgyCNdJdMgf1Lw3wbHx4AaABAg,@yasminahamdi1686,,1,vStJoetOxJg,0,1,2023-08-24T15:19:17Z,there is no voice at all,2023-08-24T15:19:17Z
UgyHivru1-dEaZD800h4AaABAg,@ST-hw2ud,,1,vStJoetOxJg,0,1,2023-08-03T16:03:54Z,"M i the only one witnessing too much noise (I mean actual radio noise) in all of his videos, how do you guys make sense of it? <br><br>It&#39;s not my speaker, I have tried 3 different ones, all the other vids on YouTube are great in sound, only these, maybe some help anyone?",2023-08-03T16:03:54Z
UgxxwV8-JYam27VEsut4AaABAg,@km7530,,1,vStJoetOxJg,0,1,2023-07-31T18:18:58Z,‚ÄòTurn that mf music off!!‚Äô I heard someone say ü§∑‚Äç‚ôÇÔ∏è,2023-07-31T18:18:58Z
UgweWqQO6RPFwuNlQDN4AaABAg,@khushbirsinghyadav,,1,vStJoetOxJg,0,10,2023-07-18T11:57:06Z,Thank you IP man!,2023-07-18T11:57:06Z
UgzbAx-Wyc227wcl0KF4AaABAg,@sohailshabir9797,,1,vStJoetOxJg,1,4,2023-07-18T06:27:11Z,Who came here from sandeep sir vedio¬ø,2023-07-18T06:32:59Z
UgzbAx-Wyc227wcl0KF4AaABAg.9sIXucBITiV9tYt5wOHFoi,@arthurc.d.8040,UgzbAx-Wyc227wcl0KF4AaABAg,2,vStJoetOxJg,0,0,2023-08-18T11:20:20Z,Konsa video me bataya ?,2023-08-18T11:20:20Z
UgxyXcrXsGDULwSgKLN4AaABAg,@Yongqi0327,,1,vStJoetOxJg,0,0,2023-05-30T14:16:54Z,how to open the course slides after downloaded,2023-05-30T14:16:54Z
UgzhaGMHqRDe8s0fpX94AaABAg,@user-yz9jx6fn2l,,1,vStJoetOxJg,1,5,2023-05-16T03:56:12Z,Does this playlist gives the same content of the old playlist that contains 112 videos,2023-05-16T03:56:12Z
UgzhaGMHqRDe8s0fpX94AaABAg.9pl2YaamrmJ9q7XbdcNlTd,@PixeLabor,UgzhaGMHqRDe8s0fpX94AaABAg,2,vStJoetOxJg,0,7,2023-05-25T06:50:09Z,did you find out?,2023-05-25T06:50:09Z
UgyUWQfk55GoqMct_U54AaABAg,@tsameerab,,1,vStJoetOxJg,5,4,2023-04-16T16:54:46Z,Don&#39;t you provide videos after 3.11 ?,2023-04-16T16:54:46Z
UgyUWQfk55GoqMct_U54AaABAg.9o_Bno4xND79p-zo5kOcsc,@habeebijaz5907,UgyUWQfk55GoqMct_U54AaABAg,2,vStJoetOxJg,0,4,2023-04-27T11:59:57Z,4 months ago his full course on machine learning 2022 was available on YouTube but for some reason they have removed it and only first 40 lectures are here.,2023-04-27T11:59:57Z
UgyUWQfk55GoqMct_U54AaABAg.9o_Bno4xND79p0DpkfjL_-,@tsameerab,UgyUWQfk55GoqMct_U54AaABAg,2,vStJoetOxJg,0,2,2023-04-27T14:11:15Z,"@@habeebijaz5907 Still its worth to pay and do Andrew&#39;s courses, specially the 4 courses on AI, such a master class",2023-04-27T14:11:15Z
UgyUWQfk55GoqMct_U54AaABAg.9o_Bno4xND79q-6IP-RWte,@mebelts8622,UgyUWQfk55GoqMct_U54AaABAg,2,vStJoetOxJg,0,0,2023-05-22T00:17:32Z,"@@tsameerab hi, do you know where can I buy that videos you have mentioned?",2023-05-22T00:18:02Z
UgyUWQfk55GoqMct_U54AaABAg.9o_Bno4xND79q7xA-fjZUT,@venkateshdhanorkar3347,UgyUWQfk55GoqMct_U54AaABAg,2,vStJoetOxJg,0,3,2023-05-25T10:42:11Z,@@mebelts8622 Coursera,2023-05-25T10:42:11Z
UgyUWQfk55GoqMct_U54AaABAg.9o_Bno4xND79tcXJhHulV9,@Essentialenglishwords-ii7ek,UgyUWQfk55GoqMct_U54AaABAg,2,vStJoetOxJg,0,0,2023-08-20T06:37:27Z,@@venkateshdhanorkar3347 can you provide me with a link to this course,2023-08-20T06:37:27Z
UgyWmZBQKgezu6SacqF4AaABAg,@i_youtube_,,1,vStJoetOxJg,0,1,2022-12-01T14:08:03Z,recording like in same his old studio,2022-12-01T14:08:03Z
UgzLlEP4RGhfbcQq2Wl4AaABAg,@necuo25,,1,vStJoetOxJg,0,5,2022-12-01T13:21:23Z,Oh weee,2022-12-01T13:21:23Z
Ugzh2ql4lPee-fnVYBZ4AaABAg,@harshvardhanhanda732,,1,wiNXzydta4c,0,0,2023-12-06T18:03:45Z,So informative,2023-12-06T18:03:45Z
Ugz817dZD6zvYauga8x4AaABAg,@km7530,,1,wiNXzydta4c,0,1,2023-07-31T18:20:31Z,Get to the point,2023-07-31T18:20:31Z
UgxvLujgiZ_GPxsFuC54AaABAg,@user-vv9rd4ur1d,,1,wiNXzydta4c,0,0,2023-05-08T02:36:38Z,thank you my dear friend!,2023-05-08T02:36:38Z
Ugyajt3U2lUdQwSAFEl4AaABAg,@JB_FX,,1,wiNXzydta4c,0,0,2023-04-30T15:51:08Z,Why did you take down other videos on ML ? How can we learn everything about machine learning. Do you offer any online course ?,2023-04-30T15:51:33Z
UgwWf8em3UawP5xmv794AaABAg,@AmNotLegend,,1,wiNXzydta4c,0,1,2023-04-29T00:57:52Z,Do i nee to know python programming first to enroll this course?,2023-04-29T00:58:10Z
UgyOfmh1ylZwn8JDIoZ4AaABAg,@kongson14,,1,wiNXzydta4c,0,6,2023-01-16T21:31:47Z,Im at my 5am proj and i guess this is what i wanna learn!,2023-01-16T21:31:47Z
UgwQ5GSu0VH6c75eRcd4AaABAg,@dmitrymitrofanov3920,,1,wiNXzydta4c,1,0,2022-12-02T00:48:53Z,"Hello,  is that  new version of the specialization?",2022-12-02T00:49:11Z
UgwQ5GSu0VH6c75eRcd4AaABAg.9j6qxO9ETvI9kAFH3ANKA4,@Andre-mi6fk,UgwQ5GSu0VH6c75eRcd4AaABAg,2,wiNXzydta4c,0,1,2022-12-28T04:59:17Z,"Yes, it is.",2022-12-28T04:59:34Z
UgzM914arX31mKLSl194AaABAg,@Adon_pm,,1,XtlwSmJfUs4,0,1,2023-12-12T12:30:32Z,‚ù§,2023-12-12T12:30:32Z
UgyODHyTTIifn_aUhSx4AaABAg,@augustine8142,,1,XtlwSmJfUs4,0,2,2023-09-12T11:33:16Z,Thank you‚ù§ . It&#39;s really helpful and inspiring for beginners like me.,2023-09-12T11:33:16Z
UgwGg-sgGBNPXVNL42l4AaABAg,@bobsmithy3103,,1,XtlwSmJfUs4,0,4,2023-08-24T12:31:02Z,I use this for background noise,2023-08-24T12:31:02Z
UgzTvTazX77AFbBcNCZ4AaABAg,@guilhermebispo3910,,1,XtlwSmJfUs4,0,8,2022-12-01T13:34:07Z,My master,2022-12-01T13:34:07Z
UgzmSB-VY8Obapw15Ot4AaABAg,@divyakarlapudi,,1,sca5rQ9x1cA,0,1,2023-10-07T11:35:53Z,pure gold üòá,2023-10-07T11:35:53Z
Ugw9abjrv-vrg8E41KB4AaABAg,@danishazmilearning3648,,1,sca5rQ9x1cA,0,2,2023-07-14T04:29:57Z,Voice isn&#39;t clear,2023-07-14T04:29:57Z
UgzGh1VexoEsHKysLSp4AaABAg,@beautifultalks2338,,1,hh6gE0LxfO8,0,0,2023-12-08T22:09:49Z,five lectures and i am just loving and addicted to course seriouslyy,2023-12-08T22:09:49Z
Ugww64uOcxdDykR8BMp4AaABAg,@dolamuoludare4383,,1,hh6gE0LxfO8,0,1,2023-08-10T13:30:06Z,üéâüéâ,2023-08-10T13:30:06Z
UgzOmCot6xU-ugL-dG94AaABAg,@aloneboy-cw6qh,,1,hh6gE0LxfO8,2,14,2023-05-18T17:01:42Z,I m from India sir and I want to be the best and world best macgine learning engineer....<br>Ur helping me alot üòä thanks sir...<br>I m not as much good in maths but<br>Now I m studying maths hard to be the best machine learning engineer....,2023-05-18T17:01:42Z
UgzOmCot6xU-ugL-dG94AaABAg.9prb1XKIDvP9xJKpywK0yf,@yahiasiddique4650,UgzOmCot6xU-ugL-dG94AaABAg,2,hh6gE0LxfO8,0,0,2023-11-19T20:29:10Z,Why all the indian people want to be machine learning engineer or software engineer?,2023-11-19T20:29:10Z
UgzOmCot6xU-ugL-dG94AaABAg.9prb1XKIDvP9xrAT6tW-jh,@alaala1110,UgzOmCot6xU-ugL-dG94AaABAg,2,hh6gE0LxfO8,0,0,2023-12-03T09:11:56Z,Hope one day your dream will come true!,2023-12-03T09:11:56Z
UgyBn0pDZk-kvSsJaW54AaABAg,@Diegodeluisballesteros,,1,gG_wI_uGfIE,0,0,2023-11-29T19:08:25Z,like because of the panda,2023-11-29T19:08:25Z
UgyvYD5YOgsADF_KFhp4AaABAg,@ranaadil3120,,1,gG_wI_uGfIE,0,2,2023-10-31T14:49:06Z,I love you all the same.,2023-10-31T14:49:06Z
UgxQap7gbVC9gdHDmnV4AaABAg,@ehsankhademi9586,,1,gG_wI_uGfIE,0,1,2023-09-18T19:59:23Z,thank you Mr.andrew,2023-09-18T19:59:23Z
UgxYTUZhPIkJj3RsXfR4AaABAg,@user-ps3pc6jc8g,,1,gG_wI_uGfIE,0,1,2023-09-12T21:38:40Z,legend,2023-09-12T21:38:40Z
Ugx3SndMtf_6eQIFB2J4AaABAg,@Falak_Gamer7,,1,gG_wI_uGfIE,0,1,2023-09-08T11:12:16Z,‚ù§‚ù§‚ù§,2023-09-08T11:12:16Z
UgxNFPVfwOPS85c1SpB4AaABAg,@dolamuoludare4383,,1,gG_wI_uGfIE,0,2,2023-08-10T13:31:03Z,Videos are helpful and brief,2023-08-10T13:31:03Z
UgwwMLSlfQvEUbjANuZ4AaABAg,@fbravoc9748,,1,gG_wI_uGfIE,0,6,2023-07-18T21:10:13Z,What a great teacher!!,2023-07-18T21:10:13Z
Ugz7X9lt6I6c6KGLG6J4AaABAg,@maliksaleem5691,,1,gG_wI_uGfIE,0,2,2023-05-17T11:39:51Z,Your vice is tough,2023-05-17T11:39:51Z
Ugzrna4f7FKXiyjpNV94AaABAg,@senaustun4380,,1,gG_wI_uGfIE,0,0,2023-05-08T12:32:10Z,&lt;3 :3,2023-05-08T12:32:10Z
Ugxhqkcy_InMp0RQJNF4AaABAg,@sasd570,,1,gG_wI_uGfIE,0,2,2023-04-20T11:09:43Z,Can voice be more clear ?,2023-04-20T11:09:43Z
UgzPgE0PESmkdIrHzUx4AaABAg,@kongson14,,1,gG_wI_uGfIE,0,7,2023-01-16T22:03:28Z,Getting more and more exciting!!,2023-01-16T22:03:28Z
UgwWMBDQmPsNGy-7faB4AaABAg,@CTOInformation,,1,_0bhZBqtCCs,0,4,2023-03-13T15:28:00Z,"this is why I always like the Chinese, they are always on point with clear logic.",2023-03-13T15:28:00Z
UgzYy0UzVkwM5TEcZrd4AaABAg,@humblesoul8685,,1,6dTL76DWYQU,0,3,2023-10-04T02:04:15Z,Can we get the link to the jupyter notebook?,2023-10-04T02:04:15Z
Ugz8-4tLecGlxK3cz7t4AaABAg,@cosmic_snot,,1,6dTL76DWYQU,0,1,2023-03-01T20:07:21Z,No access to the labs and cannot audit this course anymore. Thumbs down..,2023-03-01T20:07:21Z
UgyWiyi-NIZ5AFAjnOx4AaABAg,@sandeepgurram9118,,1,6dTL76DWYQU,0,1,2023-02-01T16:11:03Z,can get access the lab,2023-02-01T16:11:03Z
UgzPe3dU1bdwfbjO-Hx4AaABAg,@divyakarlapudi,,1,dLc-lfEEYss,1,1,2023-10-08T09:34:54Z,it&#39;s just awesome !!,2023-10-08T09:34:54Z
UgzPe3dU1bdwfbjO-Hx4AaABAg.9vb0_Al2CPI9vbN8ZIatuf,@karthik_0180,UgzPe3dU1bdwfbjO-Hx4AaABAg,2,dLc-lfEEYss,0,0,2023-10-08T12:52:06Z,Yup,2023-10-08T12:52:06Z
UgynFgpOdi1vlE9CVAB4AaABAg,@johnm6495,,1,dLc-lfEEYss,0,0,2023-09-28T16:37:17Z,"With the training examples (x,y), why is superscript with parentheses used instead of merely using subscript?",2023-09-28T16:37:17Z
UgyQGI4Q1Whyjwet3DN4AaABAg,@hafsazulfiqar727,,1,dLc-lfEEYss,0,1,2023-09-07T10:55:00Z,sir it&#39;s a great course but how can I access labs?,2023-09-07T10:55:00Z
UgwEiqJBnvBT40QZSx54AaABAg,@Aspiring-Data-Scientist,,1,dLc-lfEEYss,0,1,2023-07-20T02:11:23Z,Also add deep learning  spacialization.,2023-07-20T02:11:23Z
Ugx5rLToDFSTiwlsNkR4AaABAg,@divyakarlapudi,,1,KWULpBYzIYk,0,0,2023-10-08T09:51:12Z,Loved it !,2023-10-08T09:51:12Z
Ugxh-JwQupTJL9TX2EJ4AaABAg,@MuhammadAsif-nx7om,,1,KWULpBYzIYk,1,0,2023-07-15T04:39:56Z,"How to predict the values of w and b , what is their criteria?",2023-07-15T04:39:56Z
Ugxh-JwQupTJL9TX2EJ4AaABAg.9sAcFUAgzjA9tEEsFHopp_,@PramodShetty,Ugxh-JwQupTJL9TX2EJ4AaABAg,2,KWULpBYzIYk,0,0,2023-08-10T10:55:16Z,"w is a weight and b is a constant. The prediction is done by the machine learning algorithm. You can also calculate the w and b value using a linear equation. but you multiple data points. In simple words y = wx + b represents a line on a graph and data points are the x and y value in that line, any random point on the line will have x and y values.",2023-08-10T10:55:16Z
Ugx_EVXBZAErL-CmG5p4AaABAg,@jamesrobisnon9165,,1,KWULpBYzIYk,1,1,2023-01-30T20:21:25Z,Some resources including this video say &quot;univariate&quot; is a regression model with one variable (input) and some say it is a regression model where we only return one predicted output. Which one is correct?,2023-01-30T20:21:25Z
Ugx_EVXBZAErL-CmG5p4AaABAg.9lWs1sCX0VF9vD8n251Fr9,@johnm6495,Ugx_EVXBZAErL-CmG5p4AaABAg,2,KWULpBYzIYk,0,1,2023-09-28T17:45:40Z,"Both. Let&#39;s say they&#39;re not -- that would mean we have a model that, given an input, produces multiple predicted outputs ---&gt; In other words multiple y-hats. However, a function by definition must have one output. <br><br>If we put the line or curve produced by the function on a graph, there&#39;s a simple test called the Straight Line Test that confirms whether we call that &quot;line&quot; a function of x. If you can find a location anywhere on the graph where you could draw a vertical line that intersects with the function&#39;s line more than once, then the function &quot;fails&quot; the test and is not considered a traditional function. <br><br>Put another way, we call the function a &quot;function of x&quot; because x is the variable that determines the result of the function. The output of the function, conversely, is something determined by x. <b>*So a univariate regression model is a model that has one input variable and one output variable.*</b><br><br>This might sound confusing, so let&#39;s use the house-price example from the video:<br>- each of the marks on the graph (the things shaped like a tilted &quot;+&quot; sign) represent a house of &quot;x&quot; square feet that we <b>know</b> was sold for &quot;y&quot; dollars<br>- we have more houses we want to sell --&gt; BUT while we <b>do</b> know the square feet of each of these houses to be sold...<br>  - we <b>don&#39;t</b> know how much they would sell for, since they haven&#39;t been sold yet<br>- to predict how much the house <b>might</b> sell for, we&#39;ll use some clever math that predicts the sale-price based off of how much those aforementioned &quot;known&quot; houses <b>did</b> sell for<br>- that math results in a formula that predicts the house price based on its square feet --&gt; when plotted on a graph, the output of this formula would draw a straight line<br>- that formula is called a function<br><br>- NOW, let&#39;s say we have a 1300-square-foot house we want to sell<br>- if we put 1300 into the formula, we&#39;d get a certain output, a prediction of how much the house would sell for --&gt; in this case let&#39;s just say the formula output was $100,000<br>- but what if the formula <b>also</b> produced an output of $200,000<br>- which house price is right? could we sell the house for $200,000? That&#39;s a lot more money, but if the prediction was supposed to be $100,000, then nobody will buy this overpriced house when other similar-sized houses are being sold for way less<br>- Thusly, a function with multiple outputs wouldn&#39;t be very useful, because of this ambiguity<br>- So again, the function <b>has</b> to have only one output, and univariate regressions must also have only one input<br><br>However, KEEP THIS IN MIND:<br>- what happens if we have sample data with the same x but different y?<br>- in other words, what does it mean if we <b>know</b> that a 1200 square foot house was sold for $60,000, but ANOTHER 1200 square foot house was sold for $80,000 --&gt; that&#39;s two different outputs, two different y&#39;s; what does this mean?<br>- Nothing has changed, our function still works and will still make predictions based off of all the sample data<br>- This is because the sample data itself is <b>not</b> a function - they&#39;re just individual entities that we use to train our function<br><br>This will make more sense once the math is explained in the videos. <br>Hope this helps.",2023-09-28T17:45:40Z
Ugx-RHXZW5bWe32oRaZ4AaABAg,@sadiamanzoor6791,,1,KWULpBYzIYk,0,0,2023-01-21T20:48:01Z,How can I access that?,2023-01-21T20:48:01Z
Ugy4pwnuZs7_v5bLa9x4AaABAg,@sadiamanzoor6791,,1,KWULpBYzIYk,4,1,2023-01-21T20:47:47Z,where is lab code?,2023-01-21T20:47:47Z
Ugy4pwnuZs7_v5bLa9x4AaABAg.9l9ju1bb0af9nMZaucJoUC,@bhubanmondal05,Ugy4pwnuZs7_v5bLa9x4AaABAg,2,KWULpBYzIYk,0,0,2023-03-17T13:21:57Z,u have to enroll in coursera to get access ü•≤,2023-03-17T13:21:57Z
Ugy4pwnuZs7_v5bLa9x4AaABAg.9l9ju1bb0af9qVDeX_eCQs,@user-kj5vw9ri5c,Ugy4pwnuZs7_v5bLa9x4AaABAg,2,KWULpBYzIYk,0,1,2023-06-03T11:37:34Z,"the same question, i didn&#39;t find through the jupyter notebook",2023-06-03T11:37:34Z
Ugy4pwnuZs7_v5bLa9x4AaABAg.9l9ju1bb0af9qmlccjTh0H,@rubayetalam8759,Ugy4pwnuZs7_v5bLa9x4AaABAg,2,KWULpBYzIYk,0,1,2023-06-10T16:29:28Z,@@user-kj5vw9ri5c IT&#39;S ONLY FOR THE PEOPLE IN COURSERA.,2023-06-10T16:29:28Z
Ugy4pwnuZs7_v5bLa9x4AaABAg.9l9ju1bb0af9qmlgPlxXQT,@rubayetalam8759,Ugy4pwnuZs7_v5bLa9x4AaABAg,2,KWULpBYzIYk,0,1,2023-06-10T16:29:59Z,"@@user-kj5vw9ri5c YOU GOTTA ENROLL IN THIS COURSE, BY YOUR COURSERA ACCOUNT. HOPE IT HELPS.",2023-06-10T16:29:59Z
UgwpwqYyoRUoow6ZFGR4AaABAg,@zhiyingwang1234,,1,CFN5zHzEuGY,0,1,2023-09-21T09:34:46Z,"Thanks for making the efforts to explain every detail about function notation, abbreviation. As a hindsight, I realize this will lay a solid foundation when it comes to learning more advanced functions.",2023-09-21T09:34:46Z
UgwJPvcqZQuML7BxrLV4AaABAg,@thegbfolks,,1,CFN5zHzEuGY,1,1,2023-08-15T18:40:31Z,I understand we are considering a straight line to predict the y values. But I don&#39;t understand that on what basis we fit a straight line on the data. Is it just like drawing a straight line through the training examples? Or are there any rules for fitting a straight line through the training examples?,2023-08-15T18:40:31Z
UgwJPvcqZQuML7BxrLV4AaABAg.9tRx59aesIr9vh4nRclytl,@divyakarlapudi,UgwJPvcqZQuML7BxrLV4AaABAg,2,CFN5zHzEuGY,0,0,2023-10-10T18:07:14Z,It must pass through all the training set points or we consider the line which is close to most of the training set points.,2023-10-10T18:07:14Z
UgwhcrN_d8DczVn0beN4AaABAg,@Ailearning879,,1,CFN5zHzEuGY,0,1,2022-12-25T03:03:01Z,"<a href=""https://youtu.be/ZkMShfb023k"">https://youtu.be/ZkMShfb023k</a> (California house price prediction üìàüìäüìàüìàüìâüí∞)",2022-12-25T03:03:01Z
UgzGs1K9U6lSvNwUISh4AaABAg,@quietcorner5989,,1,peNRqkfukYY,1,0,2023-11-09T12:21:53Z,"so why you calculated J  function in the beginning with the same slope which is w=1 ,and then u calculated the value of j function from two different slopes w=1 and w=0.5? in the first one you considered that the actual function and the function of the model prediction had the same slope w=1 so it is normal that the error would be 0!! can you please clarify this i didn t get it. did you suppose in the beginning that the model  predition was 100% correct and precise and it mached with the actual function , so the error was 0?",2023-11-09T12:56:52Z
UgzGs1K9U6lSvNwUISh4AaABAg.9wti7Cm4Qtv9yLhWbdK_Cu,@Lostverseplays,UgzGs1K9U6lSvNwUISh4AaABAg,2,peNRqkfukYY,0,0,2023-12-15T15:05:58Z,"In the start yes the model prediction was 100% correct that is why the cost function(J) gave 0 as output as there was no error in prediction, when the slope became 0.5 the model(Function used to predict prices i.e f(x)) was deviated from actual prediction whose error was calculated by  J function",2023-12-15T15:06:24Z
Ugzd4dgCNSTpQeLIFIZ4AaABAg,@karthik_0180,,1,peNRqkfukYY,0,0,2023-10-08T14:48:39Z,Yes,2023-10-08T14:48:39Z
Ugx8cakZS0xjzcXTWVB4AaABAg,@tamaramartinovic,,1,peNRqkfukYY,0,4,2023-08-26T19:48:06Z,"So well explained, thank you very much!",2023-08-26T19:48:21Z
UgwLhIsgBQgl4sGL16l4AaABAg,@ooxxx,,1,peNRqkfukYY,0,2,2023-05-19T03:09:18Z,thank you!,2023-05-19T03:09:18Z
Ugy0DXlKO_FOLM0LtL14AaABAg,@YashrajVerma-ni4jn,,1,peNRqkfukYY,0,1,2023-05-17T14:57:12Z,üòä,2023-05-17T14:57:12Z
UgyOWP0bmJeeWsebJRR4AaABAg,@user-dv9zp4ii2l,,1,bFNz2u0hl9E,0,0,2023-12-18T11:30:01Z,I love your sense of humorü§£ü§£ &quot;Maybe because I am hungry&quot;,2023-12-18T11:30:01Z
UgzAQ56f5kKzYO6HBrB4AaABAg,@rasewukeshu5058,,1,bFNz2u0hl9E,1,1,2023-09-06T17:54:19Z,Is it audible?,2023-09-06T17:54:19Z
UgzAQ56f5kKzYO6HBrB4AaABAg.9uKWI-iVvD29x4OqmayXaw,@urfriend..,UgzAQ56f5kKzYO6HBrB4AaABAg,2,bFNz2u0hl9E,0,0,2023-11-14T01:15:37Z,Yes,2023-11-14T01:15:37Z
Ugx5qGaKtyZw_vpTPEl4AaABAg,@anweshpanda7417,,1,bFNz2u0hl9E,0,1,2023-08-31T05:34:35Z,I have had multivariable calculus course in college and this makes so much sense.,2023-08-31T05:34:35Z
UgxQZDZFzPFxYvpaOfV4AaABAg,@viralvideos18882,,1,bFNz2u0hl9E,0,2,2023-07-24T12:50:21Z,Excellent work‚ù§,2023-07-24T12:50:21Z
UgwDXoalmOVKd9YoVQh4AaABAg,@khatiwadaAnish,,1,L5INhX5cbWU,10,7,2023-01-15T02:06:43Z,"Hello, how can i access jupyter notebook, In the given link, i got access of slide but Jupyter notebook was missing in zip file",2023-01-15T02:06:43Z
UgwDXoalmOVKd9YoVQh4AaABAg.9ktHpqbr6El9r5qXrLPh2U,@vksingh1907,UgwDXoalmOVKd9YoVQh4AaABAg,2,L5INhX5cbWU,0,0,2023-06-18T11:37:11Z,did you find it,2023-06-18T11:37:11Z
UgwDXoalmOVKd9YoVQh4AaABAg.9ktHpqbr6El9r5vEjcKET2,@khatiwadaAnish,UgwDXoalmOVKd9YoVQh4AaABAg,2,L5INhX5cbWU,0,0,2023-06-18T12:18:15Z,@@vksingh1907 yes,2023-06-18T12:18:15Z
UgwDXoalmOVKd9YoVQh4AaABAg.9ktHpqbr6El9rSkqPsxvNK,@aashishkumarsingh428,UgwDXoalmOVKd9YoVQh4AaABAg,2,L5INhX5cbWU,0,0,2023-06-27T09:09:57Z,@@khatiwadaAnish how???,2023-06-27T09:09:57Z
UgwDXoalmOVKd9YoVQh4AaABAg.9ktHpqbr6El9rViJlmDGkD,@jinli1835,UgwDXoalmOVKd9YoVQh4AaABAg,2,L5INhX5cbWU,0,0,2023-06-28T12:45:36Z,I guess the only way to have the access to the notebook is to buy the course. This is the way how they do business. There is No free meals.,2023-06-28T12:45:36Z
UgwDXoalmOVKd9YoVQh4AaABAg.9ktHpqbr6El9rVpVXIHoti,@khatiwadaAnish,UgwDXoalmOVKd9YoVQh4AaABAg,2,L5INhX5cbWU,0,1,2023-06-28T13:48:23Z,"@@jinli1835 nope, to pay is Optional. They have really done a lot for the community !",2023-06-28T13:58:30Z
Ugx_Io77Ak6C4KTJ1VN4AaABAg,@donharrold1375,,1,WtlvKq_zxPI,0,1,2023-10-14T19:47:56Z,This is beautiful. Beyond excellent. This guy has got to be one of the best mathematical educators out there?,2023-10-14T19:47:56Z
Ugy2FNxFEaf1EfAenCN4AaABAg,@impulse1712,,1,w_2vCijLiiM,3,2,2023-09-01T20:04:14Z,How to reach global minimum if there is a chance of getting stuck at local minimum??,2023-09-01T20:04:32Z
Ugy2FNxFEaf1EfAenCN4AaABAg.9u7sBB87OW79u93BrJdyfa,@anweshpanda7417,Ugy2FNxFEaf1EfAenCN4AaABAg,2,w_2vCijLiiM,0,0,2023-09-02T07:08:25Z,"I think we have to check for the global minimum by putting w and b in the cost function. Well, that&#39;s what we do in maths at least.",2023-09-02T07:08:25Z
Ugy2FNxFEaf1EfAenCN4AaABAg.9u7sBB87OW79unm_NN2k2z,@sjlee100,Ugy2FNxFEaf1EfAenCN4AaABAg,2,w_2vCijLiiM,0,0,2023-09-18T12:02:34Z,use randomization,2023-09-18T12:02:46Z
Ugy2FNxFEaf1EfAenCN4AaABAg.9u7sBB87OW79yBhMA93KqF,@iguessnotthatserious,Ugy2FNxFEaf1EfAenCN4AaABAg,2,w_2vCijLiiM,0,0,2023-12-11T17:52:08Z,"If you use a Mean Squared Error (MSE) cost function with the right learning rate then you&#39;ll always get a global minimum.<br>why? because MSE function is a convex function and thus it&#39;s guaranteed to have just one local minimum which equals to the global minimum.<br><br>but that&#39;s just one part, the other one also important is the learning rate. If you choose too big one then you&#39;ll overshoot the global minimum and the gradient descent won&#39;t converge.<br>How to choose the right learning rate then? Just experiment! choose an initial value and plot the cost for every iteration of gradient descent, if at some point you will notice the cost started to increase then you&#39;ll know you overshot it.",2023-12-11T17:52:08Z
UgygxbRiLm5zb2M3aGZ4AaABAg,@raheemasghar2383,,1,PKm61nrqpCA,0,0,2023-12-08T04:24:47Z,Finally understood Gradient Decent!!!,2023-12-08T04:24:47Z
Ugw31N-ukwDMxSkbHwR4AaABAg,@karthik_0180,,1,PKm61nrqpCA,0,2,2023-10-08T17:53:06Z,"<a href=""https://www.youtube.com/watch?v=PKm61nrqpCA&amp;t=1m07s"">1:07</a>",2023-10-08T17:53:06Z
UgzyEI6TylFPgZWlWL14AaABAg,@harshitdabhi1503,,1,PKm61nrqpCA,0,0,2023-07-08T06:50:42Z,"Very nice explanation , I never feel this much confident !! <a href=""about:invalid#zCSafez""></a> I want to study with you in person ..",2023-07-08T06:55:28Z
UgwzSq_xK4u_GfgPaY94AaABAg,@JohnTuffin,,1,PKm61nrqpCA,0,9,2023-05-01T12:15:08Z,My gosh smart people that can explain things in simple terms are so rare. Thank you so much for this it makes it so much clearer.,2023-05-01T12:15:08Z
UgyQMSuI7EXaa5PHoEB4AaABAg,@donharrold1375,,1,k0h8emRAAHE,0,0,2023-10-15T08:39:54Z,Great but you didn‚Äôt explain how to deal with two minima?,2023-10-15T08:39:54Z
UgzZGaRyra_4EaI977t4AaABAg,@Parshant17,,1,k0h8emRAAHE,1,3,2023-01-14T10:05:23Z,"I didn&#39;t understand yet, what will happen if there are multiple minima, how algorithm will proceed after reaching local minima?",2023-01-14T10:05:23Z
UgzZGaRyra_4EaI977t4AaABAg.9krZowt9aJX9pK027iwbGr,@Dexter4o4,UgzZGaRyra_4EaI977t4AaABAg,2,k0h8emRAAHE,0,0,2023-05-05T06:35:33Z,You will learn about it in further lectures,2023-05-05T06:35:33Z
UgwYC6x1FO5bn_Ry-al4AaABAg,@DrYoshi7,,1,RGL_XUjPkGo,0,2,2023-08-31T00:17:43Z,"This is a great course Andrew, but instead of going through all the stats math, I&#39;d talk about what it really means in practical terms. We are drawing a line between a dataset with two (or more) supervised variables, and we want to minimize error such that we have a function that predicts future unsupervised output. Meaning --- how can we get price and square footage to relate to one another such that if we get new sq footage, we can predict a future price that is probably pretty accurate. There is no creativity with stats (it&#39;s all pre-programmed), so I&#39;d talk about what we are doing in practical terms. Will still stick to the end regardless......",2023-08-31T00:17:43Z
UgxdJ3wJS_SpMLPJk054AaABAg,@ak-wt6ll,,1,tHDDbqYfflM,0,0,2023-09-29T13:36:39Z,looking at this men makes me want to smile,2023-09-29T13:36:39Z
UgwzDKDvqaEuPDhsmRl4AaABAg,@sanishuaibu3804,,1,tHDDbqYfflM,0,0,2023-09-05T05:26:26Z,Please how can i get access to this codes.,2023-09-05T05:26:26Z
Ugz-RsfYoQ4aiM0RwwF4AaABAg,@abby9341,,1,tHDDbqYfflM,0,0,2023-06-13T14:46:43Z,"<a href=""https://www.youtube.com/watch?v=tHDDbqYfflM&amp;t=1m26s"">1:26</a> is the most awesome thing I have seem yet.üí•üí•",2023-06-13T14:46:43Z
UgzS8G8zSs_xQzxd-Kd4AaABAg,@kgbsameera,,1,tHDDbqYfflM,1,7,2023-06-01T16:49:35Z,Could you please share the link to the optional labs? Thanks,2023-06-01T16:49:35Z
UgzS8G8zSs_xQzxd-Kd4AaABAg.9qQcm2sDLm39yXTCjmeOHq,@geetavideos,UgzS8G8zSs_xQzxd-Kd4AaABAg,2,tHDDbqYfflM,0,0,2023-12-20T04:43:04Z,Go to the coursera link for this course.  It has all the optional labs,2023-12-20T04:43:04Z
UgyzHTyw04FOmF0AVDh4AaABAg,@nishachoudhary6965,,1,tHDDbqYfflM,0,0,2023-05-31T07:28:13Z,helpful videos,2023-05-31T07:28:13Z
UgzcGuQnsfU3XJEbPAR4AaABAg,@schubiduba1,,1,tHDDbqYfflM,0,0,2023-04-19T14:49:48Z,Where are the following videos?,2023-04-19T14:49:48Z
Ugz_cSH1LfF3fcKh2IJ4AaABAg,@vishutanwar,,1,jXg0vU0y1ak,0,0,2023-12-11T11:30:06Z,Shouldn&#39;t x be a column vector here?,2023-12-11T11:30:06Z
UgzekNiK46lgR0nYyNx4AaABAg,@sireesham6698,,1,jXg0vU0y1ak,0,2,2023-09-07T11:06:43Z,How can i get optional labs?,2023-09-07T11:06:43Z
UgwEdApjAqzh0VlL5Ix4AaABAg,@ravi6010,,1,jXg0vU0y1ak,0,5,2022-12-31T05:05:08Z,Awesome course. Amazing explanation of concepts in a simplified way!,2022-12-31T05:05:08Z
UgxmzFHbQIs4ijzdAZx4AaABAg,@user-bx5vc7qc6b,,1,U6zuBcmLxSg,0,0,2023-11-27T12:45:03Z,"üéØ Key Takeaways for quick navigation:<br><br><a href=""https://www.youtube.com/watch?v=U6zuBcmLxSg&amp;t=00m02s"">00:02</a> üöÄ <b>Vectorization in Machine Learning</b><br>- Vectorization simplifies code and improves efficiency.<br>- Learning vectorized code allows utilization of numerical linear algebra libraries and GPU hardware.<br>- Vectorization example with vectors W and X, showcasing benefits in Python code.<br><a href=""https://www.youtube.com/watch?v=U6zuBcmLxSg&amp;t=04m15s"">04:15</a> üßÆ <b>Implementing Vectorization in Code</b><br>- Non-vectorized implementations with loops can be inefficient.<br>- Introduction to a mathematical expression for the dot product of W and X with bias term.<br>- Vectorized implementation using NumPy&#39;s dot function for efficient computation.<br><a href=""https://www.youtube.com/watch?v=U6zuBcmLxSg&amp;t=05m21s"">05:21</a> üí° <b>Advantages of Vectorization</b><br>- Vectorization has two key benefits: shorter code and improved runtime efficiency.<br>- Shorter code, demonstrated with a concise one-liner using NumPy dot function.<br>- Improved runtime efficiency due to parallel hardware utilization in the numpy dot function.<br><br>Made with HARPA AI",2023-11-27T12:45:03Z
UgzQVsXoHGYJiBbq10d4AaABAg,@ak-wt6ll,,1,U6zuBcmLxSg,0,0,2023-09-29T14:19:17Z,"Andrew is gonna make coursera take my $49, actually",2023-09-29T14:19:17Z
UgwpglwWImTcEKEemRd4AaABAg,@mustafaaeea2722,,1,uvTL1N02f04,0,0,2023-12-08T18:08:12Z,How can we access the option lab? any link to it or is it a paid part of Coursera?,2023-12-08T18:08:12Z
UgwkBnYygUToxx_IAVZ4AaABAg,@mohamedhassan8260,,1,uvTL1N02f04,0,3,2023-08-20T17:35:35Z,"Insightful Prof, I hope I&#39;ll see you one day to thank you a lot due to the valuable science I&#39;ve learnt from your free playlistüíïüíï.<br>Your student from Egypt.",2023-08-20T17:35:35Z
Ugz4F83V-Wx7cfz1oeF4AaABAg,@khatiwadaAnish,,1,uvTL1N02f04,0,3,2023-01-18T15:43:49Z,"if possible, please give access of Jupyter notebook also.",2023-01-18T15:43:49Z
Ugy8SR4bVS4AMCi7i8N4AaABAg,@akshatdobhal1690,,1,uvTL1N02f04,0,5,2022-12-12T05:42:06Z,hes sooo happy while teaching this course. i love it!,2022-12-12T05:42:06Z
UgzI4nvvb7wC3gdAtPJ4AaABAg,@AbhishekKumar-eg4ok,,1,YjpCQof9tI8,2,2,2023-07-13T08:34:09Z,How I can  get slides of optional lab?<br>Please tell me.,2023-07-13T08:34:09Z
UgzI4nvvb7wC3gdAtPJ4AaABAg.9s5tT6ZU8OS9w7pqoZ2sTc,@giridharpatill,UgzI4nvvb7wC3gdAtPJ4AaABAg,2,YjpCQof9tI8,0,0,2023-10-21T12:46:37Z,buy the course,2023-10-21T12:46:37Z
UgzI4nvvb7wC3gdAtPJ4AaABAg.9s5tT6ZU8OS9yB7zP7s1zA,@vishutanwar,UgzI4nvvb7wC3gdAtPJ4AaABAg,2,YjpCQof9tI8,0,0,2023-12-11T12:34:19Z,check video description,2023-12-11T12:34:19Z
Ugy4lIoVokZZU-z9IJZ4AaABAg,@NickWindham,,1,YjpCQof9tI8,0,1,2023-04-11T02:41:41Z,Great videos!,2023-04-11T02:41:41Z
Ugx3KtzAkNvWxYhKfyF4AaABAg,@khatiwadaAnish,,1,YVtP5UGdgXg,0,3,2023-01-18T16:10:12Z,"very OP explanation, getting a lot of understanding from this playlist. if possible please provide Jupyter Notebook of this series.",2023-01-18T16:10:12Z
UgwPpG9BYZQBcJlGVO94AaABAg,@user-hy4rz6xw9w,,1,gmJqLGrUscg,0,0,2023-11-17T06:38:35Z,"<a href=""https://www.youtube.com/watch?v=gmJqLGrUscg&amp;t=00m03s"">00:03</a> Implement feature scaling to scale features with different ranges to have comparable ranges<br><a href=""https://www.youtube.com/watch?v=gmJqLGrUscg&amp;t=01m00s"">01:00</a> Mean normalization rescales the features so that they are centered around zero.<br><a href=""https://www.youtube.com/watch?v=gmJqLGrUscg&amp;t=01m58s"">01:58</a> Normalization techniques include range normalization and mean normalization.<br><a href=""https://www.youtube.com/watch?v=gmJqLGrUscg&amp;t=03m00s"">03:00</a> Standard deviation and z-score normalization<br><a href=""https://www.youtube.com/watch?v=gmJqLGrUscg&amp;t=03m55s"">03:55</a> Feature scaling aims to normalize the range of features.<br><a href=""https://www.youtube.com/watch?v=gmJqLGrUscg&amp;t=04m55s"">04:55</a> Features can have different ranges of values<br><a href=""https://www.youtube.com/watch?v=gmJqLGrUscg&amp;t=05m47s"">05:47</a> Rescaling features can help improve machine learning algorithms.<br><a href=""https://www.youtube.com/watch?v=gmJqLGrUscg&amp;t=06m47s"">06:47</a> Feature scaling can help improve the speed of gradient descent.",2023-11-17T06:38:35Z
Ugx9vvl5BEUgNr3u45F4AaABAg,@armanwirawan7099,,1,gmJqLGrUscg,0,2,2023-06-04T06:06:10Z,"thank you andrew, i know you don&#39;t have to do this but i want to mention how grateful I&#39;am i&#39;m currently doing IBM data science in coursera, this really helps their machine learning section",2023-06-04T06:06:10Z
UgxvhnBYRztd8qU0Bxx4AaABAg,@senaustun4380,,1,P_9hNBVRldM,0,6,2023-05-09T14:22:48Z,ƒ± dont know what to comment but ƒ±wanted to leave one anyway :) thank you,2023-05-09T14:22:48Z
UgyXUl1d3eGL69xu1It4AaABAg,@narasimhang4736,,1,ecOdZlY9jsQ,0,0,2023-06-11T16:12:07Z,"im getting comment line with index UNQ_C3` wasn&#39;t found in code when i submit the programming assignment, any solutions??",2023-06-11T16:12:07Z
UgyyC2YfmLs24AqK8lh4AaABAg,@wissammoussa7540,,1,ecOdZlY9jsQ,1,1,2022-12-09T12:09:58Z,"We are duplicating data by keeping x1 and x2, why don&#39;t we remove them and just keep x3? Now the info given by x1/x2/x3 will have a bigger weight than x4 through xn",2022-12-09T12:09:58Z
UgyyC2YfmLs24AqK8lh4AaABAg.9jQ5SpIUcOl9qm3J1jQcdd,@jacksonwang3974,UgyyC2YfmLs24AqK8lh4AaABAg,2,ecOdZlY9jsQ,0,1,2023-06-10T09:53:26Z,I believe the x3 = x1 * x2 only demonstrates the step that creating the new feature x3. Will probably drop x1 and x2 but needed to demonstrate the dropping steps using NumPy. Maybe not shown in this video but will be shown in the upcoming videos.,2023-06-10T09:55:07Z
UgxUunpl8Xp0vMMlPnt4AaABAg,@ikennaonyekwelu5459,,1,IFkRKJ5iBDE,0,0,2023-12-19T06:57:26Z,How do I get the optional lab codes?,2023-12-19T06:57:26Z
Ugxv2raOcs36NNd1cUp4AaABAg,@Sleeperknot,,1,IFkRKJ5iBDE,0,0,2023-09-27T05:54:48Z,"With free online math tools, we can come up with the right polynomial function that best represents the shape of our dataset plot. Then we can use that equation to do the regression. I ended up accidentally doing this to come up with a complex-looking polynomial to represent my dataset plot and then used that to predict values. I didn&#39;t have to do the regression because the coefficients were all perfect for my dataset. That online math tool might have done polynomial regression for me in the background. I knew nothing about machine learning back then.",2023-09-27T05:56:13Z
UgxCiFidBTZMnc7G-Yl4AaABAg,@monome3038,,1,xuTiAW0OR40,0,0,2023-12-11T09:35:19Z,thank YOU so so so much for simplifying the maths behind the method of ML logistic regression,2023-12-11T09:35:31Z
Ugyw2_MwYvleuMU_Bqp4AaABAg,@priyamiitian6677,,1,xuTiAW0OR40,0,1,2023-08-12T13:22:11Z,Clarity 100percent,2023-08-12T13:22:11Z
Ugy3nVXabAPMsn3WTe14AaABAg,@subhanali4535,,1,0az8RjxLLPQ,2,3,2022-12-27T12:41:59Z,"In the end of lecture, shouldn&#39;t Yhat be zero inside the ellipse, yhat = 0 (inside ellipse) and yhat = 1 (outside ellipse )",2022-12-27T12:41:59Z
Ugy3nVXabAPMsn3WTe14AaABAg.9k8VR6hnpQ59mnVwN-WkrZ,@ghboo,Ugy3nVXabAPMsn3WTe14AaABAg,2,0az8RjxLLPQ,0,1,2023-03-03T13:17:16Z,"I think it depends on the question.<br>if the question is &#39;is this email spam?&#39;, then that inside the ellipse is 0, but in the case of the question is &#39;isn&#39;t this email spam?&#39;, then the positive(yes, true, 1) part should be the inside one",2023-03-03T13:17:16Z
Ugy3nVXabAPMsn3WTe14AaABAg.9k8VR6hnpQ59wNxR1SHQVk,@lifeisbeautiful1111,Ugy3nVXabAPMsn3WTe14AaABAg,2,0az8RjxLLPQ,0,1,2023-10-27T19:00:43Z,I am allso bit confused,2023-10-27T19:00:43Z
UgzKAQM2yoiIjwv-Drh4AaABAg,@DrYoshi7,,1,vq4Ie5xWhww,0,0,2023-09-12T22:49:52Z,This course needs a mini stats class for beginners to explain error,2023-09-12T22:49:52Z
Ugx1g9midRKfSgniFRx4AaABAg,@youssifgamal8545,,1,vq4Ie5xWhww,1,1,2023-06-11T16:24:41Z,what is the base of the log ?,2023-06-11T16:24:41Z
Ugx1g9midRKfSgniFRx4AaABAg.9qpKsNVq8g89s98j_RTOLQ,@e.galois4940,Ugx1g9midRKfSgniFRx4AaABAg,2,vq4Ie5xWhww,0,4,2023-07-14T14:54:03Z,"In theory, any base works. In practice, i guess 2, 10 or e",2023-07-14T14:54:03Z
UgwrKiz9cp5ZQUmG0JV4AaABAg,@user-yw6xd1ju5q,,1,vq4Ie5xWhww,0,0,2023-05-28T04:42:24Z,thx,2023-05-28T04:42:24Z
Ugw0A-yql1coQ7FHogp4AaABAg,@akshatdobhal1690,,1,vq4Ie5xWhww,0,6,2022-12-15T06:42:32Z,okay this is where things got a bit confusing,2022-12-15T06:42:32Z
UgzFO9NYIk35hG8cQnl4AaABAg,@SatwikTrivedi-YearBTechCivilEn,,1,8upNQi-40Q8,0,0,2023-06-08T16:18:02Z,Thank You sir. Very insightful video.<br>Sir are you open to research internships.,2023-06-08T16:18:02Z
UgwcKPaiPQjPVJJ1p9F4AaABAg,@phillustrator,,1,NIiZZY7nlfU,0,3,2023-07-26T18:32:54Z,"Giving your videos pertinent titles like for example in this case: &quot;Cost function regularization&quot; would not only make your videos easier and more pleasant to navigate, they would make the YouTube algorithm direct a lot more traffic to you.",2023-07-26T18:32:54Z
UgwWUq6TC8B48CDudLJ4AaABAg,@SiddharthDesai1,,1,jhrrw8Iuus0,0,1,2023-08-30T03:23:19Z,"Hello, great series so far. Thank you very much. The optional slide did not show how you derived the derivative terms. You&#39;ve pretty much just restated what was covered much earlier when you covered gradient descent with 1 &quot;w&quot; paramter. I was hoping you would show the derivation steps.",2023-08-30T03:23:19Z
UgzTebCRUZo6m0liYzl4AaABAg,@RH-mk3rp,,1,jhrrw8Iuus0,1,0,2023-01-11T01:22:44Z,"At <a href=""https://www.youtube.com/watch?v=jhrrw8Iuus0&amp;t=2m37s"">2:37</a> and <a href=""https://www.youtube.com/watch?v=jhrrw8Iuus0&amp;t=5m10s"">5:10</a> is there a missing 1/2 term. For mean squared error I often see it without the division by 2, seems like it&#39;s personal choice. TensorFlow I&#39;m certain does not include that term.",2023-01-11T01:22:44Z
UgzTebCRUZo6m0liYzl4AaABAg.9kiucK2RrqM9rgNqwTOfxR,@waleedeid2713,UgzTebCRUZo6m0liYzl4AaABAg,2,jhrrw8Iuus0,0,0,2023-07-03T01:28:55Z,There is 1/2 in mean square error if you looking for the previous lesson there is 1/2 for the  regularization <br>but when he applied gradient descent there is not .,2023-07-03T01:28:55Z
Ugy5p6r6Wwoht7cVxYJ4AaABAg,@rudrakhare1158,,1,NhZXRzH2y-E,0,0,2023-12-07T18:08:57Z,Happy For Myself coming this far and completing the playlist. Thankyou Andrew Sir. Really appreciate the work you did and value content you created. Love From India &lt;3 .,2023-12-07T18:08:57Z
UgwIHuxElf3f7-ZpObV4AaABAg,@cecilehonda2234,,1,NhZXRzH2y-E,0,1,2023-12-06T11:25:36Z,Tack till s√∂kmotorn f√∂r akademiska artiklar!,2023-12-06T11:25:36Z
UgwZKUyoktLrLTis6W54AaABAg,@meryemOuyouss2002,,1,NhZXRzH2y-E,0,0,2023-10-26T02:34:53Z,"Your really a great professor ,thank you so much",2023-10-26T02:34:53Z
UgwUoeQ5e9xJRG7zBMx4AaABAg,@user-xg8iv8ki6v,,1,NhZXRzH2y-E,0,3,2023-07-03T07:42:39Z,how can i have access to optional lab,2023-07-03T07:42:39Z
Ugxv9c-BxFTL9mVO7yV4AaABAg,@tugbademiralp3110,,1,NhZXRzH2y-E,3,3,2023-05-24T11:30:19Z,"Hi, firstly thank you very much for sharing these great videos for us. I am just curious whether you will upload the rest of the courses or not?",2023-05-24T11:30:19Z
Ugxv9c-BxFTL9mVO7yV4AaABAg.9q5SsiDS06S9qO007ebCwW,@arjoai,Ugxv9c-BxFTL9mVO7yV4AaABAg,2,NhZXRzH2y-E,0,1,2023-05-31T16:23:38Z,Better enrol in the specialisation,2023-05-31T16:23:38Z
Ugxv9c-BxFTL9mVO7yV4AaABAg.9q5SsiDS06S9qRUPuUGN8u,@Deeplearningai,Ugxv9c-BxFTL9mVO7yV4AaABAg,2,NhZXRzH2y-E,0,2,2023-06-02T00:47:01Z,"Glad you found them helpful! For the full course, please visit <a href=""https://www.coursera.org/specializations/machine-learning-introduction"">https://www.coursera.org/specializations/machine-learning-introduction</a>",2023-06-02T00:47:01Z
Ugxv9c-BxFTL9mVO7yV4AaABAg.9q5SsiDS06S9qSnqvCKl94,@tugbademiralp3110,Ugxv9c-BxFTL9mVO7yV4AaABAg,2,NhZXRzH2y-E,0,1,2023-06-02T13:04:50Z,"@@Deeplearningai  I enrolled to the course, thank you very much for this great tutorial.",2023-06-02T13:04:50Z
UgzCvWMrfj2WRNlykul4AaABAg,@moeeljawad5361,,1,NhZXRzH2y-E,0,2,2023-05-19T13:58:52Z,"Amazing Course, Thanks for making it public. Too bad the labs were not included. Might go enroll in the Coursera speciallization in the future.",2023-05-19T13:58:52Z
UgzvbB0pkKbt3OFU8OZ4AaABAg,@senaustun4380,,1,NhZXRzH2y-E,0,1,2023-05-11T13:54:57Z,thank you :D,2023-05-11T13:54:57Z
Ugwx-xKsMZg1jRT4d2J4AaABAg,@igorlukas4989,,1,NhZXRzH2y-E,0,17,2022-12-29T14:19:05Z,"Hi, what about Course 2 and 3 for Machine Learning Specialization?",2022-12-29T14:19:05Z
UgyssGk40-3RWIapGdp4AaABAg,@afnankhan1278,,1,NgWujOrCZFo,1,0,2023-04-02T08:13:48Z,Where are remaining other 2m,2023-04-02T08:13:48Z
UgyssGk40-3RWIapGdp4AaABAg.9o-D2riJ2TT9o-D3anfaoB,@afnankhan1278,UgyssGk40-3RWIapGdp4AaABAg,2,NgWujOrCZFo,0,0,2023-04-02T08:13:54Z,??,2023-04-02T08:13:54Z
Ugykcz1mUz9YVxZTHpB4AaABAg,@yassine4201,,1,NgWujOrCZFo,1,6,2022-07-22T14:00:45Z,I have deployed a deep model in  production on real-time weld defect  inspection using my own dataset in gas pipeline production factory using rtx 3080ti on the server it works very well,2022-07-22T14:00:45Z
Ugykcz1mUz9YVxZTHpB4AaABAg.9dmnqmDvwUB9iqkx157IYr,@samsandmouse2366,Ugykcz1mUz9YVxZTHpB4AaABAg,2,NgWujOrCZFo,0,0,2022-11-25T09:29:19Z,"hi Yassine, I am very interested in your model. I am learning and would really like to see your code and work. how can i contact you",2022-11-25T09:29:19Z
UgztnkfqmaIUdqbBmI54AaABAg,@aashishmalhotra,,1,NgWujOrCZFo,0,0,2022-06-15T04:34:37Z,Thanku sir,2022-06-15T04:34:37Z
Ugxt0aVtmWeBeQKR9kh4AaABAg,@quickpresent8987,,1,NgWujOrCZFo,0,9,2022-05-16T10:55:50Z,I love you Andrew I just finishing the Bachelor degree from non tech field. And then i do self taugt with your great video and resources <br><br>I am now applying to the data scientist career hope to get the job and i give a ‚ù§Ô∏è to you thanks for teaching me and everyone !,2022-05-16T10:55:50Z
Ugy26VPSmKt9tdXynLd4AaABAg,@123arskas,,1,NgWujOrCZFo,2,72,2022-04-22T03:03:21Z,"Dear Andrew, please take good care of your health. I&#39;ve noticed over the years your health is deteriorating. I don&#39;t know if its the workload or something else but it makes all of us sad to see you like that. Please take good care of your health. You&#39;re an asset to the entire world. Thank you for the courses.",2022-04-22T03:03:21Z
Ugy26VPSmKt9tdXynLd4AaABAg.9a6JH9DrwLF9aNvUErleVM,@shakerel-sappagh5784,Ugy26VPSmKt9tdXynLd4AaABAg,2,NgWujOrCZFo,0,1,2022-04-28T23:13:00Z,Yes. You are totally right.,2022-04-28T23:13:00Z
Ugy26VPSmKt9tdXynLd4AaABAg.9a6JH9DrwLF9aVAk0PBRd2,@123arskas,Ugy26VPSmKt9tdXynLd4AaABAg,2,NgWujOrCZFo,0,1,2022-05-01T18:49:47Z,‚Äã@@123pencilboy If you were following him constantly then you&#39;d understand.,2022-05-01T18:49:47Z
UgxLK4wwird4M3bk9od4AaABAg,@DigitalAlligator,,1,e69ZWbbsGng,0,1,2022-11-08T23:21:31Z,What happened to the left face?,2022-11-08T23:21:31Z
UgyWAyE4v6aEf5JJish4AaABAg,@pretomghosh6231,,1,e69ZWbbsGng,0,0,2022-08-29T03:18:05Z,Wow! That&#39;s actually great. I found similarities between an actual project life cycle and the ML project life cycle when I think that the ML projects are never ending? Can you please enlighten me?,2022-08-29T03:18:05Z
Ugy0xaiLcSvJLR-tydB4AaABAg,@seif04,,1,e69ZWbbsGng,0,0,2022-06-05T22:52:43Z,"Prof. Andrew, is this lifecycle still valid in reinforcement learning projects ?",2022-06-05T22:52:43Z
UgzTii4f5B6R98KrU_Z4AaABAg,@cerioscha,,1,YJsRD_hU4tc,0,0,2023-04-05T00:26:45Z,"The modelling section ~ @<a href=""https://www.youtube.com/watch?v=YJsRD_hU4tc&amp;t=8m21s"">8:21</a> raises an interesting thought about the potential for synthetically generated data (which is informed by existing population parameters / heuristics) to &quot;perturb&quot; the model in a controlled way and gauge the robustness of it metrics.",2023-04-05T00:26:45Z
UgyOVGZ3-1XWa-W_Px14AaABAg,@PRATEEK30111989,,1,YJsRD_hU4tc,0,2,2022-06-16T10:34:20Z,From where  can i get the complete pipeline of how an image flows from the camera sensor to the processor then is processed by the algo and sent to the display? especially if underlying OS is android,2022-06-16T10:34:20Z
UgzDG3C1IWZ_i5O7YV54AaABAg,@zhengliu3362,,1,ErNp43wcudY,0,0,2023-09-26T02:52:17Z,Great video. Only problem is that I can&#39;t easily follow the screen scratch detection example because I&#39;m watching this video on a screen full of scratchesüòÖ,2023-09-26T02:52:17Z
UgzVtngZRCrrJ6AKAwp4AaABAg,@tagheuer001,,1,ErNp43wcudY,0,0,2023-01-18T15:32:50Z,It&#39;s pronounced &quot;cah-nare-ee&quot;  not &quot;can-aree&#39;,2023-01-18T15:32:50Z
UgwN_66CR52XfBpWYtF4AaABAg,@netmixerX,,1,ErNp43wcudY,0,4,2022-08-01T09:31:32Z,Comment test,2022-08-01T09:31:32Z
UgxyXLffjC7x-_RGtTd4AaABAg,@alymohamedhassan,,1,hq_XyP9y0xg,1,3,2022-08-10T15:29:44Z,"These videos are amazing, however is it possible to add the topic title in the video title. <br>The number of Lec. is not enough and makes it ambigious. Thank you",2022-08-10T15:29:44Z
UgxyXLffjC7x-_RGtTd4AaABAg.9eYt8AWyWS69oqVoQOjEpr,@ballerzhighlights4328,UgxyXLffjC7x-_RGtTd4AaABAg,2,hq_XyP9y0xg,0,0,2023-04-23T10:16:42Z,Yes I agree,2023-04-23T10:16:42Z
UgyslWGwPHT7bhyz8yp4AaABAg,@user-oj6vw6re5o,,1,hq_XyP9y0xg,0,0,2022-06-06T12:21:21Z,"Professor Ng became haggard, and I felt a little sad",2022-06-06T12:21:21Z
Ugx0HG7-cYKywKND8Bd4AaABAg,@growthmpsfunnels3358,,1,fiDmWKh_WeQ,0,2,2022-09-17T02:43:11Z,Sir Andrew is the best. You may know that you make a true and profound impact on people&#39;s lives leading them to the right path and not astray. That is what sets you apart sir.,2022-09-17T02:43:11Z
UgzKY9R0zdMlK78haXN4AaABAg,@Softlinks,,1,fiDmWKh_WeQ,0,0,2022-05-04T18:37:17Z,thank you so much...,2022-05-04T18:37:17Z
UgydFZTeIsIMAlkHJgd4AaABAg,@tsunamio7750,,1,fiDmWKh_WeQ,3,1,2022-04-28T11:46:07Z,"<a href=""https://www.youtube.com/watch?v=fiDmWKh_WeQ&amp;t=3m30s"">3:30</a> &quot;Make sure not to discriminate against x, y, z&quot;. &quot;Discriminate&quot; is the technical term for choosing one thing over another. Loan attribution is, by definition, a discrimination process. It is a moral imperative to prevent anyone who can&#39;t pay a loan from getting a loan. A debt trap is an even worse situation than just being poor. Hell is paved with good intentions. You must think for yourself.<br><br>You may say it is unfair that the algorithm puts a harsh weight against some groups, but if it does, it means that by giving to that group, it is more likely that many will end up in a debt trap. If you want more of those people to get what they want, without compromising their future and the algorithm&#39;s abilities, the only thing you can do is get more and better data, to differentiate with even more accuracy who really can&#39;t pay and who, despite being in a risk population, has what it takes to get the loan.",2022-04-28T11:46:07Z
UgydFZTeIsIMAlkHJgd4AaABAg.9aMgsMdUe4E9eZLgrhoVaZ,@tsunamio7750,UgydFZTeIsIMAlkHJgd4AaABAg,2,fiDmWKh_WeQ,0,0,2022-08-10T19:48:01Z,"In that sense, @gjaegreag, we agree! :)<br><br>Indeed, there definitely are biases due to the sample size. i.e. detecting an illness that only happens one in a million times, leading the algorithms to be very accurate by always returning negatives.<br><br>The kind of &quot;anti-bias&quot; I have an issue with is &quot;moral bias&quot;, where part of the data is artificially manipulated to fit the beliefs of the engineer or his company.",2023-11-01T11:20:55Z
UgydFZTeIsIMAlkHJgd4AaABAg.9aMgsMdUe4E9eZTGdpvcbK,@tsunamio7750,UgydFZTeIsIMAlkHJgd4AaABAg,2,fiDmWKh_WeQ,0,0,2022-08-10T20:54:12Z,"@gjaegreag If the data is good, the output might still be discriminatory. Reality is unjust and unfair.",2023-10-31T15:57:11Z
UgydFZTeIsIMAlkHJgd4AaABAg.9aMgsMdUe4E9eZXUEl-_ie,@tsunamio7750,UgydFZTeIsIMAlkHJgd4AaABAg,2,fiDmWKh_WeQ,0,0,2022-08-10T21:31:01Z,@gjaegreag  I know all of that. But I won&#39;t prevent you from having the last word. I can&#39;t argue with someone I agree with...,2023-11-03T12:25:21Z
UgzH3dJA5n8PAIhR2OR4AaABAg,@sedthh,,1,O5mqR4EFBQk,0,0,2023-07-31T14:56:55Z,"<a href=""https://www.youtube.com/watch?v=O5mqR4EFBQk&amp;t=6m39s"">6:39</a> should be taught in every DS course, thank you Andrew Ng!",2023-07-31T14:56:55Z
UgyWYj0JV1FD5P-k0MN4AaABAg,@afkhoso,,1,quEHyoA94rw,1,0,2023-11-28T01:02:33Z,"around <a href=""https://www.youtube.com/watch?v=quEHyoA94rw&amp;t=3m00s"">3:00</a> you say you sometimes track those noise factors in spreadsheets... i dont understand how that is possible? data is too vast. maybe if it&#39;s only 100 records to go through, but 1000, 10000, a million? or are you saying you delegate it and maybe others take chunks to notate this?",2023-11-28T01:02:33Z
UgyWYj0JV1FD5P-k0MN4AaABAg.9xdQUEBz2999xdQlpM4PwE,@afkhoso,UgyWYj0JV1FD5P-k0MN4AaABAg,2,quEHyoA94rw,0,0,2023-11-28T01:05:05Z,"oh, spoke too soon. so landing lens is used to do this?",2023-11-28T01:05:05Z
UgxiyKci8tSJmVTy4h54AaABAg,@afkhoso,,1,BdZ6bjcixhk,0,0,2023-11-28T01:14:18Z,"how are we even getting HLP? in the factory example of the cell phone screen scratches, the ENTIRE INVENTORY is not going to be quality-checked by humans.. or does it? if we&#39;re producing 1,000,000 phones, do they ALL go through a human check point for quality? im guessing it&#39;s more random checks, in batches, maybe 1 in 50.",2023-11-28T01:14:18Z
Ugz-7ezBSrVg7nUi5ep4AaABAg,@jalil_kartal,,1,BdZ6bjcixhk,0,0,2022-11-21T18:11:50Z,Very useful and valuable solutions.,2022-11-21T18:11:50Z
UgwLNGfRyhrhZ96LFj94AaABAg,@YannStoneman,,1,BlxnbyvHTyI,0,0,2022-07-19T02:48:52Z,Thanks for making the F1 score concept so clear to me! üéâ,2022-07-19T02:48:52Z
Ugwu0C9lrCivsUWtJhV4AaABAg,@fr.paschal,,1,O9ZrPXPLmWg,0,0,2023-10-02T18:20:03Z,Thank you sir. Please what do we mean by a model being large ?,2023-10-02T18:20:03Z
Ugy7BXoirnV4MSv0q3N4AaABAg,@YannStoneman,,1,O9ZrPXPLmWg,0,0,2022-07-19T16:10:22Z,"Thank you! I learned here that when you have a corner case where even humans find the mapping ambiguous, like 1 vs I written as a single line, the model‚Äôs choice of mapping is influenced by the frequency of a certain mapping choice in the training data. For example, the model will choose a mapping of 1 more often if that‚Äôs what that I was mapped to more often in the training data. <br><br>And the significance is that you can indeed skew your model in an arbitrary way in computer vision cases like this.",2022-07-19T16:10:22Z
UgwlvxlzoWfbaCnP8Wd4AaABAg,@YannStoneman,,1,DTd7TyY7a-0,0,1,2022-07-19T16:48:25Z,"Takeaway for me: there‚Äôs a trend to move from collaborative filtering to content filtering, because the latter solves the cold start problem for recommendation engines: you don‚Äôt need a bunch of people to have already liked a product, you can instead recommend based on characteristics of the product and a single user profile as a whole.",2022-07-19T16:48:25Z
UgytSvd-qXURipUhuG54AaABAg,@YannStoneman,,1,f5sN3xAEAWQ,0,1,2022-07-19T19:34:43Z,"Good idea: don‚Äôt try to figure out labeling rules myself as the MLOps guy, but rather ask the inspectors (or whatever domain expert) to agree amongst each other on the specifics.<br><br>Thank you!",2022-07-19T19:34:43Z
Ugz2nQ_HmKLeQAdGykJ4AaABAg,@YannStoneman,,1,f5sN3xAEAWQ,0,0,2022-07-19T19:15:07Z,"Really interesting point, that one of the reasons we tend to think big data is required for ml is that ml grew up with large consumer companies",2022-07-19T19:15:07Z
UgymNBF1zCmtOtVs0Gh4AaABAg,@afkhoso,,1,a-oCxdzFapE,0,0,2023-11-29T04:19:38Z,the labelers mentioned (at start of video).. are they the human&#39;s or is it a system-generate algo that is doing the labelling?,2023-11-29T04:19:38Z
Ugwi7uw9DfrYxRXjXJt4AaABAg,@awaisnayyar8647,,1,Ny970B12IQk,0,0,2023-08-29T10:00:35Z,"I have a Question, as per this video you mean our Learning algorithm will never become more accurate than HLP in reality?",2023-08-29T10:00:35Z
Ugx5jWFXpRaJ3SstHLV4AaABAg,@skssks9993,,1,Ny970B12IQk,0,0,2022-06-05T09:38:34Z,Thanks a lot,2022-06-05T09:38:34Z
UgzZw--Cur6teArs1v14AaABAg,@farleylai1102,,1,mFD5hUZubTI,0,1,2022-09-01T03:16:01Z,"Should be week 3, not 1",2022-09-01T03:16:13Z
UgylwQkVi7-SWuqO-l94AaABAg,@ssssssstssssssss,,1,43CZ0HjIC7U,0,0,2023-03-22T22:55:15Z,I think some of the problems you listed are actually solutions and there are more fundamental problems lurking beneath them.,2023-03-22T22:55:15Z
UgxBgQlNI1uBzMqKDeZ4AaABAg,@danpittsley740,,1,43CZ0HjIC7U,1,3,2022-05-30T17:08:28Z,"Another consideration I&#39;ve found useful: Is there a non-AI solution that can be attempted first?<br><br>As an ML engineer it&#39;s not as fun, but sometimes we can avoid all the headaches associated with ML/AI solutions by attempting a simple solution at first.",2022-05-30T17:08:28Z
UgxBgQlNI1uBzMqKDeZ4AaABAg.9befCGJZLFc9nqliSwsDLE,@andreamansi2441,UgxBgQlNI1uBzMqKDeZ4AaABAg,2,43CZ0HjIC7U,0,2,2023-03-29T16:13:02Z,"I totally agree<br>For example, sometimes simpler statistical approaches perform best, and time to develop is like 1%",2023-03-29T16:13:02Z
Ugz4T2d_M1XD8mhu8Sh4AaABAg,@oscarllerena2980,,1,9p7WWapTrpA,0,0,2023-07-07T07:16:39Z,zero implementation,2023-07-07T07:16:39Z
UgxFPJjDJneFnIiqF9x4AaABAg,@GWebcob,,1,9p7WWapTrpA,1,1,2023-02-10T04:24:53Z,Finished it! üòÖ,2023-02-10T04:24:53Z
UgxFPJjDJneFnIiqF9x4AaABAg.9lwUJeRK2Kp9mdCcr-NScC,@kennedyj7023,UgxFPJjDJneFnIiqF9x4AaABAg,2,9p7WWapTrpA,0,1,2023-02-27T13:16:11Z,"You are the man Gabriel, you got a great future",2023-02-27T13:16:11Z
UgzgsguOrCyvVouGRWN4AaABAg,@noisycarlos,,1,NJaVkJDrBCc,0,0,2022-04-08T23:56:58Z,"RIP my subscription box, but thank you for the course. I&#39;ll check it out",2022-04-08T23:56:58Z
UgwU1f55C2ifOLjB-Wd4AaABAg,@DamafiakingzDMK,,1,NJaVkJDrBCc,1,1,2022-04-08T23:18:11Z,Andrew NG is My HERO,2022-04-08T23:18:11Z
UgwU1f55C2ifOLjB-Wd4AaABAg.9__RAglUv179a40qQKC-Fs,@gumbo64,UgwU1f55C2ifOLjB-Wd4AaABAg,2,NJaVkJDrBCc,0,0,2022-04-21T05:43:47Z,my man,2022-04-21T05:43:47Z
UgwbBxF47OKKm37eM_t4AaABAg,@ixy6864,,1,NJaVkJDrBCc,0,0,2022-01-20T16:45:17Z,üòò thank you very much. your free course is good! I am entitled from those classes.,2022-01-20T16:45:17Z
Ugy8sJ0jZQMAyavimsN4AaABAg,@osmanmohamed2422,,1,3WaqixS_yO0,0,1,2022-04-09T14:26:20Z,Great!,2022-04-09T14:26:20Z
UgxsNJCqOIdSb2DBdSV4AaABAg,@adityarana7956,,1,ExMG-9-ridg,0,0,2022-06-06T05:30:00Z,Can you tell what was the patent idea?,2022-06-06T05:30:00Z
Ugxv30kjZPlrecaW50N4AaABAg,@erenyeager4452,,1,4Gq9E7m98xs,0,0,2022-04-09T07:27:40Z,"hey, it would be a good idea to show their educational background before taking this course. thanks.",2022-04-09T07:27:40Z
UgyOQzYAEYjrcrKxRQ14AaABAg,@SnipeSniperNEW,,1,4Gq9E7m98xs,0,0,2022-04-08T23:03:43Z,Finished the course 2 weeks ago let&#39;s hope I can land something soon üôè,2022-04-08T23:03:43Z
Ugz0U0RJiR7_XsSJcz14AaABAg,@inakigorostiaga6305,,1,H343JRrncfc,0,0,2023-03-31T17:25:14Z,Jsjsjsj<br><br>Pl),2023-03-31T17:25:14Z
UgxNa4ZniAGEMTNIjx14AaABAg,@johnfunk7568,,1,H343JRrncfc,0,1,2022-03-04T23:46:51Z,"Thanks Andrew and Chris.  Getting in the <a href=""http://dl.ai/"">DL.ai</a> NLP Specialization next week.",2022-03-04T23:46:51Z
UgzP10Dw4tD1OUEgGZ54AaABAg,@LinghuiZeng,,1,H343JRrncfc,0,1,2021-10-06T06:25:05Z,"fantastic talk! A great introduction to the motivation of neural attention mechanism, transformer and glove. The dominant thing about creativity is to break things, to learn by failing and, to read incredibly wildly and wind up making strange connections. Adapt news ideas and keep learning.",2021-10-06T06:25:05Z
UgwfMX8SgHQzOG7mirN4AaABAg,@berouaz2417,,1,H343JRrncfc,0,1,2021-08-31T22:27:47Z,Fait moi abonne merci,2021-08-31T22:27:47Z
UgwbIk0bIcOSmliDvUV4AaABAg,@JH-bb8in,,1,H343JRrncfc,0,2,2020-10-15T05:07:27Z,I took CS224 from him back in 2006 and he was a very sharp prof!,2020-10-15T05:07:27Z
Ugwem_QxpzeEGZ1NT1l4AaABAg,@davewbaldwin3369,,1,H343JRrncfc,0,7,2020-10-14T11:04:04Z,"Recommend watching Manning&#39;s lectures!  I may be showing my age (57), but Manning is someone who speaks from perspectives related to &#39;old school&#39; transitioning into &#39;new school&#39; and you can see the evolution if you keep up with his lecture series.",2020-10-14T11:04:04Z
UgyTvpd8G3EiI2K2Kr54AaABAg,@marolibez,,1,DffGdrfY9gI,0,0,2023-11-12T22:24:22Z,I am so happy to come across this interview with Kathleen! We have the same background (comparative literature) and she gave me hope in my current endeavour to break in AI and NLP :) Lots of love from Brazil!,2023-11-12T22:24:22Z
UgysIdOPN18V59p8McB4AaABAg,@shorttimecamping_freak,,1,DffGdrfY9gI,0,0,2020-12-26T08:34:00Z,"I stepped into the world of natural language processing from the patent field. I am interested in the diversity of word meanings, including individual differences. I found this article very interesting.",2020-12-26T08:34:00Z
Ugy7sWP3rpWR97_mxzl4AaABAg,@fontanads,,1,DffGdrfY9gI,0,0,2020-10-19T13:46:18Z,"Great interview. I am shifting from classic signal processing research to machine learning based applications, and I aim to work with interdisciplinary research. For instance, I took the NLP specialization in order to guide students on an automatic depression symptoms detector in social networks. Listening to a very experienced and successful researcher as Kathleen is truly inspiring to continue to pursue these type of problems. Thanks for this video!",2020-10-19T13:46:18Z
Ugzp3hGXHbqDbo29dOh4AaABAg,@zz-9463,,1,DffGdrfY9gI,0,0,2020-10-13T22:34:26Z,very inspiring! thx!,2020-10-13T22:34:26Z
Ugwfz_KT86-pVi1Mtat4AaABAg,@vladimirbosinceanu5778,,1,DffGdrfY9gI,0,4,2020-10-13T17:23:54Z,"This was really inspiring for me. I am a songwriter with a masters in psychotherapy and now I&#39;m already building my own ANNs for all sorts of data I scrape of the web. I too have started on my own and found it a bit overwhelming at the start, but it didn&#39;t take too long until I found out that I love data science and machine learning. A big thank you for the video!",2020-10-13T17:24:27Z
Ugw4iKelTJiT8P5bPep4AaABAg,@sancharisen5309,,1,DffGdrfY9gI,0,1,2020-10-13T17:02:44Z,A great influencing video ‚ù§Ô∏è. Thank you so much for the precious ‚ù§Ô∏è.,2020-10-13T17:02:44Z
Ugwjm9C-JnKB2-93b1Z4AaABAg,@chandankumarsah5514,,1,DffGdrfY9gI,0,0,2020-10-13T16:41:11Z,Thanks Andrew Ng sir and Kathleen McKeown‚ù§,2020-10-13T16:41:11Z
UgxjMDjDhYOwN6T4EAJ4AaABAg,@chandankumarsah5514,,1,DffGdrfY9gI,0,0,2020-10-13T16:39:34Z,Great,2020-10-13T16:39:34Z
Ugz72LHpEaz9gL74FyV4AaABAg,@akash.deblanq,,1,DffGdrfY9gI,0,0,2020-10-13T16:10:30Z,&lt;3,2020-10-13T16:10:30Z
Ugz5IjLttMnBWEwPSn14AaABAg,@jonathanlorence8939,,1,PiF2Aln-L3w,0,0,2020-11-01T11:08:07Z,Thanks Andrew .,2020-11-01T11:08:07Z
UgyCn1NJMeu_PaQwim94AaABAg,@user-or7ji5hv8y,,1,PiF2Aln-L3w,0,0,2020-10-14T12:10:24Z,Lots of great insights.,2020-10-14T12:10:24Z
UgxWOf9pkHf6FKs-J2h4AaABAg,@Excel_Mantra,,1,PiF2Aln-L3w,0,2,2020-10-14T00:30:00Z,Good morning üîÜüåªüôè,2020-10-14T00:30:00Z
UgyGlGlxS43qbBNnHJ54AaABAg,@anikgupta3929,,1,KGI7K_ehHsU,0,0,2022-06-10T12:51:37Z,What AI books have you read Quoc?,2022-06-10T12:51:37Z
UgwUuCKo44CTq2hKmcp4AaABAg,@vtrandal,,1,KGI7K_ehHsU,3,1,2022-01-05T20:30:51Z,What? You (Andrew Ng) recruited Geoffrey Hinton as an intern at Google Brain?,2022-01-05T20:30:51Z
UgwUuCKo44CTq2hKmcp4AaABAg.9Wpf5f8hzVQ9aV365RytdF,@TommyEVO3D,UgwUuCKo44CTq2hKmcp4AaABAg,2,KGI7K_ehHsU,0,1,2022-05-01T17:43:02Z,Exactly what I&#39;m thinking lol,2022-05-01T17:43:02Z
UgwUuCKo44CTq2hKmcp4AaABAg.9Wpf5f8hzVQ9c5XTsV4U3K,@anikgupta3929,UgwUuCKo44CTq2hKmcp4AaABAg,2,KGI7K_ehHsU,0,1,2022-06-10T12:50:58Z,I think it&#39;s Jeff Hinton... probably another young guy lol.,2022-06-10T12:50:58Z
UgwUuCKo44CTq2hKmcp4AaABAg.9Wpf5f8hzVQ9p9Umv8jjMW,@jovelnom,UgwUuCKo44CTq2hKmcp4AaABAg,2,KGI7K_ehHsU,0,0,2023-05-01T04:32:34Z,Mind blowing ü§Ø,2023-05-01T04:32:34Z
UgxfkJUOmHTZLQebM0l4AaABAg,@tienphammanh8522,,1,KGI7K_ehHsU,0,0,2021-07-03T16:58:56Z,Thank you for a great talk. Your story makes me more energy¬†and¬†determination for my journey.,2021-07-03T16:58:56Z
Ugx3AxciV2cteP43qCx4AaABAg,@ambujmittal6824,,1,KGI7K_ehHsU,0,0,2020-11-01T15:48:33Z,Please do an interview with Kaiming He for the deep learning heroes series. His contributions to the field are invaluable and I am sure many people want to hear out his story as well.,2020-11-01T15:48:33Z
Ugy7_mJWRdq6ujy9AQx4AaABAg,@bhakta43,,1,KGI7K_ehHsU,0,4,2020-10-17T21:09:47Z,"The joy of Andrew is palpable, he looks happy like a kid with a box of chocolates - that attitude is infectious, only I end up with more calories than NLP courseworks :)",2020-10-17T21:09:47Z
Ugz1B-cHYEQq5U_w8Ft4AaABAg,@quocanhnguyen7275,,1,KGI7K_ehHsU,0,0,2020-10-17T00:37:50Z,Wwhooooooohooooooo,2020-10-17T00:37:50Z
Ugy9rDCR_cuiNWj58Gp4AaABAg,@sanganh6717,,1,KGI7K_ehHsU,0,0,2020-10-14T12:44:28Z,Lovely üòçüíã üíùüíñ‚ù§Ô∏è,2020-10-14T12:44:28Z
UgycJMF0zGYGcylRaD14AaABAg,@quanghuyngo7556,,1,KGI7K_ehHsU,0,7,2020-10-14T06:50:56Z,Quoc Le - one of the most talented AI researchers today with his work. Absolutely stunning!,2020-10-21T09:13:58Z
UgyfEPW5GxCZxgukMNl4AaABAg,@madaragrothendieckottchiwa8648,,1,KGI7K_ehHsU,0,1,2020-10-13T23:35:44Z,Thank you  for work,2020-10-13T23:35:44Z
Ugyg0Y-H2RiGks-1EBx4AaABAg,@hieuza,,1,KGI7K_ehHsU,0,4,2020-10-13T21:45:15Z,"<a href=""https://www.youtube.com/watch?v=KGI7K_ehHsU&amp;t=06m54s"">06:54</a> Adam Coates&#39;s paper+result: <a href=""https://ai.stanford.edu/~ang/papers/nipsdlufl10-AnalysisSingleLayerUnsupervisedFeatureLearning.pdf"">https://ai.stanford.edu/~ang/papers/nipsdlufl10-AnalysisSingleLayerUnsupervisedFeatureLearning.pdf</a><br><a href=""https://www.youtube.com/watch?v=KGI7K_ehHsU&amp;t=08m12s"">08:12</a> &quot;Cat paper&quot;: <a href=""https://arxiv.org/abs/1112.6209"">https://arxiv.org/abs/1112.6209</a>",2020-10-13T21:45:15Z
UgyYNsmhV2asLwdz_fZ4AaABAg,@mrzgrim2366,,1,KGI7K_ehHsU,0,0,2020-10-13T21:01:05Z,respect.,2020-10-13T21:01:05Z
Ugxf1CO-LSmIVdcEzqx4AaABAg,@amilkarherrera9804,,1,1-8W6z4wBJU,0,0,2021-04-23T08:06:33Z,Thank you very much for the talk. I&#39;m from Panama and it¬¥s nice to see that people from Latin America are doing well in ML and AI,2021-04-23T08:06:33Z
UgwsDSgYDyG0BETy1Nd4AaABAg,@SUMERSINGH,,1,vMnBE9FF9vg,1,2,2020-07-27T17:16:40Z,"Thanku Sir for this,... do you have any videos related to CNN as well?<br>I am working on some Project....",2020-07-27T17:16:40Z
UgwsDSgYDyG0BETy1Nd4AaABAg.9BcKxKzplUV9CFm8zGXI91,@nikeshbajaj2029,UgwsDSgYDyG0BETy1Nd4AaABAg,2,vMnBE9FF9vg,0,0,2020-08-12T10:12:41Z,I don&#39;t have but there are plenty. Check Coursera&#39;s deeplearning specialization or tensorflow specialization. they are very helpful,2020-08-12T10:12:41Z
Ugw_6graGOd3WXGb1fh4AaABAg,@patelviralahmedabad,,1,vMnBE9FF9vg,0,3,2020-07-16T08:45:58Z,Thank you Nikesh for sharing your incredible knowledge. Very helpful,2020-07-16T08:45:58Z
UgzNFdoH9KyRMCuJ_YR4AaABAg,@bayanrubaie6628,,1,7BNFJ2Fc-P8,1,1,2021-02-14T01:26:01Z,Wow interesting,2021-02-14T01:26:01Z
UgzNFdoH9KyRMCuJ_YR4AaABAg.9JiljIUMcAZ9b9-9ynAmxs,@morebaie3412,UgzNFdoH9KyRMCuJ_YR4AaABAg,2,7BNFJ2Fc-P8,0,0,2022-05-18T00:36:43Z,Thanks,2022-05-18T00:36:43Z
UgyOUDbUH8NbUmeWnDx4AaABAg,@shikhaprajapati8540,,1,7BNFJ2Fc-P8,1,2,2020-10-29T17:43:32Z,Hi how can we get info of such events?? I wanna involve..,2020-10-29T17:43:32Z
UgyOUDbUH8NbUmeWnDx4AaABAg.9FPQkPwKAEw9b9-98FPiHu,@morebaie3412,UgyOUDbUH8NbUmeWnDx4AaABAg,2,7BNFJ2Fc-P8,0,0,2022-05-18T00:36:36Z,"Check all events at <a href=""http://deeplearning.ai/"">DeepLearning.AI</a> website and social media channels",2022-05-18T00:36:36Z
UgyFm8krGNMyGf0yCv94AaABAg,@ramanshsharma5441,,1,u1VJdicsPEE,0,0,2020-09-24T04:50:12Z,Thank you for sharing your experience with us Sachin,2020-09-24T04:50:12Z
Ugzhx6yXqUSITUzDS7l4AaABAg,@kavitachoudhary1112,,1,u1VJdicsPEE,0,0,2020-09-09T10:21:00Z,hi i am kavita from indore ..please guide how to start my research in NLP or any suggestion which topic i choose for my phd ..,2020-09-09T10:21:00Z
Ugx_FZdDrpDIMKDC1sV4AaABAg,@Sachin27071998,,1,u1VJdicsPEE,0,0,2020-08-21T05:34:30Z,"Link to the slides: <a href=""https://drive.google.com/file/d/14rDMNdRCOUbe46LFilAFjkXBBkRhsLqx/view?usp=sharing"">https://drive.google.com/file/d/14rDMNdRCOUbe46LFilAFjkXBBkRhsLqx/view?usp=sharing</a>",2020-08-21T05:34:30Z
UgyoNJQlZf9peOe_rJB4AaABAg,@Sachin27071998,,1,u1VJdicsPEE,0,1,2020-08-21T05:26:55Z,Thank you for hosting me! It was a great opportunity to present my points and experiences with everyone :),2020-08-21T05:26:55Z
UgwDobi4RsdDABjLD9l4AaABAg,@aymanpatel,,1,-LjJO5trqdA,0,1,2020-10-31T16:35:20Z,Nicely explained Rishit. Keep it going,2020-10-31T16:35:20Z
UgzBCL54OtoDHK_cn7J4AaABAg,@anshubhatia8998,,1,-LjJO5trqdA,0,1,2020-10-31T04:44:10Z,One of the reasons why I am so interested in data science is because of you! So well presented!,2020-10-31T04:44:10Z
UgySs26Cb4dwVCz5HYh4AaABAg,@DanMonster97,,1,-LjJO5trqdA,0,1,2020-10-29T17:46:13Z,Nicely explained!,2020-10-29T17:46:13Z
UgwZlsKP2CcJ44V6PgF4AaABAg,@porchahill5589,,1,az7Og6k_-3o,0,1,2022-05-18T16:24:02Z,How do make animal hath,2022-05-18T16:24:02Z
Ugyxl7h1Do8HXbWZIDN4AaABAg,@aiuniversity9457,,1,_wxSoMmqnkg,0,0,2020-11-30T14:27:05Z,"8 Weeks Immersive Artificial Intelligence  Boot camp Led by Ex-Google AI Scientist. We offer full time/part time , fast track courses with Job placement Apply today <a href=""https://globalaiu.com/"">https://globalaiu.com</a>",2020-11-30T14:27:05Z
Ugzi7bsmrFdrKCvLSMJ4AaABAg,@abdalsalamsankari1055,,1,_wxSoMmqnkg,0,0,2020-10-29T22:55:35Z,ŸÖŸÜŸàÿ± ÿØÿßŸäŸÖÿß,2020-10-29T22:55:35Z
UgyAcZlY7nxnWq6IrSp4AaABAg,@porchahill5589,,1,3aL3J5tlw7s,0,0,2022-05-18T17:44:23Z,Hi   how do I  apply to work,2022-05-18T17:44:23Z
UgzLDM9JkzEM8y1kD5Z4AaABAg,@porchahill5589,,1,3aL3J5tlw7s,0,0,2022-05-18T17:40:13Z,I have ‚ùì,2022-05-18T17:40:13Z
UgzehOLPhiwvNZcZDpd4AaABAg,@SimulationFirst,,1,3aL3J5tlw7s,0,0,2020-06-16T20:30:38Z,"Sculley paper: <a href=""https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf"">https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf</a>",2020-06-16T20:30:38Z
UgzDDmxcHzp-CObFOGF4AaABAg,@geoffreyanderson4719,,1,JvAJiU28Zfw,0,0,2021-07-09T21:41:20Z,"The man asked, &quot;What is linear regression?&quot; even while he was taking the Deep Learning specialization haha.  If you take courses in the right order, you might (?) be less confused haha.  The prerequisite for Andrew Ng&#39;s Deep Learning specialization, is Andrew Ng&#39;s (long) Machine Learning course on Coursera!  It&#39;s a great course.  There are also similar alternatives.  Don&#39;t skip prereq&#39;s haha",2021-07-09T21:41:20Z
Ugwdir7ZhI4ngMOb04V4AaABAg,@longchen9281,,1,JvAJiU28Zfw,0,0,2020-07-04T16:18:23Z,"Similar experience here. Proud of you and  best luck to you, Daniel! Getting the best of your interest is a part of life.",2020-07-04T16:18:23Z
Ugy1jMjn6Wgv0PSh4tl4AaABAg,@machinistnick2859,,1,U1bIc6pFdw4,0,0,2021-03-30T11:40:48Z,Thanks,2021-03-30T11:40:48Z
Ugx-EPRPZ_gW_UhQ-VN4AaABAg,@longchen9281,,1,U1bIc6pFdw4,0,0,2020-07-04T16:21:31Z,Exciting experience from Christine to light up the road ahead for those who are still in the tunnel.,2020-07-04T16:21:31Z
UgxKE-xOFCSCSOs79lJ4AaABAg,@cristhian4513,,1,U1bIc6pFdw4,0,0,2020-05-29T14:36:32Z,que bonita :0,2020-05-29T14:36:32Z
UgxUcdATo1_hdMKeVVx4AaABAg,@patrickprakash8,,1,U1bIc6pFdw4,0,0,2020-04-16T15:12:04Z,"She said deep learning sequence instead of &quot;Specialization&quot; <a href=""https://www.youtube.com/watch?v=U1bIc6pFdw4&amp;t=3m00s"">3:00</a>",2020-04-16T15:12:18Z
UgyeoGqQvegdvrdyyvZ4AaABAg,@codingquiz,,1,U1bIc6pFdw4,0,0,2020-04-09T00:48:41Z,thanks,2020-04-09T00:48:41Z
Ugy-xgjev1oGn7pvrn14AaABAg,@gabykun,,1,U1bIc6pFdw4,0,1,2019-06-11T14:42:38Z,Anyone here new to programming we&#39;re same.,2019-06-11T14:42:38Z
UgxIwlBOjNfmeTBf9wV4AaABAg,@aidenstill7179,,1,U1bIc6pFdw4,3,0,2019-05-27T13:49:45Z,What do I need to know to create my own Python deep learning framework? What are the books and courses to get knowledge for this?,2019-05-27T13:49:45Z
UgxIwlBOjNfmeTBf9wV4AaABAg.8vRTqEbq0ru8w4IC7iQM43,@FaizanShaikh-zg9to,UgxIwlBOjNfmeTBf9wV4AaABAg,2,U1bIc6pFdw4,0,0,2019-06-12T10:16:53Z,"First, do <br>machine learning course of Andrew ng Stanford course on Coursera  :<a href=""https://www.coursera.org/learn/machine-learning"">https://www.coursera.org/learn/machine-learning</a><br>or you can Watch Siraj Rawal video on youtube of how, to begin with, ML<br>If you already had Knowledge of python, Calculus, Linear Algebra  And ML completed go for deep learning Course.",2019-06-12T10:16:53Z
UgxIwlBOjNfmeTBf9wV4AaABAg.8vRTqEbq0ru97WTxKRFKBt,@patrickprakash8,UgxIwlBOjNfmeTBf9wV4AaABAg,2,U1bIc6pFdw4,0,0,2020-04-16T15:15:03Z,@@FaizanShaikh-zg9to Don&#39;t watch Siraj. He is fraud,2020-04-16T15:15:03Z
UgxIwlBOjNfmeTBf9wV4AaABAg.8vRTqEbq0ru97a1NreZ19q,@FaizanShaikh-zg9to,UgxIwlBOjNfmeTBf9wV4AaABAg,2,U1bIc6pFdw4,0,0,2020-04-18T09:41:36Z,@@patrickprakash8yes bro this comment was 10 months ago and at that time he doesn&#39;t have any dirt on his clothes.,2020-04-18T09:41:36Z
UgxU_sd53Oj49pzgRFJ4AaABAg,@gmshadowtraders,,1,U1bIc6pFdw4,0,0,2019-05-23T10:29:57Z,"Awesome, she is a beauty and brains extraordinaire. And Andrew, you rock as one of the giants of the ML world. Respektos.",2019-05-23T10:29:57Z
Ugw_hCCT8xkDN70PSOt4AaABAg,@zelllers,,1,U1bIc6pFdw4,0,3,2019-05-22T20:30:55Z,Is Machine Learning an instrument?<br><br><br>-Patrick,2019-05-22T20:30:55Z
UgwAdYhUQKUQ5GO8t9J4AaABAg,@saanvisharma2081,,1,U1bIc6pFdw4,0,1,2019-05-22T18:17:09Z,Andrew is asking questions on behalf of us..... that&#39;s great,2019-05-22T18:17:09Z
UgxDX7PIfEM2DACMoIp4AaABAg,@YourMakingMeNervous,,1,U1bIc6pFdw4,0,1,2019-05-22T15:11:09Z,Cool! Would have loved to hear more about your physics background.,2019-05-22T15:11:09Z
UgxDaq94haGxeFt8W9h4AaABAg,@trivials2960,,1,U1bIc6pFdw4,0,0,2019-05-22T05:21:21Z,Wow me second!! Awesome üòã,2019-05-22T05:21:21Z
UgzesJ18LkCF8yjx0Ul4AaABAg,@dudekulavidyasagar3745,,1,U1bIc6pFdw4,0,0,2019-05-22T01:47:07Z,First,2019-05-22T01:47:07Z
UgwP--NH5AVkr4YclsF4AaABAg,@carloscampo9119,,1,LWI3b5GtwVc,0,1,2020-08-21T03:39:08Z,"Andrew Ng and <a href=""http://deeplearning.ai/"">deeplearning.ai</a> came to Colombia, that&#39;s great!",2020-08-21T03:39:08Z
UgxsubjccIPMmyv9fKd4AaABAg,@sahindas4114,,1,LWI3b5GtwVc,0,0,2020-06-20T14:34:01Z,its really great to learn from him,2020-06-20T14:34:01Z
UgzWx-a-2yUYIGVXNvJ4AaABAg,@ivanpaez5332,,1,LWI3b5GtwVc,0,5,2019-11-08T11:34:22Z,"Well done for bringing Andrew Ng to Colombia to explain ML &amp; AI, keep it up!",2019-11-08T11:34:22Z
Ugw5bw6R5Z52vQ7tu5V4AaABAg,@goldilockszone4389,,1,wlQvPJHxfOE,0,0,2019-11-17T09:39:28Z,"Just put on subtitles from here (<a href=""https://www.youtube.com/watch?v=wlQvPJHxfOE&amp;t=20m43s"">20:43</a>) and read what it say...Andrew will fall over if he sees this lol",2019-11-17T09:39:28Z
UgzBhH38vo2VIBBXk5h4AaABAg,@Zineb-ru8bp,,1,wlQvPJHxfOE,0,3,2019-09-23T17:22:48Z,Andrew... what&#39;s wrong with Africa ?,2019-09-23T17:22:48Z
UgzOI_IAJLOz0Bny9-x4AaABAg,@windar2390,,1,wlQvPJHxfOE,0,1,2019-09-18T11:48:22Z,very bad audio :(,2019-09-18T11:48:22Z
Ugy6x6E_wtGD7Zxirh94AaABAg,@orionchang4827,,1,wlQvPJHxfOE,0,0,2019-09-18T06:24:29Z,I&#39;m wondering if Dr. Ng is currently a doctoral advisor and willing to guide doctoral students?,2019-09-18T06:24:29Z
UgzDynHc5w9onWh5raZ4AaABAg,@yabcodev4585,,1,wlQvPJHxfOE,0,1,2019-09-17T21:22:02Z,What&#39;s wrong with my ears?,2019-09-17T21:22:02Z
UgwBkmY2lWFKUUghUAB4AaABAg,@avinashdwivedi2015,,1,wlQvPJHxfOE,0,0,2019-09-17T17:55:44Z,I understand everything,2019-09-17T17:55:44Z
UgyQqyqImOYgb1PK5N14AaABAg,@toastersman217,,1,wlQvPJHxfOE,0,19,2019-09-17T07:31:15Z,"If you dont understand some things that Andrew said, dont worry about it.",2019-09-17T07:31:15Z
Ugxh7oHDJYVUjtYGN4d4AaABAg,@bhabeshmali3640,,1,j2nGxw8sKYU,0,1,2022-07-18T14:21:38Z,"&quot; If you don&#39;t understand, don&#39;t worry &quot; ~ A great man.",2022-07-18T14:21:38Z
Ugwm2hVeNuy1VVqThfx4AaABAg,@angryandy2000,,1,j2nGxw8sKYU,0,0,2021-11-25T10:08:28Z,great show David.  when are you going to have Andrew Ng on show,2021-11-25T10:08:28Z
Ugx8-p0J5MPExYiFTHh4AaABAg,@taneemishere,,1,j2nGxw8sKYU,0,0,2021-04-21T05:10:09Z,"If you don&#39;t understand it, don&#39;t worry about it. This is the line that gives me the motivation to learn almost any hard topic. Thanks Andrew Ng, I have been blessed to have you as my teacherü•∞ü•∞",2021-04-21T05:10:09Z
UgzYo2dlM0_TCDn6BAp4AaABAg,@machinistnick2859,,1,j2nGxw8sKYU,0,1,2021-04-01T19:55:32Z,"With AI take everyone along with us, i like that line<br>thanks",2021-04-01T20:11:16Z
UgzqrgiA0tqB1vgiYLx4AaABAg,@huabao0975,,1,j2nGxw8sKYU,0,0,2021-01-29T15:17:29Z,His coursera courses are the best out there. He is a very good teacher aside from being a true guru in machine learning.,2021-01-29T15:17:29Z
UgwjNqWIRh80yMDA5-J4AaABAg,@neuron8186,,1,j2nGxw8sKYU,0,0,2021-01-25T15:17:43Z,If you don&#39;t work at Amazon &quot; don&#39;t worry about it &quot;,2021-01-25T15:17:43Z
UgwzglTMYrxk6SoX5_F4AaABAg,@alexandercle,,1,j2nGxw8sKYU,0,0,2020-12-15T22:09:07Z,"For the sake of helping others, could anyone, please be so kind to help me contact Mr. Andrew Ng directly. All public sources are outdated. Promise to repay you with my life.Thank you alexandercle@<a href=""http://gmail.com/"">gmail.com</a>",2020-12-15T22:09:07Z
Ugy7cA_cyNyw5yk_lBp4AaABAg,@billysaku3033,,1,j2nGxw8sKYU,0,1,2020-11-08T21:18:32Z,"Andrew and Coursera really change my life, thank you a lot!",2020-11-08T21:18:32Z
Ugzd7MfjCFCToisX6Qp4AaABAg,@arnavverma8622,,1,j2nGxw8sKYU,0,0,2020-08-29T08:17:04Z,Andrew Sir you are a Legend üëåüëå,2020-08-29T08:17:04Z
Ugye8mazeyBw0B-_ICR4AaABAg,@rgnzls6483,,1,j2nGxw8sKYU,0,0,2020-04-15T13:15:07Z,He even dresses exactly like Andrew Yang lmao,2020-04-15T13:15:07Z
UgxJ4uxT_qtcD9abN5p4AaABAg,@rpodcoworkingspace,,1,j2nGxw8sKYU,0,0,2019-12-11T11:25:27Z,Thanks heaps for sharing. ^^,2019-12-11T11:25:27Z
UgxGun0GDgcOGO3SfsZ4AaABAg,@mehdi179,,1,j2nGxw8sKYU,0,0,2019-11-17T19:33:39Z,"I am hoping for a combination of DataCamp and Coursera to emerge. DataCamp is practical and easy. Coursera&#39;s programming assignments are Hard. From the view point of learning computer Science, Coursera is hard, but DataCamp is easy and step by step problem solving helper.",2019-11-17T19:36:24Z
UgybacIFj-N9f0fzRdl4AaABAg,@AspectEquity,,1,j2nGxw8sKYU,0,0,2019-10-20T10:30:21Z,Was hoping there would be a &quot;concretely&quot; reference in the comments,2019-10-20T10:30:21Z
UgwLdn8zXzfDGmMhglh4AaABAg,@grandplazaunited,,1,j2nGxw8sKYU,0,2,2019-10-17T07:38:52Z,Last thought is so important- let‚Äôs take everyone along in this new agr of AI . Respect üôè,2019-10-17T07:38:52Z
Ugx-9vjNR9_dxep2XX54AaABAg,@piyushkonher8405,,1,j2nGxw8sKYU,0,1,2019-10-16T05:20:40Z,When a 12 year kid from Indian can do it then definitely we all who are sitting in a office cabin can stand up learn and take out some meaning from our life which is getting old day by day <br>ü§®ü§®,2019-10-16T05:20:40Z
Ugw6zRPyEDmSrm6dCJh4AaABAg,@mrezagholami,,1,j2nGxw8sKYU,0,0,2019-10-06T09:48:50Z,"a new real Hero in our society, thanks MAN for all your great effort! your legacy now and in the future will shine AI community!",2019-10-06T09:48:50Z
UgxzZh9tB5uWLXApafd4AaABAg,@pratirupgoswami4373,,1,j2nGxw8sKYU,0,7,2019-10-04T18:17:21Z,One of the most legendary teacher of machine learning of all time ..the great ANDREW NG,2019-10-04T18:17:21Z
UgxDRC0sOuUwT6vyOT54AaABAg,@huili4364,,1,j2nGxw8sKYU,0,0,2019-10-04T02:16:27Z,What is the return of investment out of those jobs?,2019-10-04T02:16:27Z
Ugzqzln6EZdR5Y11ep94AaABAg,@user-kf8pn5ti5o,,1,j2nGxw8sKYU,2,47,2019-10-03T05:53:51Z,He is a legend of &quot;IN THIS VIDEO~&quot;,2019-10-03T05:53:51Z
Ugzqzln6EZdR5Y11ep94AaABAg.9-bmvVEv_xl9-lk5Y89fvC,@martylei9803,Ugzqzln6EZdR5Y11ep94AaABAg,2,j2nGxw8sKYU,0,0,2019-10-07T02:41:33Z,That&#39;s brilliant man,2019-10-07T02:41:33Z
Ugzqzln6EZdR5Y11ep94AaABAg.9-bmvVEv_xl9MVh2EJ8s_p,@jamesang7861,Ugzqzln6EZdR5Y11ep94AaABAg,2,j2nGxw8sKYU,0,0,2021-04-24T03:49:51Z,and ...&#39;CONCRETELY..&quot;,2021-04-24T03:49:51Z
UgwL6VNnazl7QaM8iQB4AaABAg,@etienneekpo348,,1,j2nGxw8sKYU,0,0,2019-10-01T17:40:39Z,"Always a delight to listen to sir Andrew&#39;s talk. <a href=""http://www.youtube.com/results?search_query=%23HeroofAI"">#HeroofAI</a>",2019-10-01T17:40:39Z
UgxqJRoZYkHcnLOTLHZ4AaABAg,@safekidda46,,1,j2nGxw8sKYU,0,0,2019-09-28T22:32:25Z,Uncle Andrew. It‚Äôs been a while...,2019-09-28T22:32:25Z
Ugz4EePA7ACFq2ZZmtR4AaABAg,@amraboughazala5986,,1,j2nGxw8sKYU,0,0,2019-09-23T17:15:16Z,"I love this man, I learned a course online from him. Very good lecturer.",2019-09-23T17:15:16Z
UgwCtkM2SBZlr1m4AJd4AaABAg,@SadParting97,,1,j2nGxw8sKYU,0,5,2019-09-19T02:13:05Z,British Andrew Yang clone,2019-09-19T02:13:05Z
UgzxmdsCTgnK_eMpvLF4AaABAg,@bernardocampos5908,,1,j2nGxw8sKYU,0,0,2019-09-17T04:33:20Z,"2 thousand dollars is nothing. YEAH, sure",2019-09-17T04:33:20Z
UgwvtasifSW8wBzYOH54AaABAg,@mctrjalloh6082,,1,j2nGxw8sKYU,0,0,2019-09-16T00:31:39Z,"Andrew Ng our, hero !",2019-09-16T00:31:39Z
Ugzmd-RcK2TySB_98Ih4AaABAg,@tumenodnuud4101,,1,j2nGxw8sKYU,0,1,2019-09-15T22:51:32Z,Andrew yang??? What???? Lol,2019-09-15T22:51:32Z
Ugwj0z-3HfvzYO7PMpV4AaABAg,@RawPeds,,1,j2nGxw8sKYU,0,0,2019-09-15T21:50:51Z,"<a href=""https://www.youtube.com/watch?v=j2nGxw8sKYU&amp;t=16m09s"">16:09</a> what is &quot;future learning&quot;?",2019-09-15T21:50:51Z
Ugx4TgIiFP4CNaB6U4R4AaABAg,@sohaibarif2835,,1,j2nGxw8sKYU,0,0,2019-09-15T19:01:11Z,So about the 12 year old from India. He actually used my project in Detroit and cited my work and it was actually demoed at Maker Faire Detroit 2018. Lookup Farmaid bot.,2019-09-15T19:01:11Z
UgwghkVAlqhSQ-9K3bl4AaABAg,@LovingBmx,,1,j2nGxw8sKYU,0,0,2019-09-15T14:23:11Z,i love you andrew ng,2019-09-15T14:23:11Z
UgwdUXYlqLR9E0i1Zt94AaABAg,@jameschen7822,,1,j2nGxw8sKYU,0,4,2019-09-15T10:41:22Z,"yanggang 2020! we support you ,you are the best yang!!!",2019-09-15T10:41:22Z
UgxxaEU693Xd5aNcbox4AaABAg,@thebrian8,,1,j2nGxw8sKYU,0,3,2019-09-15T07:57:41Z,All Andrew look the same whether it&#39;s ng or Yang,2019-09-15T07:57:41Z
UgynIi9fRAizIfNWts94AaABAg,@qq3king123,,1,j2nGxw8sKYU,0,17,2019-09-15T05:38:19Z,After Andrew Yang lost some his body fat he would definitely look like Andrew Ng,2019-09-15T05:38:19Z
UgwzHEX091HmWDUU8Wh4AaABAg,@zairemrenthlei9478,,1,j2nGxw8sKYU,0,1,2019-09-15T05:00:57Z,Andrew (ya)Ng,2019-09-15T05:00:57Z
Ugw7UQJTioNiadECQd54AaABAg,@Drvirhot,,1,j2nGxw8sKYU,0,2,2019-09-15T01:02:03Z,Yang 2020?,2019-09-15T01:02:03Z
Ugx30ugIYRXza1zwA594AaABAg,@TL-fe9si,,1,j2nGxw8sKYU,0,0,2019-09-14T23:23:43Z,"Being systematic in developing AI technology is so important and interesting, it&#39;s not boring at all :))) Much better than just trying random things and hope they will work...",2019-09-14T23:24:17Z
Ugxqm6WmJe-ewAK6nRR4AaABAg,@moonglow6639,,1,j2nGxw8sKYU,0,0,2019-09-14T21:30:32Z,&quot;AI&quot; is not electricity. Lol.. What a dumb nut.,2019-09-14T21:30:45Z
UgygxC5Kny1h5COC7k54AaABAg,@RoyalDomi,,1,j2nGxw8sKYU,0,0,2019-09-14T21:06:11Z,perfect‚ò∫Ô∏è he is an inspiration to the world,2019-09-14T21:06:11Z
Ugz4DTG66uO4jZSdnBl4AaABAg,@benzheng3997,,1,j2nGxw8sKYU,0,1,2019-09-14T20:28:37Z,he looks like andrew yang.,2019-09-14T20:28:37Z
Ugw1TcI_vb1HPCSQASd4AaABAg,@nothingiseverperfect,,1,j2nGxw8sKYU,0,3,2019-09-14T18:33:35Z,LMAOOOOOO I THOUGHT IT SAID ANDREW YANG,2019-09-14T18:33:35Z
UgzNswUq9r4IDupzgYd4AaABAg,@yutech2091,,1,j2nGxw8sKYU,0,0,2019-09-14T18:28:14Z,Waoooo <br>Sir may God bless you,2019-09-14T18:28:14Z
Ugzr77T74KEkrZ_BB5J4AaABAg,@Lets_MakeItSimple,,1,j2nGxw8sKYU,0,0,2019-09-14T17:43:15Z,Good to See Prof after so long..,2019-09-14T17:43:15Z
UgxMyrOET2Gu_gevlWF4AaABAg,@victorledezma6652,,1,j2nGxw8sKYU,0,2,2019-09-14T17:35:31Z,YANG GANG üá∫üá∏üá∫üá∏üá∫üá∏,2019-09-14T17:35:31Z
Ugws3AEvgLSr7GJa79R4AaABAg,@aakashsajwan,,1,j2nGxw8sKYU,1,33,2019-09-14T11:17:32Z,"Don&#39;t worry about it, if you don&#39;t understand",2019-09-14T11:17:32Z
Ugws3AEvgLSr7GJa79R4AaABAg.8zrRrc4VkMd9-LsE9C_PsS,@marcluettecke7238,Ugws3AEvgLSr7GJa79R4AaABAg,2,j2nGxw8sKYU,0,4,2019-09-26T16:13:08Z,This is the funniest comment I&#39;ve read in a while. Programming assignment coming up?,2019-09-26T16:13:08Z
UgyC-Vzi3E4eGsSBhjF4AaABAg,@adithyaks8584,,1,j2nGxw8sKYU,0,8,2019-09-14T10:53:16Z,Proud to say I am his student ... He made me understand the power of machine learning which I have applied on a number of projects and seen results - ( saw name Andrew Ng and opened the video ),2019-09-14T10:54:16Z
UgyPxficRJ8QQY8z5Lx4AaABAg,@BoeyChar,,1,j2nGxw8sKYU,0,1,2019-09-14T10:50:35Z,"For some reason, when he talks about leadership and responsibility towards the end of the video, a negative example of a big blue colour social media company came up on my mind?",2019-09-14T10:50:52Z
UgwfTzBUrUnQ7GK7rVh4AaABAg,@SuperBhavanishankar,,1,j2nGxw8sKYU,0,0,2019-09-14T08:31:37Z,he looks chinese,2019-09-14T08:31:37Z
UgxtGS-MJTtUAosbhbV4AaABAg,@therealkoreandaddy,,1,j2nGxw8sKYU,1,2,2019-09-14T03:37:03Z,Thought u were andrew yang for a second.,2019-09-14T03:37:03Z
UgwCcTkBfG0b6TC5ell4AaABAg,@machinistnick2859,,1,69dr4090Y-Q,0,0,2021-01-16T13:40:21Z,Thanks,2021-01-16T13:40:21Z
UgwLtMI_433w8zASBwN4AaABAg,@deadfish404,,1,69dr4090Y-Q,0,0,2019-09-30T15:23:23Z,"what happened to the video quality after <a href=""https://www.youtube.com/watch?v=69dr4090Y-Q&amp;t=23m00s"">23:00</a> ??",2019-09-30T15:23:23Z
Ugx4LxVV4TjLEbioHkV4AaABAg,@aliasad8342,,1,69dr4090Y-Q,0,4,2019-08-02T18:01:35Z,Andrew course has really helped me to understand how machine learning actually works under the hook. and later I was confused about how I&#39;m going to develop the AI solution that&#39;s where Lawrence course on TensorFlow specialization helped me. Thank you to both of you.,2019-08-02T18:01:35Z
UgwppFlq0M9M01KsLDd4AaABAg,@simobern4617,,1,69dr4090Y-Q,0,0,2019-08-01T14:18:28Z,Ce ne sont pas des illusions l&#39;innovation produit le changement donc donne des espoirs non des desillusions mais on obesserve par la pratique les desavantages les manquent et la couyrbe repare parce qu&#39;on adapte on ameliore donc le raisonnement est fauit  toute innovation offre lza joiee du nouveau la pratique l&#39;utilisation demontre les failles √† ameliorer c&#39;est cela le progres il n&#39;a y a pas de courbe ou amener les gens √† la desillusion c&#39;est faut il faut d&#39;abord la pratique l&#39;utilisation pour demontrer les failles <br>il faut un pic une descente et apres un redemarrage,2019-08-01T14:18:28Z
UgzqEKf7TlRja89m3DR4AaABAg,@jonathansum9084,,1,69dr4090Y-Q,1,5,2019-08-01T14:08:10Z,"If Andrew Ng becomes the presidential candidate, I am going to vote for him.<br>I hope we will have the Javascript course soon because that is what most young people like us use.<br>I also hope Andrew Ng covers more on &quot;how it works in math&quot;, and that is very important, and Laurence covers on the tool.<br>One more thing, some of the English subtitles are wrong. I hope there will be a fix for the deaf people or allow the community to fix it.<br><br>After taking Laurence&#39;s CNN with Tensorflow, I did not learn things like 1 by 1 filter, increasing channel, batch normalization, batch size, and more. <br>It is very important to have Andrew Ng to focus more on math.",2019-08-07T19:07:29Z
UgzqEKf7TlRja89m3DR4AaABAg.8y5SPrf3FgT8yOscP98Er8,@successisimminent9123b,UgzqEKf7TlRja89m3DR4AaABAg,2,69dr4090Y-Q,0,0,2019-08-09T03:11:31Z,"You can learn all the math from the Deep Neural Networks Specialization by Andrew NG at <a href=""http://deeplearning.ai/"">Deeplearning.ai</a>. I diid that specialization before coming to the tensorflow specialization, so that everything makes sense as I code",2019-08-09T03:11:31Z
Ugwi7K8pCVBkvtKlzCR4AaABAg,@simobern4617,,1,69dr4090Y-Q,0,0,2019-08-01T14:04:21Z,Au lieu d‚Äôun<br>ordinateur quantic il faut une imprimante quantique qui reproduit la<br>comosition des objets selon une lecture de la composition chimique<br>des compositions et les reproduire facilement comme une imprimante<br>c‚Äô‚Äôest tout <br><br><br>reproduire un atome au lieu de le teleporter,2019-08-01T14:04:21Z
Ugw7lXhyfhhC2zvZdf14AaABAg,@arjoai,,1,NKpuX_yzdYs,0,0,2022-11-15T06:02:29Z,He is such a genius that the only barrier is....<br>.<br>.<br>.<br>.<br>.<br>.<br>.<br>.<br>.<br>.<br>.<br>.<br>.<br>WRITING,2022-11-15T06:02:29Z
UgyDE8BahhsWpNVkchl4AaABAg,@ManuelArvizu,,1,NKpuX_yzdYs,1,1,2022-09-06T09:23:45Z,He might as well had used AI to express his ideas on a big screen and voice recognition instead of scribbling on that outdated blackboard....,2022-09-06T09:23:45Z
UgyDE8BahhsWpNVkchl4AaABAg.9fckiFoMaof9t1ny334rIX,@targetingmustend4016,UgyDE8BahhsWpNVkchl4AaABAg,2,NKpuX_yzdYs,0,0,2023-08-05T15:00:30Z,"haha...because back in 2017,2018 the &quot;AI ecosystem&quot; was not as we know it today. When did you know about GPT again?? Were you using the very first version??",2023-08-05T15:00:30Z
Ugzy2RqwWJ-D7wY010F4AaABAg,@Chyphor,,1,NKpuX_yzdYs,0,0,2022-04-09T16:33:04Z,Since when is voice speech AI?,2022-04-09T16:33:04Z
UgxgJgyeiJ5YS1eQZGB4AaABAg,@nehagujjar7724,,1,NKpuX_yzdYs,0,0,2021-09-30T15:16:35Z,Thanks you sir you explained very well üëç,2021-09-30T15:16:35Z
UgxZFpzg7b9oBmHIe4t4AaABAg,@krishnapatel9216,,1,NKpuX_yzdYs,0,0,2021-09-18T00:22:44Z,Can anyone tell me what he present in graph and we should remember two things?,2021-09-18T00:22:44Z
UgxyF8ZVRkUj6wFe9g94AaABAg,@kirtikansal74,,1,NKpuX_yzdYs,0,0,2021-06-07T16:26:31Z,Thank You Sir,2021-06-07T16:26:31Z
UgxcB6GCV17DE6ZSyl14AaABAg,@trexmidnite,,1,NKpuX_yzdYs,0,1,2021-02-26T04:03:16Z,The bottom line is Never mess with andrewng,2021-02-26T04:03:16Z
UgzMk4DW2B-EfBaHV5V4AaABAg,@minechannel3716,,1,NKpuX_yzdYs,0,1,2020-11-29T04:26:54Z,Learned a lot from him and his courses on Deep learning,2020-11-29T04:26:54Z
UgwQN79h16MXUyY6dRl4AaABAg,@MrTeamGuy,,1,NKpuX_yzdYs,0,0,2020-06-08T23:04:21Z,"Scan people, behavior, sell it, and go live the life of your dreams. I thought that is selling us out, homo-sapien still needs to draw females. What happens to the social animal that we always were. Also, we mimic everything like hell, it looks like from this AI sh*t we all start to feel and act like we have Aspergers. Maybe more bulletproof we would be, but then we need medication from depression (or too many emotions, especially when we&#39;re very young). More problems than people getting electrocuted. How about we take a step back and start carefully progressing instead of this rush: everyone for themselves including theories and manipulation in humankind. Also, we have roles, if not for them we wouldn&#39;t exist. Now this AI is political, which is another topic which is a conflict of our consumer interest. <br>But I guess AI is a way better salesman than us. Manipulation is good for us until something goes off the rail. Then there are people we hide stuff from because they&#39;re on a different tier of social status (personal things does exist). Then that tier has too many layers for us to count. And in the end, it&#39;s just fear. Who&#39;s to say if that won&#39;t push us out. The algorithm made for ad money which = power. Solved, now let&#39;s step back, oh wait thanks to you we can&#39;t. Thanks for the grammar fixes",2020-06-08T23:04:21Z
UgxIiseUtpOI3xEH_Ax4AaABAg,@gustafa2170,,1,NKpuX_yzdYs,0,0,2020-05-30T06:16:24Z,"Most benefit of AI will not be going to the regular folk, unlike electricity.",2020-05-30T06:16:24Z
UgyiG7LEIyBFdynrUSZ4AaABAg,@shubhamthakur7757,,1,NKpuX_yzdYs,0,1,2020-04-30T19:54:14Z,Quite nice presentation by Andrew. Really something new for me to know about the difference in traditional and internet company.,2020-04-30T19:54:14Z
Ugz1_1MwPsWW0-x4YLV4AaABAg,@zoeprincipal3560,,1,NKpuX_yzdYs,0,0,2020-04-08T19:06:11Z,That&#39;s so easy.  It&#39;s mathematics.   Think about a fraction it&#39;s no different.  Electricity comes from vibration. All you have to know is the first number. GitHub is a pain on the ass,2020-04-08T19:06:11Z
UgwOmS2cr2a_aSYHc-Z4AaABAg,@satorusotoyama5781,,1,NKpuX_yzdYs,0,2,2020-02-24T02:42:54Z,Awesome talk! I took a lot of notes and a lot of takeaways for me. Thanks Andrew!,2020-02-24T02:42:54Z
UgwUkeFJIrqbRYcAG6F4AaABAg,@greenboltz1551,,1,NKpuX_yzdYs,0,1,2019-11-02T09:08:24Z,It&#39;s all about AI and i love learning about AI,2019-11-02T09:08:24Z
Ugx9MInU5sk_UezVXe54AaABAg,@jfs3234,,1,NKpuX_yzdYs,0,1,2019-07-29T20:34:03Z,I wonder if this guy will ever learn how to write before teaching his machines to learn :),2019-07-29T20:34:03Z
UgwEfCOzU2-J6Nn3qQx4AaABAg,@user-mc3yl9tl1h,,1,NKpuX_yzdYs,0,0,2019-07-29T12:34:04Z,This video¬†is best lecture of AI,2019-07-29T12:34:04Z
UgxA5KmyrBFuko5nI114AaABAg,@carlhopkinson,,1,NKpuX_yzdYs,0,0,2019-07-11T22:26:14Z,Why is he wasting time copying sentences on a white board?,2019-07-11T22:26:14Z
UgwNJSVgYJexY9CBglV4AaABAg,@varun009,,1,NKpuX_yzdYs,0,0,2019-07-06T03:49:29Z,Lol. Thought this was an Andrew Yang video.,2019-07-06T03:49:29Z
UgxlBytlVrNkywcye-x4AaABAg,@donkeykong516,,1,NKpuX_yzdYs,0,0,2019-05-12T16:21:21Z,Heard Trump wants to ban electricity because of national security concerns,2019-05-12T16:21:21Z
UgwHpb5mow5QISYxEn54AaABAg,@KoltPenny,,1,NKpuX_yzdYs,0,1,2019-03-16T02:02:42Z,This guy knows a lot. He should write a book about this or something.,2019-03-16T02:02:42Z
UgwBBSLRWDwETTbK5i94AaABAg,@Newtube_Channel,,1,NKpuX_yzdYs,1,0,2019-03-10T09:41:51Z,Hum.. don&#39;t get carried away with AI. I wouldn&#39;t say it&#39;s electricity but just another stepping stone in a trans-formative technology. It could be said Data is the new electricity but that too can be littered with noise.,2019-03-10T09:41:51Z
UgwBBSLRWDwETTbK5i94AaABAg.8sIBTEPzvCt8tnXeSo04Hv,@heller4196,UgwBBSLRWDwETTbK5i94AaABAg,2,NKpuX_yzdYs,0,0,2019-04-16T19:42:50Z,"thats why first step of ML is Data Analysis, to filter Data, to remove the littered noise",2019-04-16T19:42:50Z
Ugx1s2WUvCLrw2F8j-h4AaABAg,@kingarthurthethirdthst3804,,1,NKpuX_yzdYs,1,10,2019-03-01T12:53:57Z,It&#39;s so weird hearing his normal voice after being used to it on 2x on Coursera,2019-03-01T12:53:57Z
Ugx1s2WUvCLrw2F8j-h4AaABAg.8rwMIR1_khl9CGXdga048R,@viveknishad5262,Ugx1s2WUvCLrw2F8j-h4AaABAg,2,NKpuX_yzdYs,0,0,2020-08-12T17:16:26Z,Which course you have taken on coursera?,2020-08-12T17:16:26Z
Ugw0NNsj1rZTMbrBpeV4AaABAg,@shubhammurari6113,,1,NKpuX_yzdYs,0,1,2019-02-07T19:50:07Z,A brief and well knitted introduction to Artificial Intelligence. AI sure is new electricity !!,2019-02-07T19:50:07Z
UgxWZ4ZCVOU-Xu5FpiB4AaABAg,@jaredhouston4223,,1,NKpuX_yzdYs,0,0,2019-01-03T04:01:23Z,buy crypto. A.I. needs the tech and it&#39;s how our economy will run in the future,2019-01-03T04:01:23Z
UgwOH1YzD3g2dV3G6YN4AaABAg,@qng199gmailcom,,1,NKpuX_yzdYs,0,0,2018-12-18T00:29:15Z,Good,2018-12-18T00:29:15Z
UgwxCA-wO9zReq5E8DR4AaABAg,@angelachikaebirim8894,,1,NKpuX_yzdYs,0,1,2018-12-12T13:54:29Z,just love this stuff,2018-12-12T13:54:29Z
Ugx5iKULvtsBQ8YQukF4AaABAg,@johnbarbuto5387,,1,NKpuX_yzdYs,1,1,2018-12-11T15:50:51Z,"Currently AI is seeking to replicate what human brains do (admittedly faster, more scalable, more distributable, less consilient, less philosophical, etc).  Obviously this compatibility with human thinking is relevant to the economic interests of companies.  As a neurologist I&#39;m quite interested in how this is evolving: both in what it is doing, and in what it is not doing, yet.  Eventually unsupervised, reinforced learning will also tell us how we think - the details of feature detection, information integration, transfer of &quot;perspectives&quot;, etc - as reflections of human neural architecture (providing, for example, insight into why we use a host of neurotransmitters).   Then things will really get interesting when machines reveal to us the specific nature of cognitive limits humans have developed through the forces of evolution.  We have constitutional behavioral programs that are now a threat to the world we wish to inhabit.  Machines can demonstrate what happens if there are alternative programs.  It is an exciting time.",2018-12-11T15:50:51Z
Ugx5iKULvtsBQ8YQukF4AaABAg.8oifx0hlJIl8rGZ1fSXuOU,@autonomous2010,Ugx5iKULvtsBQ8YQukF4AaABAg,2,NKpuX_yzdYs,0,1,2019-02-12T21:57:55Z,"As of current the &quot;key&quot; of how biological brains learn in real time hasn&#39;t been cracked yet. Current AI solutions require a ton of processing power to replicate a single skill requiring millions more examples than any grown human would ever require. The problem of &quot;catastrophic forgetting&quot; hasn&#39;t been solved yet in software.<br><br>There&#39;s a surprising amount a person has to learn... before they can learn. Thankfully if cognition is an emergent property of itself, we don&#39;t really have to know how a biological brain works. We would only need to replicate how it starts.",2019-02-12T21:59:11Z
UgyYiVC2I_acvc-3e1Z4AaABAg,@stardaggerrihannsu2363,,1,NKpuX_yzdYs,0,0,2018-12-01T21:17:18Z,"AI is more important than Writing and the Wheel, COMBINED!<br><br>True AGI, not this Neural net back propagation crap so many are doing now!",2018-12-01T21:17:18Z
UgwYHOQdvVha0BgI2yV4AaABAg,@tylerbarker4763,,1,NKpuX_yzdYs,0,0,2018-11-20T18:29:37Z,"&quot;1 second&quot;    its good pitch... but your forgetting 99% of everything else... your basing 100% of on intellectual property along with a little bit of influence...   but half through the video.. you said some thing bad about &quot;the united states&quot;...  I think that was unnecessary.    ( you mentioned a problem the united states has, but really you just suggested it right? but why would you do that )",2018-11-20T18:29:37Z
UgzsBvAPYcMVvkTjIU94AaABAg,@SergioArroyoSailing,,1,NKpuX_yzdYs,0,2,2018-11-19T04:41:23Z,"wonderful talk, relevant even today. That being said , would love to see him do an update now as it has been nearly a year since he did this talk",2018-11-19T04:41:23Z
UgwqqT1PHZbqAmcQUCF4AaABAg,@cotedazure,,1,NKpuX_yzdYs,0,1,2018-11-18T05:45:37Z,"My biggest takeaway from this talk was the &quot;new language&quot; of product management in the era of AI. Also, I enjoyed his explanation on how companies can start incorporating AI centrally into their organizations at first, and allow AI to work with different business units to apply the technology to their various challenges.",2018-11-18T05:45:37Z
UgzkFeA9CWbMLHd4Hzd4AaABAg,@ssmei,,1,NKpuX_yzdYs,0,0,2018-11-18T05:37:01Z,I wish all lectures would be like this. Seriously.,2018-11-18T05:37:01Z
UgzEbNYIjA4ICv92d1x4AaABAg,@swindler1570,,1,NKpuX_yzdYs,0,0,2018-11-11T07:22:35Z,"Rat things, when? <a href=""http://www.youtube.com/results?search_query=%23NgSecurityIndustries"">#NgSecurityIndustries</a>",2018-11-11T07:22:35Z
UgwrYdLlYin44LlyQxZ4AaABAg,@jiwonkim938,,1,NKpuX_yzdYs,0,1,2018-11-07T11:55:04Z,He speaks so eloquently.,2018-11-07T11:55:04Z
UgwOTNeOwS-H8Z2B4L54AaABAg,@DavidBruno,,1,NKpuX_yzdYs,0,13,2018-08-22T11:37:59Z,"Really love Andrew for his humbleness, the way he thinks first to help other people understand.",2018-08-22T11:37:59Z
UgxMfnlv6SNwXt3rNwB4AaABAg,@9akrish,,1,NKpuX_yzdYs,0,1,2018-08-13T13:56:49Z,Best trainer for AI,2018-08-13T13:56:49Z
Ugxu_xugs6uXuy5uU014AaABAg,@taibisaad9002,,1,NKpuX_yzdYs,0,1,2018-08-11T04:52:31Z,"<a href=""https://www.youtube.com/watch?v=NKpuX_yzdYs&amp;t=25m16s"">25:16</a> ... ‚ô•",2018-08-11T04:52:31Z
UgyC92Ech7WgBlkQY7l4AaABAg,@taibisaad9002,,1,NKpuX_yzdYs,0,0,2018-08-11T04:45:42Z,"<a href=""https://www.youtube.com/watch?v=NKpuX_yzdYs&amp;t=16m54s"">16:54</a> ... ‚ô•‚ô•‚ô•",2018-08-11T04:45:42Z
Ugz2AEKwieLarG0ikgd4AaABAg,@Salamimalicum,,1,NKpuX_yzdYs,0,1,2018-07-25T21:22:17Z,"Wait, I read papers from this guy on cs229 or 230 or so dont remember. He&#39;s a professor from Standford",2018-07-25T21:22:17Z
UgywrukB7uFdwWdU0D14AaABAg,@sodalitia,,1,NKpuX_yzdYs,0,1,2018-07-24T12:23:25Z,"AI is not a new electricity. AI implementation is most prevalent in marketing, which is a form of a parasitic activity in economy, which is not adding anything to the table, but simply makes you sell your products more efficiently than competitors. New electricity would be new form of energy or new resource. Funneling virtual money from one pocket to another is none of that. I would consider AI a new  electricity when it is implemented in proper, autonomous robotics that genuinely makes utilization of resources more efficient or replaces labor. However, as he admitted, AI is not yet capable of autonomy outside virtual environment, like games. I think self driving cars will be first to get there, but we are still far from that. The danger of companies like Google is that they in fact slow down true AI development in favor of data gathering. The capital that could be used in tech is dedicated and aimed at selling stuff and marketing, which is not productive, but a burden on actual productivity. Just think about gaming: 3/4 of the budgets of game development is marketing. Imagine what could be developed in terms of quality, when marketing didn&#39;t consume so much of a budget? The future of AI is slow and based on consumerism. The screens and apps and flashy gadgets on your phone are going to improve exponentially, while true progress in technology will be stifled by corporate greed.",2018-07-24T12:37:41Z
UgytrlM4fxLE5DVxyad4AaABAg,@satoshinakamoto171,,1,NKpuX_yzdYs,0,1,2018-07-22T14:07:45Z,beautiful handwriting,2018-07-22T14:07:45Z
Ugy10VAyQhnmnDoOS0x4AaABAg,@huiy.8767,,1,NKpuX_yzdYs,0,0,2018-07-08T19:46:29Z,"A good talk for the c-suite and aspiring entrepreneurs, but not a talk for people seeking to learn  technical/ algorithmic details of AI or deep learning.",2018-07-08T19:46:29Z
UgyYpzaHalfHeD5mGcV4AaABAg,@Draeka,,1,NKpuX_yzdYs,0,1,2018-07-02T00:13:32Z,I&#39;m upset because I had so much difficulty trying to pickup on this mans pronunciations.  Had to stop listening even though I&#39;m terribly interested.  Is there a script somewhere?,2018-07-02T00:13:32Z
UgytBOLVHDPYXEFML6Z4AaABAg,@daksh6752,,1,NKpuX_yzdYs,0,1,2018-06-26T00:47:51Z,Amazing talk.,2018-06-26T00:47:51Z
UgwAvcBU7cYzUTseWRJ4AaABAg,@thomas4315,,1,NKpuX_yzdYs,0,0,2018-06-15T09:30:57Z,"A.I  developer jobs as a 4 start general decide when to pull out of war. And at what cost.<br>A.I  developer, need to come up with how are we to pay workers for ‚Äúwhat jobs‚Äù they do after  smart robot take there jobs. Or don‚Äôt mess up the system.",2018-06-15T09:30:57Z
UgxGpL7AP2x4-E4l5i54AaABAg,@thomas4315,,1,NKpuX_yzdYs,0,0,2018-06-15T09:17:38Z,"A I isn‚Äôt  going  foward for personal right. It‚Äôs will change your life forever and can not be undone. You will not be able to drive a car anymore soon . You pay a for ride, you have a life time number cashless . Later you be restricted to classcation by wealth, etc where to live ,    Who need worker?  Who will pay us ? What do we need to do to get payed? What my purpose ? What my mission in life ,  Who am I? Clone or robot will chalange you. Ever 10 yr getting Smarter and smarter self learning. Grass not allway greener on the other side.<br>Show less",2018-06-15T09:17:38Z
UgydAgKhcJYHB2GCdb54AaABAg,@lexfridman,,1,0jspaMLxBig,12,276,2020-02-20T16:25:10Z,"I really enjoyed this conversation with Andrew. Here&#39;s the outline:<br><a href=""https://www.youtube.com/watch?v=0jspaMLxBig&amp;t=0m00s"">0:00</a> - Introduction<br><a href=""https://www.youtube.com/watch?v=0jspaMLxBig&amp;t=2m23s"">2:23</a> - First few steps in AI<br><a href=""https://www.youtube.com/watch?v=0jspaMLxBig&amp;t=5m05s"">5:05</a> - Early days of online education<br><a href=""https://www.youtube.com/watch?v=0jspaMLxBig&amp;t=16m07s"">16:07</a> - Teaching on a whiteboard<br><a href=""https://www.youtube.com/watch?v=0jspaMLxBig&amp;t=17m46s"">17:46</a> - Pieter Abbeel and early research at Stanford<br><a href=""https://www.youtube.com/watch?v=0jspaMLxBig&amp;t=23m17s"">23:17</a> - Early days of deep learning<br><a href=""https://www.youtube.com/watch?v=0jspaMLxBig&amp;t=32m55s"">32:55</a> - Quick preview: <a href=""http://deeplearning.ai/"">deeplearning.ai</a>, <a href=""http://landing.ai/"">landing.ai</a>, and AI fund<br><a href=""https://www.youtube.com/watch?v=0jspaMLxBig&amp;t=33m23s"">33:23</a> - <a href=""http://deeplearning.ai/"">deeplearning.ai</a>: how to get started in deep learning<br><a href=""https://www.youtube.com/watch?v=0jspaMLxBig&amp;t=45m55s"">45:55</a> - Unsupervised learning<br><a href=""https://www.youtube.com/watch?v=0jspaMLxBig&amp;t=49m40s"">49:40</a> - <a href=""http://deeplearning.ai/"">deeplearning.ai</a> (continued)<br><a href=""https://www.youtube.com/watch?v=0jspaMLxBig&amp;t=56m12s"">56:12</a> - Career in deep learning<br><a href=""https://www.youtube.com/watch?v=0jspaMLxBig&amp;t=58m56s"">58:56</a> - Should you get a PhD?<br><a href=""https://www.youtube.com/watch?v=0jspaMLxBig&amp;t=1h03m28s"">1:03:28</a> - AI fund - building startups<br><a href=""https://www.youtube.com/watch?v=0jspaMLxBig&amp;t=1h11m14s"">1:11:14</a> - <a href=""http://landing.ai/"">Landing.ai</a> - growing AI efforts in established companies<br><a href=""https://www.youtube.com/watch?v=0jspaMLxBig&amp;t=1h20m44s"">1:20:44</a> - Artificial general intelligence",2020-02-20T16:25:10Z
UgydAgKhcJYHB2GCdb54AaABAg.95GPSpBjHMp95GWzBxiPbJ,@dayanandak4667,UgydAgKhcJYHB2GCdb54AaABAg,2,0jspaMLxBig,0,4,2020-02-20T17:30:53Z,Thank you very much,2020-02-20T17:30:53Z
UgydAgKhcJYHB2GCdb54AaABAg.95GPSpBjHMp95Ggxs9Hr9e,@zeitgeisttv5312,UgydAgKhcJYHB2GCdb54AaABAg,2,0jspaMLxBig,0,5,2020-02-20T19:06:49Z,The reason why hand writing is fundamentally different and more powerful because you are in the act of recalling and creating neural pathways. It&#39;s like drawing you are creating something from nothninness,2020-02-20T19:06:49Z
UgydAgKhcJYHB2GCdb54AaABAg.95GPSpBjHMp95GpsWsT3Bq,@avimohan6594,UgydAgKhcJYHB2GCdb54AaABAg,2,0jspaMLxBig,0,0,2020-02-20T20:24:44Z,About time! ( üòÇ),2020-02-21T02:01:24Z
UgydAgKhcJYHB2GCdb54AaABAg.95GPSpBjHMp95HNwXk-CZE,@aheinstein291,UgydAgKhcJYHB2GCdb54AaABAg,2,0jspaMLxBig,0,1,2020-02-21T01:31:07Z,"I think you forgot:<br><a href=""https://www.youtube.com/watch?v=0jspaMLxBig&amp;t=1h22m02s"">1:22:02</a> How to throw shade at Elon Musk without mentioning his name.<br><br>Jk, thanks for another great interview!",2020-02-21T01:33:11Z
UgydAgKhcJYHB2GCdb54AaABAg.95GPSpBjHMp95Ji2EcaTuV,@jf9229,UgydAgKhcJYHB2GCdb54AaABAg,2,0jspaMLxBig,0,0,2020-02-21T23:14:01Z,Absolutely loved this one!,2020-02-21T23:14:01Z
UgyBmKvBrvXJbucyfgB4AaABAg,@user-lf4ir3mp2f,,1,0jspaMLxBig,0,0,2023-12-07T06:16:11Z,Great man,2023-12-07T06:16:11Z
UgxRm6wJtOeaj8CGbaZ4AaABAg,@YaweiHan-zz6rn,,1,0jspaMLxBig,0,0,2023-11-30T09:23:54Z,"<a href=""https://www.youtube.com/watch?v=0jspaMLxBig&amp;t=44m36s"">44:36</a>  impact has been made by ChatGPTüéâ",2023-11-30T09:23:54Z
Ugx20Pi1Bl7CWJqUzFV4AaABAg,@devmahad,,1,0jspaMLxBig,0,0,2023-11-18T20:43:59Z,"<a href=""https://www.youtube.com/watch?v=0jspaMLxBig&amp;t=24m34s"">24:34</a> reminder",2023-11-18T20:43:59Z
UgxxFx9GDwzFI-qx0YR4AaABAg,@aaronleejohnson007,,1,0jspaMLxBig,0,0,2023-11-07T21:57:25Z,"I&#39;ve been studying and getting certifications in Prompt Engineering, Mathematics, Coding, Data Science, Open Artificial Intelligence, Machine Learning, Deep Learning, and Neural Networks for a few years now. I can&#39;t find a job anywhere. When I&#39;m in a interview and talk about the cost saving benefits and increase in productivity using Artificial Intelligence and automation, they usually end the interview right away and send a Dear John letter that they went with another candidate.",2023-11-07T21:57:25Z
UgwhvA_M1-CROf_hE654AaABAg,@ashishgejo2147,,1,0jspaMLxBig,0,0,2023-10-20T15:25:49Z,Is this on vr,2023-10-20T15:25:49Z
UgwvIX_PbMINERKBFf94AaABAg,@phamgiaminh1025,,1,0jspaMLxBig,0,0,2023-08-29T12:03:35Z,"Damn, why is his voice so good.",2023-08-29T12:03:35Z
Ugx4CeRUhc0bAKKcuHp4AaABAg,@Hammadisteachingchemistry,,1,0jspaMLxBig,0,0,2023-08-28T07:43:32Z,same shirt xD,2023-08-28T07:43:32Z
UgzWDqNhvR3i7Y9uDKB4AaABAg,@scuti7073,,1,0jspaMLxBig,0,0,2023-08-25T02:30:33Z,"It doesn&#39;t matter whether you become a professor, work in a big company, or a startup. What matters are the people you surround yourself with. Be sure to surround yourself   good people.",2023-08-25T02:30:33Z
UgzDZI4Lc-lx_C3igk54AaABAg,@srinivassr5067,,1,0jspaMLxBig,0,1,2023-08-18T10:14:11Z,I really wanted to know the book he was talking about at the end!!!,2023-08-18T10:14:11Z
UgxLsCSmjfIAyd-S5rh4AaABAg,@bindiberry6280,,1,0jspaMLxBig,0,0,2023-07-26T22:21:27Z,"We all know that stealing data and ideas of training computers from individuals are so-called the big-tech AI. If they fail, they will hire so-called experts to fake so-called real data to sell so-called reality. If you find there are something they have stolen from you or the public, you should organize lawsuits even if they try to hide that with the CCP of mainland China.",2023-07-26T22:40:48Z
UgwlbnxjZYPI5P6HJTl4AaABAg,@nb8298,,1,0jspaMLxBig,0,0,2023-07-04T09:09:23Z,Thanks for having Andrew on. He is above all else very authentic in his journey.,2023-07-04T09:09:23Z
Ugx1XWPvmtAKPXvGufl4AaABAg,@dodogo777,,1,0jspaMLxBig,0,0,2023-06-07T05:47:08Z,"andrew ng, best AI/ML educator ever !",2023-06-07T05:47:08Z
UgxJZYDAWdP70-j9Z6R4AaABAg,@lakshayasaxena1771,,1,0jspaMLxBig,0,0,2023-06-05T03:54:12Z,"<a href=""https://www.youtube.com/watch?v=0jspaMLxBig&amp;t=01h03m00s"">01:03:00</a>",2023-06-05T03:54:12Z
UgzT8pkFU96plTP6Ovx4AaABAg,@mjudithg.sv.1747,,1,0jspaMLxBig,0,0,2023-05-19T10:33:09Z,"It&#39;s always interesting to hear an engineer (e.g. Andrew Ng) talking about marketing. They really believe they can do marketing without a degree in the subject. Frustrating. The world would be a better place if engineers would collaborate more with sociologists, philosophers, religious leaders and real marketers. Without this collaboration, you get monstrous things like bill G. trying to guide human kind into the future. In my very personal opinion, with all respect to this wonderful conversation.",2023-05-19T10:33:09Z
Ugz9Et5eCn4uB9bwS-F4AaABAg,@janklaas6885,,1,0jspaMLxBig,0,0,2023-05-18T13:44:11Z,"üìç<a href=""https://www.youtube.com/watch?v=0jspaMLxBig&amp;t=45m55s"">45:55</a>",2023-05-18T13:44:11Z
Ugy5meM1DpfNZE-6G-p4AaABAg,@pravachanpatra4012,,1,0jspaMLxBig,0,0,2023-05-07T20:33:19Z,"<a href=""https://www.youtube.com/watch?v=0jspaMLxBig&amp;t=1h01m14s"">1:01:14</a>",2023-05-07T20:33:19Z
UgyHvQu5ni1JVkQ0D2x4AaABAg,@AmitDotAcademy,,1,0jspaMLxBig,0,0,2023-04-23T19:03:01Z,I am watching it 3 years later and I must say this is a great interview. Great work Lex and Andrew.,2023-04-23T19:03:01Z
UgyTUgsl2i0VO_v04P14AaABAg,@mzlittle,,1,0jspaMLxBig,1,1,2023-04-23T03:49:49Z,"&quot;This is The A.I. Podcast&quot;, You just released <a href=""http://www.youtube.com/results?search_query=%23173"">#173</a> and this is #73, it took 100 podcasts for A.I. to completely blow up!",2023-04-23T03:49:49Z
UgyTUgsl2i0VO_v04P14AaABAg.9opoXg2s5OP9opqeRMrvQU,@mzlittle,UgyTUgsl2i0VO_v04P14AaABAg,2,0jspaMLxBig,0,1,2023-04-23T04:08:20Z,"GASP, <a href=""http://www.youtube.com/results?search_query=%23373"">#373</a>!!!!",2023-04-23T04:08:20Z
UgxGf3fXW0irnj7igwR4AaABAg,@aldorodriguez7310,,1,0jspaMLxBig,0,0,2023-04-22T21:51:11Z,He is the man that revolutionized education. I think Coursera is in its early stage still.,2023-04-22T21:51:11Z
Ugwp94HmF13id_dbvBl4AaABAg,@aldorodriguez7310,,1,0jspaMLxBig,0,1,2023-04-22T21:50:22Z,I love Coursera even more now. I didn‚Äôt know he was a co-founder.,2023-04-22T21:50:22Z
UgxTNtshuijNIp647pB4AaABAg,@aldorodriguez7310,,1,0jspaMLxBig,0,1,2023-04-22T21:49:40Z,"<a href=""https://www.youtube.com/watch?v=0jspaMLxBig&amp;t=14m40s"">14:40</a> This was prophetic Lex. He said you think everyone will have coding capabilities? Fast forward 3 years and welcome to the Chat GPT.",2023-04-22T21:49:40Z
Ugx4DSf_dvgymTywkhl4AaABAg,@e-readers,,1,0jspaMLxBig,0,1,2023-04-08T15:22:21Z,I really enjoyed this interview done by you and Andrew.,2023-04-08T15:22:21Z
UgzFjd69mYI54auyg_l4AaABAg,@doruktopcu,,1,0jspaMLxBig,0,0,2023-04-04T12:24:19Z,"<a href=""https://www.youtube.com/watch?v=0jspaMLxBig&amp;t=24m51s"">24:51</a> this is great really üòÇ",2023-04-04T12:24:19Z
UgzPGaMfgYw84YUOOOZ4AaABAg,@nouribenz,,1,0jspaMLxBig,0,0,2023-04-02T15:01:25Z,"üëã For beginners in Machine Learning, please apply for the Machine learning course of Andrew Ng in coursera, and if you have your school email you can apply for financial aid and get the course and the certificate for FREE ‚ù§ and let&#39;s build a better world.",2023-04-02T15:01:25Z
UgzhAaKxiQ9-pyAh-0V4AaABAg,@nouribenz,,1,0jspaMLxBig,0,0,2023-04-02T14:58:32Z,"‚ù§ Thanks for this amazing podcast üòá, I really like this man it was my gateway to the machine learning and AI world by taking the coursera ML course, it was so helpful, but unfortunately I couldn&#39;t continue it this domain cause I didn&#39;t find a job related to this field in Morocco, compagnies there are still warming up with AI so I started my jorney in programming as a Full Stack developer and now I have a dream to come back again to achieve my dreams and find a path in the AI world as an AI developer and leave a fingerprint in this huge field. <br>Thanks again, and I hope to see another episode with Andrew Ng today after the huge releases in AI like ChatGPT and midjourney etc..",2023-04-02T14:59:10Z
UgznXq7hTeocZuaa80B4AaABAg,@atomnous,,1,0jspaMLxBig,0,0,2023-03-29T10:24:42Z,I thought that&#39;s &quot;Andy Ngo&quot;,2023-03-29T10:24:42Z
UgzAc10SPAmvBUxZ1LN4AaABAg,@vominh5451,,1,0jspaMLxBig,0,0,2023-03-20T14:14:25Z,"Interesting, thank Lex for the video and invited Dr Ng",2023-03-20T14:14:25Z
UgwKBqR3oTi8hUfz7d94AaABAg,@cyntax99,,1,0jspaMLxBig,0,0,2023-03-20T07:08:01Z,All the secrets to make money with/in AI revealed by this man has just been mind blowing-ly tremendous.,2023-03-20T07:08:01Z
UgysJrczoxGSMCUbznp4AaABAg,@SidhuSK,,1,0jspaMLxBig,0,0,2023-03-05T10:48:07Z,can you please add subtitles to the interviews? it&#39;s hard for me to catch some technical words who is average in English. Thank you..,2023-03-05T10:48:07Z
UgzQw4H58tMFrFgh9BF4AaABAg,@cetrick_yeanay,,1,0jspaMLxBig,0,0,2023-02-24T17:32:18Z,Thank you for this! I&#39;m a beginner and love this type of knowledge and insight!,2023-02-24T17:32:18Z
UgyWpUS1djCtqRknYzl4AaABAg,@burkebaby,,1,0jspaMLxBig,0,0,2023-02-21T15:21:18Z,I have a PhD in AI and I can say that Andrew is THE BEST machine learning/AI educator I have ever seen on the field! The deeplearning specialization is just invaluable for any interested learner in DL.,2023-02-21T15:21:18Z
UgyTwGkOW1g7Gtq_E6t4AaABAg,@jayman5692,,1,0jspaMLxBig,0,0,2023-02-14T21:24:20Z,I‚Äôm glad he is running for office,2023-02-14T21:24:20Z
UgzRAOeXqFMUdzVbfxl4AaABAg,@Changz687,,1,0jspaMLxBig,0,0,2023-02-11T07:43:26Z,"Absolutely right about knowledge paths, this is too understudied and has a tremendous impact on the programs overall reasoning capability.",2023-02-11T07:43:26Z
UgwjD_6iEuvmnLpNke54AaABAg,@visuallization,,1,0jspaMLxBig,0,0,2023-02-07T21:49:32Z,Wow that was inspiring! Besides Andrew&#39;s skills I also admire his passion and goal to make the world an actual better place by helping people. I genuinely believe him when he says that. we need more people and devs who think and act like this.,2023-02-07T21:49:32Z
Ugzjn29i4htsmF6yjjd4AaABAg,@marlhex6280,,1,0jspaMLxBig,0,0,2023-01-31T06:50:46Z,Man this is one of the best guests that we can have in the field !!! üòÇüòÇ that was awesome that you could get this generous man!!!! Such a wonderful human you to put him on the mic and him from providing such words,2023-01-31T06:50:46Z
UgwBeckVSl5dU_oBmOF4AaABAg,@govindanchandran5326,,1,0jspaMLxBig,0,0,2023-01-29T14:25:41Z,"GONG XI FA CAI.<br>Computer science and AI is for everyone, not only Indian Nationals.<br>I am going to Write a AI Primer Textbook very soon...",2023-01-29T14:25:41Z
UgwZT8chAH3BSjibdNx4AaABAg,@bakhtiyor_sulaymonov,,1,0jspaMLxBig,0,1,2023-01-21T21:13:50Z,Thanks for the podcast,2023-01-21T21:13:50Z
UgybBfxRKQR15wMxAm14AaABAg,@nurgisaandasbek,,1,0jspaMLxBig,0,2,2023-01-09T16:38:26Z,Thank you so much for making this available Lex.,2023-01-09T16:38:26Z
Ugx6sYuJ0Qvd4S_xygB4AaABAg,@user-so7ix1pj7h,,1,0jspaMLxBig,0,8,2022-12-11T00:32:58Z,Andrew Ng is really productive in AI area. His courses of deep learning is my first AI course. It is really helpful. Helping people working great in one area makes people feel happy. do something useful for other people. Thanks Andrew and Lex.,2022-12-11T00:32:58Z
Ugzp0diOOtmgemefpqJ4AaABAg,@hamidabatemam2947,,1,0jspaMLxBig,0,1,2022-12-08T14:15:16Z,"thank yuo lex and andrew so muchüçé<a href=""about:invalid#zCSafez""></a>",2022-12-08T14:15:16Z
UgzUyPuEyR76ZKFkiAZ4AaABAg,@arunendrasingh1894,,1,0jspaMLxBig,0,0,2022-11-30T10:19:01Z,A deep learning video with 404K views. Noice on @30 November,2022-11-30T10:19:01Z
UgwPzATOukflfekNiGF4AaABAg,@Reve101,,1,0jspaMLxBig,0,53,2022-11-28T22:45:33Z,I teared up when Andrew said ‚Äúsomeone allow me the good fortune of helping them a little bit on their path to their dreams‚Äù. It restores my faith in humanity when I hear influential people like him with this much humility.,2022-11-28T22:45:33Z
UgwMT5_XnWsEr-BpkeN4AaABAg,@kennySg101,,1,0jspaMLxBig,0,0,2022-11-22T02:00:28Z,"I really hope he can come to Singapore to teach as visiting professor! Singapore is too small for him that is why he choose to stay in USA.  Born in Malaysia, educated in Singapore in his youth, hope he can return to our region.",2022-11-22T02:01:04Z
Ugw9g1dFLE8sVYKICM54AaABAg,@machinistnick2859,,1,qvT3NyaycoA,0,0,2021-03-30T11:51:03Z,Thanks,2021-03-30T11:51:03Z
Ugw4VOUJccu0fx9sZZF4AaABAg,@ramakanthrama8578,,1,qvT3NyaycoA,0,0,2020-03-17T04:58:08Z,second :P,2020-03-17T04:58:08Z
UgzztVkyB0aSSCCdM9B4AaABAg,@namanbhoj2353,,1,qvT3NyaycoA,0,1,2020-01-31T13:29:10Z,most awaited!,2020-01-31T13:29:10Z
UgycM1YdH0Mkuz67B8h4AaABAg,@machinistnick2859,,1,cI6WLiujJDY,0,0,2021-03-30T11:55:04Z,Thanks,2021-03-30T11:55:04Z
UgyfY3BQmynouh5dRmt4AaABAg,@shikhargairola5815,,1,cI6WLiujJDY,0,0,2020-02-02T17:37:13Z,want e on instagram i got 4k + views on Instagram ...let me know,2020-02-02T17:37:13Z
UgxceBjkjDgKK2NubDl4AaABAg,@ANKITRAJ-fe8dh,,1,cI6WLiujJDY,0,0,2020-01-28T02:43:06Z,Contact me,2020-01-28T02:43:06Z
UgzydGPedvPsz8Lr9sp4AaABAg,@ANKITRAJ-fe8dh,,1,cI6WLiujJDY,0,0,2020-01-28T02:42:46Z,Awesome content,2020-01-28T02:42:46Z
UgzB2zaXdE_W4-SrWM54AaABAg,@machinistnick2859,,1,7VHsWChH27g,0,0,2021-03-30T11:47:02Z,Thanks,2021-03-30T11:47:02Z
UgyHehMqFlqCKF-_SUZ4AaABAg,@arnavverma8622,,1,7VHsWChH27g,0,0,2020-10-03T19:22:16Z,Andrew Ng sir ‚ù§Ô∏è‚ò∫Ô∏è,2020-10-03T19:22:16Z
UgyhIVXiL_HSar1Xs494AaABAg,@r00t67,,1,7VHsWChH27g,1,0,2020-01-22T21:42:13Z,"Hey, where link to this course?",2020-01-22T21:42:13Z
UgyhIVXiL_HSar1Xs494AaABAg.946IgdHL086946MOr1o3FT,@r00t67,UgyhIVXiL_HSar1Xs494AaABAg,2,7VHsWChH27g,0,0,2020-01-22T22:14:36Z,Amazing how i can miss this course!,2020-01-22T22:14:36Z
UgxnpCYExPSowXJ24kJ4AaABAg,@stavcohen8502,,1,7VHsWChH27g,0,0,2020-01-22T12:56:58Z,WOHOHO!,2020-01-22T12:56:58Z
UgwIL1dx-Y1Zw7WAzUR4AaABAg,@flowoelki,,1,7VHsWChH27g,0,1,2020-01-20T19:32:13Z,In love with this team üòçüí™,2020-01-20T19:32:13Z
UgwfzKGDaqpV8rso_DR4AaABAg,@machinistnick2859,,1,nbfJ23FxvuI,0,0,2021-03-30T11:59:13Z,Thanks,2021-03-30T11:59:13Z
UgzCvP2jXdSG-7RR4lt4AaABAg,@satishnande3688,,1,nbfJ23FxvuI,0,0,2020-11-06T09:06:09Z,Wow... I have never been so excited for a course before this...,2020-11-06T09:06:09Z
UgzuikoHm3CSsdcbIwt4AaABAg,@palashsharma891,,1,nbfJ23FxvuI,0,0,2020-08-17T11:29:22Z,Yo guys. Is this tensorflow 1 or 2?,2020-08-17T11:29:22Z
UgxaL904vIhMQysZgXJ4AaABAg,@martindufour5727,,1,nbfJ23FxvuI,0,0,2020-01-14T13:13:54Z,Thank you very much for all your courses on Deep Learning. No one explains it better than you.,2020-01-14T13:13:54Z
UgysGzmUWbTD_YJ_TuB4AaABAg,@Giridhar99,,1,nbfJ23FxvuI,1,0,2019-12-13T05:39:16Z,Course is live now,2019-12-13T05:39:16Z
UgysGzmUWbTD_YJ_TuB4AaABAg.92T_gmk8SyA93XjsViD2cl,@vithalpandhare6757,UgysGzmUWbTD_YJ_TuB4AaABAg,2,nbfJ23FxvuI,0,0,2020-01-08T16:56:36Z,Where is the course,2020-01-08T16:56:36Z
Ugx3RM48EJ_rF88kDZB4AaABAg,@Giridhar99,,1,nbfJ23FxvuI,0,1,2019-12-09T03:28:41Z,when this course is starting . please tell the release date,2019-12-09T03:28:41Z
UgzRN_RAuUki_1XjDF94AaABAg,@budiman1990,,1,nbfJ23FxvuI,0,0,2019-11-28T02:05:43Z,Skynet?,2019-11-28T02:05:43Z
Ugx_gf5G7Ao7CI-IrXl4AaABAg,@basharalhusein4167,,1,nbfJ23FxvuI,0,0,2019-11-01T21:42:54Z,Hi.  Do you allow me to upload these courses on YouTube after adding Arabic subtitles?,2019-11-01T21:42:54Z
UgwOM2XIz0U7E00A-4V4AaABAg,@sebascamargo7520,,1,nbfJ23FxvuI,0,0,2019-10-28T01:02:08Z,"Thanks for leaning, is awesome the deep leaning world",2019-10-28T01:02:08Z
UgxbQBQycnsp_bxmnP54AaABAg,@mctrjalloh6082,,1,nbfJ23FxvuI,0,0,2019-10-22T14:42:43Z,Hope this will go in death with tensorflow serving and tfx etc ‚ù§,2019-10-22T14:42:43Z
Ugw3jZlnMWu26ogNiEZ4AaABAg,@abhikbanerjee3719,,1,nbfJ23FxvuI,0,0,2019-10-13T18:12:19Z,If only there was a Love React for YouTube Videos,2019-10-13T18:12:19Z
UgyG1rEHTyT3ddAu--N4AaABAg,@namanbhoj2353,,1,nbfJ23FxvuI,0,0,2019-10-13T09:27:23Z,When is it coming out?,2019-10-13T09:27:23Z
UgwSxHUx_wVeTCN2v0l4AaABAg,@anuraglahon8572,,1,nbfJ23FxvuI,0,0,2019-10-12T10:02:51Z,Is it flutter,2019-10-12T10:02:51Z
UgzHAChtGxIp-V844qp4AaABAg,@jonathansum9084,,1,nbfJ23FxvuI,0,0,2019-10-11T11:38:20Z,I hope there will be a React Native with it too.,2019-10-11T11:38:20Z
UgxPQ9-B3k_608_aMPZ4AaABAg,@YarvaAbhinayReddy,,1,nbfJ23FxvuI,0,4,2019-10-11T04:32:30Z,Cool.. when this course is going to release !!!,2019-10-11T04:32:30Z
Ugx-dU-fdGZj38iCpYp4AaABAg,@shaelanderchauhan1963,,1,nbfJ23FxvuI,0,0,2019-10-08T12:56:13Z,wow,2019-10-08T12:56:13Z
UgxUiVL528xyvW_CygN4AaABAg,@amitkharel1168,,1,nbfJ23FxvuI,1,11,2019-10-08T11:28:01Z,I love you Andrew. My life would have been nothing without your tutorials. Thankyou from my inner heart.,2019-10-08T11:28:01Z
UgxUiVL528xyvW_CygN4AaABAg.9-pG8KcPQrZ90QVVX-DsS8,@sherryhp10,UgxUiVL528xyvW_CygN4AaABAg,2,nbfJ23FxvuI,0,1,2019-10-23T07:53:23Z,Same Here,2019-10-23T07:53:23Z
Ugx_6wCKl09vflKJ6IR4AaABAg,@cutyoopsmoments2800,,1,nbfJ23FxvuI,0,1,2019-10-05T15:50:48Z,Eagerly waiting,2019-10-05T15:50:48Z
UgwcDYUT6X3iyj_24pt4AaABAg,@ryanhan3172,,1,nbfJ23FxvuI,0,0,2019-10-05T07:18:33Z,Can&#39;t wait!!!,2019-10-05T07:18:33Z
UgyVJYoxJgNnBy5M1Bp4AaABAg,@DistortedV12,,1,nbfJ23FxvuI,0,0,2019-10-04T01:20:14Z,how many courses is this now?,2019-10-04T01:20:14Z
UgyCOsGrMgH_foA99yt4AaABAg,@tranuctrinh9405,,1,nbfJ23FxvuI,0,0,2019-10-03T01:45:55Z,Super ;),2019-10-03T01:45:55Z
UgwXfVTPh3ua1LHCuT14AaABAg,@Ashish-zq3fx,,1,nbfJ23FxvuI,0,0,2019-09-28T14:25:48Z,You people drive me crazy,2019-09-28T14:25:48Z
UgyaEXuYsx4JZs_iQ0t4AaABAg,@Ashish-zq3fx,,1,nbfJ23FxvuI,0,0,2019-09-28T14:25:38Z,Waiting!!!!,2019-09-28T14:25:38Z
UgwbJKVZCmYLmatVECp4AaABAg,@JousefM,,1,nbfJ23FxvuI,0,0,2019-09-26T06:36:35Z,Sign me up boyz!,2019-09-26T06:36:35Z
UgzJAJ68l8o-FTd7Lgd4AaABAg,@gemtyler8258,,1,nbfJ23FxvuI,0,0,2019-09-25T22:24:31Z,I&#39;m excited,2019-09-25T22:24:31Z
UgylQjPDKB8d-EarZVF4AaABAg,@akshitkumar6450,,1,nbfJ23FxvuI,0,1,2019-09-25T19:09:02Z,just release it can&#39;t wait any more.,2019-09-25T19:09:02Z
UgyWuUFAPtXjQ5uNIEB4AaABAg,@johanneszwilling,,1,nbfJ23FxvuI,0,0,2019-09-25T11:43:38Z,ü§ì Is that Laurence Moroney!? Think I saw him on a live stream from this year‚Äôs Google I/O üòô That ‚ÄúZero to Hero‚Äù-Thing,2019-09-25T11:43:38Z
UgzmQyl6D3PttMjFwqZ4AaABAg,@chuheokon,,1,nbfJ23FxvuI,0,0,2019-09-25T10:24:56Z,What an amazing course. Cant wait to see that!!,2019-09-25T10:24:56Z
Ugwuql6sOqhp1RcKQ2V4AaABAg,@ambujmittal6824,,1,nbfJ23FxvuI,0,0,2019-09-25T09:33:50Z,&lt;3,2019-09-25T09:33:50Z
UgxJf93hp_WoEqkNYHJ4AaABAg,@tsung-hantsai5610,,1,nbfJ23FxvuI,0,3,2019-09-25T08:07:53Z,GitHub: lmoroney / dlaicourse / TensorFlow Deployment,2019-09-25T08:07:53Z
UgyIpovH69mRw_sXJNJ4AaABAg,@NayLinAung-ilovesumyatmaw,,1,nbfJ23FxvuI,0,0,2019-09-25T05:41:45Z,cool!,2019-09-25T05:41:45Z
UgxMfEmzA6KgyujBxLB4AaABAg,@iamkabilan,,1,nbfJ23FxvuI,0,0,2019-09-24T23:54:45Z,üëç,2019-09-24T23:54:45Z
UgyEND8SHoB_Rp-l_kN4AaABAg,@nottt5203,,1,nbfJ23FxvuI,0,3,2019-09-24T23:50:34Z,Anyone have an idea of when this may get released?,2019-09-24T23:50:34Z
Ugwf5FriAzpGj3ucfgd4AaABAg,@catalinahernandez5109,,1,nbfJ23FxvuI,0,0,2019-09-24T23:43:06Z,Excellent when?,2019-09-24T23:43:06Z
Ugz4cEw90Q2FxEuUCdp4AaABAg,@hiltyMG,,1,nbfJ23FxvuI,0,0,2019-09-24T23:36:13Z,Wow!,2019-09-24T23:36:13Z
UgzmiqepBLR_CjQAss54AaABAg,@MuruganR-tg9yt,,1,nbfJ23FxvuI,0,1,2019-09-24T23:31:15Z,i am eagerly waiting :))),2019-09-24T23:31:15Z
UgwiZu15mmYIZORmGUJ4AaABAg,@machinistnick2859,,1,y2v1-u6t5eQ,0,0,2021-03-30T11:47:53Z,Thanks,2021-03-30T11:47:53Z
UgyZZWKVIukJdh43iR94AaABAg,@roaavisions5781,,1,y2v1-u6t5eQ,0,0,2020-07-21T14:21:01Z,Undrew please i need dataset for covid 19,2020-07-21T14:21:01Z
Ugy7oaqCpSJFrQUS1OR4AaABAg,@shikhargairola5815,,1,y2v1-u6t5eQ,0,0,2020-02-14T02:40:06Z,hey i can handle your Instagram account<br>i am the owner of @artificialintelligencefacts,2020-02-14T02:40:06Z
Ugz-ImK6dMc6fsIcVpV4AaABAg,@Joe-xm3uc,,1,y2v1-u6t5eQ,0,0,2020-02-11T07:47:45Z,Best AI sources ever,2020-02-11T07:47:45Z
UgxqDPwBaDJRowlVCZx4AaABAg,@zaquielmayorga6438,,1,y2v1-u6t5eQ,0,2,2020-02-10T22:58:35Z,This course is highly recommend üëçüëç,2020-02-10T22:58:35Z
Ugw4KsT1K4V0SLfx8fV4AaABAg,@rajraji417,,1,y2v1-u6t5eQ,0,1,2020-02-10T19:57:00Z,Hi sir I&#39;m very very interested  I learn AI future of AI is big impact    how to learn AI sir   I love AI,2020-02-10T19:57:00Z
Ugy4kJAFa8Pfl4JmLrd4AaABAg,@machinistnick2859,,1,R2vIYVdMzPc,0,0,2021-03-30T11:49:01Z,Thanks,2021-03-30T11:49:01Z
UgzmA9166RMO5k-VcAF4AaABAg,@machinistnick2859,,1,_YcAEBnbtPQ,0,0,2021-03-30T11:53:59Z,Thanks,2021-03-30T11:53:59Z
Ugyd-E5vI1q1MLqOdJB4AaABAg,@machinistnick2859,,1,zGFKSQlef_0,0,0,2021-03-30T11:58:14Z,Thanks,2021-03-30T11:58:14Z
Ugzk532Dd9z_9B_Fpyl4AaABAg,@pranabsarma18,,1,zGFKSQlef_0,0,0,2020-09-12T17:47:57Z,I have Project on Image segmentation for Cancer Cell detection. Will this course be useful?,2020-09-12T17:47:57Z
UgwPrBUTFHxmTrlBZiJ4AaABAg,@JousefM,,1,zGFKSQlef_0,0,11,2020-04-17T19:57:46Z,"I just love how humble Andrew is, role model.",2020-04-17T19:57:46Z
UgyHQKOmhB-JndcyI3l4AaABAg,@anastasiianeviantseva4894,,1,zGFKSQlef_0,0,0,2020-04-15T14:21:14Z,Where is it?????It`s time to be on coursera,2020-04-15T14:21:14Z
UgykQncGkpk0Fp7s3Ul4AaABAg,@anmspro,,1,zGFKSQlef_0,0,0,2020-04-15T00:16:27Z,Is it available now?,2020-04-15T00:16:27Z
UgyKhMv-Ka47PZdBuDV4AaABAg,@shamanthnayak6015,,1,zGFKSQlef_0,0,2,2020-04-13T19:14:29Z,Where&#39;s the course?,2020-04-13T19:14:29Z
UgyBPDOOIfiDwtJUUdN4AaABAg,@pauljohny200,,1,zGFKSQlef_0,0,1,2020-04-05T08:26:03Z,I  will like to specialise this field.. thanks,2020-04-05T08:26:03Z
UgyVjDMI14PIX-t8Qwl4AaABAg,@sumitkumar-el3kc,,1,zGFKSQlef_0,0,5,2020-04-04T01:32:16Z,"Love you guys, please make a course on deep learning for genomics/computational biology too.",2020-04-04T01:32:16Z
UgyJq9xFzSyCvBzva194AaABAg,@MichaelStreit01,,1,zGFKSQlef_0,0,0,2020-04-03T05:51:24Z,Will this be available on Coursera? :),2020-04-03T05:51:24Z
Ugx3PiUQesR5WjPPrbt4AaABAg,@blueborne4031,,1,zGFKSQlef_0,0,3,2020-04-01T20:00:49Z,I&#39;m so excited! I am working on 3d CNN for MRIS right now and this is perfect,2020-04-01T20:00:49Z
Ugwt55I0cz6pHBUOn-54AaABAg,@RafiuddinKhanrafirrr,,1,zGFKSQlef_0,0,0,2020-04-01T16:23:24Z,Coming more things to learn,2020-04-01T16:23:24Z
UgyhkqNeFuwuUDH7IV94AaABAg,@no_one1073,,1,zGFKSQlef_0,0,1,2020-04-01T03:14:09Z,Looking forward to it,2020-04-01T03:14:09Z
UgyBNGQv6VvboqYvccZ4AaABAg,@vinayreddy8683,,1,zGFKSQlef_0,0,0,2020-03-31T20:52:26Z,Waiting,2020-03-31T20:52:26Z
UgzGiYtl5ExlXb4a3614AaABAg,@dimitheodoro,,1,zGFKSQlef_0,0,0,2020-03-31T20:38:28Z,AMAZING!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!,2020-03-31T20:38:28Z
Ugxp41LsLzWgek5MT-Z4AaABAg,@username42,,1,zGFKSQlef_0,0,0,2020-03-31T20:01:57Z,looking forward to seeing it,2020-03-31T20:01:57Z
UgwaNLnHtz0Egkh2MPJ4AaABAg,@Joeyyukonm,,1,zGFKSQlef_0,0,2,2020-03-31T19:21:02Z,This is what the future of AI looks like.,2020-03-31T19:21:02Z
UgwwXvjxKdSRfc4CZuZ4AaABAg,@leykunejigu7477,,1,zGFKSQlef_0,1,1,2020-03-31T18:47:12Z,what will be the prerequisite?,2020-03-31T18:47:12Z
UgwwXvjxKdSRfc4CZuZ4AaABAg.96seW8j8ImI96thoca-6N7,@mrcjproject,UgwwXvjxKdSRfc4CZuZ4AaABAg,2,zGFKSQlef_0,0,0,2020-04-01T04:35:19Z,If you have taken the deeplearning specialization then your good to go. If you are new into deeplearning then u need to understand how it works  before taking this specialization,2020-04-01T04:35:19Z
UgyrjvCjNxqbgtSjna14AaABAg,@hrantbaloyan4652,,1,zGFKSQlef_0,0,3,2020-03-31T18:22:52Z,How much will cost?Or will be free?,2020-03-31T18:22:52Z
UgzNEb4HUcxB7cXpNrl4AaABAg,@undisclosedmusic4969,,1,zGFKSQlef_0,7,13,2020-03-31T18:22:01Z,I hope they do something actually useful like 3d CNNs for ct and not just resnet 50 for x-rays all over again,2020-03-31T18:22:01Z
UgzNEb4HUcxB7cXpNrl4AaABAg.96sbcjUDA7A96t8iA3V9Nm,@ayushmehta5844,UgzNEb4HUcxB7cXpNrl4AaABAg,2,zGFKSQlef_0,0,1,2020-03-31T23:19:51Z,All over again? Is there some course out already?,2020-03-31T23:19:51Z
UgzNEb4HUcxB7cXpNrl4AaABAg.96sbcjUDA7A96uuaDQuhMl,@keistzenon9593,UgzNEb4HUcxB7cXpNrl4AaABAg,2,zGFKSQlef_0,0,0,2020-04-01T15:46:11Z,@@ayushmehta5844 There is the &quot;coursera deep learning&quot; online course,2020-04-01T15:46:11Z
UgzNEb4HUcxB7cXpNrl4AaABAg.96sbcjUDA7A96yXUfCAGOZ,@sushruthrp1870,UgzNEb4HUcxB7cXpNrl4AaABAg,2,zGFKSQlef_0,0,1,2020-04-03T01:32:32Z,"It&#39;s probably going to be just ResNets and DenseNets. Since Pranav is a part of this course, I suspect most of the content is going to be centered around building models for predicting different pathologies in a chest radiograph. The best performing model was a DenseNet121 so it&#39;s verly likely it&#39;s going to be just that or something similar.",2020-04-03T01:32:32Z
UgzNEb4HUcxB7cXpNrl4AaABAg.96sbcjUDA7A978ngqPZKi9,@ramkotha4726,UgzNEb4HUcxB7cXpNrl4AaABAg,2,zGFKSQlef_0,0,0,2020-04-07T10:34:31Z,"Hi, If you dont mind me asking what is CT? Is it CT image/scan, Thanks",2020-04-07T10:34:31Z
UgzNEb4HUcxB7cXpNrl4AaABAg.96sbcjUDA7A978oGoRkt0J,@keistzenon9593,UgzNEb4HUcxB7cXpNrl4AaABAg,2,zGFKSQlef_0,0,1,2020-04-07T10:39:34Z,"@@ramkotha4726 Yes its CT (Computer Tomography), making 3d Images of Body parts in medicine using ct scans (these scary machines where you get your brain scanned for example)",2020-04-07T10:39:34Z
Ugx5fYQCSW-DxL1LAkN4AaABAg,@islamicinterestofficial,,1,zGFKSQlef_0,0,0,2020-03-31T18:14:38Z,Waiting ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è,2020-03-31T18:14:38Z
Ugx6CNgkiMwixf0O48R4AaABAg,@habibmrad8116,,1,zGFKSQlef_0,0,0,2020-03-31T18:03:24Z,Awesome specialization.. I love it,2020-03-31T18:03:24Z
UgxC8smb3CCBzCh-SXJ4AaABAg,@asbjoern072,,1,6dQgPFaZMGQ,0,0,2023-08-14T13:07:53Z,Hi ü§ìüëçüôèPlease skip the background musik üôè,2023-08-14T13:07:53Z
UgzbswNwNxmPjoK1B_14AaABAg,@ThePressbrief,,1,6dQgPFaZMGQ,0,0,2022-10-14T21:34:30Z,How we will create these two file train_preds.csv and valid_preds.csv from first assignments.<br>Kindly suggest the code,2022-10-14T21:34:30Z
UgylbphBOYZKUuZVMKN4AaABAg,@machinistnick2859,,1,6dQgPFaZMGQ,0,0,2021-03-30T11:57:16Z,Thanks,2021-03-30T11:57:16Z
UgyWTsJDyqMt-OQUV_J4AaABAg,@LewiUberg,,1,6dQgPFaZMGQ,0,0,2020-10-10T05:38:19Z,"I see a Andrew Y. Ng. in a paper about the MURA dataset. Is this the same person? I&#39;m making a CNN right now, and was just able to predict correctly on my sons X-ras, yay! :)",2020-10-10T05:38:19Z
Ugwwui-3aG1KKl2jHWh4AaABAg,@VysakhRemesh,,1,6dQgPFaZMGQ,0,0,2020-04-16T15:24:58Z,I&#39;m so excited to join the course.,2020-04-16T15:24:58Z
Ugx6aqFnBr-AcUpJB7x4AaABAg,@swordsman-1,,1,6dQgPFaZMGQ,1,6,2020-04-07T19:13:29Z,Next time lower the music.. it&#39;s distracting,2020-04-07T19:13:29Z
Ugx6aqFnBr-AcUpJB7x4AaABAg.979j4k2lmM197AAFxFnsSd,@najibalawar666,Ugx6aqFnBr-AcUpJB7x4AaABAg,2,6dQgPFaZMGQ,0,1,2020-04-07T23:19:40Z,"Not just that, It was hard to hear",2020-04-07T23:19:40Z
UgwTN_g_7qi4gXL-acN4AaABAg,@thantyarzarhein5459,,1,6dQgPFaZMGQ,2,1,2020-04-07T18:39:16Z,Can&#39;t wait to take this courses üòçüòç,2020-04-08T03:51:44Z
UgwTN_g_7qi4gXL-acN4AaABAg.979fACGnb7W979lyemNHkH,@niyatham8525,UgwTN_g_7qi4gXL-acN4AaABAg,2,6dQgPFaZMGQ,0,0,2020-04-07T19:38:43Z,When is the course out?,2020-04-07T19:38:43Z
UgwTN_g_7qi4gXL-acN4AaABAg.979fACGnb7W97AVpPa2oXt,@no_one1073,UgwTN_g_7qi4gXL-acN4AaABAg,2,6dQgPFaZMGQ,0,1,2020-04-08T02:28:09Z,@@niyatham8525 15th April,2020-04-08T02:28:09Z
UgyAUyW96NEzRie3iZR4AaABAg,@codingquiz,,1,6dQgPFaZMGQ,0,1,2020-04-07T18:36:03Z,I am waiting for it,2020-04-07T18:36:03Z
UgysvTq7f4Ham36W3O54AaABAg,@machinistnick2859,,1,oJ2FL5BsFuQ,0,0,2021-03-30T11:18:40Z,Thanks,2021-03-30T11:18:40Z
UgwFI6I_1AjejdFK3jR4AaABAg,@anastasiianeviantseva4894,,1,oJ2FL5BsFuQ,0,1,2020-04-15T13:19:03Z,"Guys, were AI for medicine??I`ts already 15th of april :)",2020-04-15T13:19:03Z
UgxLXIdIti9s8bKNfEF4AaABAg,@rodrigueswilder,,1,oJ2FL5BsFuQ,0,0,2020-04-10T08:47:35Z,Love it and will go through this course as I did with all the other oens.,2020-04-10T08:47:35Z
UgxqoGpDmn-vkwCtWOV4AaABAg,@username42,,1,oJ2FL5BsFuQ,0,2,2020-04-09T18:39:36Z,first :D <br><br><br>STAY AT HOME STAY HEALTHY,2020-04-09T18:39:57Z
UgxYFYVphjIGzM548kh4AaABAg,@anonymous-tt2lm,,1,dvnsbOtAmYI,0,1,2021-09-10T10:21:44Z,K inn,2021-09-10T10:21:44Z
Ugw3EJlrcrKS8gzp3U54AaABAg,@machinistnick2859,,1,dvnsbOtAmYI,0,0,2021-03-30T11:16:39Z,Thanks,2021-03-30T11:16:39Z
UgxwmTO5yQLuT77sTC14AaABAg,@waqas231900,,1,dvnsbOtAmYI,1,0,2020-04-15T08:48:59Z,Great...anyone here can pl give me some images annotated by pathologist??,2020-04-15T08:48:59Z
UgxwmTO5yQLuT77sTC14AaABAg.97TCynXhuoH97Ud87n5xMn,@JousefM,UgxwmTO5yQLuT77sTC14AaABAg,2,dvnsbOtAmYI,0,0,2020-04-15T22:05:33Z,The first two courses are now out!,2020-04-15T22:05:33Z
UgyKNlCvKu0KuOs3z4x4AaABAg,@TheEducationWorldUS,,1,dvnsbOtAmYI,1,0,2020-04-15T07:11:23Z,Good ... Btw when you will launch this course ???,2020-04-15T07:11:23Z
UgyKNlCvKu0KuOs3z4x4AaABAg.97T1nvPAGZF97Ud8Q9z4Bt,@JousefM,UgyKNlCvKu0KuOs3z4x4AaABAg,2,dvnsbOtAmYI,0,0,2020-04-15T22:05:36Z,The first two courses are now out!,2020-04-15T22:05:36Z
UgxDhOlXtc5NqG24IyR4AaABAg,@FarahNazifa,,1,dvnsbOtAmYI,1,0,2020-04-15T05:48:20Z,"Hi, when will this course begin?",2020-04-15T05:48:20Z
UgxDhOlXtc5NqG24IyR4AaABAg.97StIjD-Vr297Ud7ChE6ai,@JousefM,UgxDhOlXtc5NqG24IyR4AaABAg,2,dvnsbOtAmYI,0,0,2020-04-15T22:05:26Z,The first two courses are now out!,2020-04-15T22:05:26Z
UgzHm8-ds8vcWvWBLyl4AaABAg,@scottquadrelli6688,,1,dvnsbOtAmYI,1,0,2020-04-15T01:05:06Z,Hi. Can you please let me know when this course will be available ?,2020-04-15T01:05:06Z
UgzHm8-ds8vcWvWBLyl4AaABAg.97SNtEeTtWM97Ud7qjDXrW,@JousefM,UgzHm8-ds8vcWvWBLyl4AaABAg,2,dvnsbOtAmYI,0,0,2020-04-15T22:05:31Z,The first two courses are now out!,2020-04-15T22:05:31Z
UgzPZpAgYNmN9xspQg14AaABAg,@ananthakrishnank3208,,1,_i3aqgKVNQI,0,0,2023-07-16T13:22:15Z,"<a href=""https://www.youtube.com/watch?v=_i3aqgKVNQI&amp;t=1m20s"">1:20</a>",2023-07-16T13:22:15Z
Ugy1-vE3OgOrFNzEWlh4AaABAg,@pankajchandravanshi8712,,1,_i3aqgKVNQI,0,0,2022-06-18T19:57:34Z,Thanks for uploading this materials here. I&#39;m super grateful!,2022-06-18T19:57:34Z
UgxN4f0bEyHfrkbx0Pt4AaABAg,@rafibasha1840,,1,_i3aqgKVNQI,0,0,2021-12-05T09:29:25Z,Please upload all the videos,2021-12-05T09:29:25Z
Ugya5McJBbPtZjatyPV4AaABAg,@user-lc1nm6cy5g,,1,_i3aqgKVNQI,0,0,2020-04-13T04:14:01Z,Please make english subtitle.,2020-04-13T04:14:01Z
Ugwaoprqu7nvLmLf3UB4AaABAg,@gurdeepsaini3979,,1,_i3aqgKVNQI,3,2,2019-10-27T06:22:12Z,week1 and week 2 ?,2019-10-27T06:22:12Z
Ugwaoprqu7nvLmLf3UB4AaABAg.90_dF6EBBFC96XCvottnCh,@ahn19c,Ugwaoprqu7nvLmLf3UB4AaABAg,2,_i3aqgKVNQI,0,0,2020-03-23T01:34:08Z,"<a href=""https://www.coursera.org/learn/nlp-sequence-models#syllabus"">https://www.coursera.org/learn/nlp-sequence-models#syllabus</a>",2020-03-23T01:34:08Z
Ugwaoprqu7nvLmLf3UB4AaABAg.90_dF6EBBFC9IfhEdjVJtv,@manuel783,Ugwaoprqu7nvLmLf3UB4AaABAg,2,_i3aqgKVNQI,0,0,2021-01-19T00:17:37Z,There are some videos missing from the week 3 as well.,2021-01-19T00:17:37Z
Ugwaoprqu7nvLmLf3UB4AaABAg.90_dF6EBBFC9Ihj5J4YPBA,@manuel783,Ugwaoprqu7nvLmLf3UB4AaABAg,2,_i3aqgKVNQI,0,1,2021-01-19T19:12:18Z,"After I asked them, then they said that the missing videos can be looked for on Coursera.",2021-01-19T19:12:18Z
UgwBfIkiyEKnGyNLSN14AaABAg,@mccloudsw,,1,_i3aqgKVNQI,0,12,2019-05-30T01:19:06Z,"Thank you for posting videos. Nice, but where are c5w1, c5w2? Was it done intentionally? I find c1 to c3 too easy for me, so I wanted to watch the last 2 courses since I don&#39;t have time for homework assignments at this moment, so I don&#39;t see much sense to start course at coursera.",2019-05-30T01:25:46Z
Ugzau98L9uutrDKtCaN4AaABAg,@tbru92,,1,_i3aqgKVNQI,1,13,2018-02-06T10:52:31Z,thank you!!! :) is week 1 and 2  of the last course coming as well? <br>thanks again for uploading this great courses! :),2018-02-06T10:52:31Z
Ugzau98L9uutrDKtCaN4AaABAg.8cK3yV8m29f96XCwOsaBCr,@ahn19c,Ugzau98L9uutrDKtCaN4AaABAg,2,_i3aqgKVNQI,0,1,2020-03-23T01:34:13Z,"<a href=""https://www.coursera.org/learn/nlp-sequence-models#syllabus"">https://www.coursera.org/learn/nlp-sequence-models#syllabus</a>",2020-03-23T01:34:13Z
UgxkQRNxRcYIIYJswDx4AaABAg,@SunilSharma-sp2vk,,1,_i3aqgKVNQI,0,1,2018-02-06T00:30:01Z,Nice :),2018-02-06T00:30:01Z
UgxrrWNVqYQdwMkMf7l4AaABAg,@TankNSSpank,,1,Er2ucMxjdHE,0,0,2023-03-03T23:35:46Z,This playlist is missing 3 4 5,2023-03-03T23:35:46Z
UgyGOPhmb6ZerlZi7SJ4AaABAg,@NdamuleloNemakh,,1,Er2ucMxjdHE,0,0,2022-07-12T09:35:09Z,nicely explainedüëè,2022-07-12T09:35:09Z
UgxXn1BK_lEUvP8GcEx4AaABAg,@trexmidnite,,1,Er2ucMxjdHE,0,2,2021-04-04T07:16:23Z,Andrew is the biggest brain in NLP..,2021-04-04T07:16:23Z
UgzABvn_Dck76P91O-x4AaABAg,@sandipansarkar9211,,1,Er2ucMxjdHE,0,2,2021-02-05T18:46:30Z,great explanation,2021-02-05T18:46:30Z
Ugz-YwOvOUTHKlz86-p4AaABAg,@whaleshark8700,,1,Er2ucMxjdHE,0,2,2020-08-20T03:28:36Z,good french pronunciation~~~~,2020-08-20T03:28:36Z
UgxTPAvLRqpU-pUdLDp4AaABAg,@khanzorbo,,1,Er2ucMxjdHE,0,1,2018-08-11T15:38:34Z,"Thank you for this video. I&#39;ve been searching for quite a bit for the explanation of how we get a word as the most probable output, and this video explained it to me.",2018-08-11T15:38:34Z
UgwkHJaZv1WEwgIGqC14AaABAg,@epistemophilicmetalhead9454,,1,DejHQYAGb7Q,0,1,2023-11-14T06:53:45Z,"when it comes to translation, there can be &gt;1 correct answers. BLEU (bilingual evaluation) score measures how correct a translation is by comparing it with the translation provided by actual people. modified precision is used to calculate BLEU score<br>modified precision (word by word) = max number of times the word is supposed to appear / number of times the word is present in the translation.<br>modified precision on bigrams is where you take two consecutive words at a time (like a slider) and then calculate using the same formula (but for a two word phrase this time)<br>same goes for n-grams<br>if the output is exactly equal to one of the references, all modified precision values (for 1,2,....n-grams) = 1.0<br>combined BLEU score = BP*exp(sum of k modified precisions / n)   where k goes from 1 to n and BP=brevity penalty (it penalizes translations that are too short because short translations have a higher chance of having higher modified precision scores)<br>BP = 1 if output (machine translation) length&gt;reference (human translation) length<br>BP = exp(1- (machine translation length/human translation length)) otherwise",2023-11-14T06:53:45Z
UgxrleHa8mbgufi7XXh4AaABAg,@ananthakrishnank3208,,1,DejHQYAGb7Q,0,0,2023-07-16T15:49:38Z,"<a href=""https://www.youtube.com/watch?v=DejHQYAGb7Q&amp;t=2m40s"">2:40</a>",2023-07-16T15:49:38Z
UgyVCHqgXeSomeH1bXx4AaABAg,@randomtea,,1,DejHQYAGb7Q,0,0,2022-06-04T07:14:38Z,poorly explained. and the formula is wrong. Andrew is overrated,2022-06-04T07:14:38Z
UgxyfBX3jQeNWiUQOY54AaABAg,@anthonyarmour1812,,1,DejHQYAGb7Q,0,0,2022-02-06T00:30:57Z,"Great video, but there&#39;s an error I&#39;ve seen in every resource I&#39;ve looked at. Had to find out from reading the original paper. Cumulative Bleu score = BP √ó exp( 1/n x sum(log(Pn))).. the log is an important difference. Video was great tho! I&#39;ve seen like 5 resources that seem to have left the log out",2022-02-06T00:30:57Z
Ugwhc1bs5YmAmkJeqLZ4AaABAg,@NikhilSharma-td3hr,,1,DejHQYAGb7Q,0,0,2022-01-28T16:12:21Z,Thank you.,2022-01-28T16:12:21Z
UgwBUvcpvOKe-Cz4KHF4AaABAg,@olha_,,1,DejHQYAGb7Q,0,1,2021-05-09T12:46:21Z,"I had to look this up because I didn&#39;t understand the lectures on the BLEU score from the <a href=""http://deeplearning.ai/"">Deeplearning.ai</a> NLP Coursera course and this was indeed much more helpful!",2021-05-09T12:46:21Z
Ugzd4J8gFQvwfQWTJAJ4AaABAg,@therri1227,,1,DejHQYAGb7Q,0,0,2021-03-28T10:24:45Z,Lecture L03 and L04 are missing from the playlist of the week,2021-03-28T10:24:45Z
UgxPhDfnKt6NddYsL9Z4AaABAg,@annawilson3824,,1,DejHQYAGb7Q,1,1,2020-11-06T14:52:21Z,"Why only up to p_4 n-gram, if there are 6 words in reference #1? Up to p_5 is better, no?",2020-11-06T14:52:21Z
UgxPhDfnKt6NddYsL9Z4AaABAg.9FiiWW58sKM9OxMReUwJmk,@simoncrase5360,UgxPhDfnKt6NddYsL9Z4AaABAg,2,DejHQYAGb7Q,0,1,2021-06-24T00:01:51Z,"There&#39;s an awful lot of 5-grams! Papineni et al (2002) states &quot;... as can be seen in Figure 2, the modified n-gram precision decays roughly exponentially with n...&quot;, so I expect that 5-grams are a pain to calculate, and they don&#39;t add much precision to the score.",2021-06-24T00:01:51Z
UgxBOHpii-fCzzTNqR54AaABAg,@SupunKandambige,,1,DejHQYAGb7Q,1,0,2020-02-25T17:47:29Z,"<a href=""https://www.youtube.com/watch?v=DejHQYAGb7Q&amp;t=1m59s"">1:59</a> didn&#39;t know that he uses Slack",2020-02-25T17:47:29Z
UgxBOHpii-fCzzTNqR54AaABAg.95TQr8qzu4N9KSXX_oV37x,@vinson2233,UgxBOHpii-fCzzTNqR54AaABAg,2,DejHQYAGb7Q,0,0,2021-03-04T05:17:30Z,I thought my Slack give me notification,2021-03-04T05:17:30Z
UgwNoVLnpq90NaNwihd4AaABAg,@Acha413,,1,DejHQYAGb7Q,1,3,2019-10-24T16:06:02Z,"at time <a href=""https://www.youtube.com/watch?v=DejHQYAGb7Q&amp;t=8m14s"">8:14</a> there is a mistake, the count clip for &quot;the mat&quot; should be 2, isn&#39;t it.?",2019-10-24T16:06:02Z
UgwNoVLnpq90NaNwihd4AaABAg.90Txf_Zroei90he5s5tOZf,@HTSFestival,UgwNoVLnpq90NaNwihd4AaABAg,2,DejHQYAGb7Q,0,2,2019-10-30T09:03:36Z,I&#39;m afraid not. It might be max appearence in one sentence.,2019-10-30T09:03:36Z
UgyC5JUWf9JmYtcAopp4AaABAg,@wangjohn6480,,1,DejHQYAGb7Q,1,0,2019-09-05T08:23:45Z,ÊúâËÄÅÂê¥ÁöÑ ‰∏≠ÊñáËßÜÈ¢ëÂêó Ëøô‰∏™ÁúüÁöÑÂê¨‰∏çÊáÇ,2019-09-05T08:23:45Z
UgyC5JUWf9JmYtcAopp4AaABAg.8zUxou4Qwvm94g8GWcoq9o,@user-bz7ki7dl1r,UgyC5JUWf9JmYtcAopp4AaABAg,2,DejHQYAGb7Q,0,0,2020-02-06T05:03:02Z,ÊàëËßâÂæó‰∏çÈîôÂïäÔºÅËÆ≤ÁöÑÈùûÂ∏∏Â•Ω,2020-02-06T05:03:02Z
UgwKKbKFb53g64kXwbp4AaABAg,@bobli3467,,1,DejHQYAGb7Q,0,19,2019-07-28T05:34:14Z,There is an error that BP:=exp(1-ref_output/MT_output),2019-07-28T05:34:14Z
UgykfzUZeL8ZbzG0F0Z4AaABAg,@alexminsky1,,1,DejHQYAGb7Q,1,2,2019-07-10T12:21:13Z,"One of the most boring lecturer I‚Äôve ever seen! He‚Äôs great, though.",2019-07-10T12:21:13Z
UgykfzUZeL8ZbzG0F0Z4AaABAg.8xCbgE763pl8xPFFKLGJ63,@Linz0r1s,UgykfzUZeL8ZbzG0F0Z4AaABAg,2,DejHQYAGb7Q,0,1,2019-07-15T10:06:33Z,"nice one, you made me laugh idiot !",2019-07-15T10:06:33Z
Ugwmn85rDDIGsuriFut4AaABAg,@utkarshraj9061,,1,DejHQYAGb7Q,0,1,2019-07-08T17:01:50Z,Whole course in python or octave,2019-07-08T17:01:50Z
UgzFY_f64pHdMCJJgal4AaABAg,@mebeasensei,,1,DejHQYAGb7Q,4,4,2019-03-03T16:03:44Z,&quot;on the&quot; appears twice?,2019-03-03T16:03:44Z
UgzFY_f64pHdMCJJgal4AaABAg.8s0qb7xWzVw8yqBsPRKPDQ,@jackyangara1,UgzFY_f64pHdMCJJgal4AaABAg,2,DejHQYAGb7Q,0,1,2019-08-20T03:07:12Z,"sentence 1 = 1 &quot;on the&quot;, sentence 2 = 1 &quot;on the&quot;.<br>in unigram he mentioned that we take the maximum one.<br>Thus, &quot;on the&quot; = 1",2019-08-20T03:07:12Z
UgzFY_f64pHdMCJJgal4AaABAg.8s0qb7xWzVw97B2beToVQx,@BalaguruGupta,UgzFY_f64pHdMCJJgal4AaABAg,2,DejHQYAGb7Q,0,0,2020-04-08T07:32:06Z,@@jackyangara1 &quot;On the&quot; is bigram right?,2020-04-08T07:32:06Z
UgzFY_f64pHdMCJJgal4AaABAg.8s0qb7xWzVw97B8h-eJbMU,@jackyangara1,UgzFY_f64pHdMCJJgal4AaABAg,2,DejHQYAGb7Q,0,0,2020-04-08T08:25:16Z,@@BalaguruGupta yes,2020-04-08T08:25:16Z
UgzFY_f64pHdMCJJgal4AaABAg.8s0qb7xWzVw9Ot5Q4j4xSt,@aynieeetube,UgzFY_f64pHdMCJJgal4AaABAg,2,DejHQYAGb7Q,0,0,2021-06-22T08:16:08Z,"For count clip, we take the max. occurence of the n-gram in the referenes. Not the count of the n-gram from each reference.",2021-06-22T08:16:08Z
UgytdawkxIwq7pjxulZ4AaABAg,@siddharthakantipudi2329,,1,DejHQYAGb7Q,0,0,2019-02-11T05:36:43Z,Please upload the full series !!!,2019-02-11T05:36:43Z
UgxOM9p2sfeQAl0qb9Z4AaABAg,@user-hl9mz5cs5w,,1,DejHQYAGb7Q,0,0,2019-01-16T06:28:15Z,thank you andrew.,2019-01-16T06:28:15Z
UgzswaPkZDPEo6sZ6Et4AaABAg,@jimmccarthy8087,,1,DejHQYAGb7Q,1,6,2018-12-20T23:10:11Z,Will the full series of Sequence Models be uploaded soon?,2018-12-20T23:10:11Z
UgzswaPkZDPEo6sZ6Et4AaABAg.8p5dNhXg8W79LcatTBvFOK,@neuron8186,UgzswaPkZDPEo6sZ6Et4AaABAg,2,DejHQYAGb7Q,0,0,2021-04-02T08:58:38Z,did you find it ?,2021-04-02T08:58:38Z
UgwPm5Xj2tyQXGXhO0t4AaABAg,@CTimmerman,,1,DejHQYAGb7Q,0,0,2018-12-20T17:35:58Z,"<a href=""https://www.youtube.com/watch?v=DejHQYAGb7Q&amp;t=0m45s"">0:45</a> Reference 2 is not perfectly fine.",2018-12-20T17:35:58Z
UgyicaDk1A0FCwMG40p4AaABAg,@Heyoo-vx5vt,,1,DejHQYAGb7Q,1,4,2018-11-30T05:45:36Z,I think that brevity penalty factor has to be<br> exp(1-reference_output_length/MT_output_length) if MT_output_length&lt;= reference_output_length<br>because we have to penalize when the length of the output sentence is too short.<br><br>Maybe that is a typo.,2018-11-30T05:45:36Z
UgyicaDk1A0FCwMG40p4AaABAg.8oGGwQJ0p6A8q3HXNVffCn,@DrJohnnyStalker,UgyicaDk1A0FCwMG40p4AaABAg,2,DejHQYAGb7Q,0,2,2019-01-13T21:43:26Z,Yes this is a typo. The original paper also sum over log(p) to scale Bleu between 0 and 1,2019-01-13T22:47:23Z
UgzIxKeKmkos7OMCQ7F4AaABAg,@sawsanasjea4828,,1,DejHQYAGb7Q,0,0,2018-10-24T07:12:41Z,thank you . we need more example,2018-10-24T07:12:41Z
UgzQoQQhXrw-WkksIJF4AaABAg,@shayanhati2325,,1,DejHQYAGb7Q,0,7,2018-08-15T06:18:48Z,Please upload the full series. Eagerly waiting.,2018-08-15T06:18:48Z
UgzOetDiJPS7H5rqLax4AaABAg,@aqwkpfdhtla9018,,1,DejHQYAGb7Q,0,7,2018-08-08T12:14:56Z,There is a high pitch sound. It is so annoying.,2018-08-08T12:14:56Z
UgzIGAlf130oTGTay5p4AaABAg,@jimmylee2197,,1,DejHQYAGb7Q,1,5,2018-05-06T06:47:32Z,"according to the original paper, does the BP under otherwise condition should be exp(1-reference_outut_length/MT_output_length)?",2018-05-06T06:47:32Z
UgzIGAlf130oTGTay5p4AaABAg.8ftng3CI6-P9UOFl6CyUDW,@ladingokalpay1849,UgzIGAlf130oTGTay5p4AaABAg,2,DejHQYAGb7Q,0,1,2021-11-06T02:39:11Z,yes. it was corrected later in the coursera course.,2021-11-06T02:39:11Z
UgwsArHkxcrxojjz_654AaABAg,@wenkaidai8291,,1,DejHQYAGb7Q,0,3,2018-04-30T13:38:21Z,Looking forward to your upload of full series of sequence models~,2018-04-30T13:38:21Z
UgzfLSMikd8rTSF6hT14AaABAg,@alignedbyprinciple,,1,DejHQYAGb7Q,0,1,2018-04-24T07:52:52Z,I read other people&#39;s tutorials regarding this topic and by far this is the best and easiest tutorial on bleu score. Thanks a lot.,2018-04-24T07:52:52Z
Ugy7T-nBYpgfab2qiOh4AaABAg,@kaitaoyang15,,1,DejHQYAGb7Q,0,0,2018-04-18T20:07:18Z,"Monthly Deep Learning training in the Netherlands. Early birds get 85% OFF. Please sign up from here: <a href=""https://dlapplied.com/training-history-deep-learning/"">https://dlapplied.com/training-history-deep-learning/</a>",2018-04-18T20:07:18Z
UgwbBO7L7HMX7ucvOaB4AaABAg,@veerudumpala1793,,1,DejHQYAGb7Q,1,2,2018-04-13T22:28:55Z,Brevity Penality Factor:<br>IF len(MT_output) == len(ref_output)<br>then also exp(1-m/r) equals to 1? Right?,2018-04-13T22:28:55Z
UgwbBO7L7HMX7ucvOaB4AaABAg.8f-G7lyWsye8ocLIp66kka,@registryfaceoff1108,UgwbBO7L7HMX7ucvOaB4AaABAg,2,DejHQYAGb7Q,0,0,2018-12-09T04:46:16Z,Yes. But the equation has a typo. You should swap numerator and denominator.,2018-12-09T04:46:16Z
UgxKL5MC3GjqPzPEzpF4AaABAg,@arsalan2780,,1,DejHQYAGb7Q,0,0,2018-04-03T04:44:38Z,Kindly upload full series,2018-04-03T04:44:38Z
UgwxFfVTRFZW7gfaMIp4AaABAg,@thedissociation3666,,1,DejHQYAGb7Q,0,5,2018-03-25T01:58:34Z,Thank you and also your voice is so calming,2018-03-25T01:58:34Z
Ugx58-u1yi98BBqbiSd4AaABAg,@RaviCHandra-fj8dr,,1,DejHQYAGb7Q,4,3,2018-02-09T16:25:54Z,please upload full series of sequence models. waiting for it.,2018-02-09T16:25:54Z
Ugx58-u1yi98BBqbiSd4AaABAg.8cSOVw4rD2I8e-X50_kozf,@adamishay808,Ugx58-u1yi98BBqbiSd4AaABAg,2,DejHQYAGb7Q,0,0,2018-03-20T04:25:41Z,"<a href=""https://www.youtube.com/playlist?list=PLBAGcD3siRDittPwQDGIIAWkjz-RucAc7"">https://www.youtube.com/playlist?list=PLBAGcD3siRDittPwQDGIIAWkjz-RucAc7</a>",2018-03-20T04:25:41Z
Ugx58-u1yi98BBqbiSd4AaABAg.8cSOVw4rD2I8e7KcEG59yU,@RaviCHandra-fj8dr,Ugx58-u1yi98BBqbiSd4AaABAg,2,DejHQYAGb7Q,0,0,2018-03-23T05:10:41Z,Hey thanks for the reply,2018-03-23T05:10:41Z
Ugx58-u1yi98BBqbiSd4AaABAg.8cSOVw4rD2I8mufu_rOuqJ,@simon5771,Ugx58-u1yi98BBqbiSd4AaABAg,2,DejHQYAGb7Q,0,0,2018-10-27T14:38:37Z,You can do the whole course with the Jupyter Notebook projects and quizzes and get a certification on Coursera.,2018-10-27T14:38:37Z
Ugx58-u1yi98BBqbiSd4AaABAg.8cSOVw4rD2I8uBjV19c-O-,@ensaadghedada3328,Ugx58-u1yi98BBqbiSd4AaABAg,2,DejHQYAGb7Q,0,0,2019-04-26T14:36:01Z,@@adamishay808 The playlist does not exist.,2019-04-26T14:36:01Z
UgyntWJ3ViVY6lyKSL14AaABAg,@chrischappell7643,,1,DejHQYAGb7Q,2,0,2018-02-06T18:14:32Z,thank for upload this series ... plz add course about natural processing language that pro andrew mention is last past of full series about deeplearn in coursea :)) thk,2018-02-06T18:14:32Z
UgyntWJ3ViVY6lyKSL14AaABAg.8cKrYwksLnB8hVrzN11qP7,@sainimohit23,UgyntWJ3ViVY6lyKSL14AaABAg,2,DejHQYAGb7Q,0,0,2018-06-15T07:26:54Z,wtf is wrong with your english??,2018-06-15T07:26:54Z
UgyntWJ3ViVY6lyKSL14AaABAg.8cKrYwksLnB8rEb99UPyPy,@sainimohit23,UgyntWJ3ViVY6lyKSL14AaABAg,2,DejHQYAGb7Q,0,0,2019-02-12T03:46:40Z,@@Ahmed-fj5jq no it&#39;s not... I recommend you to buy it. It worth every penny you spend.,2019-02-12T03:46:40Z
UgxwtgBOUZf0vy2yHR94AaABAg,@MrAkhilanil,,1,SysgYptB198,0,0,2023-07-25T07:46:55Z,"Sounds cool, someone should build a chat bot with this tech!",2023-07-25T07:46:55Z
UgxjBslG5ote2pVDSKR4AaABAg,@ananthakrishnank3208,,1,SysgYptB198,0,0,2023-07-17T03:16:44Z,"<a href=""https://www.youtube.com/watch?v=SysgYptB198&amp;t=3m00s"">3:00</a>",2023-07-17T03:16:44Z
Ugy8M7aY6zCv9pTOpuN4AaABAg,@arborymastersllc.9368,,1,SysgYptB198,0,0,2023-05-28T18:33:33Z,"Recursive context checking every so many words? Like after every noun verb combo identified, recheck context appropriatness.",2023-05-28T18:33:33Z
UgyR2qMnbghu0gfU5F14AaABAg,@arborymastersllc.9368,,1,SysgYptB198,0,0,2023-05-28T18:31:30Z,"Would definitely have to shift the location context weights for different languages as expressions shift word order across languages. Example: 3 left 2 right for language A. And 2 left 4 right Language B, with language specific variance to weight distribution themselves",2023-05-28T18:31:30Z
Ugxc5_wrhViUtzB8ll94AaABAg,@procrastipractice,,1,SysgYptB198,0,0,2022-12-17T09:52:29Z,Good luck with German where one verb can be split over a huge distance,2022-12-17T09:52:29Z
UgyalQyK1cNatBvc70h4AaABAg,@mohsenboughriou9846,,1,SysgYptB198,0,0,2022-12-01T12:16:18Z,man u&#39;re the best,2022-12-01T12:16:18Z
UgwD_4RwV1AZ712ysAJ4AaABAg,@jozefkoslinski4111,,1,SysgYptB198,0,0,2022-07-16T19:05:38Z,„ÄåÂãïÁîª„ÅÆÈü≥„ÅåËâØ„Åè„Å™„ÅÑ„Äç„ÄÅ,2022-07-16T19:05:38Z
UgzTkDJ26jVyEPdzDxh4AaABAg,@yeming3777,,1,SysgYptB198,0,0,2022-04-03T04:00:17Z,helps me a lot,2022-04-03T04:00:17Z
Ugz8H5FLmTkNJRM-sht4AaABAg,@thepresistence5935,,1,SysgYptB198,0,1,2022-03-29T06:56:18Z,"Attention model invented by &quot;avengers&quot; üòÜüòÜ <a href=""https://www.youtube.com/watch?v=SysgYptB198&amp;t=2m55s"">2:55</a>",2022-03-29T06:56:18Z
UgyawXBaNqMPwg5XQ_h4AaABAg,@rohithak9419,,1,SysgYptB198,0,0,2022-02-19T12:13:07Z,Sriraj is a fraud fella .. stay away,2022-02-19T12:13:07Z
Ugwfx1OgdTo6uVZS0SF4AaABAg,@TheBlackhawk2011,,1,SysgYptB198,1,68,2022-02-05T14:36:35Z,&quot;if you can&#39;t explain it simply you don&#39;t understand it well enough&quot; Andrew is one of the best instructors in the world. No wonder he teaches at Standord.,2022-02-05T14:36:35Z
Ugwfx1OgdTo6uVZS0SF4AaABAg.9Y3rC2pvGL-9aenXNIF-gu,@grownupgaming,Ugwfx1OgdTo6uVZS0SF4AaABAg,2,SysgYptB198,0,2,2022-05-05T21:49:51Z,"as someone from berkeley, this is a good comment!",2022-05-05T21:49:51Z
Ugwd2PS4mTrhZVxsflR4AaABAg,@aryanyekrangi7093,,1,SysgYptB198,0,0,2022-02-04T12:17:53Z,Great video series!,2022-02-04T12:17:53Z
Ugzxc7v962cUwNThonl4AaABAg,@2005sty,,1,SysgYptB198,1,1,2022-01-26T14:55:01Z,It is not correct that a human translator carries out translation part by part especially in the case of translation of two different languages with different grammatic rules.,2022-01-26T14:55:01Z
Ugzxc7v962cUwNThonl4AaABAg.9Xf8MP0Co9F9jQc2uvEBFg,@isodoubIet,Ugzxc7v962cUwNThonl4AaABAg,2,SysgYptB198,0,0,2022-12-09T17:03:31Z,The &quot;parts&quot; don&#39;t have to be in the same order.,2022-12-09T17:03:31Z
UgzsH5Wunzr6qkhRqLZ4AaABAg,@abail7010,,1,SysgYptB198,0,1,2021-11-12T10:19:25Z,The only thing I am not understanding is why its harder to translate shorter sentences? :),2021-11-12T10:19:25Z
UgyWtVM46JxklqNrmBV4AaABAg,@nichosetiawan1377,,1,SysgYptB198,0,0,2021-11-10T17:53:37Z,"the video image is too poor, you need to fix it more",2021-11-10T17:53:37Z
UgyeiqdXeHgzzBp7UQl4AaABAg,@danielcai1017,,1,SysgYptB198,0,1,2021-09-29T09:03:07Z,"<a href=""https://www.youtube.com/watch?v=SysgYptB198&amp;t=3m29s"">3:29</a> it seems he knows French well",2021-09-29T09:03:07Z
UgzXnb7qj1IRLJI-KoV4AaABAg,@namHoang-lb6jp,,1,SysgYptB198,0,0,2021-09-25T02:06:21Z,Some segments in the video are stamped not adjacent to each other,2021-09-25T02:06:21Z
UgzGVnF5flVvazZV5vN4AaABAg,@learnaiwithjoelbunyan4764,,1,SysgYptB198,0,0,2021-07-08T15:36:48Z,"hey guys, I am joel, I am 13 and I just started a youtube channel where I teach AI,ML,DL for free so checkout the channel and consider subscribing. Link to the channel: <a href=""https://www.youtube.com/channel/UC2tw4aaIJtLFReiF33Z6JsA"">https://www.youtube.com/channel/UC2tw4aaIJtLFReiF33Z6JsA</a>",2021-07-08T15:36:48Z
UgzsxZbhuK4BkY2BWLB4AaABAg,@frankie59er,,1,SysgYptB198,1,15,2021-05-28T04:48:41Z,"These explanations are top-notch, definitely deserving of way more views",2021-05-28T04:48:41Z
UgzsxZbhuK4BkY2BWLB4AaABAg.9NsLnmaleyw9QpDwVHJITE,@MasterofPlay7,UgzsxZbhuK4BkY2BWLB4AaABAg,2,SysgYptB198,0,0,2021-08-09T13:16:25Z,you know the BERT model is the best nlp model right?,2021-08-09T13:16:25Z
UgyxA4Jt0Kk2VY8fP-J4AaABAg,@arthurswanson3285,,1,SysgYptB198,0,0,2021-04-18T02:02:27Z,Well explained.,2021-04-18T02:02:27Z
UgwFyyvBsBaW5Eudfyp4AaABAg,@moodiali7324,,1,SysgYptB198,0,1,2021-03-21T09:26:36Z,"very good content with very bad audio quality, hope that improves one day",2021-03-21T09:26:36Z
UgzZ34h_ejE4mIN82T54AaABAg,@PookyCodes,,1,SysgYptB198,0,3,2021-01-26T12:13:42Z,Thank you so much for this valuable video!,2021-01-26T12:13:42Z
UgyyHGs1LyH1vfXcOv54AaABAg,@sandipansarkar9211,,1,SysgYptB198,0,0,2020-12-21T12:27:13Z,good expalantion but need to see again,2020-12-21T12:27:13Z
UgwQcUiMl7or4Xzn4aN4AaABAg,@youssefdirani,,1,SysgYptB198,0,2,2020-10-09T20:42:17Z,Magical voice,2020-10-09T20:42:17Z
Ugyb4MPCjBJSAc605jJ4AaABAg,@fackarov9412,,1,SysgYptB198,0,3,2020-09-29T08:18:14Z,to me seems like applying kernels(1D CNN) to RNN and call it &quot;attention&quot;,2020-09-29T08:18:14Z
UgwUdMcrO7FWlkjOBgp4AaABAg,@fahds2583,,1,SysgYptB198,0,4,2020-09-15T19:05:59Z,"video starts here <a href=""https://www.youtube.com/watch?v=SysgYptB198&amp;t=3m11s"">3:11</a>",2020-09-15T19:05:59Z
UgwyDs3kLwYglKnChpJ4AaABAg,@francois-xaviermenage4531,,1,SysgYptB198,0,2,2020-08-25T14:51:56Z,The French sentences are written on a very wrong way..,2020-08-25T14:51:56Z
UgzX3ROPQQJCHeacC3x4AaABAg,@taku8751,,1,SysgYptB198,0,0,2020-06-19T00:08:49Z,"I hope the cursor can be bigger, I can not see it.",2020-06-19T00:08:49Z
UgwYumysWjMs4YHqRn54AaABAg,@marinzhao3513,,1,SysgYptB198,0,1,2020-05-13T08:31:43Z,Ëß£ÊûêÁöÑÂæàÊ∏ÖÊô∞,2020-05-13T08:31:43Z
UgwWvwq1wkW3c8ocjTt4AaABAg,@mehmetcelepkolu7660,,1,SysgYptB198,0,44,2020-05-08T17:55:13Z,"<a href=""https://www.youtube.com/watch?v=SysgYptB198&amp;t=3m24s"">3:24</a> -  Woah, the legend is speaking French!",2020-05-08T17:55:38Z
UgzIM76BhEDsPKVMy5x4AaABAg,@saeedullah5365,,1,SysgYptB198,0,0,2020-05-03T18:48:35Z,Why LSTM have more accuracy than Bi directional LSTM though is new approach,2020-05-03T18:48:35Z
UgxjlMTNdDk5m-7vwgh4AaABAg,@Mesenqe,,1,SysgYptB198,24,154,2020-02-24T12:17:16Z,"I can&#39;t believe that, Siraj Raval has around 700K subscribers and this most valuable channel only 76K.",2020-02-24T12:17:16Z
UgxjlMTNdDk5m-7vwgh4AaABAg.95QGGipAhNl9ARl4qY6nSd,@AIPlayerrrr,UgxjlMTNdDk5m-7vwgh4AaABAg,2,SysgYptB198,0,12,2020-06-28T08:51:29Z,the worst channel on youtube...notorious...,2020-06-28T08:51:29Z
UgxjlMTNdDk5m-7vwgh4AaABAg.95QGGipAhNl9AS5cQjW06n,@Mesenqe,UgxjlMTNdDk5m-7vwgh4AaABAg,2,SysgYptB198,0,1,2020-06-28T11:59:42Z,"@@AIPlayerrrr ok, if <a href=""http://www.youtube.com/results?search_query=%23deeplearning_ai"">#Deeplearning_ai</a> is the worst channel, where almost everyone become the master of Machine learning, and Deep learning...plz recommend me which channel you use? N.B. Not in Chinese, in English.",2020-06-28T11:59:42Z
UgxjlMTNdDk5m-7vwgh4AaABAg.95QGGipAhNl9AS7IbRIFoY,@AIPlayerrrr,UgxjlMTNdDk5m-7vwgh4AaABAg,2,SysgYptB198,0,30,2020-06-28T12:14:20Z,Gery W. Adhane I am talking about Siraj Raval....,2020-06-28T12:14:20Z
UgxjlMTNdDk5m-7vwgh4AaABAg.95QGGipAhNl9AS7Y3yM2GB,@AIPlayerrrr,UgxjlMTNdDk5m-7vwgh4AaABAg,2,SysgYptB198,0,3,2020-06-28T12:16:27Z,Gery W. Adhane I remember Lex‚Äôs interview on Siraj Raval which Siraj said he only knew 50% of the materials lolll,2020-06-28T12:16:27Z
UgxjlMTNdDk5m-7vwgh4AaABAg.95QGGipAhNl9ASBIzQenOr,@Mesenqe,UgxjlMTNdDk5m-7vwgh4AaABAg,2,SysgYptB198,0,2,2020-06-28T12:49:20Z,"@@AIPlayerrrr Oh sorry, I thought you are referring to <a href=""http://www.youtube.com/results?search_query=%23deeplearning_ai"">#deeplearning_ai</a>.  In that case I agree. He manipulates us all.",2020-06-28T12:49:20Z
Ugx4g12W8XyYGERnjV14AaABAg,@anggipermanaharianja6122,,1,SysgYptB198,0,3,2020-01-04T09:49:14Z,really clear explanation,2020-01-04T09:49:14Z
Ugx_ekWTYyTXlv59njF4AaABAg,@heejuneAhn,,1,SysgYptB198,4,2,2019-12-24T21:08:04Z,"Oh, I see that is why Google translation is still bad with Engish-Japanese or Korean!",2019-12-24T21:08:04Z
Ugx_ekWTYyTXlv59njF4AaABAg.92wZjCPqNtP9BXsp-xF1Cb,@socratic-programmer,Ugx_ekWTYyTXlv59njF4AaABAg,2,SysgYptB198,0,0,2020-07-25T14:25:55Z,"Is that because the sentences read in an unusual order?<br><br>Incidentally, recent models have become a lot better at multi-translation, so maybe they are better now than before.",2020-07-25T14:25:55Z
Ugx_ekWTYyTXlv59njF4AaABAg.92wZjCPqNtP9Brka7afWaG,@peterfireflylund,Ugx_ekWTYyTXlv59njF4AaABAg,2,SysgYptB198,0,2,2020-08-02T16:58:02Z,"@@socratic-programmer No, it&#39;s not about an unusual order.  That&#39;s actually quite easy to handle.<br><br>It&#39;s because Korean and Japanese have completely different grammar from English.  They are agglutinating, have pretty free word order because they both &quot;tag&quot; their words with short sounds that tell what role they play in the sentence, and they both allow most of the &quot;real&quot; sentence to be left out if it can be inferred from context.  There are also problems with the semantic mapping between J/K and E where context is needed to figure out how to translate words/idioms.  To top it all off, Japanese and Korean both have really complicated systems of honorifics.  Oh, and copula is handled in <b>completely</b> different ways in J/K and E.<br><br>Current translation systems are really bad at handling context above the sentence level, so... you can see the problems.<br><br>Wikipedia has pretty good articles on Japanese, Korean, and English grammar.",2020-08-02T16:58:02Z
Ugx_ekWTYyTXlv59njF4AaABAg.92wZjCPqNtP9Brl_QuvIY0,@peterfireflylund,Ugx_ekWTYyTXlv59njF4AaABAg,2,SysgYptB198,0,2,2020-08-02T17:06:41Z,"Forgot to add that tokenization is another issue.  There are translating neural networks that are completely end-to-end: they take characters/punctuation as input and produce characters/punctuation as output.  Most deep learning systems use a tokenizer before the input and a &quot;detokenizer&quot; after the output.<br><br>Such a tokenizer may give all common words their own token number and it may split rarer words into smaller components, often using simple rules based on tables and regular expressions.  It may also turn things like &quot;isn&#39;t&quot; into &quot;is not&quot; for English and &quot;du&quot; into &quot;de le&quot; for French.<br><br>How to properly tokenize ideographic scripts like Chinese hanzi and Japanese kanji (and Korean Hanja) is still a research subject.<br><br>Actually, even tokenization for <b>English</b> is still a research subject!",2020-08-02T17:06:41Z
Ugx_ekWTYyTXlv59njF4AaABAg.92wZjCPqNtP9Bss7_8JYOl,@socratic-programmer,Ugx_ekWTYyTXlv59njF4AaABAg,2,SysgYptB198,0,0,2020-08-03T03:23:09Z,"@@peterfireflylund Some of those linguistic terms elude me, but that makes sense. Thanks for that explanation.",2020-08-03T03:23:09Z
Ugy06VBs2F3kfQ4KpPl4AaABAg,@bhimireddyananthreddy1487,,1,SysgYptB198,2,0,2019-11-11T19:35:04Z,"What does some set of features at <a href=""https://www.youtube.com/watch?v=SysgYptB198&amp;t=3m36s"">3:36</a> mean?",2019-11-11T19:35:04Z
Ugy06VBs2F3kfQ4KpPl4AaABAg.91CfuPafsch93bg6ERokHT,@ThePritt12,Ugy06VBs2F3kfQ4KpPl4AaABAg,2,SysgYptB198,0,0,2020-01-10T14:59:52Z,an encoding = features of a sentence,2020-01-10T14:59:52Z
Ugy06VBs2F3kfQ4KpPl4AaABAg.91CfuPafsch9ACYSqs5O5G,@Utbdankar,Ugy06VBs2F3kfQ4KpPl4AaABAg,2,SysgYptB198,0,0,2020-06-22T11:03:49Z,"To determine each feature vector(the set of features) you use the input of the word itself and the previous feature vector, which outputs a new feature vector. You can think of the feature vector as &quot;everything needed to translate the current word that came before the word in the sentence&quot;.",2020-06-22T11:03:49Z
Ugz2hVOE9q1imlfMgF14AaABAg,@theSpicyHam,,1,SysgYptB198,0,2,2019-11-09T22:42:16Z,"I learned an lot, thank you",2019-11-09T22:42:16Z
UgwIHAr7Z9_jttdYNfd4AaABAg,@inllac8832,,1,quoGRI-1l0A,0,0,2023-07-25T06:22:32Z,what math courses do people recommend if i want to understand the math in the video?,2023-07-25T06:22:32Z
Ugz8x6qxbso7f8B_mMZ4AaABAg,@wernerbonadio7141,,1,quoGRI-1l0A,0,1,2023-02-03T09:48:18Z,Prof. Ng is just great! Thank you for sharing and teaching your precious knowledge,2023-02-03T09:48:18Z
Ugx8n48EF1oDw0VdsfN4AaABAg,@citizenassembly,,1,quoGRI-1l0A,1,0,2023-01-31T08:33:02Z,"How can this video have 137K Views, if there&#39;s only 50 people in the world?",2023-01-31T08:33:02Z
Ugx8n48EF1oDw0VdsfN4AaABAg.9lYAlOngaE29mi-EgBXBIb,@kooltyme,Ugx8n48EF1oDw0VdsfN4AaABAg,2,quoGRI-1l0A,0,0,2023-03-01T09:55:21Z,wym there&#39;s only 50 people in the world,2023-03-01T09:55:21Z
UgwHCy4gb6fckKyGjnl4AaABAg,@ansh6848,,1,quoGRI-1l0A,0,2,2022-03-23T03:29:57Z,Great Work! Explained attention in such a simple manner that neither any book nor any article have done.,2022-03-23T03:29:57Z
UgwP-PRlHSQgDc3cHup4AaABAg,@runggp,,1,quoGRI-1l0A,0,0,2022-02-21T04:24:05Z,AI Hero!,2022-02-21T04:24:05Z
UgzfkuTSotoDL8ArqWZ4AaABAg,@tempdeltavalue,,1,quoGRI-1l0A,0,0,2021-12-22T15:55:25Z,using a and alpha in one formula probably not the best choice ),2021-12-22T15:55:25Z
UgyeKS5gh0X31YeBPJF4AaABAg,@skyacaniadev2229,,1,quoGRI-1l0A,1,0,2021-11-05T20:07:48Z,"In the figure at <a href=""https://www.youtube.com/watch?v=quoGRI-1l0A&amp;t=11m47s"">11:47</a>, the English word ‚Äúno‚Äù seems to have an ‚Äúempty‚Äù attention. I wonder how the word ‚Äúno‚Äù was generated?",2021-11-05T20:07:48Z
UgyeKS5gh0X31YeBPJF4AaABAg.9UNYyVMAU8t9advqHqpWye,@PrzemyslawDolata,UgyeKS5gh0X31YeBPJF4AaABAg,2,quoGRI-1l0A,0,0,2022-05-05T13:43:14Z,"Keep in mind that you generate individual words y&lt;t&gt; from (bidirectional) RNN activations s&lt;t&gt; which depend not only on the context c&lt;t&gt; but also neighboring values s&lt;t-1&gt; and s&lt;t+1&gt;. Therefore in this case the translation network could have just learned the English idiom &quot;can no longer&quot;, and figured out to insert it here, even though the &quot;no&quot; itself has little attention relation to the input sequence.",2022-05-05T13:43:14Z
UgxMe4G1easw7qUDgYR4AaABAg,@RiazMotlagh,,1,quoGRI-1l0A,0,0,2021-10-30T12:49:12Z,Thank you for clear explanation with example!,2021-10-30T12:49:12Z
UgxWs97PMdzysHgnl2d4AaABAg,@DigitalAlligator,,1,quoGRI-1l0A,0,0,2021-09-08T17:21:11Z,what happened to his left face?,2021-09-08T17:21:11Z
UgwZDIuv8Ypv8xo1XDV4AaABAg,@leonidleibman8629,,1,quoGRI-1l0A,0,0,2021-09-03T02:02:13Z,"Any references to the code? for example for the lab building date normalization that is mentioned at the end (ts <a href=""https://www.youtube.com/watch?v=quoGRI-1l0A&amp;t=11m22s"">11:22</a>)",2021-09-03T02:02:13Z
Ugx1ai_0k7fOSk2GBa94AaABAg,@danielwiczew,,1,quoGRI-1l0A,1,1,2021-04-05T07:00:24Z,"It&#39;s good that they&#39;re on the YouTube, so that you don&#39;t need to dig into courseria",2021-04-05T07:00:24Z
Ugx1ai_0k7fOSk2GBa94AaABAg.9Lk6k7RGqBG9Q9a93dni_x,@arifproklamasi8120,Ugx1ai_0k7fOSk2GBa94AaABAg,2,quoGRI-1l0A,0,0,2021-07-23T23:51:54Z,"it is such a good course material, but it&#39;s not complete lectures though.",2021-07-23T23:51:54Z
UgyQ-qwzroiN9b7JHch4AaABAg,@147852sam,,1,quoGRI-1l0A,0,0,2021-04-03T20:54:19Z,Best explanation on the attention mechanism,2021-04-03T20:54:19Z
UgzZQ9MjMKRKk9Gvrf54AaABAg,@sandipansarkar9211,,1,quoGRI-1l0A,0,0,2020-12-21T12:40:44Z,great explanation but complex one,2020-12-21T12:40:44Z
Ugz34vzaWD1BYpp6KM54AaABAg,@mrexnx,,1,quoGRI-1l0A,2,0,2020-12-04T02:24:49Z,"is alpha a scalar, or is it also a vector?",2020-12-04T02:24:49Z
Ugz34vzaWD1BYpp6KM54AaABAg.9GpUE-XJyc99JI-Dcj_r-i,@rajanchauhan6412,Ugz34vzaWD1BYpp6KM54AaABAg,2,quoGRI-1l0A,0,0,2021-02-03T06:33:53Z,It should be a vector. Considering the same attenuation can be applied on image or word vector,2021-02-03T06:33:53Z
Ugz34vzaWD1BYpp6KM54AaABAg.9GpUE-XJyc99L7q9cQgDzZ,@LouisChiaki,Ugz34vzaWD1BYpp6KM54AaABAg,2,quoGRI-1l0A,0,0,2021-03-21T00:56:21Z,It is a scalar in the word embedding space. But there are indices t an t&#39;. So it is a tensor in time steps.,2021-03-21T00:56:21Z
UgyryQ-IHV44FnLpVdZ4AaABAg,@trixonx,,1,quoGRI-1l0A,1,3,2020-07-05T10:19:18Z,This guy teaches Machine learning but does not know how to normalize audio for his videos?<br><br>The world is a funny place.,2020-07-05T10:19:18Z
UgyryQ-IHV44FnLpVdZ4AaABAg.9AiwhAHrbst9L7qr_rVHso,@LouisChiaki,UgyryQ-IHV44FnLpVdZ4AaABAg,2,quoGRI-1l0A,0,3,2021-03-21T01:02:29Z,"Well, depending on whether you are here for the knowledge or the audio quality like all other Youtubers who make video as their career.",2021-03-21T01:04:00Z
Ugwk7aRSa_B82P3HIjx4AaABAg,@taku8751,,1,quoGRI-1l0A,0,3,2020-06-19T00:49:14Z,THE BEST INTRODUCTION OF ATTENSION MODEL!,2020-06-19T00:49:14Z
UgzTyKZEOEW5Fz4JlbV4AaABAg,@malikokodark7849,,1,quoGRI-1l0A,0,0,2020-05-14T21:20:03Z,salut,2020-05-14T21:20:03Z
UgyvVYpN-kOno5fMGUl4AaABAg,@pranabsarkar,,1,quoGRI-1l0A,0,3,2020-05-02T12:23:41Z,You are a great teacher! thanks a lot :),2020-05-02T12:23:41Z
UgyLqLzQGG6DIPXTMd14AaABAg,@abhishekkrthakur,,1,quoGRI-1l0A,2,6,2020-03-20T15:09:13Z,Best explanation ever :),2020-03-20T15:09:13Z
UgyLqLzQGG6DIPXTMd14AaABAg.96QwovTP1t4970w8Fni5bZ,@thecowgoesvroom672,UgyLqLzQGG6DIPXTMd14AaABAg,2,quoGRI-1l0A,0,0,2020-04-04T09:14:23Z,That&#39;s a lot coming from someone like you :-),2020-04-04T09:14:23Z
UgyLqLzQGG6DIPXTMd14AaABAg.96QwovTP1t498aA2ql2hU5,@vishnuunnikrishnan5539,UgyLqLzQGG6DIPXTMd14AaABAg,2,quoGRI-1l0A,0,0,2020-05-13T07:28:46Z,Hai Triple Grand master,2020-05-13T07:28:46Z
UgxZCRGlChhQjaAL2fZ4AaABAg,@UkJoMr,,1,quoGRI-1l0A,0,12,2019-12-18T08:06:22Z,"I bing-watched this series. Thanks, Andrew Ng.",2019-12-18T08:06:22Z
UgyB2cl579plTPA0W6d4AaABAg,@neonlight1203,,1,quoGRI-1l0A,0,4,2019-12-06T07:44:18Z,Thank you sir. You make it look so easy.,2019-12-06T07:44:18Z
UgxvNUsK2qCXT-4r-Nt4AaABAg,@meetgandhi8782,,1,quoGRI-1l0A,2,2,2019-09-08T08:14:30Z,"Are all the time step activation (at&#39;s) along with s(t-1) fed into the neural network and if they are, is it just a concatenation of these vectors?",2019-09-08T08:14:30Z
UgxvNUsK2qCXT-4r-Nt4AaABAg.8zbf8hHfIgI93lyizi_Vx8,@jtfidje,UgxvNUsK2qCXT-4r-Nt4AaABAg,2,quoGRI-1l0A,0,0,2020-01-14T14:54:59Z,Did you ever figure this out? Wondering the exact same thing!,2020-01-14T14:54:59Z
UgxvNUsK2qCXT-4r-Nt4AaABAg.8zbf8hHfIgI94XOF23uW6f,@Biggzlar,UgxvNUsK2qCXT-4r-Nt4AaABAg,2,quoGRI-1l0A,0,0,2020-02-02T10:10:14Z,@@jtfidje s^t is a weighted aggregate of step activations a^t. Only a given s^t and y^t-1 are fed into the decoder. Hope this helps in case you haven&#39;t found out already.,2020-02-02T10:10:14Z
Ugzb6cLs9X7vm6u_V5F4AaABAg,@jerrylin5089,,1,quoGRI-1l0A,1,2,2019-07-22T01:09:32Z,Will you publish the entire sequence model series on youtube?,2019-07-22T01:09:32Z
Ugzb6cLs9X7vm6u_V5F4AaABAg.8xfJMAyDjgz96UQ-1pHd43,@jhanaaaaa,Ugzb6cLs9X7vm6u_V5F4AaABAg,2,quoGRI-1l0A,0,1,2020-03-21T23:30:35Z,You can audit them all for free on coursera,2020-03-21T23:30:35Z
UgxJEqpskK0nJe1DB654AaABAg,@teetanrobotics5363,,1,quoGRI-1l0A,0,1,2019-07-16T20:17:15Z,Please upload weeks 1 and 2 for Sequence models,2019-07-16T20:17:15Z
Ugx9aCtBxFJkmK3tp6x4AaABAg,@j-c6625,,1,quoGRI-1l0A,0,0,2019-04-07T14:27:19Z,Is S^i == c^i ? And are those = y^i ?,2019-04-07T14:27:19Z
UgwB3rgTkHviuPFLmZp4AaABAg,@tunestar,,1,quoGRI-1l0A,0,2,2018-12-20T16:58:41Z,Didn&#39;t like it... too much Optimus Prime for my taste.,2018-12-20T16:58:41Z
UgxKpps53Rfqh5jJrgt4AaABAg,@chefboyrdee1,,1,quoGRI-1l0A,0,5,2018-12-02T19:13:11Z,great work ! absolute genius explanation and beautiful way of handling bi-directional LSTMs ! just wow.  Hello from Toronto :D,2018-12-02T19:13:11Z
Ugx--8SV-ocSOPqOppt4AaABAg,@jellekastelein7316,,1,quoGRI-1l0A,4,3,2018-09-28T15:02:50Z,"Maybe I&#39;m missing something, but what target vectors do we train the attention network on? Is this a supervised learning problem, i.e. do we need to know how the words should be aligned a priori?",2018-09-28T15:02:50Z
Ugx--8SV-ocSOPqOppt4AaABAg.8lk2ce3rQtl8maosEm_WwC,@jairoalves8083,Ugx--8SV-ocSOPqOppt4AaABAg,2,quoGRI-1l0A,0,0,2018-10-19T21:32:07Z,I believe you train than using the translation quality they produce. Everything is optmized to increase the final translated sentence output quality.,2018-10-19T21:32:07Z
Ugx--8SV-ocSOPqOppt4AaABAg.8lk2ce3rQtl8mbtDDQExQz,@jellekastelein7316,Ugx--8SV-ocSOPqOppt4AaABAg,2,quoGRI-1l0A,0,1,2018-10-20T07:29:19Z,"Ah, right, so you just train them by backpropagating the errors like anything else. That should have been more obvious to me. Thanks!",2018-10-20T07:29:19Z
Ugx--8SV-ocSOPqOppt4AaABAg.8lk2ce3rQtl8mkLE-ACBgq,@jairoalves8083,Ugx--8SV-ocSOPqOppt4AaABAg,2,quoGRI-1l0A,0,4,2018-10-23T14:16:45Z,just to add a bit more detail. You put the attention between LSTM-decoder and LSTM-encoder. It is just another layer to be trained.,2018-10-23T14:16:45Z
Ugx--8SV-ocSOPqOppt4AaABAg.8lk2ce3rQtl8ovyprn_yjY,@bhaskararun1233,Ugx--8SV-ocSOPqOppt4AaABAg,2,quoGRI-1l0A,0,0,2018-12-16T19:46:01Z,"Intuitively n theoretically attention values (alpha&lt;t,t&#39;&gt;) are scalar values for each time step(each word in the sentence to be translated in this case) ie. We want to find out how much attention we need to give each word (at t&#39;) in the input context to get the translation (at t) right. We find these values like any other trainable parameter by minimizing the loss(correctness of translation in this case - Bleu score)",2018-12-16T19:46:01Z
UgwJvvTSrnGJm3K6mHp4AaABAg,@taibisaad9002,,1,quoGRI-1l0A,0,0,2018-08-11T05:56:09Z,!,2018-08-11T05:56:09Z
Ugw0fjPGaaWuAaiyJo54AaABAg,@akashtyagi1269,,1,quoGRI-1l0A,1,2,2018-07-18T11:03:21Z,Please upload the full series,2018-07-18T11:03:21Z
Ugw0fjPGaaWuAaiyJo54AaABAg.8iqDzYHkmJk9C16kq5In1M,@josephpareti9156,Ugw0fjPGaaWuAaiyJo54AaABAg,2,quoGRI-1l0A,0,0,2020-08-06T17:32:53Z,if you enroll in coursera deep learning you have access to all videos,2020-08-06T17:32:53Z
UgzBFsvTO0DVCpcBvKd4AaABAg,@sezan92,,1,quoGRI-1l0A,0,0,2018-04-16T11:06:51Z,"I have found a lot of help from this article <a href=""http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/"">http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/</a>",2018-04-16T11:06:51Z
Ugwy0XiK6sQisJsAHpJ4AaABAg,@X_platform,,1,quoGRI-1l0A,5,13,2018-02-06T23:58:04Z,"Isn&#39;t attention exactly the same as &quot;weight&quot;? It looks to me the exact same concept of weight*input, just the &quot;input&quot; is now the local output of RNN, and the &quot;weight&quot; changed name to &quot;attention&quot;. Is there any more to it that I missed?",2018-02-06T23:58:04Z
Ugwy0XiK6sQisJsAHpJ4AaABAg.8cLTs2I7q_E8f5lZbt8Nj9,@sezan92,Ugwy0XiK6sQisJsAHpJ4AaABAg,2,quoGRI-1l0A,0,4,2018-04-16T11:07:46Z,yes you&#39;re right. They are special kind of weight to let the decoder know which words are important. Important words will be multiplied with higher weights while the opposite for less important words,2018-04-16T11:07:46Z
Ugwy0XiK6sQisJsAHpJ4AaABAg.8cLTs2I7q_E8maogbpjAFl,@jairoalves8083,Ugwy0XiK6sQisJsAHpJ4AaABAg,2,quoGRI-1l0A,0,1,2018-10-19T21:30:32Z,"As I understand, normally, the decoder would not use any of the input activations, just the last s&lt;t-1&gt;. Now, it uses s&lt;t-1&gt; and a context that is based on different attention weights to compute a different input to be considered also on the decoder cell processing. I see this as being a different mechanism than just using a &quot;weight * input&quot; concept.",2018-10-19T21:30:32Z
Ugwy0XiK6sQisJsAHpJ4AaABAg.8cLTs2I7q_E8mtxpvO4osK,@lailai6402,Ugwy0XiK6sQisJsAHpJ4AaABAg,2,quoGRI-1l0A,0,2,2018-10-27T07:56:01Z,You&#39;re absolutely right that it is an attempt to obfuscate a very trivial mechanism. Using softmax isn&#39;t specific to &quot;attention&quot; either. It&#39;s probably a result of being confounded by treating data as a &quot;language&quot;.,2018-10-27T07:56:01Z
Ugwy0XiK6sQisJsAHpJ4AaABAg.8cLTs2I7q_E8uc22Dq2n79,@jessieqiu2252,Ugwy0XiK6sQisJsAHpJ4AaABAg,2,quoGRI-1l0A,0,11,2019-05-07T05:06:21Z,"I think one important property of attention is that the sum needs to be 1, while weights do not need to meet that requirement.",2019-05-07T05:06:21Z
Ugwy0XiK6sQisJsAHpJ4AaABAg.8cLTs2I7q_E8yHQ5NeUx4i,@MrCmon113,Ugwy0XiK6sQisJsAHpJ4AaABAg,2,quoGRI-1l0A,0,0,2019-08-06T05:38:47Z,"The question is where there should be connections and how they should be updated. In traditional seq2seq you would only have one context vector, which doesn&#39;t work as well.",2019-08-06T05:38:47Z
UgwFzdTfqdjbDK8B7vV4AaABAg,@ananthakrishnank3208,,1,vm2SI8AJY0s,0,0,2023-07-17T05:49:23Z,"<a href=""https://www.youtube.com/watch?v=vm2SI8AJY0s&amp;t=5m00s"">5:00</a>",2023-07-17T05:49:23Z
UgzVhGY_uKkF8trcTqR4AaABAg,@sandipansarkar9211,,1,vm2SI8AJY0s,0,2,2020-12-20T17:05:00Z,sppech recognition models .little bit tough,2020-12-20T17:05:00Z
UgwTIEEpbjbEGRszfep4AaABAg,@randywelt8210,,1,vm2SI8AJY0s,0,5,2018-02-12T08:50:09Z,"In my opinion, the dnn-hmm hybrid approach is still competitive. Not Sure, but Microsofts human level paper used a ensemble with all Kind of models. IBM did something very similiar. Only baidu relies on ctc only?? Or do all companies Switch to attention seq2seq??",2018-02-12T08:50:09Z
UgzpP0VUbPqEpaBp_0R4AaABAg,@DhirajPatra,,1,ArPaAX_PhIs,0,1,2023-02-17T06:09:57Z,My best teacher,2023-02-17T06:09:57Z
UgywlBLOehmayoYd39l4AaABAg,@mdaljadd6942,,1,ArPaAX_PhIs,0,0,2022-11-07T19:17:47Z,C4W3L05 Bounding Box Prediction : https://www.youtube.com/watch?v=yo9S3eNtkXc,2023-10-31T23:59:53Z
UgynPWOpipKu81n62wt4AaABAg,@sparagkouegk,,1,ArPaAX_PhIs,0,0,2022-08-03T16:19:09Z,Is the volume too low?,2022-08-03T16:19:09Z
UgwfZrcndbG3wMG9FFh4AaABAg,@jaewoochoi3034,,1,ArPaAX_PhIs,0,0,2021-07-30T05:46:17Z,The best,2021-07-30T05:46:17Z
UgydpgsNvwf39br9ROp4AaABAg,@toyotomihideyoshi8,,1,ArPaAX_PhIs,0,0,2021-02-12T09:32:06Z,"it is a good video,, ;)",2021-02-12T09:32:06Z
UgyhjFYmyTKi81Konul4AaABAg,@sandipansarkar9211,,1,ArPaAX_PhIs,0,0,2021-01-17T14:15:55Z,niceexplanation,2021-01-17T14:15:55Z
UgwFF0gcKhxdRyI3Ti54AaABAg,@usf5914,,1,ArPaAX_PhIs,0,1,2021-01-16T22:31:50Z,"playlist is 6hour, 1minute, 12second.",2021-01-16T22:31:50Z
UgzvWxx_fNWzKbDD4Kp4AaABAg,@janinewang8308,,1,ArPaAX_PhIs,0,17,2020-12-06T11:50:20Z,"I feel so lucky to find out these videos, thank you.",2020-12-06T11:50:20Z
UgwL5vtrZFExEaOHll54AaABAg,@timdai6396,,1,ArPaAX_PhIs,2,2,2020-09-18T02:22:29Z,for some reason there were Korean subtitles on for default.,2020-09-18T02:22:29Z
UgwL5vtrZFExEaOHll54AaABAg.9DjCkSP6Sa59KDpBH9vekd,@sumangole1503,UgwL5vtrZFExEaOHll54AaABAg,2,ArPaAX_PhIs,0,0,2021-02-26T12:11:53Z,Youtube is racist,2021-02-26T12:11:53Z
UgwL5vtrZFExEaOHll54AaABAg.9DjCkSP6Sa59lCnvVk-xbs,@jlim3913,UgwL5vtrZFExEaOHll54AaABAg,2,ArPaAX_PhIs,0,0,2023-01-23T01:20:39Z,Korea&#39;s passion about AI,2023-01-23T01:20:39Z
UgyZoC4WxUQuf6Wxtpl4AaABAg,@brutuschina,,1,ArPaAX_PhIs,1,64,2020-05-19T18:22:27Z,The woman in the picture for &quot;neural style transfer&quot; is actually his wife. :),2020-05-19T18:22:27Z
UgyZoC4WxUQuf6Wxtpl4AaABAg.98qmcl13BL59YzqpCBaILe,@WahranRai,UgyZoC4WxUQuf6Wxtpl4AaABAg,2,ArPaAX_PhIs,0,3,2022-02-28T12:28:31Z,But he is not going to transfer her to you in anycase !,2022-02-28T12:28:31Z
UgxYeWusmgr4kWOn_Md4AaABAg,@hichembenchikh930,,1,ArPaAX_PhIs,2,0,2020-04-27T11:34:24Z,i need the programming exercices for specialisation  courses  coursera (zip file),2020-04-27T11:34:24Z
UgxYeWusmgr4kWOn_Md4AaABAg.97xPRsYCXz698BvOXIyHQ5,@ojasrox,UgxYeWusmgr4kWOn_Md4AaABAg,2,ArPaAX_PhIs,0,1,2020-05-03T12:10:54Z,"Search on google, &quot;Deep learning andrew ng github&quot; and you&#39;ll get maany github repos",2020-05-03T12:10:54Z
UgxYeWusmgr4kWOn_Md4AaABAg.97xPRsYCXz698C9C9t1iA2,@hichembenchikh930,UgxYeWusmgr4kWOn_Md4AaABAg,2,ArPaAX_PhIs,0,0,2020-05-03T14:20:17Z,@@ojasrox but what I need is the exercises (zip files) not the solution,2020-05-03T14:20:17Z
UgxB2uA-wmN4DnWrxQ94AaABAg,@geocarvalhont,,1,ArPaAX_PhIs,0,1,2019-11-08T20:17:57Z,sensei,2019-11-08T20:17:57Z
UgydKK-vSXhyECcEW5V4AaABAg,@user-rt8dy4zb4h,,1,ArPaAX_PhIs,4,44,2019-05-12T20:26:13Z,"Anybody starting, I suggest you use 1.5x Playback speed. It should save your time a lot. Really.",2019-05-12T20:26:13Z
UgydKK-vSXhyECcEW5V4AaABAg.8uqZHrWTCE792eNlsnXVqO,@MSDOS128,UgydKK-vSXhyECcEW5V4AaABAg,2,ArPaAX_PhIs,0,9,2019-12-17T19:37:15Z,Are amphetamines now legal in Israel? Because it&#39;s almost unintelligable at 1.5x :-D :-D,2019-12-17T19:37:15Z
UgydKK-vSXhyECcEW5V4AaABAg.8uqZHrWTCE796wxFmpqA0Z,@ayushgarg9575,UgydKK-vSXhyECcEW5V4AaABAg,2,ArPaAX_PhIs,0,0,2020-04-02T10:47:57Z,Already watching at 2.3x... üòÇüòÇ,2020-04-02T10:47:57Z
UgydKK-vSXhyECcEW5V4AaABAg.8uqZHrWTCE79KKVcHSVaoc,@harveypeng1469,UgydKK-vSXhyECcEW5V4AaABAg,2,ArPaAX_PhIs,0,6,2021-03-01T02:26:53Z,"@@MSDOS128 Good job, I&#39;m using 500X speed, it really saved a lot of time",2021-03-01T02:26:53Z
UgydKK-vSXhyECcEW5V4AaABAg.8uqZHrWTCE79OX-kUSezYh,@ahoangdinh3690,UgydKK-vSXhyECcEW5V4AaABAg,2,ArPaAX_PhIs,0,0,2021-06-13T09:04:05Z,nice advice,2021-06-13T09:04:05Z
UgxRR2R1CBdIENaSEnh4AaABAg,@mustafayavuz5528,,1,ArPaAX_PhIs,3,5,2019-03-18T16:02:53Z,"sen nasƒ±l bir kralsƒ±n ya, youtubea y√ºklemi≈ü videolarƒ±",2019-03-18T16:02:53Z
UgxRR2R1CBdIENaSEnh4AaABAg.8scTR-Or2FV8yKw28dsKgn,@zeyuren7508,UgxRR2R1CBdIENaSEnh4AaABAg,2,ArPaAX_PhIs,0,1,2019-08-07T14:24:25Z,ËØ¥ÁöÑ‰∫õÂï•‰∫Ü,2019-08-07T14:24:25Z
UgxRR2R1CBdIENaSEnh4AaABAg.8scTR-Or2FV91QWOPkB0r6,@timeToRiseAndGrow,UgxRR2R1CBdIENaSEnh4AaABAg,2,ArPaAX_PhIs,0,0,2019-11-17T04:32:33Z,pata ni yo ke bolny aen tou,2019-11-17T04:32:33Z
UgxRR2R1CBdIENaSEnh4AaABAg.8scTR-Or2FV9Oy0kn2AJ8Z,@nithinsai2250,UgxRR2R1CBdIENaSEnh4AaABAg,2,ArPaAX_PhIs,0,0,2021-06-24T06:11:36Z,Pora picchi pulka,2021-06-24T06:11:36Z
UgxWbEInE2yU4vhP6Op4AaABAg,@raziabid,,1,ArPaAX_PhIs,2,6,2018-11-13T14:16:59Z,This is a very informative course. Can I get the slides?,2018-11-13T14:16:59Z
UgxWbEInE2yU4vhP6Op4AaABAg.8naPx4D1odW8ypWoeysAal,@arjunsubedi745,UgxWbEInE2yU4vhP6Op4AaABAg,2,ArPaAX_PhIs,0,4,2019-08-19T20:50:57Z,just screenshot them!,2019-08-19T20:50:57Z
UgxWbEInE2yU4vhP6Op4AaABAg.8naPx4D1odW9mb-spDYTLX,@saiefzneti5391,UgxWbEInE2yU4vhP6Op4AaABAg,2,ArPaAX_PhIs,0,0,2023-02-26T16:46:17Z,You can get them for free from the official website.,2023-02-26T16:46:17Z
Ugy6QkV5ko73fNDhR994AaABAg,@MrSuperGerald,,1,ArPaAX_PhIs,8,2,2018-05-30T21:28:48Z,Why pay the exact same content on Coursera?? I do!,2018-05-30T21:28:48Z
Ugy6QkV5ko73fNDhR994AaABAg.8gtAbeCQox58jhblegoEQZ,@azunia4,Ugy6QkV5ko73fNDhR994AaABAg,2,ArPaAX_PhIs,0,12,2018-08-08T23:18:08Z,The homeworks can easily be cloned from one of several github repositories after a quick google search + the certificate may seem fancy but industry doesn&#39;t seem to care much about these types of certificates when hiring,2018-08-08T23:18:08Z
Ugy6QkV5ko73fNDhR994AaABAg.8gtAbeCQox58lKZVv7Er-b,@1100100il,Ugy6QkV5ko73fNDhR994AaABAg,2,ArPaAX_PhIs,0,0,2018-09-18T08:10:39Z,certificate,2018-09-18T08:10:39Z
Ugy6QkV5ko73fNDhR994AaABAg.8gtAbeCQox58q5gf2Nh9cd,@bobcrunch,Ugy6QkV5ko73fNDhR994AaABAg,2,ArPaAX_PhIs,0,1,2019-01-14T20:10:18Z,"I&#39;m taking the class right now, and some of the course videos are missing from this playlist, e.g. the videos on objects and bounding boxes.",2019-01-14T20:10:18Z
Ugy6QkV5ko73fNDhR994AaABAg.8gtAbeCQox58rLoSFM-RxW,@sourabhkhandelwal689,Ugy6QkV5ko73fNDhR994AaABAg,2,ArPaAX_PhIs,0,1,2019-02-14T22:57:33Z,"Bob Crunch, you can Audit this course from the Coursera website, which basically means you can watch the videos for free but don&#39;t get access to the quizzes and assignments.",2019-02-14T22:57:33Z
Ugy6QkV5ko73fNDhR994AaABAg.8gtAbeCQox58rLvNfDkc8d,@bobcrunch,Ugy6QkV5ko73fNDhR994AaABAg,2,ArPaAX_PhIs,0,4,2019-02-14T23:58:06Z,"@@sourabhkhandelwal689 I have audited the Coursera class. I&#39;ve copied the code from the course Jupyter Notebooks and have screenshots of the other information on the Notebooks. The only thing missing is the datasets. You can search the &#39;Net for equivalent datasets; e.g., I found a hand sign language dataset (sign-language-digits-dataset) that&#39;s equivalent to the courses dataset. I found a converter that converts the numerical arrays to an JPG (package imageio). It will take an effort to adapt the code, but it&#39;s a good learning experience.",2019-02-14T23:58:06Z
UgxU4_ddCEFNdS3NTUp4AaABAg,@VipinKumar-mf5lv,,1,ArPaAX_PhIs,3,0,2018-03-12T21:43:56Z,can we use 2MB image to object detection and image classification if model is trained for 256by256 pixel images,2018-03-12T21:43:56Z
UgxU4_ddCEFNdS3NTUp4AaABAg.8dhmYIoMgpE8zrE8_0xfI3,@iloverock1989,UgxU4_ddCEFNdS3NTUp4AaABAg,2,ArPaAX_PhIs,0,3,2019-09-14T09:17:39Z,"In convention, CNN model&#39;s input has to reshape into the specific scale before start computation.",2019-09-14T09:17:39Z
UgxU4_ddCEFNdS3NTUp4AaABAg.8dhmYIoMgpE9IVWnLxCocv,@maspoetry1,UgxU4_ddCEFNdS3NTUp4AaABAg,2,ArPaAX_PhIs,0,1,2021-01-14T16:05:59Z,i would lower the resolution first,2021-01-14T16:05:59Z
UgxU4_ddCEFNdS3NTUp4AaABAg.8dhmYIoMgpE9Jq2W_9HWU2,@jamesdickens1374,UgxU4_ddCEFNdS3NTUp4AaABAg,2,ArPaAX_PhIs,0,1,2021-02-16T21:16:06Z,"Yes you can. In pytorch for the faster r-cnn framework with torchvision you can input a shape of any size, and the GeneralTransform module will rescale it to a fixed min and max size. Convolution operations do not require a certain spatial size as input, although you will see in Tensorflow that they often have checks for the input shape size that do restrict the shape of the image, however this is not necessary in my opinion. The ROI pool operation from the Faster R-CNN architecture gives you a fixed size tensor no matter what your input shape is (assuming it has 3 channels as in an RGB image of course).",2021-02-16T21:16:06Z
Ugy0bzWbeprptMztCmt4AaABAg,@aga5839,,1,XuD4C8vJzEQ,0,0,2023-10-07T14:35:06Z,gokil,2023-10-07T14:35:06Z
Ugxjcn6X4xnAi0KeHk54AaABAg,@m0tivati0n71,,1,XuD4C8vJzEQ,0,2,2023-04-12T07:28:55Z,5 years later and this video is super helpful. Thank you.,2023-04-12T07:29:27Z
UgyOGiygbbaGe7lP9Zx4AaABAg,@ahmetkarakartal9563,,1,XuD4C8vJzEQ,0,0,2022-11-09T21:01:29Z,That&#39;s what I need. Thank you so much,2022-11-09T21:01:29Z
UgzgzeS4zvHK3Fy7yit4AaABAg,@user-oj4hr5rh6i,,1,XuD4C8vJzEQ,0,0,2022-06-13T03:45:52Z,similar to run-length encoding.,2022-06-13T03:45:52Z
UgyXotEVOf_kcUhxXYJ4AaABAg,@ewwitsantonio,,1,XuD4C8vJzEQ,0,1,2022-02-11T20:55:27Z,Excellent explanation. Thank you so much!,2022-02-11T20:55:27Z
UgylrYQNRBstSdxGsc14AaABAg,@letslearnjava1753,,1,XuD4C8vJzEQ,0,0,2021-08-02T04:11:14Z,"If you want to understand the  application of this powerful edge detection techniques , you can refer this video--<br><a href=""https://youtu.be/cToG83MLkqw"">https://youtu.be/cToG83MLkqw</a><br>Happy Learning üòä‚úåüèª",2021-08-02T04:11:14Z
Ugxth6g1W5ofpoBNl5V4AaABAg,@toyotomihideyoshi8,,1,XuD4C8vJzEQ,0,0,2021-02-12T09:38:58Z,"it is a good video,, ;)",2021-02-12T09:38:58Z
UgwFVrCMpJAMiEnZPyd4AaABAg,@chicme6435,,1,XuD4C8vJzEQ,0,0,2021-02-10T03:37:20Z,This guy andrew is greatn,2021-02-10T03:37:20Z
Ugy2scDXXW7Np2qaEfl4AaABAg,@mayursonowal,,1,XuD4C8vJzEQ,0,0,2021-02-01T11:41:03Z,bhagwaan,2021-02-01T11:41:03Z
UgzVe8eHOJDBwyvfE114AaABAg,@sandipansarkar9211,,1,XuD4C8vJzEQ,0,0,2021-01-26T04:26:32Z,great explanation,2021-01-26T04:26:32Z
UgwxSkuqqlpwkHs95td4AaABAg,@ml_initiator722,,1,XuD4C8vJzEQ,0,0,2021-01-12T10:24:54Z,"when doing convolution operation he wrote -5 and also in the filter used -1 for vertical edge detection. Why do we use negative numbers if the pixel range is from 0 to 255.<br><a href=""https://youtu.be/XuD4C8vJzEQ?list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF&amp;t=280"">https://youtu.be/XuD4C8vJzEQ?list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF&amp;t=280</a>",2021-01-12T10:25:48Z
UgyHcNtYMcWOah833HF4AaABAg,@1UniverseGames,,1,XuD4C8vJzEQ,0,0,2020-12-29T05:02:23Z,How do you guys code to find vertical and horizontal edges of an image. Any resources you would like to share,2020-12-29T05:02:23Z
UgyJGTuKfAClnFDS-gJ4AaABAg,@MuhannadGhazal,,1,XuD4C8vJzEQ,0,3,2020-12-01T15:42:45Z,"edge detection was a subject that we studied multiple times during my years in college and never understood what it is about, i now fully understand in just few minutes... many thanks",2020-12-01T15:42:45Z
UgwxlPs9jPP6jAacfLJ4AaABAg,@salmesfer52,,1,XuD4C8vJzEQ,0,13,2020-11-17T13:27:10Z,"Finally,a deep-learning session with no coding! <br><br>Thank you, as usual clear and very easy to understand and very informative!",2020-11-17T13:27:10Z
Ugz0qNuQUdBaVcAxM8N4AaABAg,@prafulkulkarni1758,,1,XuD4C8vJzEQ,0,3,2020-09-21T13:53:44Z,Wonderful &amp; highly informative session ! üôè,2020-09-21T13:53:44Z
UgxnbF-ihz_E9xDMi8p4AaABAg,@jinyang4796,,1,XuD4C8vJzEQ,0,0,2020-09-01T10:51:17Z,Thank you! This really helped!,2020-09-01T10:51:17Z
UgwCovZ2O3BZTpE1ziZ4AaABAg,@jonesbbq307,,1,XuD4C8vJzEQ,2,5,2020-06-16T05:08:04Z,He can do AI by pen and paper. Who need GPU,2020-06-16T05:08:04Z
UgwCovZ2O3BZTpE1ziZ4AaABAg.99xSz3qgl349K6e5HbWY_S,@noorameera26,UgwCovZ2O3BZTpE1ziZ4AaABAg,2,XuD4C8vJzEQ,0,0,2021-02-23T17:20:15Z,hahahah agree!,2021-02-23T17:20:15Z
UgwCovZ2O3BZTpE1ziZ4AaABAg.99xSz3qgl349LQZru9PhpT,@harshitpant4864,UgwCovZ2O3BZTpE1ziZ4AaABAg,2,XuD4C8vJzEQ,0,0,2021-03-28T07:30:48Z,This is basic image processing.<br>IMHO nothing to do with AI.,2021-03-28T07:30:48Z
Ugw7dBmq96VkHdCYgs54AaABAg,@asdasvbddf,,1,XuD4C8vJzEQ,0,0,2020-05-27T06:23:23Z,"<a href=""https://www.youtube.com/watch?v=XuD4C8vJzEQ&amp;t=3m22s"">3:22</a> Why don&#39;t the filter matrix be flipped before calculate?",2020-05-27T06:24:35Z
UgzdDCSnI-CHEI3apNJ4AaABAg,@biargeamauri,,1,XuD4C8vJzEQ,0,3,2020-05-25T18:31:05Z,Big lecture!<br>Thank you so much Professor Andrew NG,2020-05-25T18:31:05Z
Ugy7WJsDhPtACBxZksN4AaABAg,@nathan3804,,1,XuD4C8vJzEQ,2,0,2020-05-16T07:08:56Z,Would  you still use a 3x3 filter when you work with higher resolution images like 1000x1000 or maybe a 1920x1080 px image.  wouldn&#39;t that increase the computational time? If not what filter would be best for edge detection?,2020-05-16T07:08:56Z
Ugy7WJsDhPtACBxZksN4AaABAg.98hrABso8vT9BCyyfB9OzN,@kerolosemad8326,Ugy7WJsDhPtACBxZksN4AaABAg,2,XuD4C8vJzEQ,0,0,2020-07-17T11:35:37Z,maybe resizing ur images to a smaller size avoiding using bigger filters that would add more computational power,2020-07-17T11:35:37Z
Ugy7WJsDhPtACBxZksN4AaABAg.98hrABso8vT9LQbMxQbCN5,@harshitpant4864,Ugy7WJsDhPtACBxZksN4AaABAg,2,XuD4C8vJzEQ,0,0,2021-03-28T07:52:40Z,"@Nathan Nunes Most image processing software like openCV and matlab use fast Fourier transform (fft) for convolution and related operations, which produces results with an error in the range of 10^(-14), when compared to actual convolution, which can be counted as infinitesimally small.<br>Or if they HAVE TO use actual convolution they use multiple cores (parallel computations) of your computer to produce the output, which is still significantly slower than using fft.<br><br>I don&#39;t think what  @@kerolosemad8326 suggests is correct, as resizing will induce loss of detail.",2021-03-28T07:52:40Z
Ugw5dU68uCNXUaUIhKZ4AaABAg,@breakdancerQ,,1,XuD4C8vJzEQ,0,0,2020-04-09T22:49:08Z,This is very good stuff,2020-04-09T22:49:08Z
UgzjwBb-WQ3Kmbz_H7F4AaABAg,@snackbob100,,1,XuD4C8vJzEQ,1,0,2020-03-14T12:14:52Z,"can someone please explain this to me, i cant find it anywhere. does the person create the filter? or does the network do it. As in is the filter acting like a neuron, where it gets updated in back propogation? WHere is this filter coming from?",2020-03-14T12:14:52Z
UgzjwBb-WQ3Kmbz_H7F4AaABAg.96BB5hEl9bn9B0h9f6ITr9,@khushboovyas5932,UgzjwBb-WQ3Kmbz_H7F4AaABAg,2,XuD4C8vJzEQ,0,0,2020-07-12T17:09:05Z,First we have to assume one filter based on our requirement and we can tune the filter parameter while fine tuning the model..,2020-07-12T17:09:05Z
UgyAYObAe57recZVzft4AaABAg,@ruozhuli2170,,1,XuD4C8vJzEQ,0,2,2020-02-01T01:24:57Z,"Nice lecture, thanks! saved my life!",2020-02-01T01:24:57Z
Ugz1ZAMp4qz-Mk6CDsx4AaABAg,@99ansh,,1,XuD4C8vJzEQ,0,0,2020-01-24T17:56:05Z,"why are we not rotating the filter by 180 degrees? for convolution, it is the first step.",2020-01-24T17:56:05Z
Ugwg5eYJ9QHbLn4heb54AaABAg,@manuelkarner8746,,1,XuD4C8vJzEQ,0,10,2019-12-22T00:39:17Z,haha after the first 6 seconds i recogniced the voice from the stanford ML coursera course and immideatly subcribed :),2019-12-22T00:39:17Z
UgzR9zzg4LjRdjkiEvR4AaABAg,@minagabriel5556,,1,XuD4C8vJzEQ,0,0,2019-12-19T17:51:28Z,"I think you are wrong about conv in <a href=""https://www.youtube.com/watch?v=XuD4C8vJzEQ&amp;t=7m47s"">7:47</a>, isn&#39;t this supposed to be correlation or correlate2d, your signs are all flipped?",2019-12-19T17:51:28Z
Ugx-Pu2d0GAqmY9adNZ4AaABAg,@FarizDarari,,1,XuD4C8vJzEQ,0,14,2019-12-08T03:52:35Z,Now I get why Andrew Ng is such a great teacher!,2019-12-08T03:52:35Z
UgzJmFsNcrroPtwMkrV4AaABAg,@GhostkillerPlaysMC,,1,XuD4C8vJzEQ,0,0,2019-12-06T07:14:36Z,Very straightforward video.. thank you!,2019-12-06T07:14:36Z
Ugx91puKIY0p0JSPqWl4AaABAg,@hiramrayotorres2030,,1,XuD4C8vJzEQ,0,0,2019-12-01T17:14:28Z,Andrew saves the day...again!,2019-12-01T17:14:28Z
UgxEuU6ayOjJrHT_b2R4AaABAg,@_Mandal_,,1,XuD4C8vJzEQ,0,0,2019-11-14T17:59:11Z,east and west Andrew is the best,2019-11-14T17:59:11Z
UgywUpZL07bYzZHcmQB4AaABAg,@AffanSamad,,1,XuD4C8vJzEQ,1,0,2019-09-18T18:27:43Z,Why we use filters? or why we need filters?,2019-09-18T18:28:16Z
UgywUpZL07bYzZHcmQB4AaABAg.9-1WGqsXnS792LDvTBzSt-,@boubakarousmanou2698,UgywUpZL07bYzZHcmQB4AaABAg,2,XuD4C8vJzEQ,0,0,2019-12-09T23:46:22Z,filters are used to reduce noise in images,2019-12-09T23:46:22Z
Ugz5Lq95AwxF0ZVlc294AaABAg,@rishavpaudel8325,,1,XuD4C8vJzEQ,0,0,2019-09-14T10:39:53Z,sir why is the sum of filters always zero?????????,2019-09-14T10:39:53Z
UgzpTR1hpi1g_X8EYaZ4AaABAg,@user-kj4iv6nn1n,,1,XuD4C8vJzEQ,0,0,2019-08-21T21:55:07Z,what if the matrix is look like <br>[10 10 10 10 10 10<br> 10 10 10 10 10 10<br> 10 10 10 10 10 10<br>   0   0   0   0   0   0 <br>   0   0   0   0   0   0<br>   0   0   0   0   0   0 ]<br>can u still do the trick?,2019-08-21T21:55:07Z
Ugy1zpzqugLekc7SqOx4AaABAg,@SidharthRajaram,,1,XuD4C8vJzEQ,0,0,2019-07-15T07:59:27Z,"God bless Andrew! the best, always!",2019-07-15T07:59:27Z
UgzYWrE814--He2ePV14AaABAg,@foroughsodaei8067,,1,XuD4C8vJzEQ,0,0,2019-06-10T12:58:30Z,Thanksssssss,2019-06-10T12:58:30Z
UgywT3m3tnbglm4w6YZ4AaABAg,@yejijang2152,,1,XuD4C8vJzEQ,0,0,2019-06-06T07:15:50Z,Í∞êÏÇ¨Ìï©ÎãàÎã§ :),2019-06-06T07:15:50Z
UgzTrb0h4vEOJBvUZzd4AaABAg,@siddharthsvnit,,1,XuD4C8vJzEQ,0,9,2019-06-06T01:50:18Z,"This becomes convolution because filter is symmetric, techncally speaking the way it is explained here it is actually describing cross correlation",2019-06-06T01:50:18Z
Ugz6y5ihIB4pgpiOZL14AaABAg,@igorsrajer982,,1,XuD4C8vJzEQ,0,1,2019-06-04T09:09:17Z,"wp man, thanks",2019-06-04T09:09:17Z
UgzXWG-kqJadooNR9yp4AaABAg,@riseabovehate9476,,1,XuD4C8vJzEQ,0,0,2019-05-23T20:07:24Z,Excellent,2019-05-23T20:07:24Z
UgwSJqULcu6-86a_gsx4AaABAg,@kajabanthanavas1516,,1,XuD4C8vJzEQ,0,1,2019-05-23T18:54:25Z,nice explanation,2019-05-23T18:54:25Z
UgwLFnrbL4wYMpRrBsl4AaABAg,@ashishjohnsonburself,,1,XuD4C8vJzEQ,1,0,2019-05-01T16:24:26Z,"can the filter [[-1,0,1],[-1,0,1],[-1,0,1]] be the vertical edge detector instead of [[1,0,-1],[1,0,-1],[1,0,-1]] (as shown in the intuition) ?",2019-05-01T16:24:26Z
UgwLFnrbL4wYMpRrBsl4AaABAg.8uOnsLu7Uio8xFTlvlYWCJ,@annim2226,UgwLFnrbL4wYMpRrBsl4AaABAg,2,XuD4C8vJzEQ,0,1,2019-07-11T15:01:04Z,"yes, as I understood it it would be fine either way.",2019-07-11T15:01:04Z
Ugw3gadvg-v1oQFnsVx4AaABAg,@kld0093,,1,XuD4C8vJzEQ,0,0,2019-03-18T07:30:48Z,This is awesome,2019-03-18T07:30:48Z
UgzEt6YZ_AK7D6nkM0d4AaABAg,@Canda-fh4xc,,1,XuD4C8vJzEQ,2,5,2019-02-17T14:12:46Z,"Thank you for the amazing tutorial. You made it really simple.<br>I have few questions:<br>1- Based on what you decide the size of the filter(Kernels)?<br>2- Based of what you decide the matrix indices for the filter.<br>4- How did you find out the output matrix(image) size is 4x4 before the calculation?<br>5 - What if the size of the matrix(image) is 2x2 OR 5x5, How can we use the filter?<br> <br>Thank you,",2019-02-17T14:12:46Z
Ugwe_yAWNDlKiFhkr-l4AaABAg,@inquisitiverakib5844,,1,am36dePheDc,0,2,2022-07-11T17:05:39Z,"üí•üí• <a href=""https://www.youtube.com/watch?v=am36dePheDc&amp;t=5m15s"">5:15</a> üí•üí• main idea of DL",2022-07-11T17:05:39Z
UgyWkGWdD-HeYZFxkcx4AaABAg,@inhibited44,,1,am36dePheDc,0,1,2022-03-11T17:19:51Z,I wonder if they break this stuff down into eigenvalues and vectors?  Reminds me of linear algebra I had in 1984,2022-03-11T17:19:51Z
Ugyx95mOzVcoR3m7SeN4AaABAg,@kamalgoyal9376,,1,am36dePheDc,0,0,2022-01-04T02:22:26Z,"Sir, seems you are God of AI, ML, DL!!!",2022-01-04T02:22:26Z
UgywZP2Xz_B_IXAytsN4AaABAg,@moustafah1,,1,am36dePheDc,0,5,2021-04-25T19:25:38Z,This guy is a father to all of us ! x),2021-04-25T19:25:38Z
Ugx5Ob0NcBwhOlEFHQd4AaABAg,@sandipansarkar9211,,1,am36dePheDc,0,0,2021-01-23T19:25:25Z,nice explanation,2021-01-23T19:25:25Z
UgzVzg9NOGJee0oIh5F4AaABAg,@jinyang4796,,1,am36dePheDc,0,5,2020-09-01T10:56:10Z,Clear explanation! Thank you so much for making this simple to understand.,2020-09-01T10:56:10Z
Ugw907z4TE6K5kPMDl54AaABAg,@babitakumari-cz2if,,1,am36dePheDc,0,0,2020-06-15T20:44:24Z,everything with andrew ng is so good .but...why his voice tear my ears???,2020-06-15T20:44:24Z
Ugwh5wQX8kgJmPkwoGB4AaABAg,@amitnair92,,1,am36dePheDc,0,3,2020-05-01T20:32:06Z,"if someone wishes to see a simple implementation in Python using NumPy  <a href=""https://github.com/nairsgithub/machine/blob/master/convolution_gray_image.py"">https://github.com/nairsgithub/machine/blob/master/convolution_gray_image.py</a>  Code here will take an image as an input and output a Convoluted image just as shown in this video.",2020-05-01T20:32:06Z
UgxJdWLMgh4gchizGbx4AaABAg,@theseriousguy2136,,1,am36dePheDc,0,1,2020-02-04T01:09:18Z,Pure gold sir..I took courses worth 20k but they r in no match with yours...,2020-02-04T01:09:18Z
UgzQBTrOeu83Ptnh2gJ4AaABAg,@goonerjhh,,1,am36dePheDc,0,0,2019-07-26T11:56:04Z,Hello very helpful video!<br><br><br>I wanted to ask in one of my exams I was asked to calculate the magnitude after applying the edge detection method .. would you please help me with that if you can !<br><br><br>Also was asked about applying the 3x3 median on a certain pixel!,2019-07-26T11:56:04Z
UgyzlxDoit55Jb35Hxp4AaABAg,@riseabovehate9476,,1,am36dePheDc,0,0,2019-05-27T16:51:48Z,Why do we flip the mask in image convolution,2019-05-27T16:51:48Z
UgxWYfOtNNCQlnP-sWR4AaABAg,@phucnguyenhuusi9286,,1,am36dePheDc,0,0,2019-04-20T02:40:46Z,I like this course,2019-04-20T02:40:46Z
UgwNZj4vqViUCPS6b154AaABAg,@ibrahimakyayla7025,,1,am36dePheDc,0,0,2019-04-07T11:07:45Z,Hocam te≈üekk√ºrler,2019-04-07T11:07:45Z
UgwjYgfrkcmRFIY6Fj54AaABAg,@samTaf,,1,am36dePheDc,0,0,2018-12-30T08:55:38Z,thank you,2018-12-30T08:55:38Z
UgyIrzd3yLCA7BLfRQ14AaABAg,@FalkensMaze84,,1,am36dePheDc,1,8,2018-07-22T22:15:42Z,Was a 3x3 filter chosen because the image was 6x6? Is there a relationship between image matrix dimension and filter matrix dimension?<br><br>Edit: this question is answered in the next video. :),2018-07-22T22:28:47Z
UgyIrzd3yLCA7BLfRQ14AaABAg.8j0j6VnhP2z8pIidLSVCnU,@juanjunqueras9965,UgyIrzd3yLCA7BLfRQ14AaABAg,2,am36dePheDc,0,2,2018-12-26T01:06:16Z,"I haven&#39;t seen the next video yet, but the idea is that in order to calculate the value of a pixel on the output image, you need to compute all the surrounding pixels of that pixel on the input image",2018-12-26T01:06:16Z
UgxmZ8nolacrw_7zTHx4AaABAg,@imenmkaddem7451,,1,am36dePheDc,3,2,2018-06-21T12:21:51Z,"Good explanation ^_^,, How can we choose the best filters suitable for our images?",2018-06-21T12:21:51Z
UgxmZ8nolacrw_7zTHx4AaABAg.8hkqVuzpxfq8pIipBdPxFJ,@juanjunqueras9965,UgxmZ8nolacrw_7zTHx4AaABAg,2,am36dePheDc,0,1,2018-12-26T01:07:53Z,@Spirit I have C and an assembly version of edge sobel. I&#39;ll try to share with you my repository assap,2023-11-18T20:57:48Z
UgxmZ8nolacrw_7zTHx4AaABAg.8hkqVuzpxfq8rH0U8N0QGR,@chriscampell6864,UgxmZ8nolacrw_7zTHx4AaABAg,2,am36dePheDc,0,1,2019-02-13T02:15:13Z,"You can either choose the filter yourself manually, or &#39;learn&#39; the filter/kernel weights during the training process in a CNN via backpropagation. He mentions this at around time <a href=""https://www.youtube.com/watch?v=am36dePheDc&amp;t=4m05s"">4:05</a> in the video.",2019-02-13T02:16:48Z
UgxmZ8nolacrw_7zTHx4AaABAg.8hkqVuzpxfq9wIK0fFjtqn,@fachrichannel164,UgxmZ8nolacrw_7zTHx4AaABAg,2,am36dePheDc,0,0,2023-10-25T14:31:23Z,‚Äã@@juanjunqueras9965pleas send your code mate,2023-10-25T14:31:23Z
UgzCp6VRiW2IULBi8jp4AaABAg,@rachadlakis1,,1,smHa2442Ah4,0,0,2022-10-07T12:02:35Z,Thank<br> you.,2022-10-07T12:02:35Z
Ugx2iIsDvRcx7c-Za2x4AaABAg,@seanmenzies1986,,1,smHa2442Ah4,0,1,2021-05-06T12:28:41Z,"Such great explanations to what&#39;s going on under the hood. Knowing is one thing, teaching is an entirely different animal. Kudos to the teacher for having mastered both!",2021-05-06T12:28:41Z
UgzSJSsaabDUayymsk94AaABAg,@aramroshani6197,,1,smHa2442Ah4,1,1,2020-12-31T01:42:21Z,"Thanks for your great videos, but please can you explain which parmeter(s) determine the value for each member of the filters, I mean why do you use (1,1,1 / 0,0,0 / -1,-1,-1) but not other numbers. <br><br>Thanks advance.",2020-12-31T01:42:21Z
UgzSJSsaabDUayymsk94AaABAg.9HuvpXQbL599SaCmJ781j8,@hammad365,UgzSJSsaabDUayymsk94AaABAg,2,smHa2442Ah4,0,0,2021-09-22T10:20:28Z,"He explained that in the previous video, and explained other methods that use other numbers, or parameters that could be learnt too",2021-09-22T10:20:28Z
UgzxgWScM-jijdJ65K94AaABAg,@rahuldey6369,,1,smHa2442Ah4,0,1,2020-12-12T07:34:32Z,"An extremely insightful lecture as always have been. But when to use Valid padding and when to use Same it wasn&#39;t clear, I mean in which scenarios we&#39;ll consider them and why?",2020-12-12T07:34:32Z
Ugy4yBWe-xHfTVIfPgJ4AaABAg,@anjanakesavan5615,,1,smHa2442Ah4,1,1,2020-06-21T12:01:32Z,Thank you so much for the explanation on zero padding. Why do we use 0 for padding and not 1 ?,2020-06-21T12:01:32Z
Ugy4yBWe-xHfTVIfPgJ4AaABAg.9AA4GiPpCL_9JVNQHtmK7B,@Payah-sy8qw,Ugy4yBWe-xHfTVIfPgJ4AaABAg,2,smHa2442Ah4,0,0,2021-02-08T11:15:27Z,"because we want the pixel values ‚Äã‚Äãwe want to filter using the kernel, still get the actual pixel values ‚Äã‚Äãwhen convoluted as they are not affected by the numbers in the padding",2021-02-08T11:15:27Z
UgxO7R393wZ4HUOA7Sp4AaABAg,@danieltheshark,,1,smHa2442Ah4,0,0,2020-04-27T20:39:42Z,thank you so much... Just Thank you !,2020-04-27T20:39:42Z
UgxV-MOcAqnVkb-gdqN4AaABAg,@marcbroadus,,1,smHa2442Ah4,0,2,2020-04-23T09:08:36Z,"Sir Andrew, you&#39;re the boss!",2020-04-23T09:08:36Z
UgxaE_kep10aN-zXluh4AaABAg,@kvishnudev,,1,smHa2442Ah4,0,14,2020-04-11T06:13:33Z,Andew is one of the most knowledgeable person on machine learning out there.<br>His explanation is much based on theory.  Thank you very much sharing the valuable info in youtube,2020-04-11T06:13:33Z
Ugx1gIDeTKziRtoaBVJ4AaABAg,@rohanshetty1016,,1,smHa2442Ah4,1,1,2020-03-18T17:28:09Z,"***Note:<br><a href=""https://www.youtube.com/watch?v=smHa2442Ah4&amp;t=5m58s"">5:58</a> - Valid Convolution actually means that the input image size is &#39;valid&#39;  for this operation and there&#39;s no need for padding...",2020-03-18T17:28:09Z
Ugx1gIDeTKziRtoaBVJ4AaABAg.96M27meCo2c9H1j33H8M7C,@gorgolyt,Ugx1gIDeTKziRtoaBVJ4AaABAg,2,smHa2442Ah4,0,1,2020-12-09T05:53:16Z,"No, that&#39;s not what it means. Your comment really makes no sense in context, a convolution can be applied to any image of any size, there is no concept of a &quot;valid image size for the operation&quot;. The video is correct.",2020-12-09T05:53:16Z
UgyXR-2TX_IK83dbQ3t4AaABAg,@shahriarrahman8425,,1,smHa2442Ah4,0,4,2020-02-26T09:54:42Z,Was struggling with some conceptions and this lecture provided insights I needed. Thank you so much!,2020-02-26T09:54:42Z
Ugy_W7Kr2OJxA_Ghwph4AaABAg,@Shewanee25,,1,smHa2442Ah4,1,0,2019-09-24T03:07:28Z,What is the difference between reflective padding and zero padding ?,2019-09-24T03:07:28Z
Ugy_W7Kr2OJxA_Ghwph4AaABAg.9-FJivAmCLB99vojNMoK-s,@rahulpalli36,Ugy_W7Kr2OJxA_Ghwph4AaABAg,2,smHa2442Ah4,0,0,2020-06-15T13:48:25Z,"in reflective padding , the edge pixels are added onto the outside copying the pixels from the edge of the <a href=""http://image.in/"">image.in</a> zero padding just add the zero pixels",2020-06-15T13:48:25Z
Ugxrr7C2oCbM53r0WTV4AaABAg,@vipinmakde2426,,1,smHa2442Ah4,1,7,2018-01-12T19:50:32Z,"When the stride is greater than 1 and we are using SAME padding concept, thus the size of the input image is retained.<br>For example : input = 16, filter = 5, stride =5. Is value of P =(5-1)/2=2 ? Thus makeing the output of size [(n+2p-f)/stride]+1= 4<br>It can be seen clearly that output size is not retained.",2018-01-12T19:50:32Z
Ugxrr7C2oCbM53r0WTV4AaABAg.8bKef9fvtOt8oJNZ2YXUMR,@farmanshah1647,Ugxrr7C2oCbM53r0WTV4AaABAg,2,smHa2442Ah4,0,10,2018-12-01T10:41:09Z,"The formula for calculating p in case of stride &gt; 1 should be:<br><br>Derivation:<br>(n + 2p - f)/s + 1 = n<br>(n + 2p - f + s) / s = n<br>n + 2p -f + s = ns <br><br>Formula: p = [n(s-1) + f - s] / 2<br><br>In your case where:<br>input = 16, filter = 5, stride =5.<br>p = [16(5-1) + 5 - 5] / 2<br>p = 64 / 2 = 32<br><br>Recheck:<br>Output = (n + 2p - f)/s + 1 = (16 + 64 - 5) / 5 + 1 = 16",2018-12-01T11:05:21Z
UgyDNx6kJKpDgn1Whyx4AaABAg,@SanjeetKumar-ef6fj,,1,tQYZaDn_kSg,0,0,2022-12-28T15:47:55Z,"At <a href=""https://www.youtube.com/watch?v=tQYZaDn_kSg&amp;t=8m27s"">8:27</a> I didn&#39;t understand (A*B)*C = A*(B*C). Can someone help?",2022-12-28T15:47:55Z
UgytrtVv_doFS8jFpDZ4AaABAg,@hamzaqureshi6214,,1,tQYZaDn_kSg,0,0,2022-04-24T17:48:17Z,"Excellent  explanation <a href=""about:invalid#zCSafez""></a>",2022-04-24T17:48:17Z
Ugxi10q3Kl1sJrgOOLB4AaABAg,@EW-mb1ih,,1,tQYZaDn_kSg,1,0,2022-01-29T15:25:23Z,What is the interest of using strided convolution?,2022-01-29T15:25:23Z
Ugxi10q3Kl1sJrgOOLB4AaABAg.9XmvDLPF4i99YPWoaHbi90,@sameeragrawal2897,Ugxi10q3Kl1sJrgOOLB4AaABAg,2,tQYZaDn_kSg,0,0,2022-02-14T00:33:02Z,"I think it can increase or decrease the resolution of the image after the convolution is applied, which might be beneficial in your specific case.",2022-02-14T00:33:02Z
UgyLi2S8jLqKDPTKv8J4AaABAg,@vaneesh03,,1,tQYZaDn_kSg,0,0,2021-07-23T11:29:58Z,Thanks for everything! you guys changed how the world learns now.,2021-07-23T11:29:58Z
Ugz6OpAgGeA4BAF4B0t4AaABAg,@khadijaiddrisu4279,,1,tQYZaDn_kSg,0,2,2021-05-25T02:37:01Z,"in the upper left corner, of the output, i keep getting 88 instead of 83, can someone cross-check",2021-05-25T02:37:01Z
UgxGRrMjNy7Ncegf7SN4AaABAg,@pedrovelazquez138,,1,tQYZaDn_kSg,0,0,2021-04-12T20:33:50Z,Thank you!,2021-04-12T20:33:50Z
UgynCSm7xqTZBZY8n0B4AaABAg,@manuel783,,1,tQYZaDn_kSg,1,26,2021-01-18T23:21:58Z,"Strided convolutions <b>CORRECTION</b><br><br>At <a href=""https://www.youtube.com/watch?v=tQYZaDn_kSg&amp;t=4m44s"">4:44</a> when Andrew was explaining the technical note on cross-correlation vs convolution, the flipping of the filter was incorrect. <br><br>The correct filter after flipping vertically and horizontally would be:<br><br>7 |  9 | -1<br>2 |  0 |  1<br>5 |  4 |  3",2021-01-18T23:21:58Z
UgynCSm7xqTZBZY8n0B4AaABAg.9Ifas-Ztyqe9mUdgH4hgUu,@liulitong883,UgynCSm7xqTZBZY8n0B4AaABAg,2,tQYZaDn_kSg,0,0,2023-02-23T20:08:55Z,I got the same output as yours and was wondering where did I do wrong lol,2023-02-23T20:08:55Z
Ugx2kZp1c7EzwCYWOq94AaABAg,@leilalovegood4131,,1,tQYZaDn_kSg,0,1,2020-07-05T04:03:48Z,thx so much!,2020-07-05T04:03:48Z
UgyMcS8gC5ce07yeOh94AaABAg,@masqueraderx,,1,tQYZaDn_kSg,0,12,2020-06-23T12:12:30Z,"Thank you for the comment about cross correlations and convolutins. My gosh, i was going to get crazy xD",2020-06-23T12:12:30Z
UgwtCf_d_pd1HJ-o_Wp4AaABAg,@siddhinathkharade156,,1,tQYZaDn_kSg,0,0,2020-05-07T09:46:19Z,Thanks for sharing valuable stuff with us...!,2020-05-07T09:46:19Z
UgwEDvD22kAkZAcCIFp4AaABAg,@hhawesomeness3094,,1,tQYZaDn_kSg,0,0,2020-02-19T22:20:12Z,"Love ya to bits, Andrew, but why are your eyebrows purple?",2020-02-19T22:20:12Z
Ugymib6MQWTSAJWS-Et4AaABAg,@BoomChickaWahWah666,,1,tQYZaDn_kSg,0,3,2020-01-21T17:59:37Z,great tutorial. Thank you so much!,2020-01-21T17:59:37Z
UgwUkMSJGjNoib6TUJh4AaABAg,@sehvanawais3891,,1,tQYZaDn_kSg,2,2,2020-01-01T12:11:12Z,any one please tell me why we add one at the end in this formula,2020-01-01T12:11:12Z
UgwUkMSJGjNoib6TUJh4AaABAg.93FCe0f9XK093wT_JP8sfE,@WorIdProductions,UgwUkMSJGjNoib6TUJh4AaABAg,2,tQYZaDn_kSg,0,1,2020-01-18T16:45:41Z,"Draw the fxf grid in the top left corner of the nxn grid. Then notice the distance from the top right corner of the fxf grid to the top right corner of the nxn grid is n-f. n-f is them the number of additional times we can shift the fxf grid right by one. But we also need to include the initial position of the fxf grid in the nxn grid, hence + 1. Similar logic applies in the vertical direction. Also, as an example try the formula when n and f are the same and p = 0",2020-01-18T16:45:41Z
UgwUkMSJGjNoib6TUJh4AaABAg.93FCe0f9XK093y6I2eApXz,@sehvanawais3891,UgwUkMSJGjNoib6TUJh4AaABAg,2,tQYZaDn_kSg,0,1,2020-01-19T08:00:42Z,@@WorIdProductions now i understand it means we want to consider the every first element  of the nxn grid. in simple words we consider the zero th element of the matrix.,2020-01-19T08:00:42Z
UgzI1oikuv3wSrYjaY94AaABAg,@xingtongliu1636,,1,tQYZaDn_kSg,1,25,2019-12-18T21:01:24Z,I think the convolution kernel is flipped wrongly in this video when comparing with the cross correlation.,2019-12-18T21:01:24Z
UgzI1oikuv3wSrYjaY94AaABAg.92h6C62HNx395GDhj-a70W,@sanz1996_,UgzI1oikuv3wSrYjaY94AaABAg,2,tQYZaDn_kSg,0,2,2020-02-20T14:42:28Z,yeah its flipped wrongly,2020-02-20T14:42:28Z
UgxpQpOGt5q4TzrK7-x4AaABAg,@mohammadhelaluddin3982,,1,tQYZaDn_kSg,0,4,2019-08-22T06:53:23Z,"At <a href=""https://www.youtube.com/watch?v=tQYZaDn_kSg&amp;t=1m10s"">1:10</a>, the calculation was correct? It seems to be 88 instead of 83.",2019-08-22T06:57:19Z
UgzxqkcUIMSYdYUL1eJ4AaABAg,@chrisbailey658,,1,tQYZaDn_kSg,6,30,2019-08-13T21:18:08Z,"At <a href=""https://www.youtube.com/watch?v=tQYZaDn_kSg&amp;t=5m50s"">5:50</a> is the flipped matrix correct? If we&#39;re just flipping the horizontal and vertical axis I think it should be:<br> 7, 9, -1<br> 2, 0, 1<br> 5, 4, 3",2019-08-13T21:18:08Z
UgzxqkcUIMSYdYUL1eJ4AaABAg.8ya79Wyq5IW8ym6xSmMBm3,@HAL-9000-,UgzxqkcUIMSYdYUL1eJ4AaABAg,2,tQYZaDn_kSg,0,0,2019-08-18T13:07:14Z,he flipped the transposed matrix (?),2019-08-18T13:07:14Z
UgzxqkcUIMSYdYUL1eJ4AaABAg.8ya79Wyq5IW8ymwc4_S0aL,@chrisbailey658,UgzxqkcUIMSYdYUL1eJ4AaABAg,2,tQYZaDn_kSg,0,2,2019-08-18T20:47:26Z,"@@HAL-9000- Yeah exactly, I think it&#39;s a mistake",2019-08-18T20:47:26Z
UgzxqkcUIMSYdYUL1eJ4AaABAg.8ya79Wyq5IW8zyxxTLECYx,@manhngo2724,UgzxqkcUIMSYdYUL1eJ4AaABAg,2,tQYZaDn_kSg,0,0,2019-09-17T09:21:23Z,@@chrisbailey658  I think it&#39;s correct. You should check it again,2019-09-17T09:21:23Z
UgzxqkcUIMSYdYUL1eJ4AaABAg.8ya79Wyq5IW8zz2I55tTWA,@chrisbailey658,UgzxqkcUIMSYdYUL1eJ4AaABAg,2,tQYZaDn_kSg,0,4,2019-09-17T10:08:01Z,"It&#39;s a mistake in the video. Convolution is flipping the matrix top to bottom and left to right, and then applying cross correlation.",2019-09-17T10:08:01Z
UgzxqkcUIMSYdYUL1eJ4AaABAg.8ya79Wyq5IW91ITM46-03L,@adityashidhaye9879,UgzxqkcUIMSYdYUL1eJ4AaABAg,2,tQYZaDn_kSg,0,1,2019-11-14T01:32:05Z,@@chrisbailey658 Yes you&#39;re right he made a mistake.,2019-11-14T01:32:05Z
UgwUT_E4CCh-Scgr6cB4AaABAg,@ChintanDaveGhost47,,1,tQYZaDn_kSg,2,5,2019-08-06T17:03:43Z,"<a href=""https://www.youtube.com/watch?v=tQYZaDn_kSg&amp;t=1m23s"">1:23</a> Nice",2019-08-06T17:03:43Z
UgwUT_E4CCh-Scgr6cB4AaABAg.8yIdTvcWXok94XaZDmgHQ-,@prudvi01,UgwUT_E4CCh-Scgr6cB4AaABAg,2,tQYZaDn_kSg,0,0,2020-02-02T12:06:35Z,Nice,2020-02-02T12:06:35Z
UgwUT_E4CCh-Scgr6cB4AaABAg.8yIdTvcWXok9OE-li8Ss3-,@goksuceylan8844,UgwUT_E4CCh-Scgr6cB4AaABAg,2,tQYZaDn_kSg,0,0,2021-06-05T23:58:41Z,Nice,2021-06-05T23:58:41Z
Ugx6J9F_HnboHPnln6t4AaABAg,@m4ng4n,,1,tQYZaDn_kSg,0,0,2019-07-17T08:09:39Z,"Just one thing: i find this cross-correlation vs convolution more of a lazy notation problem. The same way we learn the transposed W for efficiency reasons, we learn the flipped filter. The idea is based on the convolution operation, it&#39;s just that it&#39;s inpractical to compute the flipping for no reason.",2019-07-17T08:09:39Z
Ugz5JsrJiNOrT517BI94AaABAg,@generativechaos,,1,tQYZaDn_kSg,4,4,2019-04-11T05:19:56Z,"So, why we do stride? I can&#39;t come up with advatages of it.",2019-04-11T05:19:56Z
Ugz5JsrJiNOrT517BI94AaABAg.8t_6vzoHtGK8uasg_3Y828,@CyborgGaming99,Ugz5JsrJiNOrT517BI94AaABAg,2,tQYZaDn_kSg,0,9,2019-05-06T18:16:38Z,"Dimensionality reduction, if our images are very computationaly expensive.",2019-05-06T18:16:38Z
Ugz5JsrJiNOrT517BI94AaABAg.8t_6vzoHtGK8wqH9a9eFw1,@cimplesolution3447,Ugz5JsrJiNOrT517BI94AaABAg,2,tQYZaDn_kSg,0,2,2019-07-01T10:50:35Z,"Stride helps to reduce the size of the image, a particularly useful feature.",2019-07-01T10:50:35Z
Ugz5JsrJiNOrT517BI94AaABAg.8t_6vzoHtGK8xl_GZmUTPC,@ahmettarhan1870,Ugz5JsrJiNOrT517BI94AaABAg,2,tQYZaDn_kSg,0,1,2019-07-24T11:32:45Z,it decreases the size of matrix,2019-07-24T11:32:45Z
Ugz5JsrJiNOrT517BI94AaABAg.8t_6vzoHtGK98zlRHXu4iQ,@ihebbibani5293,Ugz5JsrJiNOrT517BI94AaABAg,2,tQYZaDn_kSg,0,3,2020-05-23T06:05:10Z,"actually all answers lack a precision. Actually , even by default (stride=1) reduce the matrix dimension.But , the advantage of introducing stride (&gt;=2) is to ACCELERATE the matrix size reduction and thus help us to avoid computational expense as Cib said .",2020-05-23T06:05:48Z
UgwUL34QNbS01UEKT2F4AaABAg,@tsegaynigus8976,,1,tQYZaDn_kSg,1,1,2019-02-01T15:22:12Z,so how compare convolusion and coorelation,2019-02-01T15:22:12Z
UgwUL34QNbS01UEKT2F4AaABAg.8qoX-ihltRu8sUrzhQkgLA,@PRATIK1900,UgwUL34QNbS01UEKT2F4AaABAg,2,tQYZaDn_kSg,0,14,2019-03-15T07:53:02Z,"Cross-Correlation : what we have been doing for the last few videos.<br>Convolution :flipping the filter first, before doing the rest of the steps.<br><br>So we are actually doing cross-correlation(because we are skipping on the flipping) , but deep learning literature just calls this convolution (which is technically incorrect).<br><br>These 2 process are used for different applications. Cross-correlation is usually used for object detection and tracking, while convolution(actual convolution with flipping) is used for adding different kind of effects such as blurring, etc.",2019-03-15T07:53:02Z
UgxdEtVKCGitPGtAo_Z4AaABAg,@ridhajuneja8445,,1,tQYZaDn_kSg,2,0,2018-12-20T20:33:53Z,is it really flipping on horizontal and vertical axis or doing something else,2018-12-20T20:33:53Z
UgxdEtVKCGitPGtAo_Z4AaABAg.8p5MUr-twPO8sUsOAvZRBg,@PRATIK1900,UgxdEtVKCGitPGtAo_Z4AaABAg,2,tQYZaDn_kSg,0,0,2019-03-15T07:56:31Z,"Just flipping. Check out the formula for both cross-correlation and convolution, they are just slightly different.<br>These 2 process are used for different applications. Cross-correlation is usually used for object detection and tracking, while convolution(actual convolution with flipping) is used for adding different kind of effects such as blurring, etc.",2019-03-15T07:56:31Z
UgxdEtVKCGitPGtAo_Z4AaABAg.8p5MUr-twPO93_gtBvFhuT,@mahdou3608,UgxdEtVKCGitPGtAo_Z4AaABAg,2,tQYZaDn_kSg,0,1,2020-01-09T20:28:12Z,@@PRATIK1900 he means that in the video if he flipped it on horizontal and vertical axis we should obtain a different result,2020-01-09T20:28:12Z
UgwHQnV7auYF92e1kQR4AaABAg,@Geoters,,1,tQYZaDn_kSg,0,1,2018-10-02T17:00:11Z,Do convolution layers have bias? Like normal layers do?,2018-10-02T17:00:11Z
UgylBsxs8GEcCzaC0S14AaABAg,@srinivasnaredla1090,,1,tQYZaDn_kSg,0,2,2018-09-30T07:50:36Z,what is the point of striding?,2018-09-30T07:50:36Z
UgzeUZgClT5itfgcEJR4AaABAg,@hanweijie8092,,1,tQYZaDn_kSg,3,2,2018-09-02T07:08:37Z,"Based on previous video, using padding preserves the information from being discarded.  How about striped, does it discard any information?",2018-09-02T07:13:56Z
UgzeUZgClT5itfgcEJR4AaABAg.8kgFgd7bKNO8uqY95s-bOS,@user-rt8dy4zb4h,UgzeUZgClT5itfgcEJR4AaABAg,2,tQYZaDn_kSg,0,1,2019-05-12T20:16:16Z,it does. cuz u skip some cells according to ur stride.,2019-05-12T20:16:16Z
UgzeUZgClT5itfgcEJR4AaABAg.8kgFgd7bKNO8uqYC9NvD7L,@user-rt8dy4zb4h,UgzeUZgClT5itfgcEJR4AaABAg,2,tQYZaDn_kSg,0,2,2019-05-12T20:16:41Z,but not on large images. only smaller ones get affected,2019-05-12T20:16:41Z
UgzeUZgClT5itfgcEJR4AaABAg.8kgFgd7bKNO8wqHtZsCCgL,@cimplesolution3447,UgzeUZgClT5itfgcEJR4AaABAg,2,tQYZaDn_kSg,0,2,2019-07-01T10:57:00Z,"Yeah, it also discards some information. So while developing the model, have to check what value of stride (s) fit best for the required model.",2019-07-01T10:57:00Z
UgxRHjCL9l6j4BcRzjR4AaABAg,@vagos06,,1,tQYZaDn_kSg,0,1,2018-08-25T20:19:09Z,"Just a small correction: Output(2,3) should be 117, not 127.",2018-08-25T20:19:09Z
UgyCPRawHvqikxi13Ld4AaABAg,@mohammadrashid274,,1,tQYZaDn_kSg,1,3,2018-05-25T23:11:16Z,"hello, whats the purpose behind flipping the filter before convoluting it with the image ?",2018-05-25T23:11:16Z
UgyCPRawHvqikxi13Ld4AaABAg.8ggUMhhpYFY8kJG2V_Mn-W,@sleepmaster02,UgyCPRawHvqikxi13Ld4AaABAg,2,tQYZaDn_kSg,0,2,2018-08-23T23:29:58Z,"Towards the end of the video, Andrew Ng explains that the convolution operation as defined in the math textbook has this nice associative property, i.e. (a*b)*c = a*(b*c). However, it doesn&#39;t matter for DNN.",2018-08-23T23:29:58Z
Ugy-a02VmCluEF2kCat4AaABAg,@rhysm8167,,1,KTB_OFoAQcc,0,0,2023-12-20T11:11:49Z,great video. Thank you !,2023-12-20T11:11:49Z
Ugx0-RBIeDFB9saXm4R4AaABAg,@thomaswilhelm9698,,1,KTB_OFoAQcc,0,0,2023-11-26T19:45:12Z,"Finally, someone who can clearly explain the material!",2023-11-26T19:45:12Z
Ugw8-76hQpS4L6lxCAV4AaABAg,@__dekana__,,1,KTB_OFoAQcc,0,0,2023-10-18T04:49:06Z,He explains this so well that I want to binge the entire playlist.,2023-10-18T04:49:06Z
UgxOoEXUyyrqiGYQNhV4AaABAg,@-MuhamadFahmiAmmar,,1,KTB_OFoAQcc,0,0,2023-06-07T02:41:04Z,"WOW,  paham juga akhirnya, thanks",2023-06-07T02:41:04Z
Ugy8r0wKwXUgtwWOMZh4AaABAg,@jacksonvaldez5911,,1,KTB_OFoAQcc,0,0,2023-05-07T10:27:14Z,"Why is the output 2 dimensions? If you convolve over a 2d image with a 2d filter, you get a 2d output. Wouldnt this mean if you convolve over a 3d image(R, G, B) with a 3d filter, then the output should be 3 dimensions as well right?<br><br>Edit:<br>I think I get it now. It&#39;s because the size of the 3rd dimension is the same for both the filter and the rgb image, so it only has to convolve over the z axis once, producing a 3rd dimension size of 1 in the output. So technically the output is 3 dimensions, it&#39;s just that the 3rd dimension is a size of 1 which is basically just 2d<br><br>If you convolved over an rgb image with a 2x2x2 filter, than the output would then be 3 dimensions.",2023-05-07T10:34:35Z
UgwkTVDbaNfFYhiHXA14AaABAg,@CL-lightcolor,,1,KTB_OFoAQcc,0,0,2023-02-11T13:45:40Z,"Nice video<br>This is a course on Image Processing - Frequency domain filters <a href=""https://youtu.be/gjvwgWJqzko"">https://youtu.be/gjvwgWJqzko</a>",2023-02-11T13:45:40Z
UgxLTQY7tK7IKPBBdDd4AaABAg,@devanshgoel3433,,1,KTB_OFoAQcc,0,0,2022-11-20T13:34:21Z,thank u sir! You are the real hero.,2022-11-20T13:34:21Z
Ugw8JC-LO-yGOXCNWFN4AaABAg,@abrahamowos,,1,KTB_OFoAQcc,2,0,2022-11-19T09:20:36Z,Are the filter values trainable?,2022-11-19T09:20:36Z
Ugw8JC-LO-yGOXCNWFN4AaABAg.9ibIAs9fD0h9lwS_fuNijq,@fndTenorio,Ugw8JC-LO-yGOXCNWFN4AaABAg,2,KTB_OFoAQcc,0,1,2023-02-10T04:09:44Z,That is the whole point.,2023-02-10T04:09:44Z
Ugw8JC-LO-yGOXCNWFN4AaABAg.9ibIAs9fD0h9qbQ5SPCGVR,@ben-hn2ek,Ugw8JC-LO-yGOXCNWFN4AaABAg,2,KTB_OFoAQcc,0,0,2023-06-06T06:40:55Z,yes,2023-06-06T06:40:55Z
UgwRIJ29HTz01TwYDq94AaABAg,@practicaldeeplearningforbe9412,,1,KTB_OFoAQcc,0,0,2022-08-20T13:02:02Z,"How convolution operation works...<a href=""https://www.youtube.com/watch?v=akUdtkC_PY8"">https://www.youtube.com/watch?v=akUdtkC_PY8</a>",2022-08-20T13:02:02Z
Ugzy0YylKx001G-QZwt4AaABAg,@user-wc7hm3rn5c,,1,KTB_OFoAQcc,0,0,2022-07-25T16:10:27Z,anda perlu menjelaskan kandungan,2022-07-25T16:10:27Z
UgwHOuwD5MHK1TERH5t4AaABAg,@muneshchauhan,,1,KTB_OFoAQcc,0,9,2022-04-01T15:55:03Z,The way Andrew deconstructed the 3D convolution into a simple series of steps just goes in to say how great teachers can accelerate learning by manifolds.,2022-04-01T15:55:03Z
UgyoHoxTzPWhhqiumoR4AaABAg,@cem_kaya,,1,KTB_OFoAQcc,0,1,2022-03-21T13:34:18Z,thanks for clarifying that the filter is channel deep,2022-03-23T10:49:52Z
UgzTX-EHNUKIcbTZCJN4AaABAg,@nikhilbadveli5810,,1,KTB_OFoAQcc,2,2,2022-03-11T17:11:09Z,Can we use different filter sizes in the multiple filter case? And what will be the output shape then?,2022-03-11T17:11:09Z
UgzTX-EHNUKIcbTZCJN4AaABAg.9ZRfuwPPq8Z9_6wx_OX-y9,@chetankumar9463,UgzTX-EHNUKIcbTZCJN4AaABAg,2,KTB_OFoAQcc,0,0,2022-03-28T12:27:24Z,Answer mila?,2022-03-28T12:27:24Z
UgzTX-EHNUKIcbTZCJN4AaABAg.9ZRfuwPPq8Z9qbQ28MEEQ_,@ben-hn2ek,UgzTX-EHNUKIcbTZCJN4AaABAg,2,KTB_OFoAQcc,0,0,2023-06-06T06:40:28Z,yes you can use different filter sizes out put shape can be calculated with the formula : [(n+2p-f)/s+1] x [(n+2p-f)/s+1]     Where n is size of image <br>f is size of filter <br>p = padding<br>s = stride <br>1st  [(n+2p-f)/s+1]    is for row and 2nd [(n+2p-f)/s+1]  for column or be taken in vice versa too,2023-06-06T06:40:28Z
Ugx75JjxQ31uacjlAjJ4AaABAg,@kebakent,,1,KTB_OFoAQcc,0,2,2022-02-22T22:12:19Z,It&#39;s funny how concepts like this can be so confusing when you don&#39;t know it. I had no idea the conv layers had an extra unconfigurable dimension and going from 3d to 2d confused me.,2022-02-22T22:12:19Z
UgyVCGUJHAyipJodrZV4AaABAg,@harshdevmurari007,,1,KTB_OFoAQcc,0,0,2022-02-12T19:22:50Z,The most effective way of explaining depth(no of channels) of CNN,2022-02-12T19:22:50Z
UgzLmJTBmcVRIWizgyV4AaABAg,@strongsyedaa7378,,1,KTB_OFoAQcc,0,0,2021-11-13T19:28:20Z,From 3√ó3 convolution how comes 4x4?,2021-11-13T19:28:20Z
UgxQyLf5Jk8gfJTC7eZ4AaABAg,@sammyj29,,1,KTB_OFoAQcc,0,3,2021-08-01T11:01:41Z,"By far the best explanation I have ever seen. Such simple and crisp! <br><br>I had one doubt though professor, can we use CNN with data apart from images? If so, what does the filter size represent then? And how do we interpret the features of the data in terms of number of input channels?",2021-08-01T11:01:41Z
UgxymXH09aW2QG5AbDl4AaABAg,@pedrovelazquez138,,1,KTB_OFoAQcc,0,0,2021-04-12T17:16:21Z,Thank you!!!,2021-04-12T17:16:21Z
Ugz0ohsLNkrdp6FBwCZ4AaABAg,@JoaoPedro-pi9ee,,1,KTB_OFoAQcc,0,7,2021-04-12T16:51:32Z,Best explanation I&#39;ve found about convolutions over multiple channels. Thanks.,2021-04-12T16:51:32Z
UgxS3UGbGL1TwNyV5yZ4AaABAg,@mitakshra1,,1,KTB_OFoAQcc,0,0,2021-03-11T04:10:20Z,thankyou sir for having great people like you in this life,2021-03-11T04:10:20Z
UgzW-ltIP60oA1JeJy94AaABAg,@user-gy8co1gk8o,,1,KTB_OFoAQcc,0,0,2021-01-28T19:30:18Z,!thank you so much,2021-01-28T19:30:18Z
UgyxA-ESQTp02EVnB3p4AaABAg,@sandipansarkar9211,,1,KTB_OFoAQcc,0,0,2021-01-26T17:49:18Z,nice explanation,2021-01-26T17:49:18Z
UgzHBWFkEtJq-pl5ML54AaABAg,@MuhannadGhazal,,1,KTB_OFoAQcc,2,0,2020-12-06T20:53:31Z,"<a href=""https://www.youtube.com/watch?v=KTB_OFoAQcc&amp;t=6m02s"">6:02</a>, i was expecting the output to be 4 x 4 x 3. why it was just 4 x 4 ?",2020-12-06T20:53:31Z
UgzHBWFkEtJq-pl5ML54AaABAg.9Gwbh2NEVcE9HnG97YnjrR,@adhoc3018,UgzHBWFkEtJq-pl5ML54AaABAg,2,KTB_OFoAQcc,0,1,2020-12-28T02:14:44Z,"It think that it is because he is using the 3 filters as a cube. Thus, after the multiplication, you should sum everything. For the output to be 4 x 4 x 3 I think it would be necessary to have 3 filters for each channel",2020-12-28T02:14:44Z
UgzHBWFkEtJq-pl5ML54AaABAg.9Gwbh2NEVcE9qbQbzyBUik,@ben-hn2ek,UgzHBWFkEtJq-pl5ML54AaABAg,2,KTB_OFoAQcc,0,0,2023-06-06T06:45:30Z,"because he added the three filter values into one , in normal black and white for 3x3 filter u get 9 values here since u have 3 color channels ie 3 filters and 3 matrix to represent an image so u get to add 27 values which he added into a single cell",2023-06-06T06:45:30Z
Ugy-OOL_vsqkZIJ9RJF4AaABAg,@bobo0612,,1,KTB_OFoAQcc,0,0,2020-11-30T10:05:08Z,brilliant!,2020-11-30T10:05:08Z
UgyCe2pTj42B08u9ggJ4AaABAg,@GagarineYuri,,1,KTB_OFoAQcc,3,1,2020-10-20T20:10:39Z,"@<a href=""https://www.youtube.com/watch?v=KTB_OFoAQcc&amp;t=3m11s"">3:11</a> : So do we add the 3 convolution to output the value of the 4x4 feature map ?",2020-10-20T20:10:39Z
UgyCe2pTj42B08u9ggJ4AaABAg.9F2WQzTJCdr9FFNNIbHf2I,@robbellis5944,UgyCe2pTj42B08u9ggJ4AaABAg,2,KTB_OFoAQcc,0,3,2020-10-25T20:01:38Z,"Yes.  Instead of thinking of it as 3x 2D convolutions added together, try thinking of it as 1x 3D convolution.  It&#39;s still an element-wise product and sum of the cube of filters (or kernel) and a 3D portion of the stack of images.",2020-10-25T20:01:38Z
UgyCe2pTj42B08u9ggJ4AaABAg.9F2WQzTJCdr9uOmnQrpS3Q,@muhammadmaazwaseem7452,UgyCe2pTj42B08u9ggJ4AaABAg,2,KTB_OFoAQcc,0,0,2023-09-08T09:44:14Z,"Why do we add the 3 convolutions, why not take thake their average value?",2023-09-08T09:44:14Z
UgyCe2pTj42B08u9ggJ4AaABAg.9F2WQzTJCdr9uOmwqh9llA,@muhammadmaazwaseem7452,UgyCe2pTj42B08u9ggJ4AaABAg,2,KTB_OFoAQcc,0,0,2023-09-08T09:45:32Z,‚Äã@@robbellis5944Why do we add the 3 convolutions instead of taking their average value?,2023-09-08T09:45:32Z
UgzzYngRfqy83AOfTTB4AaABAg,@elgs1980,,1,KTB_OFoAQcc,2,0,2020-09-14T07:14:00Z,"<a href=""https://www.youtube.com/watch?v=KTB_OFoAQcc&amp;t=5m51s"">5:51</a>, I don&#39;t understand why the result is not 4x4x3, but 4x4. So where are the 3 layers?",2020-09-14T07:14:00Z
UgzzYngRfqy83AOfTTB4AaABAg.9D_QwC1ecxS9Dl0Jy6T5Vz,@agueconfle4889,UgzzYngRfqy83AOfTTB4AaABAg,2,KTB_OFoAQcc,0,1,2020-09-18T19:12:21Z,"it seems like each layer resulted from dot product is added up to a single number. That means, you have 3x3x3 (27) multiply operations that sums up.",2020-09-18T19:12:21Z
UgzzYngRfqy83AOfTTB4AaABAg.9D_QwC1ecxS9k8QoiaiBxN,@elgs1980,UgzzYngRfqy83AOfTTB4AaABAg,2,KTB_OFoAQcc,0,0,2022-12-27T12:01:39Z,"<a href=""https://www.youtube.com/watch?v=KTB_OFoAQcc&amp;t=3m21s"">3:21</a> answered my question, add them all those numbers.",2022-12-27T12:01:39Z
UgxLNgSOripBPHZs8wl4AaABAg,@rs9130,,1,KTB_OFoAQcc,0,2,2020-09-07T05:06:31Z,output of rgb channels after convolution must be 4x4x3 right?,2020-09-07T05:06:31Z
UgwpWjuZOLtyb4FT-D14AaABAg,@aiinabox1260,,1,KTB_OFoAQcc,2,0,2020-08-02T19:09:30Z,"Awesome. Hv 4 questions, scratching my head for the last 2 weeks. In my conv layer 1, I mentioned 32 filter , does that mean 32 diff features will be  extracted from each image sequentially,  am using greyscale image 28x28x1. Is it possible to make the filters to apply in parallel . Next,  In the case of multiple filters , can the filters applied on the image in parallel or in sequential ? How to influence the conv layer to use multiple filters ? Next question is, how to override the default filter by custom filter type ?",2020-08-02T19:10:26Z
UgwpWjuZOLtyb4FT-D14AaABAg.9Brzd0fCfAx9CJ88LvzkEU,@aiinabox1260,UgwpWjuZOLtyb4FT-D14AaABAg,2,KTB_OFoAQcc,0,0,2020-08-13T17:31:17Z,@MattAufF5 thanks a lot. But still I hv one nagging question... Let&#39;s say if 32 filters ( feature detectors)  applied on a single image won&#39;t it cause any contention ?,2023-11-16T20:05:39Z
UgwpWjuZOLtyb4FT-D14AaABAg.9Brzd0fCfAx9CJBpsp8deV,@aiinabox1260,UgwpWjuZOLtyb4FT-D14AaABAg,2,KTB_OFoAQcc,0,0,2020-08-13T18:03:35Z,"@MattAufF5 awesome, thanks a ton",2023-11-16T05:34:11Z
UgxGoAin4Dombrj3HJp4AaABAg,@redash3861,,1,KTB_OFoAQcc,0,0,2020-06-12T13:39:15Z,Dude I really was searching this for 2 days but there was no clear explanation on volumes thanks a lot,2020-06-12T13:39:15Z
Ugw82xvXGIFxtdIA3NB4AaABAg,@amitnair92,,1,KTB_OFoAQcc,0,0,2020-05-01T20:12:32Z,"ok, so at first i was a little confused by what adding all the filters at last mean. say pixal at position (0,0) for RGB are 20,10,30  after applying filter adding all the channels means [20,10,30] and not [60] . correct me if i am wrong.",2020-05-01T20:12:32Z
UgyUS-aUUaEZHgGlse94AaABAg,@DrN007,,1,KTB_OFoAQcc,0,5,2020-04-30T18:17:05Z,Great! So a conv64 basically applies 64 different filters on segments of the input.,2020-04-30T18:17:05Z
UgyDFPWWbxRe1K4RyvV4AaABAg,@thealgorithm7633,,1,KTB_OFoAQcc,0,0,2020-04-13T15:17:57Z,Is it possible that the number of filter channels greater than the number of input channels?,2020-04-13T15:17:57Z
UgyB2_XXpSL0F4XsAql4AaABAg,@purpleturtledotcom,,1,KTB_OFoAQcc,2,141,2020-03-23T09:05:24Z,"Found this gem after wasting my time on several &#39;fancy&#39; deeplearning video tutorials. <br>&quot;If you can‚Äôt explain something in simple terms, you don‚Äôt understand it.&quot; <br>- Feynman",2020-03-23T09:05:24Z
UgyB2_XXpSL0F4XsAql4AaABAg.96Y0ZyzoqnQ9AiI6rGAqNL,@leilalovegood4131,UgyB2_XXpSL0F4XsAql4AaABAg,2,KTB_OFoAQcc,0,3,2020-07-05T04:15:56Z,can&#39;t agree more,2020-07-05T04:15:56Z
UgyB2_XXpSL0F4XsAql4AaABAg.96Y0ZyzoqnQ9Oy5Ui3NFNI,@nithinsai2250,UgyB2_XXpSL0F4XsAql4AaABAg,2,KTB_OFoAQcc,0,4,2021-06-24T06:52:58Z,"yeah they all just use fancy words like keras, tensorflow blah blah blah",2021-06-24T06:52:58Z
UgxQwM-SZHcTKd94pip4AaABAg,@prabhur764,,1,KTB_OFoAQcc,0,0,2020-03-21T10:08:20Z,@Sahil Bandar can i give ur contact no. or email id,2020-03-21T10:08:20Z
Ugx0mgGCU12Gioccsa54AaABAg,@majinfu,,1,KTB_OFoAQcc,0,1,2020-02-23T00:30:15Z,Thank you so much! This video helped me to understand CNN very much!,2020-02-23T00:30:15Z
UgzHUSx9iUCJ0kT2Qut4AaABAg,@kuramarosetta8193,,1,jPOAS7uCODQ,0,0,2023-10-22T12:11:43Z,"<a href=""https://www.youtube.com/watch?v=jPOAS7uCODQ&amp;t=14m16s"">14:16</a> Mind blown here, very fun trying to follow. Thank you very much.",2023-10-22T12:11:43Z
Ugzi7D9kc195iwjmPQp4AaABAg,@abdullahiabdislaan8907,,1,jPOAS7uCODQ,0,0,2023-07-06T11:45:01Z,"The explanation of the lecture is something completely different other sources of the internet when it comes deep nueral network ,it builds the intuition behind the content.<br>Thanks Andrew I&#39;m very appreciate for that.",2023-07-06T11:45:01Z
UgyLJT90zLEh_bs7n7x4AaABAg,@user-zy7tx1ph6r,,1,jPOAS7uCODQ,0,0,2023-06-06T15:10:48Z,"Looks like here number of channels (like R,G,B denoted earlier by n_c) and numbr of filters (horizontal, vertical etc)  are both represented by n_c. This is confusing to me. Am I missing a point here?",2023-06-06T15:10:48Z
UgzDfEljp0VjHb7e-It4AaABAg,@chamanthipyneni7827,,1,jPOAS7uCODQ,0,0,2022-12-25T06:02:30Z,How many layers does a cnn need to have for 4 class labels?,2022-12-25T06:02:30Z
UgwEgAPRjD59EFnwO3x4AaABAg,@richiekho8938,,1,jPOAS7uCODQ,0,0,2022-10-20T11:27:06Z,"It is a very cool resource, just that the volume becomes smaller and smaller. take a breath, sir.",2022-10-20T11:27:06Z
UgzwRBDobtEkn8Ue3ox4AaABAg,@Chuukwudi,,1,jPOAS7uCODQ,0,1,2022-06-29T22:32:31Z,Do not worry guys if you do not fully understand this part. The next video will  make you understand better. I literally left the next video to come and type this here to help anyone who like me did not fully understand this particular video. The next one will make it clear.,2022-06-29T22:32:31Z
UgyJwbADlMFcFDSeDC14AaABAg,@ansumansamal3767,,1,jPOAS7uCODQ,0,0,2022-03-12T14:56:22Z,LEGEND,2022-03-12T14:56:22Z
Ugz2Yig2WXOUo7zKuyV4AaABAg,@hariharannair3281,,1,jPOAS7uCODQ,0,0,2021-11-18T17:47:38Z,Andrew not seen god but probably he looks like u,2021-11-18T17:47:38Z
Ugxn0a_rgxAgGQyrqr54AaABAg,@ibrahimmostafa9441,,1,jPOAS7uCODQ,0,0,2021-09-18T17:08:26Z,"You are a Great sir , thank you",2021-09-18T17:08:26Z
Ugz7mMCpV2GdpX_piqZ4AaABAg,@pedrovelazquez138,,1,jPOAS7uCODQ,0,0,2021-04-12T20:11:58Z,"I love your explanations. Thank you. You change lives, greerings from Paraguay.",2021-04-12T20:11:58Z
UgxMOkuged5t7iFxAtd4AaABAg,@sandipansarkar9211,,1,jPOAS7uCODQ,0,0,2021-01-14T20:32:26Z,nice explanation,2021-01-14T20:32:26Z
UgxoxuYjjg6R57Ngyph4AaABAg,@sandipansarkar9211,,1,jPOAS7uCODQ,0,0,2021-01-14T19:58:29Z,great exoplanation,2021-01-14T19:58:29Z
Ugznq7H2PFK0mnixZyt4AaABAg,@MrBemnet1,,1,jPOAS7uCODQ,0,1,2020-12-15T21:40:01Z,16 minute is brutal,2020-12-15T21:40:01Z
UgxZK4S1V034v5TQ6AB4AaABAg,@alperturk1824,,1,jPOAS7uCODQ,0,0,2020-12-07T07:22:36Z,Reisssss,2020-12-07T07:22:36Z
Ugzd0ZlbtZHI8U_4TR14AaABAg,@WahranRai,,1,jPOAS7uCODQ,0,1,2020-11-14T10:12:31Z,"<a href=""https://www.youtube.com/watch?v=jPOAS7uCODQ&amp;t=5m02s"">5:02</a> good explanation but reading slides very difficult (especially indices and exponents)",2020-11-14T10:12:31Z
Ugx76mcjBukh1Jb9I5F4AaABAg,@elgs1980,,1,jPOAS7uCODQ,0,0,2020-09-14T07:27:12Z,How are the 3 layers combined to one layer in the output?,2020-09-14T07:27:12Z
UgzJw95Ab6QV9mfwGah4AaABAg,@ahmadsuleyman5378,,1,jPOAS7uCODQ,2,0,2020-08-17T09:58:02Z,"In the activation notation A = m * n(h) * n(w)  *  n(c), can any one explain what does that &#39;m&#39; stand for ?",2020-08-17T09:58:02Z
UgzJw95Ab6QV9mfwGah4AaABAg.9CScS5TyOad9CTClEbOV1c,@arrusticodavid,UgzJw95Ab6QV9mfwGah4AaABAg,2,jPOAS7uCODQ,0,1,2020-08-17T15:24:06Z,It&#39;s the number of examples since A is the result of stacking each activation matrix.,2020-08-17T15:24:06Z
UgzJw95Ab6QV9mfwGah4AaABAg.9CScS5TyOad9Q5kpm4Ddom,@sauravpandey900,UgzJw95Ab6QV9mfwGah4AaABAg,2,jPOAS7uCODQ,0,0,2021-07-22T12:08:18Z,m here represent batch size,2021-07-22T12:08:18Z
Ugwu_uieQFMoB39S0Yx4AaABAg,@arisioz9360,,1,jPOAS7uCODQ,0,20,2020-07-22T21:58:20Z,We should start giving our college money to Andrew instead lads,2020-07-22T21:58:20Z
UgwtD4pTs4ytQ12Mv8x4AaABAg,@Vinoth89Karur,,1,jPOAS7uCODQ,0,0,2020-05-19T11:02:23Z,Thank you sir..,2020-05-19T11:02:23Z
UgwpAEFJIpSSMqOMuaZ4AaABAg,@amitnair92,,1,jPOAS7uCODQ,1,0,2020-05-03T04:48:38Z,"How Does the 3x3x3 filter output 4x4 what happens to colour channels do they add up ? [23,5,1] if this is the first pixel in the RBG image is the output a greyscale 29 ???",2020-05-03T04:48:38Z
UgwpAEFJIpSSMqOMuaZ4AaABAg.98B7mAOHFB398PcatLG0QX,@bharshavardhan2007,UgwpAEFJIpSSMqOMuaZ4AaABAg,2,jPOAS7uCODQ,0,0,2020-05-08T19:56:04Z,"<a href=""https://www.youtube.com/watch?v=KTB_OFoAQcc&amp;list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF&amp;index=6"">https://www.youtube.com/watch?v=KTB_OFoAQcc&amp;list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF&amp;index=6</a><br><br><br>watch from 2 minutes",2020-05-08T19:56:04Z
UgwZHLzpVUajxAnpfFd4AaABAg,@marcbroadus,,1,jPOAS7uCODQ,3,16,2020-04-23T13:24:34Z,"I had a bad break up and your deep learning videos are making me get the intellectual pleasure and urge to spend time as effectively as possible. You touch lives, Andrew. Lots of love for you.",2020-04-23T13:24:34Z
UgwZHLzpVUajxAnpfFd4AaABAg.97nIsCguXCB9MSqCp3Tgt0,@HimanshuMauryadesigners,UgwZHLzpVUajxAnpfFd4AaABAg,2,jPOAS7uCODQ,0,1,2021-04-23T01:12:13Z,"It seems that you are an intellectual sir. I don&#39;t know whether you will read this or not but still. Try rearranging the weights, bias or the number of layers or what not. Whats stopping you from again patching with her? Its happy to be sad sometimes. You are fucking creating intelligence, what is a human mind?",2021-04-23T01:12:13Z
UgwZHLzpVUajxAnpfFd4AaABAg.97nIsCguXCB9MSqIFMt--f,@HimanshuMauryadesigners,UgwZHLzpVUajxAnpfFd4AaABAg,2,jPOAS7uCODQ,0,2,2021-04-23T01:12:58Z,Only reply when you are again with her.,2021-04-23T01:12:58Z
UgwZHLzpVUajxAnpfFd4AaABAg.97nIsCguXCB9N9Iuat8Ha2,@jimmiemunyi,UgwZHLzpVUajxAnpfFd4AaABAg,2,jPOAS7uCODQ,0,1,2021-05-10T07:38:20Z,@@HimanshuMauryadesigners haha this is the energy i need in my life,2021-05-10T07:38:20Z
Ugy5ZuKaKEIpZH5Dgqp4AaABAg,@nivi6414,,1,jPOAS7uCODQ,1,0,2020-03-09T16:21:09Z,the audio is not good man..there is some disturbance which is continuously hurting ears.,2020-03-09T16:21:09Z
Ugy5ZuKaKEIpZH5Dgqp4AaABAg.95zkJBW-CaW9BQyKjKVmTY,@arisioz9360,Ugy5ZuKaKEIpZH5Dgqp4AaABAg,2,jPOAS7uCODQ,0,2,2020-07-22T21:59:24Z,Press &#39;M&#39; to fix it,2020-07-22T21:59:24Z
Ugwfh9Pm-EbLPuZB7jR4AaABAg,@shreejanshrestha1931,,1,jPOAS7uCODQ,0,1,2020-01-17T08:51:58Z,i am a bit confuse here. can anyone say what will be the value of L in n(l-1). output of previous layer means ? 4*4*2? or any other??? so in next layer will there be n(4-1) ? or what?,2020-01-17T09:01:45Z
UgySfrhq5zcaTiabxll4AaABAg,@user-bz7ki7dl1r,,1,jPOAS7uCODQ,0,0,2020-01-09T05:41:27Z,"Thank you, Andrew Ng.",2020-01-09T05:41:27Z
UgxaVrFdTrFkEQlrIa94AaABAg,@_JoyshreeMozumder,,1,jPOAS7uCODQ,0,1,2019-10-13T14:54:15Z,is it convolution layer?,2019-10-13T14:54:15Z
Ugw7vGDaEU7sKa1I8Dh4AaABAg,@theruisu21,,1,jPOAS7uCODQ,0,16,2019-10-02T10:11:00Z,Good and clear explanation.<br>Difficult to find this good elsewhere.,2019-10-02T10:11:00Z
UgwMmfGB9pkJ9GeFi8t4AaABAg,@winviki123,,1,jPOAS7uCODQ,1,6,2019-08-22T13:25:41Z,Thank you Andrew sensei!,2019-08-22T13:25:41Z
UgwMmfGB9pkJ9GeFi8t4AaABAg.8ywSF4Amad99d7ly6rokWe,@amaan6723,UgwMmfGB9pkJ9GeFi8t4AaABAg,2,jPOAS7uCODQ,0,0,2022-07-06T06:16:10Z,Dude he is chinese. Not japanese,2022-07-06T06:16:10Z
UgyRZWHctbPQCxSReKF4AaABAg,@parthpatel7853,,1,jPOAS7uCODQ,0,22,2019-06-13T17:00:57Z,"Correction: @ <a href=""https://www.youtube.com/watch?v=jPOAS7uCODQ&amp;t=2m05s"">2:05</a> -- It&#39;s 6x6x3 to 4x4x2 instead of 4x4x4.",2019-06-13T17:00:57Z
Ugylm49ES7eL2HvYkCF4AaABAg,@stftcalculations,,1,jPOAS7uCODQ,1,58,2019-03-19T14:08:15Z,"the thing with his lectures vs every other source on the planet for the machine and deep learning is that he teaches by developing your intuition. Believe me, I have tried every other material and none has made me understand the machine and deep learning the way his lectures do. Thanks, Andrew you are the best teacher out there.",2019-03-19T14:08:15Z
Ugylm49ES7eL2HvYkCF4AaABAg.8seq6Jtgd6f8zluAoR66oM,@sandyz1000,Ugylm49ES7eL2HvYkCF4AaABAg,2,jPOAS7uCODQ,0,7,2019-09-12T07:38:15Z,True but you also need to debug your code to understand more about implementation. I believe to understand the concept totally you need to build it or reverse engineer existing code (mostly code from github). I have been introduced to Andrew Ng lecture very late in my career but those all concept looks very familiar because I have already worked on the implementation sides and believe me the maths look very satisfying when you look at the python code.,2019-09-12T07:38:33Z
UgzpNMtkyed4VXIkC314AaABAg,@PRATIK1900,,1,jPOAS7uCODQ,0,0,2019-03-15T11:58:50Z,"Can we relate using two filters to 2 nodes of a neural net(because each node has its own weight vector) ? If so, shouldn&#39;t the bias added to the two 4x4 results be the same, since the bias is constant for one layer?",2019-03-15T11:58:50Z
UgxfDheAC_OFNt6Y5hJ4AaABAg,@santhoshpapisetty7418,,1,jPOAS7uCODQ,0,5,2019-03-12T19:02:02Z,"nice lectures sir,you are the father of deep learning.",2019-03-12T19:02:02Z
Ugy_9lxy5b3hjRvlV5d4AaABAg,@i_amdosa3068,,1,jPOAS7uCODQ,0,0,2019-01-29T09:26:25Z,day 1,2019-01-29T09:26:25Z
UgyHqCMyjCZaLqENvqN4AaABAg,@shobhitsrivastava4496,,1,jPOAS7uCODQ,0,1,2018-12-23T14:18:36Z,You are really great sir<br>hoping to meet you one day !,2018-12-23T14:18:36Z
UgzjRlYQsrLNdX0bttp4AaABAg,@arsalan2780,,1,jPOAS7uCODQ,1,0,2018-11-29T03:02:10Z,"@ <a href=""https://www.youtube.com/watch?v=jPOAS7uCODQ&amp;t=10m05s"">10:05</a> padding should be 2p[l-1] since padding is done on input not filters layer or output later... and same goes for stripe.. <br>I am bit confused here.. <br>does l go along with time when that step is performed regardless of on which layers its performed ..",2018-11-29T03:02:10Z
UgzjRlYQsrLNdX0bttp4AaABAg.8oDPRUKcd1f8wA1jWZ9bB-,@wolfisraging,UgzjRlYQsrLNdX0bttp4AaABAg,2,jPOAS7uCODQ,0,0,2019-06-14T15:48:28Z,"It is 2p[l] because we are getting layer [l] by applying this padding &quot;p&quot; on the previous layer. So basically &quot;p&quot; is  property of layer [l] not [l - 1]. <br>For example, in multilayer neural networks you create weight matrix to apply on previous layer [l - 1] to generate next [l], so the matrix is the property of layer [l] not [l - 1].",2019-06-14T15:48:28Z
UgyFM2omJlFYw4gEbeZ4AaABAg,@sau002,,1,jPOAS7uCODQ,0,0,2018-08-15T13:17:09Z,Do we need a bias parameter for every Kernel at the Convolutional layer? I understand the significance of Bias at the fully connected layer. As per my understanding (I am probably wrong) the Convolutional layers are performing feature detection. E.g. edge detection ?,2018-08-15T13:17:09Z
Ugwkh787At1DcVEAJih4AaABAg,@sbarter,,1,jPOAS7uCODQ,2,48,2018-07-17T23:13:34Z,Andrew Ng is a god,2018-07-17T23:13:34Z
Ugwkh787At1DcVEAJih4AaABAg.8ioxkuRFDu88p0D0xXfwy6,@navid2368,Ugwkh787At1DcVEAJih4AaABAg,2,jPOAS7uCODQ,0,3,2018-12-18T20:34:57Z,"Agreed, I absolutely love him.",2018-12-18T20:34:57Z
Ugwkh787At1DcVEAJih4AaABAg.8ioxkuRFDu896kwaQmIGMy,@bethelhall7792,Ugwkh787At1DcVEAJih4AaABAg,2,jPOAS7uCODQ,0,0,2020-03-28T18:51:17Z,A god of AI,2020-03-28T18:51:17Z
UgxhogLugKdx_YLDjml4AaABAg,@jalendarch89,,1,jPOAS7uCODQ,1,2,2018-01-07T07:58:14Z,280,2018-01-07T07:58:14Z
UgxhogLugKdx_YLDjml4AaABAg.8b6WAiBgZbB8ciUYRHHnA8,@ajayg1305,UgxhogLugKdx_YLDjml4AaABAg,2,jPOAS7uCODQ,0,3,2018-02-16T07:45:46Z,27 weights + 1 bias = 28 * 10 filters =  280,2018-02-16T07:45:46Z
UgwrTe-aGcsZQN6_G6B4AaABAg,@swfsql,,1,3PyJA9AfwSk,0,0,2023-09-05T22:52:44Z,"<a href=""https://www.youtube.com/watch?v=3PyJA9AfwSk&amp;t=6m00s"">6:00</a> you could also describe that last layer as a conv3d layer with one 7x7x40 filter",2023-09-05T22:52:44Z
Ugy2Eaohba8pTJ-hsKV4AaABAg,@amoonmohammed8041,,1,3PyJA9AfwSk,0,0,2023-08-14T10:31:11Z,amazing explanation! thank you sir for making things easy to understand.,2023-08-14T10:31:11Z
UgyM3xtlUMGS-LLoEXN4AaABAg,@David-mr4cn,,1,3PyJA9AfwSk,0,0,2023-07-02T13:41:49Z,"i would be really curious about the exact information flow <br><br>if you have a 39x39x3 input so an input with 3 channels <br>and you use 10 filters in the conv-layer<br><br>i would suppose, in order to conserve all information, one would apply all 10 filters on the 3 channels independtly, leaving you with 3*10 output channels with the dimensions 37x37 <br>so now since the output dimension is 37x37x10 and not 37x37x30, my question is : what happens there to merge the information of the channels from 30 to 10 is it summed or averaged i dont see it ??",2023-07-02T13:41:49Z
UgzVLsQsma7p5RGSX1l4AaABAg,@omarkadhim3193,,1,3PyJA9AfwSk,0,0,2023-06-04T15:01:32Z,Started learning with Andrew in 2015 on Coursera. What a generous and gifted person. So grateful.,2023-06-04T15:01:32Z
UgwkiKj3xu75aBOr-CR4AaABAg,@mudassarahmad5729,,1,3PyJA9AfwSk,0,0,2023-04-17T11:39:36Z,can you explain the mathematical operation of the layers? how can a 3*3 fliter use 39*39*3 tensor to give 37*37*1 output,2023-04-17T11:39:56Z
UgxFrDD-8Gk1V4AP6Mp4AaABAg,@moeininstructor,,1,3PyJA9AfwSk,0,0,2022-12-20T07:30:45Z,Too goo üëç,2022-12-20T07:30:45Z
UgxY4iZXWUvUjKrKo3J4AaABAg,@devanshgoel3433,,1,3PyJA9AfwSk,0,0,2022-11-21T09:06:29Z,thank u sir,2022-11-21T09:06:29Z
UgzpiOMe9cqahfN7pqd4AaABAg,@gravisriders8124,,1,3PyJA9AfwSk,1,0,2022-04-20T16:10:06Z,Are all filters unique in all layer or some filters might be the same in multiple layers (e.g. in layer 1 and 2)?,2022-04-20T16:10:06Z
UgzpiOMe9cqahfN7pqd4AaABAg.9a2Zio746hq9hAZjCweXDj,@doggilovh,UgzpiOMe9cqahfN7pqd4AaABAg,2,3PyJA9AfwSk,0,1,2022-10-14T18:23:50Z,The filters are learned by the network. Its unlikely that the network would learn the same exact filter in multiple layers.,2022-10-14T18:23:50Z
Ugw9p5_HavHdamXy_mh4AaABAg,@johnsonli6467,,1,3PyJA9AfwSk,0,0,2022-03-16T04:01:04Z,"May i ask for fully connected layer, how to calculate the weigh? (With the input )",2022-03-16T04:01:04Z
UgwHoR7W08itPb0xZUN4AaABAg,@132_gehna_anand6,,1,3PyJA9AfwSk,0,0,2022-03-05T12:06:03Z,"explain starting <a href=""https://www.youtube.com/watch?v=3PyJA9AfwSk&amp;t=4m37s"">4:37</a>",2022-03-05T12:06:03Z
Ugx7KJyI75xzd_G80lx4AaABAg,@long3850,,1,3PyJA9AfwSk,0,1,2021-06-06T08:42:27Z,best cnn explantation on youtube !,2021-06-06T08:42:27Z
Ugx-QDt6NIkkQHJXIz94AaABAg,@manuel783,,1,3PyJA9AfwSk,0,2,2021-01-18T23:23:17Z,"Simple Convolutional Network Example <b>CORRECTION</b><br><br>Correction in &quot;Simple Convolutional Network Example,&quot; <a href=""https://www.youtube.com/watch?v=3PyJA9AfwSk&amp;t=1m14s"">1:14</a>:  <br><br>p=0 means valid convolutions instead of same convolutions.<br><br>Setting the padding to zero results in &quot;valid convolutions&quot;",2021-01-18T23:23:17Z
Ugw1yEgtD5wapbEX-MB4AaABAg,@sandipansarkar9211,,1,3PyJA9AfwSk,1,0,2020-12-23T14:16:34Z,great explanation.need to watch again,2020-12-23T14:16:34Z
Ugw1yEgtD5wapbEX-MB4AaABAg.9HbfmYgD5fY9scnGlJTO5p,@theexplorer9012,Ugw1yEgtD5wapbEX-MB4AaABAg,2,3PyJA9AfwSk,0,0,2023-07-26T12:34:12Z,lol,2023-07-26T12:34:12Z
Ugx_QCVqbYFWvTgsOdN4AaABAg,@mueez.mp4,,1,3PyJA9AfwSk,1,1,2020-11-03T18:57:19Z,Are we implicitly implying that the first filter has 3 channels and the second 10?,2020-11-03T18:57:19Z
Ugx_QCVqbYFWvTgsOdN4AaABAg.9FbRA6nCvW09K1UhDIb3O2,@VishalBalaji,Ugx_QCVqbYFWvTgsOdN4AaABAg,2,3PyJA9AfwSk,0,1,2021-02-21T17:13:15Z,"No, all the filters mentioned have dimension of f x f x 3. This convolves with input to give n x n output. If we have, let&#39;s say, 10 filters, then we have 10 such n x n outputs. Hence, the dimension would be n x n x 10.",2021-02-21T17:13:15Z
Ugz7ov1jqCz2sicB5194AaABAg,@minakshiboruah1356,,1,3PyJA9AfwSk,0,0,2020-09-27T16:23:08Z,"Hi Folks All have taken symmetric filter to avoid explaining the nitty gritty of conv. multiplication for that u will need to refer <a href=""https://youtu.be/QfFogANxpdA"">https://youtu.be/QfFogANxpdA</a> Thank You to u &amp; the difference b/w cross correlation &amp; conv.  2D not a single video is to be found I guess only 1 more may exist.",2020-09-27T16:23:08Z
UgzosvK4MCdf0gjAlXt4AaABAg,@elgs1980,,1,3PyJA9AfwSk,6,3,2020-09-14T08:09:00Z,"Andrew, can you please explain why the 3 channels suddenly become 1 when convolved to the next layer? Did you add them together?",2020-09-14T08:12:21Z
UgzosvK4MCdf0gjAlXt4AaABAg.9D_XDxYmGa79F_ANmlWiYc,@reggaebin,UgzosvK4MCdf0gjAlXt4AaABAg,2,3PyJA9AfwSk,0,0,2020-11-02T21:52:09Z,I think that he considered 1 channel of 3. The picture has 3 channels of RGB colors.,2020-11-02T21:52:09Z
UgzosvK4MCdf0gjAlXt4AaABAg.9D_XDxYmGa79HTxVN3awHv,@yashwanths2622,UgzosvK4MCdf0gjAlXt4AaABAg,2,3PyJA9AfwSk,0,3,2020-12-20T04:58:12Z,See the &#39;convolutions over volumes&#39; video.,2020-12-20T04:58:12Z
UgzosvK4MCdf0gjAlXt4AaABAg.9D_XDxYmGa79HTxXnisc5W,@yashwanths2622,UgzosvK4MCdf0gjAlXt4AaABAg,2,3PyJA9AfwSk,0,1,2020-12-20T04:58:32Z,@@reggaebin No.,2020-12-20T04:58:32Z
UgzosvK4MCdf0gjAlXt4AaABAg.9D_XDxYmGa79JLOczNBJ-w,@n2o_tv513,UgzosvK4MCdf0gjAlXt4AaABAg,2,3PyJA9AfwSk,0,0,2021-02-04T14:13:40Z,The prev video has the explanation.,2021-02-04T14:13:40Z
UgzosvK4MCdf0gjAlXt4AaABAg.9D_XDxYmGa79NCjWhBj64z,@valeriafonsecadiaz1527,UgzosvK4MCdf0gjAlXt4AaABAg,2,3PyJA9AfwSk,0,0,2021-05-11T15:37:19Z,"Yes, they are added, see two previous videos",2021-05-11T15:37:19Z
Ugwx_-IrQhnWYeXsTMp4AaABAg,@muhammadalam2498,,1,3PyJA9AfwSk,1,7,2020-09-13T16:02:34Z,"In the first layer we used 3x3x3 with 10 different filters. I know from the previous videos that the filters channel and the input channel would be the same and would result in a 37x37x1 output matrix and with 10 filters would result in 37x37x10. In the second layer, would our filter still be 5x5x3? or 5x5x10? if 10, what would those 10 represent? because in the first layer the 3 represents the color channel.",2020-09-13T16:02:34Z
Ugwx_-IrQhnWYeXsTMp4AaABAg.9DYncbgmdfC9EX4bs2rl9x,@guyindisguise,Ugwx_-IrQhnWYeXsTMp4AaABAg,2,3PyJA9AfwSk,0,19,2020-10-07T20:32:40Z,"In the second layer it would be 5x5x10.<br>The 10 represents the channels, same as before, except this time the channels do not contain information about colors (RGB) but instead contain information on whatever those 10 filters/kernels learned in the previous layer.<br>So out of those 10 channels one could be horizontal edges, another could be vertical edges, another could be a diagonal gradient etc.<br><br>Each filter of layer 2 will pick up on different combinations of those 10 new channels.<br>As a hypothetical example if one filter of layer 2 had a 1 in the top left for the horizontal edge channel and also a 1 in the top left for the vertical edge channel (and every other weight set to 0) then it would likely detect top left edges with something similar to a 90 degree angle)<br><br>So to recap: in the first layer filters combine information on different colors, while later they combine information on other different concepts that were previously learned.",2020-10-07T20:32:40Z
Ugxph5XTXc13J4B8Ww14AaABAg,@YazeedAlkosai,,1,3PyJA9AfwSk,0,0,2020-08-13T10:47:31Z,"thanks for the fruitful video, I have a 3D model need to measure the feature of length, width, and depth by implementing CNN. is it possible to use CNN to gain better measuring?",2020-08-13T10:47:31Z
Ugwz27ilFySRVEus_094AaABAg,@asdkazmi,,1,3PyJA9AfwSk,1,0,2020-07-17T10:30:11Z,"why you didn&#39;t use such a filter which can reduce output into 7x7x40 within just one layer? e.g.<br>if we choose filter in first layer 15x15x40 with stride = 4 and padding = 0 then output within one layer will be 7x7x40<br>It is also seen that in all the lectures, usually used filter size was 3x3x(No. of Channels) or max up-to 5x5x(No. of Channels). Is it always recommended to take a small size of filter?",2020-07-17T10:30:11Z
Ugwz27ilFySRVEus_094AaABAg.9BCrUS76TZw9hAZdTFFwbV,@doggilovh,Ugwz27ilFySRVEus_094AaABAg,2,3PyJA9AfwSk,0,0,2022-10-14T18:23:03Z,The network can learn more sophisticated functions with more layers.,2022-10-14T18:23:03Z
Ugxlypsv4bzIUakEEZx4AaABAg,@lennonli9100,,1,3PyJA9AfwSk,0,1,2020-06-09T16:15:14Z,why filters are always square?,2020-06-09T16:15:14Z
Ugxc0-emhcTuTRUjr0d4AaABAg,@ankitmishra9108,,1,3PyJA9AfwSk,0,1,2020-05-27T08:55:25Z,Can you please make a video for training CNN from scratch? How will we got those filters by training?,2020-05-27T08:55:25Z
Ugy1PECUCljpCM_KKVZ4AaABAg,@muhammadtahirmahmood6559,,1,3PyJA9AfwSk,1,1,2020-02-18T04:35:57Z,"Is this just me or someone else also noticed? Or may be i am wrong. On layer 3 when video is at <a href=""https://www.youtube.com/watch?v=3PyJA9AfwSk&amp;t=4m12s"">4:12</a> its f3 and s2, shouldn&#39;t it be s3 ?. Please correct me.",2020-02-18T04:35:57Z
Ugy1PECUCljpCM_KKVZ4AaABAg.959zhic2WfR98PkHbJV_H6,@bharshavardhan2007,Ugy1PECUCljpCM_KKVZ4AaABAg,2,3PyJA9AfwSk,0,0,2020-05-08T21:03:13Z,Yes you are right. s and p always corresponds to current layer.,2020-05-08T21:03:13Z
Ugz3B9_-3qd6R1CphX14AaABAg,@mp0157,,1,3PyJA9AfwSk,2,1,2019-08-02T20:44:40Z,"Horizontal and vertical are examples of two filters, anybody know what are the other type of filters used in the example that brings the filter count to 20? Thanks",2019-08-02T20:44:40Z
Ugz3B9_-3qd6R1CphX14AaABAg.8y8j_iTALgh8yD4-DMT7Zz,@kishanlal676,Ugz3B9_-3qd6R1CphX14AaABAg,2,3PyJA9AfwSk,0,1,2019-08-04T13:08:44Z,"Horizontal and vertical filters detect horizontal(0¬∞) and Vertical Edges(90¬∞) in the input image..Whereas remaining 18 filters can be used to detect edges that are in different angles say 45¬∞,60¬∞,etc. Correct me if I&#39;m wrong",2019-08-04T13:08:44Z
Ugz3B9_-3qd6R1CphX14AaABAg.8y8j_iTALgh8yDp9USy6sr,@mp0157,Ugz3B9_-3qd6R1CphX14AaABAg,2,3PyJA9AfwSk,0,1,2019-08-04T20:09:34Z,@@kishanlal676 Thank you :) That was my first thought too! I was wondering if there was more to it than angular edge detection filters.,2019-08-04T20:09:34Z
Ugz3-I7O2aW1Vdsj4vN4AaABAg,@sokhibtukhtaev9693,,1,3PyJA9AfwSk,1,4,2019-07-15T13:08:55Z,"so the full size of filters used in the first conv process is 3x3x3 (10 of them), and full size of filters used in the second conv process is 5x5x10 (20 of them), and full size of filters used in the third conv process is 5x5x20 (40 of them)? that is a bit confusing especially when you only input the 2D filter size and the number of filters in Keras conv2D. In that case it would be <br>model.add(Conv2D(10, (3, 3), padding=&quot;same&quot;, activation=&quot;relu&quot;))<br>model.add(Conv2D(20, (5, 5), padding=&quot;same&quot;, activation=&quot;relu&quot;))<br>model.add(Conv2D(40, (5, 5), padding=&quot;same&quot;, activation=&quot;relu&quot;))<br>And the last dimensions of the filters would automatically be input based on the previous number of filters (or just 3 for the first layer, because 3 is RGB of input image here).<br><br><br>Anything to correct or add?",2019-07-15T13:08:55Z
Ugz3-I7O2aW1Vdsj4vN4AaABAg.8xP_72-v7iQ90dNWNNQAXp,@jgc9700,Ugz3-I7O2aW1Vdsj4vN4AaABAg,2,3PyJA9AfwSk,0,0,2019-10-28T17:12:58Z,"I have that same question, please could someone solve it? Thanks",2019-10-28T17:12:58Z
UgwEdCpgdzUTpTDVAKh4AaABAg,@ruifengwang9690,,1,3PyJA9AfwSk,5,12,2019-04-18T05:16:14Z,It&#39;s so lucky to learn all this with you. Thank you.,2019-04-18T05:16:14Z
UgwEdCpgdzUTpTDVAKh4AaABAg.8tr83xo_4MH9RQ4Z9AjNsW,@ramonbodie513,UgwEdCpgdzUTpTDVAKh4AaABAg,2,3PyJA9AfwSk,0,0,2021-08-24T06:05:36Z,Sorry to be so off topic but does anyone know a trick to get back into an Instagram account??<br>I somehow lost the login password. I appreciate any assistance you can offer me,2021-08-24T06:05:36Z
UgwEdCpgdzUTpTDVAKh4AaABAg.8tr83xo_4MH9RQ5zip1rzp,@jaxxdamien7452,UgwEdCpgdzUTpTDVAKh4AaABAg,2,3PyJA9AfwSk,0,0,2021-08-24T06:18:06Z,@Ramon Bodie instablaster :),2021-08-24T06:18:06Z
UgwEdCpgdzUTpTDVAKh4AaABAg.8tr83xo_4MH9RQ84XWI5NK,@ramonbodie513,UgwEdCpgdzUTpTDVAKh4AaABAg,2,3PyJA9AfwSk,0,0,2021-08-24T06:36:22Z,@Jaxx Damien i really appreciate your reply. I got to the site thru google and Im in the hacking process atm.<br>Looks like it&#39;s gonna take a while so I will get back to you later with my results.,2021-08-24T06:36:22Z
UgwEdCpgdzUTpTDVAKh4AaABAg.8tr83xo_4MH9RQBfVUIYlZ,@ramonbodie513,UgwEdCpgdzUTpTDVAKh4AaABAg,2,3PyJA9AfwSk,0,0,2021-08-24T07:07:46Z,"@Jaxx Damien It did the trick and I now got access to my account again. I am so happy:D<br>Thank you so much, you saved my ass :D",2021-08-24T07:07:46Z
UgwEdCpgdzUTpTDVAKh4AaABAg.8tr83xo_4MH9RQD-nGGHEO,@jaxxdamien7452,UgwEdCpgdzUTpTDVAKh4AaABAg,2,3PyJA9AfwSk,0,0,2021-08-24T07:19:25Z,@Ramon Bodie No problem xD,2021-08-24T07:19:25Z
UgwK4wdPRuJ8VKwWQ-t4AaABAg,@ZANO439,,1,3PyJA9AfwSk,0,2,2019-01-03T16:55:03Z,best explanation well done &lt;3,2019-01-03T16:55:03Z
UgyYhtoGWa0ZJQg6lVJ4AaABAg,@MrRfvideos,,1,3PyJA9AfwSk,2,2,2018-10-04T08:14:57Z,"I would suggest to use a dark background, something like a dark theme. The complete white background is too much for the eyes and causes headache if you watch 10 of the videos in a row!<br>Thanks for the great videos.",2018-10-04T08:14:57Z
UgyYhtoGWa0ZJQg6lVJ4AaABAg.8lyliSkih1A8sW66xPc3Sy,@PRATIK1900,UgyYhtoGWa0ZJQg6lVJ4AaABAg,2,3PyJA9AfwSk,0,0,2019-03-15T19:24:28Z,i dont know if its the same for others but I find that watching bright stuff is harder on the eyes if the room you are in is dark. Maybe watch in a well-lit room? might be less stressful for your eyes,2019-03-15T19:24:28Z
UgyYhtoGWa0ZJQg6lVJ4AaABAg.8lyliSkih1A8u6HpI7F5Bv,@NikhilAngadBakshi,UgyYhtoGWa0ZJQg6lVJ4AaABAg,2,3PyJA9AfwSk,0,0,2019-04-24T11:49:19Z,@@PRATIK1900 Or reduce the brightness of your screen :p,2019-04-24T11:49:19Z
Ugw8BAs3VPP7-amC0uh4AaABAg,@sau002,,1,3PyJA9AfwSk,4,2,2018-09-08T18:30:17Z,Beautifully explained. Thank you for this video.  I understand the intuition behind a convolutional filter (or kernel) . e.g. It could be performing edge detection. What is the intuition behind applying 2 consecutive layers of Convolution filters? i.e. the output of first convolution filter going into the second convolution filter.,2018-09-08T18:30:17Z
Ugw8BAs3VPP7-amC0uh4AaABAg.8kwvTXcP3oR8ly2STy9BRQ,@edubezerra35,Ugw8BAs3VPP7-amC0uh4AaABAg,2,3PyJA9AfwSk,0,5,2018-10-04T01:30:41Z,"In a face recognition setting, for example, the first filter could detect edges (as you said), while the next filter could detect more complex forms resulting from composing two or more edges (e.g., a nose, an mouth, an eye, etc). Then another filter could detect entire faces based on the activations produced by the previous filter.",2018-10-04T01:30:41Z
Ugw8BAs3VPP7-amC0uh4AaABAg.8kwvTXcP3oR8o6Xoji4VxM,@dhruvb2689,Ugw8BAs3VPP7-amC0uh4AaABAg,2,3PyJA9AfwSk,0,1,2018-11-26T11:00:41Z,"+Eduardo Bezerra a question of mine is: we would like to believe that cnns work this way, ie with each layer a more complicated feature is detected. However, when training an actual network, we are starting with randomized parameters and optimizing over them. How do we know that we will always end up with a network in which the 1st layer detects edges etc ?",2018-11-26T11:00:41Z
Ugw8BAs3VPP7-amC0uh4AaABAg.8kwvTXcP3oR8odGnrGGocs,@edubezerra35,Ugw8BAs3VPP7-amC0uh4AaABAg,2,3PyJA9AfwSk,0,0,2018-12-09T13:26:12Z,"@@dhruvb2689 Although we sort of managed to emulated this behaviour present in biological brains on our artificial neural nets, we still do not know how this happens. See <a href=""https://youtu.be/AyzOUbkUf3M"">https://youtu.be/AyzOUbkUf3M</a> for more details. This presentation is 10 years old, but I dont think the situation changed much.",2018-12-09T13:26:12Z
Ugw8BAs3VPP7-amC0uh4AaABAg.8kwvTXcP3oR9HTxq3DnfpI,@yashwanths2622,Ugw8BAs3VPP7-amC0uh4AaABAg,2,3PyJA9AfwSk,0,0,2020-12-20T05:01:09Z,"@@dhruvb2689 We don&#39;t, which is why have to tune the hyperparameters :).",2020-12-20T05:01:09Z
Ugw2yF3m4QF_H5Z7e154AaABAg,@FasstEddie,,1,8oOgPUO-TBY,0,0,2023-02-13T02:04:35Z,is it just me or does the matrix glitch multiple times in this video?,2023-02-13T02:04:35Z
Ugy3bIi2N0KF1zhkr394AaABAg,@arkanandi8806,,1,8oOgPUO-TBY,0,0,2022-12-07T11:13:46Z,Pooling layers incorporates to a certain extent spatial invariance. It would be really great if you can just describe why and how!,2022-12-07T11:13:46Z
UgzF-VhkDctyobGEiWl4AaABAg,@juanandreslopezcubides5626,,1,8oOgPUO-TBY,0,0,2022-09-12T01:40:12Z,"If I have a dimension of 11x11 and a maxpool2d of 3, according to the formula it would be 9, but in Keras it says 3, why?",2022-09-12T01:42:52Z
UgyR6cABWORTIXk5kP94AaABAg,@inquisitiverakib5844,,1,8oOgPUO-TBY,0,1,2022-07-13T06:00:40Z,awesome content. I&#39;ve a question if in the pooling layer no learning occurs then what is the need to do pooling,2022-07-13T06:00:40Z
Ugy7aENAWAHs7FbRxIF4AaABAg,@user-ke3jc4tr7u,,1,8oOgPUO-TBY,0,0,2022-05-09T13:51:29Z,ÍµêÏàòÎãò. Ïª®Î≥ºÎ£®ÏÖò Î†àÏù¥Ïñ¥ ÌõÑÏóê Í∞íÏùÑ ÏùºÏûêÎ°ú Ïû¨Î∞∞Ïó¥ÌõÑÏóê fc layerÎ°ú ÎÑ£ÎäîÍ±¥ ÏïåÍ≤†ÏäµÎãàÎã§. Í∑∏ÌõÑ Î™áÍ∞úÏùò Ï∏µÏùÑÍ±∞Ï≥ê Í∞úÏàòÎ•º Ï¢ÄÎçî Ï§ÑÏù∏ÌõÑÏóê softmaxÌïòÏó¨ classifyÌïòÎäîÍ≤ÉÎèÑ ÏïåÍ≤†ÏäµÎãàÎã§. Í∑∏ÌõÑ Ïó≠Ï†ÑÌååÎäî Ïñ¥ÎñªÍ≤å ÌïòÎäîÍ±¥ÏßÄÏöî? softmaxÌïòÏó¨ ÎÇòÏò® Í∞íÎ∂ÄÌÑ∞ Ïñ¥Îñ§ Í∏∞Ï§ÄÏùÑ Í∞ÄÏßÄÍ≥† Ïó≠Ï†ÑÌååÎ•º ÏãúÏûëÌïòÏó¨ fc layerÎ•º Í±∞Ï≥ê Ïñ¥Îñ§ÏãùÏúºÎ°ú convolution layerÏùò ÌïÑÌÑ∞Ïóê Í∞ÄÏ§ëÏπòÎ•º Ï†ÅÏö©ÌïòÎäîÏßÄ Í∑∏ Í≥ºÏ†ïÏù¥ ÏÉùÎûµÎêòÏñ¥ÏûàÏñ¥ Ïù¥Ìï¥Í∞Ä Ïñ¥Î†µÏäµÎãàÎã§.,2022-05-09T13:51:29Z
UgwQXmUntWSUKHDoZIB4AaABAg,@ervinperetz5973,,1,8oOgPUO-TBY,0,0,2022-03-23T02:05:25Z,"Why do the number of channels double in AlexNet and VGG-19 ?  Supposedly it&#39;s because overlapped pooling is used.  But it&#39;s not clear how the extra channels are formulated.   (e.g.  for 2x2 overlapped pooling, presumably with stride 1 in both directions, width and height are halved (unlike in your overlapped pooling example), and <a href=""http://www.youtube.com/results?search_query=%23channels"">#channels</a> doubles; that doesn&#39;t add up wrt the number of pooling operations).",2022-03-23T02:05:25Z
UgwDtXwql8Bn2dSN6xh4AaABAg,@VPrashanthedb,,1,8oOgPUO-TBY,0,1,2021-09-22T08:29:07Z,em chepparu sirüëåüëå,2021-09-22T08:29:07Z
UgystNsCRWZX69XKFsN4AaABAg,@harrybyrne7124,,1,8oOgPUO-TBY,0,0,2021-09-06T22:27:25Z,"I understand why you&#39;d want to use pooling to reduce the size of your data, but why would you use this instead of an auto encoder?",2021-09-06T22:27:25Z
UgzSxQryZqUrbFxzDzl4AaABAg,@jimmiemunyi,,1,8oOgPUO-TBY,0,2,2021-05-08T08:55:30Z,4 years later. Thank youuuuuuuu,2021-05-08T08:55:30Z
UgyT27qpr1JHYYnb7U54AaABAg,@davidtorres5012,,1,8oOgPUO-TBY,0,0,2021-04-28T15:21:16Z,Thanks a lot !,2021-04-28T15:21:16Z
UgyFn5gwHORGjea_fjN4AaABAg,@sandipansarkar9211,,1,8oOgPUO-TBY,0,0,2021-01-26T18:05:08Z,nice explanation,2021-01-26T18:05:08Z
Ugymy00yTTDuN43fqkp4AaABAg,@danielregassa9805,,1,8oOgPUO-TBY,2,39,2020-08-21T00:52:29Z,"For anyone wondering why average pooling isn&#39;t used often, it&#39;s because its functionality can be easily replicated by a filter with all elements = 1/n where n is the number of elements in the filter",2020-08-21T00:52:29Z
Ugymy00yTTDuN43fqkp4AaABAg.9CaxBs-zYck9QBcldTpfoC,@ekayesorko,Ugymy00yTTDuN43fqkp4AaABAg,2,8oOgPUO-TBY,0,0,2021-07-24T18:53:16Z,thanks man.,2021-07-24T18:53:16Z
Ugymy00yTTDuN43fqkp4AaABAg.9CaxBs-zYck9YzRvz4Vyci,@WahranRai,Ugymy00yTTDuN43fqkp4AaABAg,2,8oOgPUO-TBY,0,0,2022-02-28T08:42:15Z,But backpropagation is in favor of pooling (no backpropagation),2022-02-28T08:42:15Z
UgzV9PqewRBosZh1fHB4AaABAg,@Vinoth89Karur,,1,8oOgPUO-TBY,0,1,2020-05-19T11:01:48Z,Awesome sir..  Thank you so much..,2020-05-19T11:01:48Z
Ugz_qa-eK4AXxzUc6Jd4AaABAg,@MrQwerty2524,,1,8oOgPUO-TBY,0,0,2019-07-09T09:57:45Z,"So, does this formula mean that we substract 0.5 when dealing with decimals?",2019-07-09T09:57:45Z
UgwZQDUPMBW9DvmmJ7t4AaABAg,@adityaachmad2265,,1,8oOgPUO-TBY,1,2,2019-04-16T02:38:42Z,anyone know about backward pooling ?,2019-04-16T02:38:42Z
UgwZQDUPMBW9DvmmJ7t4AaABAg.8tlhSMmaotq9PUrI-GCAk7,@codingtheworld6747,UgwZQDUPMBW9DvmmJ7t4AaABAg,2,8oOgPUO-TBY,0,0,2021-07-07T09:34:20Z,"<a href=""https://www.youtube.com/watch?v=XE3krf3CQls&amp;list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&amp;index=26"">https://www.youtube.com/watch?v=XE3krf3CQls&amp;list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&amp;index=26</a> <br><br>After 2 Years :), but maybe someone also wants to look.",2021-07-07T09:34:20Z
UgwOF40aroKdwAegVex4AaABAg,@sjl4554,,1,8oOgPUO-TBY,5,3,2019-02-05T04:57:04Z,underlining reason of max pooling??,2019-02-05T04:57:04Z
UgwOF40aroKdwAegVex4AaABAg.8qxhdaSRudw8rc1UujL4nN,@chaitanyag6297,UgwOF40aroKdwAegVex4AaABAg,2,8oOgPUO-TBY,0,20,2019-02-21T15:27:21Z,"Max pooling, which is a form of down-sampling is used to identify the most important features. <br><br><br>Means we are just taking the prominent edge/feature n that part , after conv layer edges will have a high positive number , so when you take the highest value in a part , you are looking at the edge/feature which is dominating others and more distinguishing , this has the advantage of downsizing our data for the dense layer to have less connections while taking the important features(leaving the less dominant features behind)",2019-02-21T15:27:21Z
UgwOF40aroKdwAegVex4AaABAg.8qxhdaSRudw97hknKF4s6H,@abishekseshan1757,UgwOF40aroKdwAegVex4AaABAg,2,8oOgPUO-TBY,0,4,2020-04-21T09:41:51Z,Chaitanya G<br>But what is the guarantee that the pixel with highest value is most important? How can we determine that?,2020-04-21T09:41:51Z
UgwOF40aroKdwAegVex4AaABAg.8qxhdaSRudw97ncy-RrOS7,@oscarw1976,UgwOF40aroKdwAegVex4AaABAg,2,8oOgPUO-TBY,0,3,2020-04-23T16:28:51Z,"@@abishekseshan1757 max pooling isn&#39;t necessarily applied to pixels, it can be applied to a layer of neuron outputs",2020-04-23T16:28:51Z
UgwOF40aroKdwAegVex4AaABAg.8qxhdaSRudw98pO2LadTe0,@rohitborra2507,UgwOF40aroKdwAegVex4AaABAg,2,8oOgPUO-TBY,0,1,2020-05-19T05:19:39Z,@@chaitanyag6297 thanks bro,2020-05-19T05:19:39Z
UgwOF40aroKdwAegVex4AaABAg.8qxhdaSRudw9DnQSL2oCoQ,@snippletrap,UgwOF40aroKdwAegVex4AaABAg,2,8oOgPUO-TBY,0,2,2020-09-19T17:39:09Z,@@abishekseshan1757 there is no guarantee but it works well in practice,2020-09-19T17:39:09Z
Ugy8uxVeBxbIlAe-bDd4AaABAg,@fatimahmath4819,,1,8oOgPUO-TBY,0,0,2019-01-31T16:05:27Z,thank u very much sir,2019-01-31T16:05:27Z
Ugz2bkFxXpVNVFX8g6F4AaABAg,@farimankashani8627,,1,8oOgPUO-TBY,0,1,2018-12-07T12:05:09Z,Thanks! so useful.,2018-12-07T12:05:09Z
Ugx7r97hhMn5LQk5pn94AaABAg,@anandinamdar4054,,1,8oOgPUO-TBY,3,0,2018-10-05T07:11:10Z,is maxpooling differentiable?,2018-10-05T07:11:10Z
Ugx7r97hhMn5LQk5pn94AaABAg.8m0EDC7IYcN8oTD9fDE0KO,@timharris72,Ugx7r97hhMn5LQk5pn94AaABAg,2,8oOgPUO-TBY,0,3,2018-12-05T06:22:43Z,No there aren&#39;t any learnable parameters,2018-12-05T06:22:43Z
Ugx7r97hhMn5LQk5pn94AaABAg.8m0EDC7IYcN8sJeK7Qlx5R,@NisseOhlsen,Ugx7r97hhMn5LQk5pn94AaABAg,2,8oOgPUO-TBY,0,0,2019-03-10T23:21:59Z,"yes, it is differentiable, but unless you made the size of the pooling window a parameter you wouldn&#39;t get anything out of differentiating.<br><br>Example: <br><br>If you have a 3 by 3 filter you have n = 9 parameters in your filter.<br><br>so the max pooling operation would for once instance of a stride be f(x) = Sum(x)/n, where Sum(x) means the sum of all n elements. <br><br>Differentiating with respect to x would give you Sum(1/n), which doesn&#39;t help you since x is not our parameter and this is not what we are trying to train.<br><br>Differentiating with respect to n, allowing n to be trainable, would give you -n^-2.  <br><br>So IF we allow the pooling filter size to be trainable, the YES, max pooling is both differentiable AND usefully so.<br><br>However, this is seemingly not used (although I&#39;m not sure why).",2019-03-10T23:21:59Z
Ugx7r97hhMn5LQk5pn94AaABAg.8m0EDC7IYcN99cguKvAm0F,@shubhamchandra9258,Ugx7r97hhMn5LQk5pn94AaABAg,2,8oOgPUO-TBY,0,0,2020-06-08T03:34:26Z,The entire neural network as a whole is differentiable. That can&#39;t happen if the pooling layer wasn&#39;t differentiable. Differentiable means for every small change in input there is a small change in output and not abrupt change.,2020-06-08T03:34:26Z
UgwedbV4go6v2AUCOeB4AaABAg,@rajkkapadia,,1,8oOgPUO-TBY,0,12,2018-09-29T18:10:20Z,Amazing explanation sir.,2018-09-29T18:10:20Z
UgyZ58hnhuPtV2re24l4AaABAg,@safi2297,,1,8oOgPUO-TBY,0,5,2018-08-09T14:42:13Z,it&#39;s really useful and easy to understand thanks for the video. keep it up the good work.,2018-08-09T14:42:13Z
Ugz4KNCnIyqujWEA4FV4AaABAg,@mikiyaszelalem3872,,1,bXJx7y51cl0,0,0,2023-12-05T15:27:15Z,"I dont understand how the parameters came to be 208, .... in the conv layer",2023-12-05T15:27:15Z
UgwXhphrCQ4wsVvviMJ4AaABAg,@ECB-SanjayReddy,,1,bXJx7y51cl0,0,0,2023-08-20T18:00:23Z,the 120 and 84 we took in FC3 AND FC4 is it our choice like we can choose any? and also the softmax value can we choose anything other than 10?,2023-08-20T18:00:23Z
UgwbKwP0mWK_-97JnJB4AaABAg,@objecttracking31,,1,bXJx7y51cl0,0,0,2023-02-06T08:19:37Z,"Below is the Keras implementation of AlexNet, please anybody can solve how they get Dense (4096) in th FC layer 2. The code is given as follow.<br><br><br>model = tf.keras.models.Sequential([<br>    # 1st conv<br>  tf.keras.layers.Conv2D(96, (11,11),strides=(4,4), activation=&#39;relu&#39;, input_shape=(227, 227, 3)),<br>  tf.keras.layers.BatchNormalization(),<br>  tf.keras.layers.MaxPooling2D(2, strides=(2,2)),<br>    # 2nd conv<br>  tf.keras.layers.Conv2D(256, (11,11),strides=(1,1), activation=&#39;relu&#39;,padding=&quot;same&quot;),<br>  tf.keras.layers.BatchNormalization(),<br>     # 3rd conv<br>  tf.keras.layers.Conv2D(384, (3,3),strides=(1,1), activation=&#39;relu&#39;,padding=&quot;same&quot;),<br>  tf.keras.layers.BatchNormalization(),<br>    # 4th conv<br>  tf.keras.layers.Conv2D(384, (3,3),strides=(1,1), activation=&#39;relu&#39;,padding=&quot;same&quot;),<br>  tf.keras.layers.BatchNormalization(),<br>    # 5th Conv<br>  tf.keras.layers.Conv2D(256, (3, 3), strides=(1, 1), activation=&#39;relu&#39;,padding=&quot;same&quot;),<br>  tf.keras.layers.BatchNormalization(),<br>  tf.keras.layers.MaxPooling2D(2, strides=(2, 2)),<br>  # To Flatten layer<br>  tf.keras.layers.Flatten(),<br>  # To FC layer 1<br>  tf.keras.layers.Dense(4096, activation=&#39;relu&#39;),<br>    # add dropout 0.5 ==&gt; tf.keras.layers.Dropout(0.5),<br>  <a href=""http://www.youtube.com/results?search_query=%23to"">#To</a> FC layer 2<br>  tf.keras.layers.Dense(4096, activation=&#39;relu&#39;),<br>    # add dropout 0.5 ==&gt; tf.keras.layers.Dropout(0.5),<br>  tf.keras.layers.Dense(output_class_units, activation=&#39;softmax&#39;)<br>])",2023-02-06T08:19:37Z
UgwsYQvwpiOFigwZ2ip4AaABAg,@chamanthipyneni7827,,1,bXJx7y51cl0,0,0,2022-12-25T05:58:43Z,How many layers does a cnn need to have for 4 class labels?,2022-12-25T05:58:43Z
UgyauNQKNrKfsXfrbTl4AaABAg,@saritrath6655,,1,bXJx7y51cl0,7,38,2022-07-28T18:27:06Z,"The CORRECT calculation of the no. of parameters  per layer is given as:<br>1.  Conv1 layer:  We have 6 filters of size (5*5*3)  [6 filters as per the example by Andrew earlier and not as per the table] . For each filter convolution operation with the image input  we will have a bias, so 6 biases. <br>Total params:  (5*5*3 + 1) * 6 = 456<br><br>2.  Conv2 layer:  We have 16 filters of size (5*5*6)  . For each filter convolution operation with the image input  we will have a bias, so 16 biases. <br>Total params:  (5*5*6 + 1) * 16 = 2416<br><br>3.  FC3 layer:  We have 400 inputs and 120 neurons . Each neuron will be associated with 1 bias of its own. <br>Total params:  400*120 + 120 = 48120.<br><br>4.  FC4 layer:  For this layer we have 120 inputs [from FC3] and 84 neurons of FC4 layer itself. Each neuron will be associated with 1 bias of its own. <br>Total params:  120*84 +84 = 10164<br><br>5.  The sigmoid /Output layer:  For this layer we have 84 inputs [from FC4] and 10 neurons of the output layer itself. Each neuron will be associated with 1 bias of its own. <br>Total params: 84*10 + 10 =850.<br><br>Total no. of parameters  = 456 + 2416 + 48120 + 10164 + 850 = 62006. <br><br>Hope it helped  ;-)",2022-07-28T18:27:06Z
UgyauNQKNrKfsXfrbTl4AaABAg.9e1j5oH9QFd9gPNL9GhSDm,@SOFTWAREMASTER,UgyauNQKNrKfsXfrbTl4AaABAg,2,bXJx7y51cl0,0,0,2022-09-25T15:52:47Z,It really did help. Thanks man,2022-09-25T15:52:47Z
UgyauNQKNrKfsXfrbTl4AaABAg.9e1j5oH9QFd9hyKRMv6pNG,@gajendrasingh8467,UgyauNQKNrKfsXfrbTl4AaABAg,2,bXJx7y51cl0,0,0,2022-11-03T11:31:28Z,thanks,2022-11-03T11:31:28Z
UgyauNQKNrKfsXfrbTl4AaABAg.9e1j5oH9QFd9kDhpbpCRvX,@SanjeetKumar-ef6fj,UgyauNQKNrKfsXfrbTl4AaABAg,2,bXJx7y51cl0,0,0,2022-12-29T13:15:16Z,"Shouldn&#39;t in first layer, parameters be calculated as (5*5+1)*6*3=468?",2022-12-29T13:15:16Z
UgyauNQKNrKfsXfrbTl4AaABAg.9e1j5oH9QFd9lmb0e1WzDH,@objecttracking31,UgyauNQKNrKfsXfrbTl4AaABAg,2,bXJx7y51cl0,0,0,2023-02-06T08:19:47Z,"Below is the Keras implementation of AlexNet, please anybody can solve how they get Dense (4096) in th FC layer 2. The code is given as follow.<br><br><br>model = tf.keras.models.Sequential([<br>    # 1st conv<br>  tf.keras.layers.Conv2D(96, (11,11),strides=(4,4), activation=&#39;relu&#39;, input_shape=(227, 227, 3)),<br>  tf.keras.layers.BatchNormalization(),<br>  tf.keras.layers.MaxPooling2D(2, strides=(2,2)),<br>    # 2nd conv<br>  tf.keras.layers.Conv2D(256, (11,11),strides=(1,1), activation=&#39;relu&#39;,padding=&quot;same&quot;),<br>  tf.keras.layers.BatchNormalization(),<br>     # 3rd conv<br>  tf.keras.layers.Conv2D(384, (3,3),strides=(1,1), activation=&#39;relu&#39;,padding=&quot;same&quot;),<br>  tf.keras.layers.BatchNormalization(),<br>    # 4th conv<br>  tf.keras.layers.Conv2D(384, (3,3),strides=(1,1), activation=&#39;relu&#39;,padding=&quot;same&quot;),<br>  tf.keras.layers.BatchNormalization(),<br>    # 5th Conv<br>  tf.keras.layers.Conv2D(256, (3, 3), strides=(1, 1), activation=&#39;relu&#39;,padding=&quot;same&quot;),<br>  tf.keras.layers.BatchNormalization(),<br>  tf.keras.layers.MaxPooling2D(2, strides=(2, 2)),<br>  # To Flatten layer<br>  tf.keras.layers.Flatten(),<br>  # To FC layer 1<br>  tf.keras.layers.Dense(4096, activation=&#39;relu&#39;),<br>    # add dropout 0.5 ==&gt; tf.keras.layers.Dropout(0.5),<br>  <a href=""http://www.youtube.com/results?search_query=%23to"">#To</a> FC layer 2<br>  tf.keras.layers.Dense(4096, activation=&#39;relu&#39;),<br>    # add dropout 0.5 ==&gt; tf.keras.layers.Dropout(0.5),<br>  tf.keras.layers.Dense(output_class_units, activation=&#39;softmax&#39;)<br>])",2023-02-06T08:19:47Z
UgyauNQKNrKfsXfrbTl4AaABAg.9e1j5oH9QFd9n71Gmk_DLW,@MrAmgadHasan,UgyauNQKNrKfsXfrbTl4AaABAg,2,bXJx7y51cl0,0,2,2023-03-11T12:33:22Z,"@@SanjeetKumar-ef6fj  I don&#39;t think so. Each filter has only one bias associated with it. Notice that the filter has the same depth as its input. So if an input is 3 channels, each filter will have 3 channels and it will have only one bias.",2023-03-11T12:33:22Z
Ugw-e2D3bhyTjr0C1ix4AaABAg,@viditsharma3929,,1,bXJx7y51cl0,0,0,2022-05-26T16:31:46Z,I think the parameters are all wrong. i mean their count as per your teachings,2022-05-26T16:32:09Z
UgylkIWqOZWYNpBkdrt4AaABAg,@vivekv6764,,1,bXJx7y51cl0,0,0,2022-05-22T01:35:41Z,"For anyone coming to this video as of 21 May 2022, the numbers in the figure &amp; the table (at the end) don&#39;t match. The correct calculations are in the comment posted by Turzo Bose.",2022-05-22T01:36:12Z
Ugy9_DhW-CrfAWvbSwV4AaABAg,@dylanyves6331,,1,bXJx7y51cl0,0,0,2022-02-28T16:29:20Z,I don&#39;t understand why he said as the layer goes deeper the channels increase. Shouldn&#39;t the channels always have the same value?,2022-02-28T16:29:20Z
UgwVQ6Dr4Da9CZI0hx54AaABAg,@mohammadserdar5351,,1,bXJx7y51cl0,0,1,2022-01-29T18:15:39Z,wrong wrong wrong !!!,2022-01-29T18:15:39Z
Ugya3U6vi8HXv769G-14AaABAg,@afrinsultana5972,,1,bXJx7y51cl0,0,0,2022-01-26T12:18:13Z,I have shortage of words to admire you. Thank you sir.,2022-01-26T12:18:13Z
UgwpxI5OQlWef4RvvJ14AaABAg,@thuandiec5756,,1,bXJx7y51cl0,0,0,2021-11-20T10:21:14Z,I dont know which is 120?,2021-11-20T10:21:14Z
UgwZ-sbIhxnAlO2jAFd4AaABAg,@turzobose40,,1,bXJx7y51cl0,2,13,2021-04-28T13:51:16Z,"Here are the 5 typos: (Note: the first CONV layer in the table on the last slide has 8 filters, not 6 filters as drawn by Andrew in the second last slide)<br><br>1. 208 should be (5*5*3 + 1) * 8 = 608<br><br>2. 416 should be (5*5*8 + 1) * 16 = 3216<br><br>3. There should be 1 bias parameter for every neuron for the fully-connected layers. Hence, FC3 will have 120 bias params for 120 neurons and FC4 should have 84 bias params for 84 neurons.<br><br>So, FC3 =&gt; 400 * 120 + 120 = 48120<br>&amp;, FC4 =&gt; 120 * 84 + 84 = 10164<br><br>4. FInally the softmax layer should be 84*10 + 10(for bias 1param/neuron) = 850",2021-04-28T14:04:42Z
UgwZ-sbIhxnAlO2jAFd4AaABAg.9Mg42bk6iX-9W_3unC7x7A,@FritzKissa,UgwZ-sbIhxnAlO2jAFd4AaABAg,2,bXJx7y51cl0,0,1,2021-12-30T09:49:20Z,"One could argue that Softmax doesn&#39;t have any learnable parameters, and there&#39;s FC5 layer missing where the parameter count would be 850.",2021-12-30T09:49:20Z
UgwZ-sbIhxnAlO2jAFd4AaABAg.9Mg42bk6iX-9bJPKGy-7KL,@vivekv6764,UgwZ-sbIhxnAlO2jAFd4AaABAg,2,bXJx7y51cl0,0,0,2022-05-22T01:37:43Z,"For anyone reading the comments, this comment here (by Turzo Bose) has the 100% correct calculations. The basic problem is that the figure he draws &amp; the table (at the end) don&#39;t match. So, ust follow the table at the end and you&#39;ll get the correct calculations.",2022-05-22T01:38:49Z
UgxtoGyt5iXKRsAwd4l4AaABAg,@saramessara4241,,1,bXJx7y51cl0,0,0,2021-03-30T08:52:08Z,why is softmax used only in the output layer?,2021-03-30T08:52:08Z
UgzBOEfEzU1ALRAZREB4AaABAg,@billykotsos4642,,1,bXJx7y51cl0,0,2,2021-03-12T17:28:27Z,"The Myth, the Legend",2021-03-12T17:28:27Z
UgyzKPAu4xrClMsNr9d4AaABAg,@manuel783,,1,bXJx7y51cl0,1,19,2021-01-18T23:29:09Z,"CNN Example <b>CORRECTION</b><br><br>Starting from <a href=""https://www.youtube.com/watch?v=bXJx7y51cl0&amp;t=9m45s"">9:45</a>, please note that the calculation of the number of parameters is incorrect.<br><br>Here are the 5 typos:<br><br>1. 208 should be (5*5*3 + 1) * 8 = 608<br><br>2. 416 should be (5*5*8 + 1) * 16 = 3216<br><br>3. In the FC3, 48001 should be 400*120 + 120 = 48120, since the bias should have 120 parameters, not 1<br><br>4. Similarly, in the FC4, 10081 should be 120*84 + 84 (not 1) = 10164<br><br>(Here, the bias is for the fully connected layer.  In fully connected layers, there will be one bias for each neuron, so the bias become In FC3 there were 120 neurons so 120 biases.)<br><br>5. Finally, in the softmax, 841 should be 84*10 + 10 = 850",2021-01-18T23:29:09Z
UgyzKPAu4xrClMsNr9d4AaABAg.9IfbgcQjVSy9VtwnuenbDi,@zachshaffer44,UgyzKPAu4xrClMsNr9d4AaABAg,2,bXJx7y51cl0,0,0,2021-12-13T15:51:08Z,"These are wrong too, the correct calculations are in a comment below",2021-12-13T15:51:08Z
UgzUHuendT3KkGE6RCh4AaABAg,@siddhantpathak3162,,1,bXJx7y51cl0,0,0,2020-10-04T06:40:39Z,"Awesome video, but a hell lot of mistakes in the table",2020-10-04T06:40:39Z
UgyTqzmkYHw4uFXQl0x4AaABAg,@debarunkumer2019,,1,bXJx7y51cl0,1,0,2020-09-26T14:28:42Z,"In the table shown at the last part of the video. The parameter is calculated om multiplying the preceding and present activation size and adding one to the product. That is what I have inferred from the table. What is the significance of adding one to the product ?<br>For instance, considering input FC3, the parameter size is determined by taking the product of (120*400)+1 = 48001. Why 1 is being added to the result?",2020-09-26T14:28:42Z
UgyTqzmkYHw4uFXQl0x4AaABAg.9E46DW6b_B59MgaRrqPVnZ,@gowthamarun43,UgyTqzmkYHw4uFXQl0x4AaABAg,2,bXJx7y51cl0,0,0,2021-04-28T18:43:05Z,"it is wrong it should be 48120, 120*400 + 120. the 120 which is added is the bias for 120 hidden units",2021-04-28T18:43:05Z
UgyFVFcQI1LYyu-vPqZ4AaABAg,@elgs1980,,1,bXJx7y51cl0,0,0,2020-09-14T08:43:12Z,Are the layer of 120 and layer of 84 hidden layers?,2020-09-14T08:43:12Z
UgyFBZ4AdaKsD1R5GnR4AaABAg,@elgs1980,,1,bXJx7y51cl0,1,0,2020-09-14T08:36:05Z,What filters are the 6 filters? I mean what numbers should be filled in the filters?,2020-12-14T17:58:16Z
UgyFBZ4AdaKsD1R5GnR4AaABAg.9D__KOJp4ue9HFs09MUq13,@ThePaypay88,UgyFBZ4AdaKsD1R5GnR4AaABAg,2,bXJx7y51cl0,0,0,2020-12-14T17:40:52Z,"its number of features you would want to learn. It&#39;s trial &amp; error number . Before deep learning they were doing manually image procesing filters so you would put what you want ( aka if you want to detect horizontal edge you would add one filter for that , for vertical add one more , for blurriines add one etc.) 6 hopes it finds 6 features like this.",2020-12-14T17:40:52Z
Ugz4SNvk4wual7CqZ154AaABAg,@aymannaeem22,,1,bXJx7y51cl0,10,48,2020-08-28T22:15:31Z,"Getting the # parameters If we applied it on the NN example (LeNet-5)<br>For Conv 1: where f=5, # of filters=6 not 8 , # previous channels = 3<br>Rule : (f * f * # previous channels + bias ) *# of filters<br>= (5*5 *3 +1) * 6 = 456<br><br>For Conv 2: where f=5, # of filters =16 , # previous channels = 6<br>Rule : (f * f * # previous channels + bias ) * # of filters<br>= (5*5 *6 +1)  * 16 = 2416",2020-09-03T01:18:30Z
Ugz4SNvk4wual7CqZ154AaABAg.9CvGa9ruAAY9GTsWfcA-WK,@zql7351,Ugz4SNvk4wual7CqZ154AaABAg,2,bXJx7y51cl0,0,1,2020-11-25T07:43:17Z,"You are right. It is actually what happens in Keras for 3-channel images. Plus, the number of parameters for FC3, FC4, and softmax are 48120, 10164, and 850 resp.",2020-11-25T07:47:05Z
Ugz4SNvk4wual7CqZ154AaABAg.9CvGa9ruAAY9Gg2oDPKWo1,@aninditadas832,Ugz4SNvk4wual7CqZ154AaABAg,2,bXJx7y51cl0,0,1,2020-11-30T10:32:04Z,thank you so much for this correction else I was under the assumption that everything I have followed until now is wrong :D,2020-11-30T10:32:04Z
Ugz4SNvk4wual7CqZ154AaABAg.9CvGa9ruAAY9GovdjoIb_l,@felixpotter6420,Ugz4SNvk4wual7CqZ154AaABAg,2,bXJx7y51cl0,0,1,2020-12-03T21:13:54Z,"cheers fam, i was having a bit of a mental breakdown but uve alleviated my mind.",2020-12-03T21:13:54Z
Ugz4SNvk4wual7CqZ154AaABAg.9CvGa9ruAAY9HVEhtFAu_X,@krranaware8396,Ugz4SNvk4wual7CqZ154AaABAg,2,bXJx7y51cl0,0,0,2020-12-20T16:56:34Z,Is it like input image is 32*32*1 and not 32*32*3?,2020-12-20T16:56:34Z
Ugz4SNvk4wual7CqZ154AaABAg.9CvGa9ruAAY9HjgplH_mbW,@govindashrestha190,Ugz4SNvk4wual7CqZ154AaABAg,2,bXJx7y51cl0,0,1,2020-12-26T16:59:39Z,You are right. Parameters in videos are wrong.,2020-12-26T16:59:39Z
UgyCY7PV1JgWxCimIUd4AaABAg,@abhishekshankar1136,,1,bXJx7y51cl0,0,1,2020-06-25T17:48:45Z,"<a href=""https://www.youtube.com/watch?v=bXJx7y51cl0&amp;t=9m50s"">9:50</a> correction -  no of parameters in CONV1 and CONV2  is (5x5x3+1)x8 = 608  &amp; (5x5x8+1)x16=3216  respectively<br>                               FC3  is  120(480+1)=57720  &amp;  FC4 is  84*(120+1)=10164",2020-06-25T17:51:25Z
UgyI5r3qsGai-N1pbwF4AaABAg,@NguyenNhan-yg4cb,,1,bXJx7y51cl0,6,0,2020-05-16T03:12:06Z,"please anyone, why 5 in the first convolution layer ( why 32-5+1 = 28). &#39;5&#39;  from where ??? please help me",2020-05-16T03:12:06Z
UgyI5r3qsGai-N1pbwF4AaABAg.98hR3Zyoyki98ki3Pe7yT8,@tejasvigupta07,UgyI5r3qsGai-N1pbwF4AaABAg,2,bXJx7y51cl0,0,0,2020-05-17T09:47:05Z,"its the formula  (n-l+1) n=32, l=5",2020-05-17T09:47:05Z
UgyI5r3qsGai-N1pbwF4AaABAg.98hR3Zyoyki98kwPoMdEbE,@NguyenNhan-yg4cb,UgyI5r3qsGai-N1pbwF4AaABAg,2,bXJx7y51cl0,0,0,2020-05-17T11:52:29Z,"@@tejasvigupta07 bro 32 is the input image 32x32, and what about 5 ?",2020-05-17T11:52:29Z
UgyI5r3qsGai-N1pbwF4AaABAg.98hR3Zyoyki98l3_RK-hHm,@tejasvigupta07,UgyI5r3qsGai-N1pbwF4AaABAg,2,bXJx7y51cl0,0,0,2020-05-17T13:03:50Z,5 comes from the size of filter. Here it is a 5x5 filter or f=l=5.,2020-05-17T13:03:50Z
UgyI5r3qsGai-N1pbwF4AaABAg.98hR3Zyoyki98l44l74HfY,@NguyenNhan-yg4cb,UgyI5r3qsGai-N1pbwF4AaABAg,2,bXJx7y51cl0,0,0,2020-05-17T13:08:15Z,"@@tejasvigupta07 bro thanks so much, what about 120 and why 16@5x5 become 120 and 120 become 84. i can understand 10 maybe the label (0,1,2,3,4,5,6,7,8,9)",2020-05-17T13:08:15Z
UgyI5r3qsGai-N1pbwF4AaABAg.98hR3Zyoyki98l5anSkq5I,@tejasvigupta07,UgyI5r3qsGai-N1pbwF4AaABAg,2,bXJx7y51cl0,0,0,2020-05-17T13:21:30Z,When we make a layer we get to decide the number of units we want in a hidden layer. What I mean is that our hidden layer can have 5 units and I can connect it next to a layer with 10 units or even 2 units. When we make a layer in neural network it&#39;s up to to us to select the number of units in that.,2020-05-17T13:21:30Z
UgzyDONw8LJb6wFFUJl4AaABAg,@nagarajnagu7714,,1,bXJx7y51cl0,13,0,2020-05-09T09:20:24Z,Plzz any one How depth value changeing from 6 to 16,2020-05-09T09:20:24Z
UgzyDONw8LJb6wFFUJl4AaABAg.98R3dyLLGf-98R6_fZfyx0,@bharshavardhan2007,UgzyDONw8LJb6wFFUJl4AaABAg,2,bXJx7y51cl0,0,0,2020-05-09T09:46:02Z,"6 or 16 is the number of filters used. so for each layer its our wish to use number of filters which means, we can use different filters to get different types of features like vertical edges, horizontal edges.",2020-05-09T09:46:02Z
UgzyDONw8LJb6wFFUJl4AaABAg.98R3dyLLGf-98R6nQmkTrl,@bharshavardhan2007,UgzyDONw8LJb6wFFUJl4AaABAg,2,bXJx7y51cl0,0,0,2020-05-09T09:47:55Z,"watch again at 1.05 point of time, he mentioned he is using 6 filters",2020-05-09T09:47:55Z
UgzyDONw8LJb6wFFUJl4AaABAg.98R3dyLLGf-98R7-k3FVV_,@nagarajnagu7714,UgzyDONw8LJb6wFFUJl4AaABAg,2,bXJx7y51cl0,0,0,2020-05-09T09:49:44Z,Before that He using total 5filters right.. Wt is the use of using filters  again,2020-05-09T09:49:44Z
UgzyDONw8LJb6wFFUJl4AaABAg.98R3dyLLGf-98R7X6M8XYT,@nagarajnagu7714,UgzyDONw8LJb6wFFUJl4AaABAg,2,bXJx7y51cl0,0,0,2020-05-09T09:54:17Z,Getting  28 value by using  formula Right.. How  6 I am not getting.. In the  calculation  we  are  filter value 5 than  how  it&#39;s 6??,2020-05-09T09:54:17Z
UgzyDONw8LJb6wFFUJl4AaABAg.98R3dyLLGf-98R8HWo85QV,@bharshavardhan2007,UgzyDONw8LJb6wFFUJl4AaABAg,2,bXJx7y51cl0,0,0,2020-05-09T10:00:54Z,@@nagarajnagu7714 f = 5 means one filter size is 5 x 5. It doesn&#39;t mean 5 filters are used. in the video after 1.05 he says he is using 6 filters.,2020-05-09T10:00:54Z
UgxQ4riLYkmYvV290i54AaABAg,@subodhsharma3038,,1,bXJx7y51cl0,3,14,2020-05-08T12:54:54Z,"@Andrew sir, I think some  CORRECTION is needed in Neural network example, for calculation number of parameters in CONV and FC layer.<br>I hope below steps will help someone:<br><br><br>## Formula to calculate number of parameters in CONV and FC layer:<br>========================================================<br>Formula 1:<br>-----------------<br>Number of parameters in CONV layer = ((m*n*c)+1)*k<br>	where m = shape of width of the filter,<br>		n = shape of height of the filter,<br>		c = number of channels <br>		k = number of filters and<br>		add bias 1 for each filter<br>		<br>Formula 2:<br>-----------------<br>Number of parameters in FC layer = (Number of input +1) * Number of output <br>			  <br>##########################################################	  <br><br>Example-1: Using above Formula 1 in CONV1:<br>-------------------------------------------------------------------------<br>	Given: <br>		(f=5,s=1),<br>		number of channels = c = 3 [from (32,32,3)]and <br>		number of filters = k = 8  [from (28,28,8)]<br>		<br>	Here, filter shape = f= 5, means f = m*n = 5 * 5<br>		   <br>	Therefore, Number of parameters in CONV1 layer= ((m*n*c)+1)*k<br>													= ((5*5*3)+1)*8<br>													= ((75)+1)*8<br>													= (76)*8<br>													= 608<br>															<br>Example-2: Using above Formula 1 in CONV2:<br>-------------------------------------------------------------------------<br>	Given: <br>		(f=5,s=1),<br>		number of channels = c = 8 [from (14,14,8)]and <br>		number of filters = k = 16  [from (10,10,16)]<br>		<br>	Here, filter shape = f= 5, means f = m*n = 5 * 5<br>		   <br>	Therefore, Number of parameters in CONV2 layer= ((m*n*c)+1)*k<br>													= ((5*5*8)+1)*16<br>													= ((200)+1)*16<br>													= (201)*16<br>													= 3216<br>															<br>Example-3: Using above Formula 2 in FC3:<br>-------------------------------------------------------------------<br>	Given:<br>		Number of input = 400 and <br>		Number of ouput = 120  [from (120,1)]	<br>	<br>	Therefore, Number of parameters in FC3 layer = (Number of input + 1) * Number of output<br>											 = (400+1)*120<br>											 = (401)*120<br>											 = 48120<br><br>Example-4: Using above Formula 2 in FC4:<br>--------------------------------------------------------------------		<br>	Given:<br>		Number of input = 120 and <br>		Number of ouput = 84  [from (84,1)]	<br>	<br>	Therefore, Number of parameters in FC4 layer = (Number of input + 1) * Number of output<br>											 = (120+1)*84<br>											 = (121)*84<br>											 = 10164											 <br>Reference:<br>	<a href=""https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks"">https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks</a>",2020-05-08T12:54:54Z
UgxQ4riLYkmYvV290i54AaABAg.98OsP4IKBhI98RIHD34o67,@bharshavardhan2007,UgxQ4riLYkmYvV290i54AaABAg,2,bXJx7y51cl0,0,1,2020-05-09T11:28:14Z,"<a href=""https://towardsdatascience.com/understanding-and-calculating-the-number-of-parameters-in-convolution-neural-networks-cnns-fc88790d530d"">https://towardsdatascience.com/understanding-and-calculating-the-number-of-parameters-in-convolution-neural-networks-cnns-fc88790d530d</a><br><br><br>You are right.<br>The link has the corrected parameters. You can have a look at it if you want.",2020-05-09T11:28:14Z
UgxQ4riLYkmYvV290i54AaABAg.98OsP4IKBhI99xYJVMUHOI,@1984ssn,UgxQ4riLYkmYvV290i54AaABAg,2,bXJx7y51cl0,0,0,2020-06-16T05:54:41Z,in the CONV layer need to modify the no parameter,2020-06-16T05:54:41Z
UgxQ4riLYkmYvV290i54AaABAg.98OsP4IKBhI9eYLYZO-3_f,@mirabirhossain1842,UgxQ4riLYkmYvV290i54AaABAg,2,bXJx7y51cl0,0,0,2022-08-10T10:27:30Z,"I think there is a catch. If you are calculating with 3 channels, then CONV1 layer should be 28*28*3*8. Why are you not correcting this?",2022-08-10T10:27:30Z
Ugwg6WRVQo1RcOOhZld4AaABAg,@PramodShetty,,1,ay3zYUeuyhU,0,0,2023-08-08T19:27:50Z,Need a tutorial like this on Recurrent Neural Network too,2023-08-08T19:27:50Z
UgxwOgYqJRMz7KLza9Z4AaABAg,@ahmedamin3492,,1,ay3zYUeuyhU,0,0,2023-07-16T19:16:11Z,"Let&#39;s say we have 10 classes meaning that we have 10 outputs, do we push all the 10 outputs to zero (gradient descent)?",2023-07-16T19:16:11Z
UgwWbhyHJzKutBNkBHl4AaABAg,@high_fly_bird,,1,ay3zYUeuyhU,0,1,2023-03-31T16:04:28Z,"I am so fund of these series and from this teacher! Not only his explanations are easy to perceive, but also they give firm basics for future exploration of neural networks. Thank you so much!",2023-03-31T16:04:28Z
Ugx-1IBsX81uiRZFrB94AaABAg,@manuel783,,1,ay3zYUeuyhU,0,1,2021-01-18T23:45:20Z,"Why Convolutions? <b>CORRECTION</b><br><br>Starting around <a href=""https://www.youtube.com/watch?v=ay3zYUeuyhU&amp;t=2m15s"">2:15</a> minute, the number of parameters should have been:<br><br>(5*5*3+1)*6 = 456<br><br>This is based on the equation:<br><br>(f[l] √ó f[l] √ó nc[l‚àí1] + 1) √ó nc[l].<br><br>f[l] is the filter height (and width).<br><br>nc[l‚àí1] is the number of channels in the previous layer.<br><br>nc[l]‚Äã is the number of channels in the current layer.<br><br>The &quot;1&quot; is the bias term.<br><br>(It was by mistake (5*5+1)*6=156 in the video.)",2021-01-18T23:45:20Z
UgxDxxk7EBtdOSM0-6B4AaABAg,@krishnamishra8598,,1,ay3zYUeuyhU,1,0,2020-09-21T08:52:04Z,why do we use convolution ??? why not just simple ANN in case of image ?? main question is what is need of convolution in CNN?? please Answer....,2020-09-21T08:52:04Z
UgxDxxk7EBtdOSM0-6B4AaABAg.9DrciURfPtD9DscIW6XJYw,@gokhantekel2715,UgxDxxk7EBtdOSM0-6B4AaABAg,2,ay3zYUeuyhU,0,0,2020-09-21T18:07:37Z,"Hi sir, mentioned@<a href=""https://www.youtube.com/watch?v=ay3zYUeuyhU&amp;t=1m20s"">1:20</a>",2020-09-21T18:07:37Z
UgzhLenPu7Im_CqFzdF4AaABAg,@ssverma80,,1,ay3zYUeuyhU,0,0,2020-01-22T11:57:21Z,very informative sir.,2020-01-22T11:57:21Z
UgxXR0oLGhiWg-NTdZV4AaABAg,@KunalLal1984,,1,ay3zYUeuyhU,0,2,2019-07-19T10:16:35Z,"During training, how do we train a convolution layer that is succeeded by a pooling layer? The pooling layer will add a non-linearity which will make differentiation impossible.",2019-07-19T10:16:35Z
UgzJz6-cwWyA1uhoeHJ4AaABAg,@safaviriziful,,1,ay3zYUeuyhU,0,0,2019-06-17T17:29:54Z,"I noticed only layer 1 has constant filter values such as edge detector matrix, and other layers has random filter values. Is this interpretion correct?",2019-06-17T17:29:54Z
Ugy0dH2sF6uYWwdD3mJ4AaABAg,@rushiagrawal9667,,1,ay3zYUeuyhU,3,55,2019-06-01T05:52:46Z,"My note of the video:<br><br><br><br>Why CNNs are so effective<br> - Parameter (i.e. weights) sharing<br>  ‚óã One filter is applied to whole image multiple times<br>   ¬ß Insight: if a feature detector (i.e. filter) is useful in multiple parts of image<br> - Sparsity of connections<br>  ‚óã If we connect the two layers fully, we&#39;ll get millions or billions of parameters (i.e. weights)<br>   ¬ß Insight: A filter applied to one area produces one output pixel. This output pixel is not dependent on other areas of the input image. This reduces parameters (i.e. no of weights) drastically<br><br><br> - Translation invariance<br>  ‚óã Using the CNN methodology means that if image of cat is shifted by a few pixels, it&#39;ll still be iddentified as  a cat",2019-06-01T05:52:46Z
Ugy0dH2sF6uYWwdD3mJ4AaABAg.8vcVE-oAQFZ90kiXfM8HeH,@sunnygoswami2248,Ugy0dH2sF6uYWwdD3mJ4AaABAg,2,ay3zYUeuyhU,0,0,2019-10-31T13:40:04Z,thankyou!,2019-10-31T13:40:04Z
Ugy0dH2sF6uYWwdD3mJ4AaABAg.8vcVE-oAQFZ94_aEQJ-ibR,@billykotsos4642,Ugy0dH2sF6uYWwdD3mJ4AaABAg,2,ay3zYUeuyhU,0,0,2020-02-03T16:01:28Z,good notes,2020-02-03T16:01:28Z
Ugy0dH2sF6uYWwdD3mJ4AaABAg.8vcVE-oAQFZ9Tw8wBGz0s0,@piyalikarmakar5979,Ugy0dH2sF6uYWwdD3mJ4AaABAg,2,ay3zYUeuyhU,0,0,2021-10-25T19:21:33Z,So helpful...Thank you sir,2021-10-25T19:21:33Z
UgwwZ2-FySc-FeGVXpV4AaABAg,@ivanamedojevic,,1,ay3zYUeuyhU,0,0,2018-09-20T11:31:08Z,"In this course, they do not explain backprop algorithm. On the beginning, they say that operation convolution is not exactly the same, they do not flip for 180 degrees filter. But in papers and articles where explain this procedure, everyone flip the filter in forwardprop and backprop.  <a href=""https://grzegorzgwardys.wordpress.com/2016/04/22/8/"">https://grzegorzgwardys.wordpress.com/2016/04/22/8/</a>  <br><a href=""https://www.jefkine.com/general/2016/09/05/backpropagation-in-convolutional-neural-networks/"">https://www.jefkine.com/general/2016/09/05/backpropagation-in-convolutional-neural-networks/</a><br>Zhifei Zhang. 2016. Derivation of Backpropagation in Convolutional Neural Network (CNN)",2018-09-20T11:31:08Z
Ugz_-2QcNcrtDQ6Ptop4AaABAg,@bismillahjan7159,,1,ay3zYUeuyhU,6,7,2018-07-29T12:15:09Z,"I think the number of parameters (<a href=""https://www.youtube.com/watch?v=ay3zYUeuyhU&amp;t=2m28s"">2:28</a>) in CNN, given example,  should be 456 not 156 because the filter size is is 5x5x3",2018-07-29T12:15:09Z
Ugz_-2QcNcrtDQ6Ptop4AaABAg.8jHfx1hcOyD8jNWjgjBPmP,@zuozhou8329,Ugz_-2QcNcrtDQ6Ptop4AaABAg,2,ay3zYUeuyhU,0,0,2018-07-31T18:41:23Z,"i think what you were thinking, my cal is 5*5*3*8+8 = 608",2018-07-31T18:41:23Z
Ugz_-2QcNcrtDQ6Ptop4AaABAg.8jHfx1hcOyD8jNXIy2FlWy,@zuozhou8329,Ugz_-2QcNcrtDQ6Ptop4AaABAg,2,ay3zYUeuyhU,0,0,2018-07-31T18:46:20Z,"oops mb, thought we had 8 filters. You&#39;re right, should be 456",2018-07-31T18:46:20Z
Ugz_-2QcNcrtDQ6Ptop4AaABAg.8jHfx1hcOyD8lI5ws8yHTT,@amanpahariya7228,Ugz_-2QcNcrtDQ6Ptop4AaABAg,2,ay3zYUeuyhU,0,2,2018-09-17T09:13:50Z,I think weights for all filter are assumed to be same,2018-09-17T09:13:50Z
Ugz_-2QcNcrtDQ6Ptop4AaABAg.8jHfx1hcOyD8qjoaXKMw2y,@antoniogomes00,Ugz_-2QcNcrtDQ6Ptop4AaABAg,2,ay3zYUeuyhU,0,0,2019-01-30T19:28:27Z,"I think it&#39;s correct... nw*nh*<a href=""http://www.youtube.com/results?search_query=%23filters"">#filters</a> +bias --- 5*5*6+6=156",2019-01-30T19:28:27Z
Ugz_-2QcNcrtDQ6Ptop4AaABAg.8jHfx1hcOyD8uFFC2fAUhi,@punitgalav8537,Ugz_-2QcNcrtDQ6Ptop4AaABAg,2,ay3zYUeuyhU,0,0,2019-04-27T23:19:31Z,"this is not the 3d kernel, it is 5*5*1 kernel that how 156 parameters.",2019-04-27T23:19:31Z
UgzahzYzAXTL0K516ud4AaABAg,@baskorobaskoro7972,,1,ay3zYUeuyhU,1,1,2018-04-29T22:15:25Z,How to set value in kernel (filter) matrix? Is it random?,2018-04-29T22:15:25Z
UgzahzYzAXTL0K516ud4AaABAg.8fdRJ-KtNsR8j5aH1g5M_X,@borispenaloza6384,UgzahzYzAXTL0K516ud4AaABAg,2,ay3zYUeuyhU,0,3,2018-07-24T19:34:42Z,"Yes.. at first you will randomize all parameters of the network , i.e. the filter parameters an the biases. The whole idea is to learn the weights of those filters, thus at the end you extract the right features for the training set that you used.",2018-07-24T19:34:42Z
UgwQ2a8pkOyi0dXx0Bh4AaABAg,@KevinKuei,,1,ay3zYUeuyhU,10,50,2017-12-01T23:47:38Z,"@<a href=""https://www.youtube.com/watch?v=ay3zYUeuyhU&amp;t=2m27s"">2:27</a>, I think the number of parameters should be (5*5*3 + 1) * 6 = 456",2017-12-01T23:47:38Z
UgwQ2a8pkOyi0dXx0Bh4AaABAg.8_dwPvUXChM8cGpdAwjWpb,@ravijain1469,UgwQ2a8pkOyi0dXx0Bh4AaABAg,2,ay3zYUeuyhU,0,0,2018-02-05T04:40:49Z,yep!,2018-02-05T04:40:49Z
UgwQ2a8pkOyi0dXx0Bh4AaABAg.8_dwPvUXChM90AQIfY9Wp5,@chancychan7175,UgwQ2a8pkOyi0dXx0Bh4AaABAg,2,ay3zYUeuyhU,0,0,2019-10-17T02:00:06Z,exactly,2019-10-17T02:00:06Z
UgwQ2a8pkOyi0dXx0Bh4AaABAg.8_dwPvUXChM90owwpSF07N,@swapnildubey6428,UgwQ2a8pkOyi0dXx0Bh4AaABAg,2,ay3zYUeuyhU,0,0,2019-11-02T05:02:56Z,why +1,2019-11-02T05:02:56Z
UgwQ2a8pkOyi0dXx0Bh4AaABAg.8_dwPvUXChM90y-qc1U0of,@camilaonofri2624,UgwQ2a8pkOyi0dXx0Bh4AaABAg,2,ay3zYUeuyhU,0,1,2019-11-05T17:30:12Z,@@swapnildubey6428 the bias,2019-11-05T17:30:12Z
UgwQ2a8pkOyi0dXx0Bh4AaABAg.8_dwPvUXChM918awGWmnOq,@swapnildubey6428,UgwQ2a8pkOyi0dXx0Bh4AaABAg,2,ay3zYUeuyhU,0,0,2019-11-10T05:34:40Z,@@camilaonofri2624 thanks,2019-11-10T05:34:40Z
UgzemjJzCP7aKDUFjFx4AaABAg,@sharifimroz6231,,1,-bvTzZCEOdM,2,0,2020-04-24T16:04:44Z,"Why we use odd filters mostly for example 3*3, 5*5, 7*7, ....?",2020-04-24T16:04:44Z
UgzemjJzCP7aKDUFjFx4AaABAg.97qA-A3yxC799yWwHjwStk,@basavarajpatil9821,UgzemjJzCP7aKDUFjFx4AaABAg,2,-bvTzZCEOdM,0,4,2020-06-16T15:01:53Z,because we always want perfect int values rather than the floating values for the filter design or during padding.,2020-06-16T15:01:53Z
UgzemjJzCP7aKDUFjFx4AaABAg.97qA-A3yxC79HnMDsP360r,@adhoc3018,UgzemjJzCP7aKDUFjFx4AaABAg,2,-bvTzZCEOdM,0,1,2020-12-28T03:07:48Z,He explained it in one of the previous videos.,2020-12-28T03:07:48Z
Ugwe1_fos3praLCXxGV4AaABAg,@miguelacuna7148,,1,-bvTzZCEOdM,1,1,2019-12-21T18:43:10Z,"Hi, i just started to study AI by my self and it&#39;s quite difficult because there is a lot to cover, sometimes i get lost. Can you recommend a book that helpes me as a guide. Thanks, i love your videos.",2019-12-21T18:43:10Z
Ugwe1_fos3praLCXxGV4AaABAg.92o_lDWYxs492oao6eFIMa,@veloenoir1507,Ugwe1_fos3praLCXxGV4AaABAg,2,-bvTzZCEOdM,0,1,2019-12-21T18:52:18Z,I can recommend this course and the one done by fastai. Get an overview and just learn specific areas as is needed. Consistency is key!,2019-12-21T18:52:18Z
UgzK4N2wKBBE3ooe9_94AaABAg,@i_amdosa3068,,1,-bvTzZCEOdM,1,0,2019-01-29T11:00:26Z,day : 1,2019-01-29T11:00:26Z
UgzK4N2wKBBE3ooe9_94AaABAg.8qgKeqH3-yO91Iibv6Fydv,@adityashidhaye9879,UgzK4N2wKBBE3ooe9_94AaABAg,2,-bvTzZCEOdM,0,0,2019-11-14T03:54:12Z,ok,2019-11-14T03:54:12Z
UgwZWgGbHZG2CMXtidV4AaABAg,@oktayvosoughi6199,,1,dZVkygnKh1M,0,0,2023-10-08T19:29:31Z,do you have papers that prof said in the lecture?,2023-10-08T19:29:31Z
UgwXpibduLRwWB5rJbp4AaABAg,@PramodShetty,,1,dZVkygnKh1M,0,0,2023-08-08T19:30:56Z,how is 6 channels converted to 16 channels?,2023-08-08T19:30:56Z
UgzLz42pAKNunSh_XRR4AaABAg,@jacobjonm0511,,1,dZVkygnKh1M,7,0,2022-07-14T12:12:19Z,"it is confusing, is the kernel 3*3*3 or 3*3? I assume for the RGB images it is 3*3*3.",2022-07-14T12:12:19Z
UgzLz42pAKNunSh_XRR4AaABAg.9dT04dE5QpK9pNe_Ub9rNr,@gerrardandeminem,UgzLz42pAKNunSh_XRR4AaABAg,2,dZVkygnKh1M,0,0,2023-05-06T16:36:13Z,It is 3*3*no. of filter,2023-05-06T16:36:13Z
UgzLz42pAKNunSh_XRR4AaABAg.9dT04dE5QpK9pOb_ghzXny,@jacobjonm0511,UgzLz42pAKNunSh_XRR4AaABAg,2,dZVkygnKh1M,0,0,2023-05-07T01:29:16Z,"@@gerrardandeminem are you sure? based on this video it is 3*3*3:<br><a href=""https://www.youtube.com/watch?v=Lakz2MoHy6o&amp;list=LL&amp;index=30&amp;t=1461s"">https://www.youtube.com/watch?v=Lakz2MoHy6o&amp;list=LL&amp;index=30&amp;t=1461s</a>",2023-05-07T01:29:16Z
UgzLz42pAKNunSh_XRR4AaABAg.9dT04dE5QpK9pOeDlFIM9t,@gerrardandeminem,UgzLz42pAKNunSh_XRR4AaABAg,2,dZVkygnKh1M,0,0,2023-05-07T01:52:22Z,@@jacobjonm0511 I think Andrew ng explains this in previous videos of this series. It is an arbitrary choice.,2023-05-07T01:52:22Z
UgzLz42pAKNunSh_XRR4AaABAg.9dT04dE5QpK9pOigpabQC2,@jacobjonm0511,UgzLz42pAKNunSh_XRR4AaABAg,2,dZVkygnKh1M,0,0,2023-05-07T02:31:25Z,"@@gerrardandeminem it is not arbitrary. Here is another video at <a href=""https://www.youtube.com/watch?v=dZVkygnKh1M&amp;t=7m23s"">7:23</a><br><a href=""https://www.youtube.com/watch?v=pDdP0TFzsoQ&amp;list=LL&amp;index=31&amp;t=1078s"">https://www.youtube.com/watch?v=pDdP0TFzsoQ&amp;list=LL&amp;index=31&amp;t=1078s</a>",2023-05-07T02:31:25Z
UgzLz42pAKNunSh_XRR4AaABAg.9dT04dE5QpK9pOl2KbB6Ha,@gerrardandeminem,UgzLz42pAKNunSh_XRR4AaABAg,2,dZVkygnKh1M,0,0,2023-05-07T02:51:58Z,"@@jacobjonm0511 If you are asking about the first input. then yes, it is 3*3*3. But it is arbitrary afterwards",2023-05-07T02:51:58Z
UgxF9ja2lyn_re0z9qh4AaABAg,@kiranarun1868,,1,dZVkygnKh1M,3,1,2020-10-12T15:24:06Z,After same padding how did 27x27x96 become 27x27x256?,2020-10-12T15:24:06Z
UgxF9ja2lyn_re0z9qh4AaABAg.9EiPHFcKneN9FKCNSC3sGZ,@alexiafairy,UgxF9ja2lyn_re0z9qh4AaABAg,2,dZVkygnKh1M,0,7,2020-10-27T17:01:44Z,"Conv layer, since its same padding so the height and weight remained 27X27, but they used 256 filters, or channels, so the dimensions became 27x27x256",2020-10-27T17:01:44Z
UgxF9ja2lyn_re0z9qh4AaABAg.9EiPHFcKneN9ria3dWN9EN,@rahul25iit,UgxF9ja2lyn_re0z9qh4AaABAg,2,dZVkygnKh1M,0,0,2023-07-03T22:02:52Z,@@alexiafairy Andrew doesn&#39;t explicitly mention about using 256 filters.,2023-07-03T22:02:52Z
UgxF9ja2lyn_re0z9qh4AaABAg.9EiPHFcKneN9x-kVmVQ7QE,@devanshgoel3433,UgxF9ja2lyn_re0z9qh4AaABAg,2,dZVkygnKh1M,0,0,2023-11-12T05:57:23Z,@@rahul25iit That&#39;s because if we will watch playlist in serial order. Then one can get to know such things have to be considered by default if he has not mentioned explicitly.,2023-11-12T05:57:23Z
UgxsqQBAI3d0BUpTpMV4AaABAg,@sheethalgowda6616,,1,dZVkygnKh1M,2,2,2020-06-05T19:12:55Z,"How does a 14√ó14√ó6 turn into 10√ó10√ó16, I mean we have 6 14√ó14  filtered output images, how to apply 16 filters for 6 14√ó14 output images",2020-06-05T19:12:55Z
UgxsqQBAI3d0BUpTpMV4AaABAg.99XdvEJpEZJ9N_yetRs_N9,@anhphan8643,UgxsqQBAI3d0BUpTpMV4AaABAg,2,dZVkygnKh1M,0,0,2021-05-21T01:31:25Z,@@awest11000 so how do you know how many filters can fit with next layer?,2021-05-21T01:31:25Z
UgxsqQBAI3d0BUpTpMV4AaABAg.99XdvEJpEZJ9g4CBrzcIAr,@socrabate,UgxsqQBAI3d0BUpTpMV4AaABAg,2,dZVkygnKh1M,0,0,2022-09-17T10:31:20Z,"The critical part is that you SUM UP those 10x10x6 on depth(6). So when a filter of 5x5x6 is applied on a 14x14x6 tensor it will yield 10x10x1, just like a filter of 5x5x5 on a tensor 14x14x6 would yield a 10x10x2 output, and a 5x5x4 on the same tensor would yield a 10x10x3 output etc...",2022-09-17T10:31:20Z
UgzN2kMiKEITg29YGhV4AaABAg,@navneetchaudhary4842,,1,dZVkygnKh1M,3,0,2020-03-30T09:33:19Z,as we see in lenet or in our conv network when we apply filter dimension is decrease each time  ex:- in leNet 32*32*1 when we get conv layer by 6 filters of 5*5 matrix then the answer is 28*28*6  but in VGG 16 the answer we get every time is same like 224*224*3 result in 224*224*64 only no. of filters are change let me help with that or explain it .,2020-03-30T09:33:19Z
UgzN2kMiKEITg29YGhV4AaABAg.96p5K_aAK3E98ypdhlpqyg,@legacies9041,UgzN2kMiKEITg29YGhV4AaABAg,2,dZVkygnKh1M,0,2,2020-05-22T21:22:43Z,The block sizes do not change in VGG because the authors use zero padding throughout. I hope this helps.,2020-05-22T21:22:43Z
UgzN2kMiKEITg29YGhV4AaABAg.96p5K_aAK3E9B2oT8IAuLN,@ayushyarao9693,UgzN2kMiKEITg29YGhV4AaABAg,2,dZVkygnKh1M,0,1,2020-07-13T12:51:23Z,i think joe meant that there is suitable padding used to make sure that they both are same size.Which must be 2.,2020-07-13T12:51:23Z
UgzN2kMiKEITg29YGhV4AaABAg.96p5K_aAK3E9v3B0dQ9dMP,@kemalmudie3134,UgzN2kMiKEITg29YGhV4AaABAg,2,dZVkygnKh1M,0,0,2023-09-24T20:52:44Z,@@ayushyarao9693  p=1.  (n+2p-f )s+1  =&gt;  (224+2(1)-3)/1+1 224.   Ans after 3 years of comment.  I wrote it may help who learning from it now and came to see this doubt.,2023-09-24T20:52:44Z
Ugyc3J6mnIMtwNZplF94AaABAg,@aayushpaudel2379,,1,dZVkygnKh1M,3,2,2019-09-13T08:13:18Z,224 on convolution by 3*3 filter twice should give 220. Help me with this !!,2019-09-13T08:13:18Z
Ugyc3J6mnIMtwNZplF94AaABAg.8zoXzJusDaW99yaCxk1XON,@basavarajpatil9821,Ugyc3J6mnIMtwNZplF94AaABAg,2,dZVkygnKh1M,0,0,2020-06-16T15:39:15Z,1st filter(3x3) = n-f+1 = 224-3+1=222<br>2nd filter(3x3) = 222-3+1 = 220,2020-06-16T15:39:15Z
Ugyc3J6mnIMtwNZplF94AaABAg.8zoXzJusDaW9CYTTHjrt-Y,@shaunli7001,Ugyc3J6mnIMtwNZplF94AaABAg,2,dZVkygnKh1M,0,3,2020-08-19T16:26:16Z,"Here they use same convolutions, which means padding = 1.",2020-08-19T16:26:16Z
Ugyc3J6mnIMtwNZplF94AaABAg.8zoXzJusDaW9JmjZ9R-xi-,@trexmidnite,Ugyc3J6mnIMtwNZplF94AaABAg,2,dZVkygnKh1M,0,0,2021-02-15T14:23:59Z,Dont be such an ass to check every single thing,2021-02-15T14:23:59Z
UgxYV-KbERdJQBkZ5xp4AaABAg,@sandyz1000,,1,dZVkygnKh1M,1,20,2019-09-12T11:59:43Z,AlexNet was remarkable when it first came. Setting up two GPUs for training was very difficult and communication among Gpus using mpi require great deal of effort. Those guy were really geeks to figure out such solution,2019-09-12T11:59:43Z
UgxYV-KbERdJQBkZ5xp4AaABAg.8zmN5kp5p8r9aME7W_EnQ7,@SuperSmitty9999,UgxYV-KbERdJQBkZ5xp4AaABAg,2,dZVkygnKh1M,0,2,2022-04-28T07:26:11Z,Setting up one GPU with tensorflow today is a feat of engineering.,2022-04-28T07:26:11Z
UgzbJT5rArbGG5WenMx4AaABAg,@Dohkim-ni6um,,1,dZVkygnKh1M,0,0,2019-08-29T07:53:06Z,skip too many things in AlexNet part..,2019-08-29T07:53:06Z
UgyX0bRFTl9nSRouttZ4AaABAg,@kaushilkundalia2197,,1,dZVkygnKh1M,0,0,2019-05-19T10:09:43Z,"<a href=""https://arxiv.org/pdf/1409.1556.pdf"">https://arxiv.org/pdf/1409.1556.pdf</a><br>VGG - 16",2019-05-19T10:09:43Z
UgzHf9n1Z2Z2sPh8pNR4AaABAg,@kaushilkundalia2197,,1,dZVkygnKh1M,0,1,2019-05-19T10:05:41Z,"<a href=""https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf"">https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf</a> <br>AlexNet Research paper",2019-05-19T10:05:41Z
UgwBTiC-hwQ0RKVIj794AaABAg,@yinghong3543,,1,dZVkygnKh1M,1,8,2019-04-09T07:22:44Z,"At <a href=""https://www.youtube.com/watch?v=dZVkygnKh1M&amp;t=8m40s"">8:40</a>, the AlexNet, why the channel suddenly shrank from 384 to 256?",2019-04-09T07:22:44Z
UgwBTiC-hwQ0RKVIj794AaABAg.8tVBObeP_O38uer-IKtaIT,@CyborgGaming99,UgwBTiC-hwQ0RKVIj794AaABAg,2,dZVkygnKh1M,0,10,2019-05-08T07:18:49Z,"It&#39;s just the number of filters they used, they decided to up the filters from 96 to 256 to 384 at first, and probably when they realized that their results aren&#39;t changing much, they decided to back the filter number. Number of channels is just the number of filters they decided to use, there is no &quot;explanation&quot; or math formula as to why they chose those jumps(they explain it in the paper probably)",2019-05-08T07:18:49Z
UgxL5tNjAe0B1jWOvf14AaABAg,@shwethasubbu3385,,1,dZVkygnKh1M,2,4,2019-01-27T07:49:21Z,"At <a href=""https://www.youtube.com/watch?v=dZVkygnKh1M&amp;t=13m37s"">13:37</a>, why do we have [CONV 64] x 2 ? why do we perform the CONV operation twice (when we get the same dimensions each time) ?<br>Also, what is the advantage of increasing the number of channels and decreasing the height and width?",2019-01-27T07:49:21Z
UgxL5tNjAe0B1jWOvf14AaABAg.8qaqCZ3ioU08uerzi6D32c,@CyborgGaming99,UgxL5tNjAe0B1jWOvf14AaABAg,2,dZVkygnKh1M,0,1,2019-05-08T07:27:28Z,"Well you don&#39;t have to change dimensions every time in order to actually get some results. It was just their way of trying to detect patterns in images, it just looks unusual",2019-05-08T07:27:28Z
UgxL5tNjAe0B1jWOvf14AaABAg.8qaqCZ3ioU09Gytyvzu2zt,@MuhannadGhazal,UgxL5tNjAe0B1jWOvf14AaABAg,2,dZVkygnKh1M,0,0,2020-12-07T18:11:43Z,p=1 here so the dimensions stayed the same..,2020-12-07T18:11:43Z
Ugw5RJQyQxZtycs-iKN4AaABAg,@roshnisingh8342,,1,dZVkygnKh1M,5,1,2018-12-11T10:09:02Z,How 400 to 120 to 84 in fully connected layers?,2018-12-11T10:09:02Z
Ugw5RJQyQxZtycs-iKN4AaABAg.8oi3pVkE_cX8pWlYrpVQf5,@janvonschreibe3447,Ugw5RJQyQxZtycs-iKN4AaABAg,2,dZVkygnKh1M,0,0,2018-12-31T12:01:06Z,The next layers needs not have the same number of nodes than the previous ones,2018-12-31T12:01:06Z
Ugw5RJQyQxZtycs-iKN4AaABAg.8oi3pVkE_cX8qvrdDsDN72,@pallawirajendra,Ugw5RJQyQxZtycs-iKN4AaABAg,2,dZVkygnKh1M,0,2,2019-02-04T11:45:55Z,Every 400 nodes are connected to every 120 nodes and every 120 nodes are connected to every 84 nodes. There are no maths but only¬†your experience which helps you decide the number of nodes.,2019-02-04T11:45:55Z
Ugw5RJQyQxZtycs-iKN4AaABAg.8oi3pVkE_cX8r9zukXcj5k,@ritapravadutta7939,Ugw5RJQyQxZtycs-iKN4AaABAg,2,dZVkygnKh1M,0,2,2019-02-10T08:46:49Z,120 and 84 are just choice of number of nodes for LeNet-5,2019-02-10T08:46:49Z
Ugw5RJQyQxZtycs-iKN4AaABAg.8oi3pVkE_cX9BzkToPTGuE,@Joshua-dl3ns,Ugw5RJQyQxZtycs-iKN4AaABAg,2,dZVkygnKh1M,0,2,2020-08-05T19:30:58Z,"they chose those numbers as they work best for the model, you have to find out what number of neurons works well for you",2020-08-05T19:30:58Z
Ugw5RJQyQxZtycs-iKN4AaABAg.8oi3pVkE_cX9C0VJ8T6m1w,@roshnisingh8342,Ugw5RJQyQxZtycs-iKN4AaABAg,2,dZVkygnKh1M,0,1,2020-08-06T11:48:10Z,Thank you all for helping out,2020-08-06T11:48:10Z
Ugy70ZXUYk8wR6uMxhx4AaABAg,@uchungnguyen1474,,1,dZVkygnKh1M,3,0,2018-10-15T19:25:57Z,i have question how come from 90216 parameters to 4096 parameters? and how do i know how many layers i need?,2018-10-15T19:25:57Z
Ugy70ZXUYk8wR6uMxhx4AaABAg.8mRIF_fRYs48naHEv7mAIf,@adamajinugroho830,Ugy70ZXUYk8wR6uMxhx4AaABAg,2,dZVkygnKh1M,0,0,2018-11-13T13:00:55Z,"im havent followed this video yet, did you mean layer or parameter?<br>for the layer it came from the experiment of the given architecture",2018-11-13T13:00:55Z
Ugy70ZXUYk8wR6uMxhx4AaABAg.8mRIF_fRYs48q7ygPyJGZ3,@muhammadharris4470,Ugy70ZXUYk8wR6uMxhx4AaABAg,2,dZVkygnKh1M,0,1,2019-01-15T17:26:15Z,"90216 resulted from flattening the the last layer  conv layer. 4096 are not the parameters but the number of hidden layers of that layer. lastly, number of  layers is a hyperparameter meaning you have to experiment with what works best for your problem",2019-01-15T17:26:15Z
Ugy70ZXUYk8wR6uMxhx4AaABAg.8mRIF_fRYs49HFomlbL_RF,@ThePaypay88,Ugy70ZXUYk8wR6uMxhx4AaABAg,2,dZVkygnKh1M,0,0,2020-12-14T17:12:42Z,"number is just multiplication of  width*height*channel  ,  about how many you need they just test ( or phd students test ) and report to advisor professor<br><br>kek",2020-12-14T17:12:42Z
UgyKXxujeDuN9tXjK494AaABAg,@sau002,,1,dZVkygnKh1M,3,3,2018-09-10T14:11:47Z,Excellent video. Thank you very much. I have a question.  When we apply the 2nd set of convolution 16 filters - do we not apply this filter on the 6 channels we produced in the  previous layer?  Therefore the final output after the 2nd pooling should be  5X5 X 16filters X 6 filters  = 400x6=2400 ?,2018-09-10T14:11:47Z
UgyKXxujeDuN9tXjK494AaABAg.8l0bTvQ7Xqo8lXeaCee1jq,@sau002,UgyKXxujeDuN9tXjK494AaABAg,2,dZVkygnKh1M,0,3,2018-09-23T10:13:55Z,"I think I understand why.  Every filter should be visualized as a 3d matrix , i.e. a volume.  Each layer in the volume operates on each of the channels. E.g. In case of R,G,B picture, the first layer of filters would have 3 matrices each , 1 matrix for R, 1 matrix for G, 1 matrixfor B.   The 3 matrices in a single filter would operate on the R,G,B image to produce a single 2d matrix. Now 6 filters in the first layer produce 6 two dimensional matrices. Think of the count 6 as a picture with 6 channels. Therefore in the subsequent filter layers, your input picture is made up of 6 two dimensional matrices.  Each of the 16 filters in the second filter layer have a depth of 6 in the 3 rd dimension, i.e. a stack of 6 two dimensional matrices. Therefore 16 of these 6 channeled filters operate on the input image (which can be thought of as a 6 channel image produced by convolution in the first layer).",2018-09-23T10:13:55Z
UgyKXxujeDuN9tXjK494AaABAg.8l0bTvQ7Xqo8lXeeI4GYaG,@sau002,UgyKXxujeDuN9tXjK494AaABAg,2,dZVkygnKh1M,0,3,2018-09-23T10:14:29Z,The previous videos from ANG have the answer to my question. I have summarized below.,2018-09-23T10:14:29Z
UgyKXxujeDuN9tXjK494AaABAg.8l0bTvQ7Xqo994NIwweHZh,@pengsun1355,UgyKXxujeDuN9tXjK494AaABAg,2,dZVkygnKh1M,0,1,2020-05-25T10:21:01Z,@@sau002 good job:),2020-05-25T10:21:01Z
UgzJQjmnwdFtPDmm5iR4AaABAg,@rubel7829,,1,dZVkygnKh1M,0,20,2017-12-07T19:22:01Z,thanku very very much mr andrew ng...........u made my all the task super easy....now its like piece of a cake...u cant believe that  how much i struggle to demystify all the issues regarding about deep-learning  specially conv.,2017-12-07T19:22:01Z
UgzvqUEBDlWDeRsduwB4AaABAg,@swfsql,,1,ZILIbUvp5lk,0,0,2023-09-06T10:08:52Z,"I think we could use the ResNet concept to improve Dropout, creating a &quot;shutdown&quot; regularization: <br><br>Select a layer (or rather nodes from that layer) that ought to be shutdown and instead only act on the cost function, by adding a cost relative to that layer not being an identity layer. Then the network is free to gradually adapt itself (hopefully by reducing train-set overfit and generalizing) as to push that layer into being evermore so of an identity one. Then if that layer manages to be an identity, it can be permanently shutdown.<br>This could be a way to reduce the network size, and maybe could automatically be applied on high variance with low bias.<br><br>As far as linear Z functions go, one way for a layer to be an identity is if it has the same amount of nodes as inputs, and if you make a cost for each node[j] so that only their weight[j] is 1 while all other weights are 0, so this would be similar to a &quot;identity&quot; Z layer. But I think that trying to make the activation function also an identity is a hassle, but even ignoring the activation function, if you could still manage to just shutdown the Z function nodes and stack the posterior activation back into the previous activation, that would already be a network simplification.<br><br>Edit: We also could try to simplify the activation functions if we generalize them and re-parametrize them. Eg. for a ReLU activation function, we could turn it into a leaky ReLU where the leaky-side parameter starts at zero (so it&#39;s just like  normal ReLU), then we add a cost of that parameter being zero and we let backprop start pushing it towards 1, in which case that previously ReLU activation has turned into the identity activation, which can them be gracefully shutdown.",2023-09-06T10:31:46Z
Ugz6YeI3ABOA7ybvIoJ4AaABAg,@mayuommabok4720,,1,ZILIbUvp5lk,0,0,2023-05-23T19:08:11Z,((())),2023-05-23T19:08:11Z
UgySu3hGrsMLVGXFlI54AaABAg,@ahmedb2559,,1,ZILIbUvp5lk,0,0,2023-01-09T19:30:09Z,Thank you !,2023-01-09T19:30:09Z
UgxqHTq-5Ee1pbvWcJR4AaABAg,@patrickyu8470,,1,ZILIbUvp5lk,0,0,2022-07-28T01:15:38Z,"Just a question for those out there - has anyone been able to use techniques from ResNets to improve the convergence speed of deep fully connected networks? Usually people use skip connections in the context of convolutional neural nets but I haven&#39;t seen much gain in performance with fully connected ResNets, so just wondering if there&#39;s something else I may be missing.",2022-07-28T01:16:38Z
Ugylb-zfEp_xGMljh4R4AaABAg,@iasonaschristoulakis6932,,1,ZILIbUvp5lk,0,0,2022-05-17T11:02:35Z,Excellent both theoretically and technically,2022-05-17T11:02:35Z
Ugy26Lq2k0enM13J43Z4AaABAg,@ravivaghasiya5680,,1,ZILIbUvp5lk,0,0,2022-05-10T18:53:00Z,"Hello everyone.  In this video at time 5.20 you have mentioned that as number of layers increase in plain network , training error gets increased in practice. Could you please explain me or Share me some references why does this actually occurs? One reason,i found that vanishing gradient problem and this can be addressed using ReLU. Thus, one can use ReLU in plain network. Then why does ResNet is very traditional?",2022-05-10T18:53:00Z
UgwasfgiRVoMdu4vnH14AaABAg,@anuramdesh,,1,ZILIbUvp5lk,0,0,2022-05-04T13:26:43Z,"Sir, very nice explanation as always, thanks a lot.",2022-05-04T13:26:43Z
Ugxf6KqsTk8HLk4XWaR4AaABAg,@chrlemes,,1,ZILIbUvp5lk,0,0,2022-04-22T20:34:47Z,I think the title of the paper is wrong. The correct one is &quot;Deep residual learning for image recognition&quot;.,2022-04-22T20:34:47Z
UgyevUiz_FxzLnjBh4J4AaABAg,@Alex-xx8ij,,1,ZILIbUvp5lk,0,0,2022-03-19T10:55:17Z,Your explanation is very clear! Thank you for the lecture.,2022-03-19T10:55:17Z
Ugz-2tY8cx3bV373VMZ4AaABAg,@rahuldogra7171,,1,ZILIbUvp5lk,0,0,2021-07-10T19:31:52Z,what is the benefit of adding identity blocks and skip it?  Instead of skipping it why then we are adding?,2021-07-10T19:31:52Z
Ugy44XG2MhJsTDqTh9Z4AaABAg,@wliw3034,,1,ZILIbUvp5lk,0,0,2021-05-22T17:30:52Z,Good,2021-05-22T17:30:52Z
UgzlrREJKVMQ3_4udnt4AaABAg,@davidtorres5012,,1,ZILIbUvp5lk,0,0,2021-04-29T23:35:01Z,"You are the best, Andrew",2021-04-29T23:35:01Z
UgyNZ5vkQkWkXYRvN5V4AaABAg,@kumarabhishek5652,,1,ZILIbUvp5lk,0,1,2021-04-13T07:38:04Z,Why training error is increasing in reality as opposed to theory in plain model??,2021-04-13T07:38:04Z
UgycZ3RE7-mpb9QGgMF4AaABAg,@Cicatka.Michal,,1,ZILIbUvp5lk,0,1,2021-04-02T09:07:44Z,Finally got it! Sometimes it is hard for me to grasp even the basic concepts if I don&#39;t know what I should understand and take from the topic. Thank You very much for these videos that will at first tell you what problem you are trying to solve is and why you should solve it and then clearly explains the soulutions. Thumbs up! :),2021-04-02T09:07:44Z
UgzVxOv_DTcId5oi4i14AaABAg,@MrRynRules,,1,ZILIbUvp5lk,0,0,2021-03-25T04:34:37Z,Thank you!,2021-03-25T04:34:37Z
Ugz1WpXBCvT3f4R6Kpt4AaABAg,@trexmidnite,,1,ZILIbUvp5lk,0,0,2021-02-10T02:51:06Z,Sounds like terminator..,2021-02-10T02:51:06Z
UgybBpYFtEEhYS1h8pF4AaABAg,@shivani404sheth4,,1,ZILIbUvp5lk,0,0,2021-01-23T03:37:11Z,Meet the ML god,2021-01-23T03:37:11Z
UgzXTwxXy0WtqEYAYol4AaABAg,@mannansheikh,,1,ZILIbUvp5lk,0,0,2020-11-14T11:59:09Z,Great,2020-11-14T11:59:09Z
UgxzYlQUDKa_R8lE92V4AaABAg,@whyitdoesmatter2814,,1,ZILIbUvp5lk,0,0,2020-10-09T03:27:25Z,Wait!!!!!  Z_{l+1} should normally be equal to W_{l}a_{l} + b_{l+1}??,2020-10-09T03:27:25Z
UgytT8IaO9rSFn6f14t4AaABAg,@lorenzosorgi6088,,1,ZILIbUvp5lk,2,0,2020-09-05T12:43:51Z,is there any theoretical motivation justifying the increasing error of a deep plain network during training?,2020-09-05T12:43:51Z
UgytT8IaO9rSFn6f14t4AaABAg.9DDqX8Qbh929G1uXo6HCA_,@mohnishiitk,UgytT8IaO9rSFn6f14t4AaABAg,2,ZILIbUvp5lk,0,0,2020-11-14T11:02:11Z,"Theoretically, the error should go down. But in practice, I think the exploding gradients for a network with a large number of layers increases the error.",2020-11-14T11:02:11Z
UgytT8IaO9rSFn6f14t4AaABAg.9DDqX8Qbh929I1KQx6xxsX,@anasalnuaimi,UgytT8IaO9rSFn6f14t4AaABAg,2,ZILIbUvp5lk,0,0,2021-01-02T22:40:43Z,"Yes there is. I am not sure why Andrew Ng didn&#39;t touch up on this. Basically once you add the skip connection you are including an additive term inside the non-linearity. The additive term can only increase the function space (the range of the function <a href=""https://www.intmath.com/functions-and-graphs/2a-domain-and-range.php)"">https://www.intmath.com/functions-and-graphs/2a-domain-and-range.php)</a> as it is &lt;&lt;nested&gt;&gt; inside the original function (the theory of nesting functions). Hence, you allow the network to have more approximating/predictive capacity in each layer. You can visit the D2L lectures about this:<br><a href=""https://d2l.ai/chapter_convolutional-modern/resnet.html?highlight=resnet"">https://d2l.ai/chapter_convolutional-modern/resnet.html?highlight=resnet</a>",2021-01-02T22:40:43Z
Ugx6SmigDjKOldGTOaF4AaABAg,@viniciussantana8737,,1,ZILIbUvp5lk,0,1,2020-08-29T14:14:12Z,Andrew os simply the best instrutor in neural networks subject out there. Helped me a Lot.,2020-08-29T14:14:12Z
UgwlkmNmi28IReU-1UF4AaABAg,@tayyabahayat6898,,1,ZILIbUvp5lk,0,0,2020-08-21T14:32:56Z,"Best video on RseNet Architecture. Click on the link and learn ResNet in easiest wording.<br><a href=""https://www.youtube.com/watch?v=fvrIqFCUWV4&amp;t=44s"">https://www.youtube.com/watch?v=fvrIqFCUWV4&amp;t=44s</a>",2020-08-21T14:32:56Z
Ugyljicbys1jH6bcC494AaABAg,@steeltwistercoaster,,1,ZILIbUvp5lk,0,0,2020-08-21T01:16:30Z,+1 this is great,2020-08-21T01:16:30Z
Ugyf7mJWgh-zcznUCRt4AaABAg,@promethful,,1,ZILIbUvp5lk,1,2,2020-08-14T11:25:47Z,So the skipped connections don&#39;t literally skip layers but rather add the original input onto the output of the &#39;skipped&#39; layers?,2020-08-14T11:25:47Z
Ugyf7mJWgh-zcznUCRt4AaABAg.9CL3654vsJt9Q8CR09ypE6,@user-cg7ut9lj3e,Ugyf7mJWgh-zcznUCRt4AaABAg,2,ZILIbUvp5lk,0,0,2021-07-23T10:56:40Z,"I think so too, at least it is the only explanation that I understand",2021-07-23T10:56:40Z
Ugz0mjkZvlSkaFpRnSJ4AaABAg,@zekarias9888,,1,ZILIbUvp5lk,0,8,2020-05-20T12:30:17Z,"WooW. After I watched 5 other videos about ResNets, I was still lost. Now I got this video and it cleared my misunderstandings out of my mind. Super cool!",2020-05-20T12:30:17Z
Ugz2M8lI0M3nupxx3wx4AaABAg,@altunbikubra,,1,ZILIbUvp5lk,0,0,2020-05-03T09:44:54Z,"Thank you, it was a very brief and simplified explanation, loved it.",2020-05-03T09:44:54Z
UgxveOXLMRDtvzqFdyp4AaABAg,@JonesDTaylor,,1,ZILIbUvp5lk,0,4,2020-04-17T09:11:22Z,I am doing the DL specialization after finishing your old ML course. By far you are the best teacher out there. Thank you so much for this.,2020-04-17T09:11:22Z
UgzubcY0hRPnFNyd_H14AaABAg,@amir06a,,1,ZILIbUvp5lk,0,0,2020-03-28T21:52:06Z,I have a very silly doubt if the skip layers/connections exist isn&#39;t the real layers in play = total layers/2?,2020-03-28T21:52:06Z
UgzO-x2n6e7P0T6YSQF4AaABAg,@JohnDoe-vr4et,,1,ZILIbUvp5lk,0,14,2020-02-13T05:57:39Z,Me after listening to most people explaining Resnet: &quot;What? Why? Why do you do this?&quot;<br>Me after listening to Andrew: &quot;Makes sense. Easy peasy.&quot;,2020-02-13T05:57:39Z
UgzLyu-Sc02N3NKkNvp4AaABAg,@astropiu4753,,1,ZILIbUvp5lk,1,7,2020-02-07T16:43:38Z,there&#39;s some high-frequency noise in many of this specialization&#39;s videos which is hurting my ears.,2020-02-07T16:43:38Z
UgzLyu-Sc02N3NKkNvp4AaABAg.94jyEhvIMSF97fU-tatIO1,@ntumbaeliensampi6305,UgzLyu-Sc02N3NKkNvp4AaABAg,2,ZILIbUvp5lk,0,6,2020-04-20T12:27:56Z,use a low pass filter. Lol,2020-04-20T12:27:56Z
Ugx4zB5KtTWFNrxUsIV4AaABAg,@mikebot5361,,1,ZILIbUvp5lk,1,0,2019-11-26T12:45:30Z,"If we use resnets, are we losing the information in between the layers?",2019-11-26T12:45:30Z
Ugx4zB5KtTWFNrxUsIV4AaABAg.91nZxmXBQZ89JpxZzITgZy,@s.s.1930,Ugx4zB5KtTWFNrxUsIV4AaABAg,2,ZILIbUvp5lk,0,0,2021-02-16T20:24:09Z,"no, we&#39;re not losing them - we just add x after a amount of layers (in this example 2 layers) - this is our ResNet block",2021-02-16T20:24:09Z
UgzNtLTsrOOIRHkWhit4AaABAg,@sanjurydv,,1,ZILIbUvp5lk,0,1,2019-11-06T10:18:44Z,never seen tutorial videos which such a clear explanation. He is the best,2019-11-06T10:18:44Z
UgzupDUiGYdkb3oerSB4AaABAg,@swapnildubey6428,,1,ZILIbUvp5lk,2,1,2019-11-02T07:09:47Z,"how are the dimensions handled, I mean that dimension of a[l] could happen to be unequal to a[l + 2];",2019-11-02T07:09:47Z
UgzupDUiGYdkb3oerSB4AaABAg.90pASvh7yLa93Mha08on9i,@SuperVaio123,UgzupDUiGYdkb3oerSB4AaABAg,2,ZILIbUvp5lk,0,1,2020-01-04T10:04:57Z,Padding,2020-01-04T10:04:57Z
UgzupDUiGYdkb3oerSB4AaABAg.90pASvh7yLa9Jpx6ruoAub,@s.s.1930,UgzupDUiGYdkb3oerSB4AaABAg,2,ZILIbUvp5lk,0,0,2021-02-16T20:20:10Z,padding with zeros or using an Conv 1x1 inside skip connection,2021-02-16T20:20:10Z
UgzNExKmDmFhTEgkMb54AaABAg,@MeAndCola,,1,ZILIbUvp5lk,1,14,2019-10-29T00:15:55Z,"&quot;man pain&quot; <a href=""https://www.youtube.com/watch?v=ZILIbUvp5lk&amp;t=2m10s"">2:10</a> üòÇ",2019-10-29T00:15:55Z
UgzNExKmDmFhTEgkMb54AaABAg.90e7vAyOgV598BeaEOyvhc,@altunbikubra,UgzNExKmDmFhTEgkMb54AaABAg,2,ZILIbUvp5lk,0,0,2020-05-03T09:44:06Z,omg he is really writing that :D,2020-05-03T09:44:06Z
UgzPUrJ-4gQv4Cas_MB4AaABAg,@rahulrathnakumar785,,1,ZILIbUvp5lk,2,1,2019-05-02T01:11:17Z,"If a_l skips two layers to directly enter the final ReLU, how do we get the z_(l+2) in the final equation a_(l+2) =g(z_(l+2) + a_(l))? Thanks!",2019-05-02T01:11:17Z
UgzPUrJ-4gQv4Cas_MB4AaABAg.8uPkA5BNkVw92LEN8LpBKW,@IvanOrsolic,UgzPUrJ-4gQv4Cas_MB4AaABAg,2,ZILIbUvp5lk,0,2,2019-12-09T23:50:17Z,"You still calculate them, you just keep a copy of the original a_l value and plug it into the network before calculating a[l+2].<br><br>Why would you even do that? It&#39;s explained in the next video",2019-12-09T23:50:17Z
UgzPUrJ-4gQv4Cas_MB4AaABAg.8uPkA5BNkVw9PIN9YQhO01,@mohe4ever514,UgzPUrJ-4gQv4Cas_MB4AaABAg,2,ZILIbUvp5lk,0,0,2021-07-02T13:11:25Z,"@@IvanOrsolic If we plug this value to the network, then what is the benefit of skipping the layers? still we are going through the layers to calculate a[l+2], we just added one more term here but how it helps in skipping the connection ?",2021-07-02T13:11:25Z
Ugw8IkRpdaCF_pMtXa54AaABAg,@HexagonalClosePacked,,1,ZILIbUvp5lk,0,0,2019-04-15T21:56:34Z,I&#39;m trying to understand the components behind Semantic Segmentation and your videos really helped!,2019-04-15T21:56:34Z
Ugw7l7ER-vYa5ixueFt4AaABAg,@kavorkagames,,1,ZILIbUvp5lk,2,0,2019-01-30T18:22:11Z,I find a ResNet behaves as a shallower net. It gives a solution that resembles that of a four to six (roughly) layered net when being eight laters. ResNets are out for me.,2019-01-30T18:22:11Z
Ugw7l7ER-vYa5ixueFt4AaABAg.8qjh0DMdLfn8rcmBjmhroU,@okktok,Ugw7l7ER-vYa5ixueFt4AaABAg,2,ZILIbUvp5lk,0,3,2019-02-21T22:24:09Z,Kavorka Games ResNets are now that state of the art for image recognition. Every new architecture uses it and doesn‚Äôt make sense anymore to use plain networks.,2019-02-21T22:24:09Z
Ugw7l7ER-vYa5ixueFt4AaABAg.8qjh0DMdLfn96lGfcjW0B7,@amir06a,Ugw7l7ER-vYa5ixueFt4AaABAg,2,ZILIbUvp5lk,0,0,2020-03-28T21:55:29Z,"@@okktok  but isn&#39;t the actual layers in play = total layers/2 as we are providing a shortcut?<br>so, on a broader note, they are just like plain networks which looks bigger?",2020-03-28T21:55:29Z
Ugx0RT8eumleLfmKyhp4AaABAg,@joshsmit779,,1,ZILIbUvp5lk,2,159,2019-01-23T03:14:03Z,your videos are iconic and should be preserved in the national library,2019-01-23T03:14:22Z
UgxSWfWT1Xm1V0WqW314AaABAg,@ahmadsaeedkhattak20,,1,RYth6EbBUqM,0,0,2023-09-01T04:47:30Z,"Andrew Ng is a true technologist, soo involved in his lectures that he almost started Kung Fu art @<a href=""https://www.youtube.com/watch?v=RYth6EbBUqM&amp;t=8m47s"">8:47</a> when it sounded like Kung kung kung fu, kung kung kung fu ... üòÜüòÜüòÜ",2023-09-01T04:47:30Z
UgyOyZzQLOjPPW2TxUt4AaABAg,@ahmedb2559,,1,RYth6EbBUqM,0,0,2023-01-09T19:37:34Z,Thank you !,2023-01-09T19:37:34Z
Ugysfo82myRto4-Joyh4AaABAg,@rm175,,1,RYth6EbBUqM,0,0,2022-12-11T05:21:41Z,Just amazing. So clear.,2022-12-11T05:21:41Z
UgzEj0sLR64xDuVuyzl4AaABAg,@anasputhawala6390,,1,RYth6EbBUqM,0,0,2022-12-03T22:45:59Z,"I have a question:<br>You mention that the W matrix and b MAY decay IF we use weight-decay. Isn&#39;t that a big IF though?¬†<br>Like is weight-decay a part of the residual network / skip-connections? In most cases, the W and b will not be decaying to 0, how is residual network / skip-connections useful in those cases?",2022-12-03T22:45:59Z
Ugyvc1_u66oIlVryHl54AaABAg,@mohammedalsubaie3512,,1,RYth6EbBUqM,1,0,2022-11-30T19:19:47Z,"thank you very much Andrew, Could anyone please explain what 3X3 conv means? I would really appreciate that",2022-11-30T19:19:47Z
Ugyvc1_u66oIlVryHl54AaABAg.9j3gV4y1ezm9j3gb79KB0W,@mohammedalsubaie3512,Ugyvc1_u66oIlVryHl54AaABAg,2,RYth6EbBUqM,0,0,2022-11-30T19:20:45Z,do you mean 3x3 filters?,2022-11-30T19:20:45Z
UgwjkkfTUQzLXi1E2nZ4AaABAg,@43SunSon,,1,RYth6EbBUqM,1,1,2022-11-04T15:41:41Z,"Question: let‚Äôs assume I do have an identity function learned, then a[l+2] = a [l], then what? I feel like we are doing f(x) + 0 = f(x), what‚Äôs the point of ‚Äúadding nothing‚Äù? Since I am not following here, I can‚Äôt tell why Residual Networks is good for deeper NN training.",2022-11-04T15:41:41Z
UgwjkkfTUQzLXi1E2nZ4AaABAg.9i0LrsYpowe9nTiv_lz7FH,@kartikeyakhare5089,UgwjkkfTUQzLXi1E2nZ4AaABAg,2,RYth6EbBUqM,0,2,2023-03-20T08:06:51Z,"The residual block ensures that our layer at least learns the output from the previous layer, so the performance doesn&#39;t get worse. This is helpful because the plain networks often struggle to learn even the identity mapping with increased depth, leading to worse performance.",2023-03-20T08:06:51Z
Ugxqz_xvo1pH9PHsGPN4AaABAg,@RH-mk3rp,,1,RYth6EbBUqM,0,1,2022-10-07T02:25:11Z,"so if the input encounters a skip connection route, does it take both or does it always take the skip connection? If it&#39;s the latter case then what&#39;s the point in even including all those skipped layers?",2022-10-07T02:25:11Z
UgxkV6cMuj-dkOp-J0R4AaABAg,@heejuneAhn,,1,RYth6EbBUqM,0,1,2022-08-10T07:21:52Z,The L2 regularization is a kind of mandatory?,2022-08-10T07:21:52Z
UgzEyDDjGYzbbqEwboV4AaABAg,@heejuneAhn,,1,RYth6EbBUqM,0,0,2022-08-10T07:18:11Z,Still I cannot get the intuition why Skip connection works better.  It seems still experimental to me.  ^^;,2022-08-10T07:18:11Z
UgyB_7XPjoWTnKFSnnt4AaABAg,@patrickyu8470,,1,RYth6EbBUqM,0,0,2022-07-28T01:20:52Z,"(copied from the previous video in series) Just a question for those out there - has anyone been able to use techniques from ResNets to improve the convergence speed of deep fully connected networks? Usually people use skip connections in the context of convolutional neural nets but I haven&#39;t seen much gain in performance with fully connected ResNets, so just wondering if there&#39;s something else I may be missing.",2022-07-28T01:20:52Z
UgxQMGTQCjUVhFit53N4AaABAg,@6884,,1,RYth6EbBUqM,0,0,2022-01-13T18:10:25Z,"am I the only one that thought that the pointer at <a href=""https://www.youtube.com/watch?v=RYth6EbBUqM&amp;t=0m55s"">0:55</a> was actually a bug on their screen?",2022-01-13T18:10:25Z
UgyFmxyv4yRQrGvOQWF4AaABAg,@muzeroj173,,1,RYth6EbBUqM,1,3,2021-12-17T16:01:12Z,"watched 3 times,during past 2 year, each time learn something new!",2021-12-17T16:01:12Z
UgyFmxyv4yRQrGvOQWF4AaABAg.9W3G82EjDRb9dMBLnxKhKB,@ShubhamKumar-me7xy,UgyFmxyv4yRQrGvOQWF4AaABAg,2,RYth6EbBUqM,0,0,2022-07-11T20:36:06Z,or each time you didn&#39;t listen to him carefully?,2022-07-11T20:36:06Z
UgzY7U2G02yNvmgPSQV4AaABAg,@hackercop,,1,RYth6EbBUqM,0,0,2021-11-14T16:57:13Z,Thanks Andrew! now I understand it.,2021-11-14T16:57:13Z
Ugwv2GCiJEeYnbR8g414AaABAg,@ruchirjain1163,,1,RYth6EbBUqM,0,3,2021-10-23T12:41:27Z,"Wow my lecturer made such a mess to explain why the layers just learn identity mapping, this was much easier to understand",2021-10-23T12:41:27Z
Ugz6T2_9gsxcyUZiq_R4AaABAg,@anirudhgangadhar6158,,1,RYth6EbBUqM,2,1,2021-09-17T17:32:32Z,"&quot;Residual networks can easily learn the identity function&quot; - but isn&#39;t this true only when the weights and biases are 0? In the real situation, why would this happen? Its not making sense to me why you would skip connections and have the learned weights go to &quot;0&quot;. If someone could please clarify this, I would be extremely grateful.",2021-09-17T17:32:32Z
Ugz6T2_9gsxcyUZiq_R4AaABAg.9SP6FS_PF_h9XlOckIE7dl,@user-cp5qh5uc9n,Ugz6T2_9gsxcyUZiq_R4AaABAg,2,RYth6EbBUqM,0,0,2022-01-29T01:12:39Z,"It essentially means that the residual layer can easily learn the identity function over the input by setting the weights to zero. This leads to layer giving an output that is at least NOT WORSE than the output of the previous layer. On the other hand, plain networks may struggle to learn the identity mapping and as a result can lead to worse performance with increasing layers.",2022-01-29T01:12:39Z
Ugz6T2_9gsxcyUZiq_R4AaABAg.9SP6FS_PF_h9Y8pukZZfLm,@derekthompson2301,Ugz6T2_9gsxcyUZiq_R4AaABAg,2,RYth6EbBUqM,0,0,2022-02-07T13:01:32Z,Hi did you figure it out ? I&#39;m stuck at it now :(,2022-02-07T13:01:32Z
UgzSOFEAd1LLij_ZmnB4AaABAg,@firstpenguin5653,,1,RYth6EbBUqM,0,1,2021-07-06T13:38:13Z,Thanks! This is why ResNet at the same time Andrew works!,2021-07-06T13:38:13Z
UgwuC26j1nXRk9gf6WR4AaABAg,@robingutsche1117,,1,RYth6EbBUqM,1,3,2021-05-05T22:48:34Z,"In case we learn something useful in g(w[l+2] x a[l+1]+ b[l+2]), isnt it possible that adding the activations of the previous layer a[l] can actually decrease performance? So in that case a plain network would do a better job?",2021-05-05T22:50:35Z
UgwuC26j1nXRk9gf6WR4AaABAg.9Mz36-4YQcq9YQCt2OtM6E,@zxynj,UgwuC26j1nXRk9gf6WR4AaABAg,2,RYth6EbBUqM,0,1,2022-02-14T06:58:07Z,"I guess if the performance is worse, then w and b will be 0 and nothing is learned. al is preserved through the &#39;game progress saving&#39; technique, so al+2 is at least as good as al",2022-02-14T06:58:27Z
UgzQ_RS3z_7BjbMBX8B4AaABAg,@user-ok6hr3ld9h,,1,RYth6EbBUqM,0,1,2021-04-20T10:29:28Z,i love this video! thanks professor andrew!!,2021-04-20T10:29:28Z
Ugw0YjKT8nSIfjqUiXB4AaABAg,@iammakimadog,,1,RYth6EbBUqM,0,13,2021-03-20T16:26:48Z,"The residual block guarantees that at least your deep NN performs as well as shallow one, so there&#39;s no reason to train a shallow NN rather than deep NN because theoritcailly deeper NN outperforms shallower NN.",2021-03-20T16:26:48Z
UgzYi98HE5CQUAg_9O14AaABAg,@sandipansarkar9211,,1,RYth6EbBUqM,0,0,2021-01-03T19:30:27Z,very good explantion.Need to watch again,2021-01-03T19:30:27Z
Ugyttpd6SzQtvN-ZyWZ4AaABAg,@paulcurry8383,,1,RYth6EbBUqM,2,0,2021-01-02T22:37:38Z,"I‚Äôm still left wondering, why is it good to learn the identity? A lot of videos I see just say ‚Äúthe identity is good to learn‚Äù but I don‚Äôt intuitively see why a model would want to learn that, and why the inability to learn the identity causes instability in deeper networks.",2021-01-02T22:37:38Z
Ugyttpd6SzQtvN-ZyWZ4AaABAg.9I1K4H9GZA99IYTOWldH4Z,@MrBemnet1,Ugyttpd6SzQtvN-ZyWZ4AaABAg,2,RYth6EbBUqM,0,2,2021-01-15T19:33:58Z,if the network learns identity then at least adding additional layers will not decrease performance.,2021-01-15T19:33:58Z
Ugyttpd6SzQtvN-ZyWZ4AaABAg.9I1K4H9GZA99RXkPggZ6wX,@frasergilbert2949,Ugyttpd6SzQtvN-ZyWZ4AaABAg,2,RYth6EbBUqM,0,0,2021-08-27T05:34:43Z,"@@MrBemnet1 That make sense. But by adding more layers, is the extra ReLU functions at the end the only difference? This is compared to having a shallow layer.",2021-08-27T05:34:43Z
UgyVBXk1sU0pLtmZlqR4AaABAg,@baranaldemir5570,,1,RYth6EbBUqM,3,1,2020-12-26T21:48:15Z,"Can someone please correct me if I&#39;m wrong? As far as I understand if L2 regularization(weight decay) causes z[L+2] to become 0. Relu just carries a[L] to the next layer. Otherwise, it learns from both z[L+2] and a[L]. So, it bypass the vanishing gradient problem but increases the exploding gradient problem Am I right?",2020-12-26T22:07:10Z
UgyVBXk1sU0pLtmZlqR4AaABAg.9HkCrWe0e9C9Q8FoUNh-7J,@user-cg7ut9lj3e,UgyVBXk1sU0pLtmZlqR4AaABAg,2,RYth6EbBUqM,0,0,2021-07-23T11:26:13Z,I also have this question,2021-07-23T11:26:13Z
UgyVBXk1sU0pLtmZlqR4AaABAg.9HkCrWe0e9C9TM981v-WH8,@karatuno,UgyVBXk1sU0pLtmZlqR4AaABAg,2,RYth6EbBUqM,0,0,2021-10-11T10:31:25Z,same question,2021-10-11T10:31:25Z
UgyVBXk1sU0pLtmZlqR4AaABAg.9HkCrWe0e9C9Y8qo2ZlZYb,@derekthompson2301,UgyVBXk1sU0pLtmZlqR4AaABAg,2,RYth6EbBUqM,0,0,2022-02-07T13:09:22Z,same here,2022-02-07T13:09:22Z
UgyKeW20CQi4nALzQlV4AaABAg,@MuhannadGhazal,,1,RYth6EbBUqM,1,0,2020-12-07T20:00:03Z,what is a weight decay? anyone please help. thanks..,2020-12-07T20:00:03Z
UgyKeW20CQi4nALzQlV4AaABAg.9Gz5NLo9rAZ9HkBPIFU620,@baranaldemir5570,UgyKeW20CQi4nALzQlV4AaABAg,2,RYth6EbBUqM,0,0,2020-12-26T21:35:32Z,L2 regularization,2020-12-26T21:35:32Z
Ugz4CXyczUTCzhFm5dp4AaABAg,@elgs1980,,1,RYth6EbBUqM,2,0,2020-09-15T12:30:42Z,"If a layer is meant to be skipped, why was it there in the first place?",2020-09-15T12:30:42Z
Ugz4CXyczUTCzhFm5dp4AaABAg.9DcZyeP28xE9DlNG-KIQD7,@mufaddalkanpurwala462,Ugz4CXyczUTCzhFm5dp4AaABAg,2,RYth6EbBUqM,0,3,2020-09-18T22:32:47Z,"If the residual block has not learnt anything or is not useful, regularisation will help negate the effect of that layer and help bypass the previous activations thereby not sacrificing the performance of the layer.<br>If the residual block has learnt something useful, even after regularisation, the knowledge learnt is stored plus the activations from the previous layer are also added, thereby not sacrificing the performance of the layer.<br>So, it helps you keep deep layers with its ability to learn and not learn information.",2020-09-18T22:32:47Z
Ugz4CXyczUTCzhFm5dp4AaABAg.9DcZyeP28xE9Y8sbe5f-vL,@derekthompson2301,Ugz4CXyczUTCzhFm5dp4AaABAg,2,RYth6EbBUqM,0,0,2022-02-07T13:25:09Z,"‚Äã@@mufaddalkanpurwala462 Hi, thanks for your explain. There&#39;re some points I&#39;m still not clear:<br>- l2 regularisation makes W close to 0 but not exactly 0. Moreover, W is a matrix so it&#39;s very unlikely for all elements in it to be 0. So how is the layer skipped ?<br>- Why would we want add activations from previous layer with knowledge learned ? why adding them won&#39;t sacrificing the performance of the layer ?<br>Hope you can help me with this, thanks a lot !",2022-02-07T13:33:14Z
UgzNbJ8PtE4Mt8kMyXp4AaABAg,@Ashokkumar-ds1nq,,1,RYth6EbBUqM,1,0,2020-07-25T06:17:39Z,"But we can also take w and b as 1 so that a[l+1]=a[l] and a[l+2]=a[l+1]. By doing so, we can get identity function without ResNets. Isn&#39;t it?",2020-07-25T06:17:39Z
UgzNbJ8PtE4Mt8kMyXp4AaABAg.9BX-wqK7Jgo9E1dE88A-s5,@5paceb0i,UgzNbJ8PtE4Mt8kMyXp4AaABAg,2,RYth6EbBUqM,0,0,2020-09-25T15:28:10Z,@Sunny kumar you can&#39;t explicitly make w and b as 1.. they are set by the gradient descent algo... If you are confused ‚Äúthen how w can become 0 ?‚Äù  it is possible by applying l1 regularisation ( read about this ),2020-09-25T15:28:10Z
UgwqCDO7bPC7JLVeHel4AaABAg,@kartiksirwani4657,,1,RYth6EbBUqM,1,104,2020-02-27T05:51:24Z,what a teacher he is ...watching his video is equivalent to reading 10 articles and watching 100 videos,2020-02-27T05:51:24Z
UgwqCDO7bPC7JLVeHel4AaABAg.95XIVB_g-eO9veb1bYgUpR,@piyushkumar-wg8cv,UgwqCDO7bPC7JLVeHel4AaABAg,2,RYth6EbBUqM,0,0,2023-10-09T18:59:56Z,You are high on ML.,2023-10-09T18:59:56Z
Ugyw9t0PD9-bIIIGPfd4AaABAg,@shuyuwang4867,,1,RYth6EbBUqM,2,0,2020-02-05T15:28:47Z,Why does the filter number double after pooling is applied? Any suggestion.,2020-02-05T15:28:47Z
Ugyw9t0PD9-bIIIGPfd4AaABAg.94eg4oWdE_m95hspjliQEA,@snippletrap,Ugyw9t0PD9-bIIIGPfd4AaABAg,2,RYth6EbBUqM,0,2,2020-03-02T17:49:18Z,"The dimension of the image is reduced. Pooling allows the network to learn more features over a larger window of the image, at the cost of lower resolution.",2020-03-02T17:49:56Z
Ugyw9t0PD9-bIIIGPfd4AaABAg.94eg4oWdE_m96ZeyO2dL0P,@shuyuwang4867,Ugyw9t0PD9-bIIIGPfd4AaABAg,2,RYth6EbBUqM,0,0,2020-03-24T00:26:22Z,@@snippletrap thank u. Very good explanation,2020-03-24T00:26:22Z
Ugz-f2wpkjTKwxu3C3h4AaABAg,@billykotsos4642,,1,RYth6EbBUqM,1,10,2020-02-02T14:22:59Z,Finally it clicks in my head. Thanks Andrew !!!,2020-02-02T14:22:59Z
Ugz-f2wpkjTKwxu3C3h4AaABAg.94XqAErCkk59JZdBNAJZec,@trexmidnite,Ugz-f2wpkjTKwxu3C3h4AaABAg,2,RYth6EbBUqM,0,0,2021-02-10T02:58:56Z,Your brain clicks?,2021-02-10T02:58:56Z
Ugy4_EFr2sdVaXXO-u54AaABAg,@razorphone77,,1,RYth6EbBUqM,1,11,2019-12-19T15:18:11Z,"I don&#39;t really understand what he means when he says the identity function is easy for the residual block to learn. It&#39;s not really learnt anything if all we do is append the initial input to the end. Given that we&#39;re saying the conv blocks are effectively superfluous because the weights are close to zero, I can&#39;t see what&#39;s gained in the whole process. We just appear to have extra calculation for the sake of it when we already have the output of layer a(l)",2019-12-19T15:18:11Z
Ugy4_EFr2sdVaXXO-u54AaABAg.92j3iDCebH393MiaWkgOy2,@SuperVaio123,Ugy4_EFr2sdVaXXO-u54AaABAg,2,RYth6EbBUqM,0,15,2020-01-04T10:13:46Z,Basically the baseline here is that you&#39;re trying to hopefully improve performance. In your worst case scenario the deeper layers dont learn anything and het your performance doesnt take a hit thanks to your skip connections. But in most cases these layers will learn something too that can only help improve performance. So yes although there are a lot of extra calculations you might get better performance. Again depends on application and trade offs,2020-01-04T10:13:46Z
UgxCAPePw8K6S-OKitx4AaABAg,@jorjiang1,,1,RYth6EbBUqM,0,1,2019-11-11T19:15:45Z,"so does it mean that resnet models must to train with a certain degree of weight decay for it to make sense, otherwise it is just equivalent to a plain network",2019-11-11T19:16:05Z
Ugza2Mk2Z_3n72ylTrN4AaABAg,@subhamjha8917,,1,c1RBQzKsDCk,0,0,2023-10-13T13:35:23Z,In what situations is it useful? Can you please provide some case study/example.,2023-10-13T13:35:23Z
Ugx4QNNY0tBTWAug59N4AaABAg,@MabrookAlas,,1,c1RBQzKsDCk,0,0,2023-09-27T20:12:20Z,Great üëçüèº,2023-09-27T20:12:20Z
UgwyzW6L9tNahgY0qp14AaABAg,@katyhessni,,1,c1RBQzKsDCk,0,0,2023-06-23T14:15:19Z,Thanks,2023-06-23T14:15:19Z
UgylF9bPOiXEr5csKUB4AaABAg,@computerlifesupport,,1,c1RBQzKsDCk,0,0,2022-12-08T04:08:18Z,thaanks (‚åê‚ñ†_‚ñ†),2022-12-08T04:08:18Z
UgytMRlNe5YaVQTPWiF4AaABAg,@urarakono442,,1,c1RBQzKsDCk,1,0,2022-11-12T22:45:49Z,Does the yellow block of size 1*1*32 have the same numbers over 32 voxels?,2022-11-12T22:45:49Z
UgytMRlNe5YaVQTPWiF4AaABAg.9iLhlHnRF0H9on6wTr3VXR,@MrAmgadHasan,UgytMRlNe5YaVQTPWiF4AaABAg,2,c1RBQzKsDCk,0,0,2023-04-22T02:41:38Z,No. It can have 32 different weights.,2023-04-22T02:41:38Z
UgyDn0fO8euP9wL_lSN4AaABAg,@devstuff2576,,1,c1RBQzKsDCk,2,1,2022-04-28T17:23:30Z,This is HORRIBLE!,2022-04-28T17:23:30Z
UgyDn0fO8euP9wL_lSN4AaABAg.9aNIUKDy3Kx9cWorOFfY02,@waltere.poquioma3251,UgyDn0fO8euP9wL_lSN4AaABAg,2,c1RBQzKsDCk,0,0,2022-06-21T03:11:05Z,Do you mean a horrible explanation or a horrible architecture?,2022-06-21T03:11:38Z
UgyDn0fO8euP9wL_lSN4AaABAg.9aNIUKDy3Kx9djrmjZgNfp,@gumbo64,UgyDn0fO8euP9wL_lSN4AaABAg,2,c1RBQzKsDCk,0,0,2022-07-21T10:37:26Z,@@waltere.poquioma3251 cursed machine learning,2022-07-21T10:37:26Z
Ugw-PmneNqtqdDziIzp4AaABAg,@siddhantvats9088,,1,c1RBQzKsDCk,0,1,2021-10-11T08:45:29Z,"Curious if we use filters any some other dim but less channel, won&#39;t it reduce the resulting channel?",2021-10-11T08:45:29Z
UgxptO7iYfySYbbmeCl4AaABAg,@trexmidnite,,1,c1RBQzKsDCk,0,0,2021-02-10T10:35:38Z,Scary movie,2021-02-10T10:35:38Z
UgzeCxNwnn4FgX9Kunh4AaABAg,@sandipansarkar9211,,1,c1RBQzKsDCk,0,0,2021-01-04T15:30:22Z,good explanation,2021-01-04T15:30:22Z
Ugwsdr48H01fT5T_j-h4AaABAg,@lennonli9100,,1,c1RBQzKsDCk,0,3,2020-06-16T16:43:21Z,isnt it just a regular filter with 1by1 dimension that is not used for edge detection but change filter dimension or add non linearity?,2020-06-16T16:43:21Z
UgzPaYDFVTn3T69qriR4AaABAg,@MeAndCola,,1,c1RBQzKsDCk,2,1,2019-10-29T00:43:11Z,"Is this also the case for normal sized filters too? Filters aren&#39;t applied over 2D&#39;ally, for each channel, but rather 3D&#39;ally, over the entire channels?",2019-10-29T00:43:11Z
UgzPaYDFVTn3T69qriR4AaABAg.90eB1tqNwyU97Bf1XEEdgD,@XxXMrGuiTarMasTerXxX,UgzPaYDFVTn3T69qriR4AaABAg,2,c1RBQzKsDCk,0,0,2020-04-08T13:16:34Z,"As far as I understood, yeah. But I think sometimes (specially at the beginning of the network) the filter is shared over the three channels RGB. This is, instead of, for example, a 3x3x3 filter, you only have a 3x3x1 filter and the parameters are shared. However, this is a trick, and the filters are applied in 3D",2020-04-08T13:16:34Z
UgzPaYDFVTn3T69qriR4AaABAg.90eB1tqNwyU9on7B-YLrWL,@MrAmgadHasan,UgzPaYDFVTn3T69qriR4AaABAg,2,c1RBQzKsDCk,0,0,2023-04-22T02:43:45Z,"Yes. Every filter in a cnn will have 3 dimensions (height, width, depth) with depth being equal to the depth of the input features maps.",2023-04-22T02:43:45Z
UgwPMriPrRiK4saqw9N4AaABAg,@nikhilrana8800,,1,c1RBQzKsDCk,2,2,2019-10-15T18:37:21Z,"When we multiply 1*1*32 filter with 6*6*32 then no. after multiplied we get for all the 32 channels, we have to take the sum and then apply the relu function to it. Is I am right??",2019-10-15T18:38:00Z
UgwPMriPrRiK4saqw9N4AaABAg.9072q2CC_IL92x51sgEAWz,@sammathew243,UgwPMriPrRiK4saqw9N4AaABAg,2,c1RBQzKsDCk,0,1,2019-12-25T01:59:07Z,Yes,2019-12-25T01:59:07Z
UgwPMriPrRiK4saqw9N4AaABAg.9072q2CC_IL9SwoM900g9R,@shaelanderchauhan1963,UgwPMriPrRiK4saqw9N4AaABAg,2,c1RBQzKsDCk,0,1,2021-10-01T05:00:51Z,@@sammathew243 and relu will be a Number if greater than zero and 0 if no is less or equl to 0 right?,2021-10-01T05:01:23Z
UgwBh3CDdYHTEO70HtJ4AaABAg,@sadenb,,1,c1RBQzKsDCk,1,0,2019-04-23T20:23:05Z,Can a siamese network be done upon 1x1 convolutions  if we have precomputed 1-D features ?,2019-04-23T20:23:05Z
UgwBh3CDdYHTEO70HtJ4AaABAg.8u4cpLCtjfp8zmcS4SJjFu,@sandyz1000,UgwBh3CDdYHTEO70HtJ4AaABAg,2,c1RBQzKsDCk,0,1,2019-09-12T14:22:34Z,You can use inception n/w which uses 1x 1 convolution for computing the embedding for the siamese n/w. Siamese which means same or similar is used in the final layer where constructive loss / triplet loss is used to optimise the loss function so that similar vectors tend to have less distance than dissimilar vectors with certain margins in it.,2019-09-12T14:22:34Z
UgyIrgyWQZrj3ewRiKx4AaABAg,@JagtarSingh-pv9mn,,1,c1RBQzKsDCk,0,3,2019-04-04T00:17:53Z,Is there information sharing happening across the channels in this case?,2019-04-04T00:17:53Z
UgzO6Mifw8HMrd7e5-t4AaABAg,@btobin86,,1,c1RBQzKsDCk,5,7,2019-03-22T21:23:40Z,I&#39;m not quite sure what he means when he says the output is the # of filters. Doesn&#39;t the output of one of those 1 x 1 x 32 (in this case) filters just a single real number?,2019-03-22T21:23:40Z
UgzO6Mifw8HMrd7e5-t4AaABAg.8snLK-0qSFW8tAW2R4lyHz,@chaitragn3379,UgzO6Mifw8HMrd7e5-t4AaABAg,2,c1RBQzKsDCk,0,0,2019-04-01T06:39:09Z,"may be its a channel(R,G,B) and number of filters are different.",2019-04-01T06:40:05Z
UgzO6Mifw8HMrd7e5-t4AaABAg.8snLK-0qSFW8tAcCJd2F8u,@anasfirdousi,UgzO6Mifw8HMrd7e5-t4AaABAg,2,c1RBQzKsDCk,0,2,2019-04-01T07:41:40Z,"The output after applying filter =   ( n - f + 1 ) x  ( n - f + 1 ) x <a href=""http://www.youtube.com/results?search_query=%23of"">#of</a> filters<br><br>n = input dimension which is 6 x 6, so n = .6<br>f = filter dimension which is 1 x 1, so f = 1<br># of filters = 32<br><br>so the final o/p after applying all filters will be:<br><br>( 6 - 1 + 1 ) x ( 6 -1 +1 ) x 32 = 6 x 6 x 32<br><br>The formula n - f + 1 works when stride = 1 , watch : <a href=""https://www.youtube.com/watch?v=smHa2442Ah4&amp;index=4&amp;list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF"">https://www.youtube.com/watch?v=smHa2442Ah4&amp;index=4&amp;list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF</a>",2019-04-01T07:41:40Z
UgzO6Mifw8HMrd7e5-t4AaABAg.8snLK-0qSFW8uuC7hVWJpI,@NikhilAngadBakshi,UgzO6Mifw8HMrd7e5-t4AaABAg,2,c1RBQzKsDCk,0,2,2019-05-14T06:20:48Z,Yes for each filter at each location is a single real number. Therefore for one 1x1 filter the output over all locations in the input image volume is an image with depth=1. Usually we have multiple filters and hence the output depth is equal to the number of filters.,2019-05-14T06:20:48Z
UgzO6Mifw8HMrd7e5-t4AaABAg.8snLK-0qSFW8zmbnTwC1xw,@sandyz1000,UgzO6Mifw8HMrd7e5-t4AaABAg,2,c1RBQzKsDCk,0,3,2019-09-12T14:16:53Z,"( 1 x 1 x 32 ) is the filter volume and <a href=""http://www.youtube.com/results?search_query=%23n"">#n</a> x ( 1 x 1 x 32) where as n = no of filter. The output of ( 1 x 1 x 32) gives a scalar value for each pixel in the 32 input channel and <a href=""http://www.youtube.com/results?search_query=%23n"">#n</a> is the no of channel in the output filter.",2019-09-12T14:16:53Z
UgzO6Mifw8HMrd7e5-t4AaABAg.8snLK-0qSFW9cFmTvMXLC6,@user-ft7bk7yc9n,UgzO6Mifw8HMrd7e5-t4AaABAg,2,c1RBQzKsDCk,0,1,2022-06-14T12:23:11Z,"This is old but I will answer for future viewers - In my understanding the # of filters IS NOT 32, the number of filters will be the number of times you applied different filters of 1X1X32, so if you did 1X1X32 X Z times you will get here 6X6XZ",2022-06-14T12:23:11Z
UgwD8Wx9SEPkrGq5vOR4AaABAg,@EranM,,1,c1RBQzKsDCk,0,0,2019-01-21T11:54:09Z,thsrink!,2019-01-21T11:54:09Z
Ugws1KAs8ZArN9NOx3l4AaABAg,@oktayvosoughi6199,,1,C86ZXvgpejM,1,0,2023-10-09T15:51:49Z,what I can not understand is that how after applying 5x5 or 3x3 filter still we have 28x28 output as we saw in earlier lecture we can found it by nh-2p-f+1/s.,2023-10-09T15:51:49Z
Ugws1KAs8ZArN9NOx3l4AaABAg.9veGVi76EHU9vxzxjH0nWl,@muhammadmaazwaseem7452,Ugws1KAs8ZArN9NOx3l4AaABAg,2,C86ZXvgpejM,0,0,2023-10-17T07:43:18Z,The answer is padding,2023-10-17T07:43:18Z
UgxUelM459qpB11-e8p4AaABAg,@harshniteprasad5301,,1,C86ZXvgpejM,3,1,2023-06-14T09:36:16Z,"<a href=""https://www.youtube.com/watch?v=C86ZXvgpejM&amp;t=7m59s"">7:59</a> the value of the convoluted matrix should be 24*24*32, since the 28*28 when convoluted with a 5*5 filter will return (28-5+1) 24.",2023-06-14T09:36:16Z
UgxUelM459qpB11-e8p4AaABAg.9qwKWik2vvi9rGGTeEyN8p,@aangulog,UgxUelM459qpB11-e8p4AaABAg,2,C86ZXvgpejM,0,1,2023-06-22T12:44:56Z,"Not necessarily, padding can lead to a matrix of the same dimensions.",2023-06-22T12:44:56Z
UgxUelM459qpB11-e8p4AaABAg.9qwKWik2vvi9rGrfs9ORp7,@harshniteprasad5301,UgxUelM459qpB11-e8p4AaABAg,2,C86ZXvgpejM,0,0,2023-06-22T18:18:48Z,"@@aangulog but it wasnt mentioned that we are using padding , yes you are correct tho we can get that output using padding",2023-06-22T18:18:48Z
UgxUelM459qpB11-e8p4AaABAg.9qwKWik2vvi9rHBpxKahNw,@aangulog,UgxUelM459qpB11-e8p4AaABAg,2,C86ZXvgpejM,0,0,2023-06-22T21:23:40Z,"@@harshniteprasad5301 Maybe it&#39;s implied, because you can say the same for the stride.",2023-06-22T21:23:40Z
Ugw_MLNozQXhFScPbTB4AaABAg,@ahmeddrief3103,,1,C86ZXvgpejM,0,0,2023-05-26T19:05:34Z,why did you use max pooling and do the same padding i thoughout the utilization of max pooling is to divide the dimension ??,2023-05-26T19:05:34Z
Ugy6W5yEwEy8Cwqlmmt4AaABAg,@rehabnafea5058,,1,C86ZXvgpejM,0,0,2022-07-20T22:15:57Z,"That was very useful for me, thank you so much",2022-07-20T22:15:57Z
UgyL6zTyoXFyEpyomOF4AaABAg,@mike19558,,1,C86ZXvgpejM,0,0,2022-04-18T15:24:20Z,Really helpful!,2022-04-18T15:24:20Z
Ugxrfofp7RgM5Yocma94AaABAg,@Ghumnewali,,1,C86ZXvgpejM,0,0,2022-04-16T21:14:54Z,Now I gotta watch Inception again.. ü§î,2022-04-16T21:14:54Z
UgyGDsR3frjg_mC77M14AaABAg,@rafibasha4145,,1,C86ZXvgpejM,0,0,2021-12-26T06:37:37Z,"@8:84,why we need to multiply with output  28*28*16 instead of 1*1*192*16",2021-12-26T06:37:37Z
Ugy4hSVt1QfpjzPlAIR4AaABAg,@strongsyedaa7378,,1,C86ZXvgpejM,0,0,2021-11-28T13:10:11Z,Why he&#39;s soo many filters? Can anyone explain me?,2021-11-28T13:10:11Z
UgwjKZ2FoKWMdWZT3dZ4AaABAg,@cexploreful,,1,C86ZXvgpejM,0,0,2021-10-31T00:35:32Z,Andrew is HUGEEE!‚ò∫,2021-10-31T00:36:00Z
UgyZX5nyTcUN0lUZUp54AaABAg,@essamaly5233,,1,C86ZXvgpejM,0,0,2021-09-23T17:34:38Z,"There are some nasty and offensive commercials comes during viewing this video, I think Andrew <b>should</b> do something about it.",2021-09-23T17:34:38Z
UgxjZ2ucziaHGp67rAJ4AaABAg,@anandtewari8014,,1,C86ZXvgpejM,0,0,2021-08-12T16:00:11Z,GREAT SIR,2021-08-12T16:00:11Z
UgwA-M7t2dVvPcMXNVR4AaABAg,@manuel783,,1,C86ZXvgpejM,0,1,2021-01-18T23:47:34Z,"Inception Network Motivation <b>CORRECTION</b><br><br>At <a href=""https://www.youtube.com/watch?v=C86ZXvgpejM&amp;t=3m00s"">3:00</a>, Andrew should have said 28 x 28 x 192 instead of 28 x 28 x 129. The subtitles have been corrected.",2021-01-18T23:47:34Z
UgyvHvK-a2FIAdgsYlB4AaABAg,@shvprkatta,,1,C86ZXvgpejM,0,0,2021-01-15T19:36:41Z,amazing sir..thank you,2021-01-15T19:36:41Z
Ugy5ymJPbg53vPnNJix4AaABAg,@sandipansarkar9211,,1,C86ZXvgpejM,0,0,2021-01-04T15:41:23Z,nice explanation.need to watch again,2021-01-04T15:41:23Z
UgwrYlXZG0GHEmGQMOR4AaABAg,@SuilujChannel,,1,C86ZXvgpejM,0,3,2020-12-09T13:25:59Z,"question regarding the 1x1 conv strategy at <a href=""https://www.youtube.com/watch?v=C86ZXvgpejM&amp;t=6m00s"">6:00</a> <br><br>i understand that this trick reduces the number of parameters. but what i don&#39;t understand is how it is comparable to the original 5x5 conv.<br>from my understand this would create completely different features because it does not use the original input of the layer but the output of the 1x1 conv. So what&#39;s the point?<br><br>Update: Ah okay he mentions this thought at the end of the video. It seems there is no big impact on performance &quot;if you choose the reduction right&quot;.",2020-12-09T13:31:05Z
UgxilhbFTbxnasHjI6l4AaABAg,@gorgolyt,,1,C86ZXvgpejM,2,2,2020-12-08T16:40:22Z,"Absolutely lucid, as ever. üëè",2020-12-08T16:40:22Z
UgxilhbFTbxnasHjI6l4AaABAg.9H0JJlOYaNg9kK-amu2GvC,@moustaphambaye3017,UgxilhbFTbxnasHjI6l4AaABAg,2,C86ZXvgpejM,0,0,2022-12-31T23:54:42Z,P,2022-12-31T23:54:42Z
UgxilhbFTbxnasHjI6l4AaABAg.9H0JJlOYaNg9sECVRbgsXm,@gunbirbaveja1793,UgxilhbFTbxnasHjI6l4AaABAg,2,C86ZXvgpejM,0,0,2023-07-16T14:03:09Z,P,2023-07-16T14:03:09Z
UgzmvFQbU5IMaxL2W5J4AaABAg,@agneljohn6093,,1,C86ZXvgpejM,0,0,2020-08-08T02:46:38Z,When I try to work on Coursera . Artificial intelligence using tensorflow . When I run the. Assignment number 3 . It says kernel died and will restract automatically,2020-08-08T02:46:38Z
Ugzeg8MsKao2Nw_jP_p4AaABAg,@suryanarayanan5158,,1,C86ZXvgpejM,2,4,2020-04-28T06:26:31Z,what does &quot;same&quot; mean? Does it mean have the  same height and width as the previous layer?,2020-04-28T06:26:31Z
Ugzeg8MsKao2Nw_jP_p4AaABAg.97zR-kwba7g9857miz2O6h,@alanamonteiro5381,Ugzeg8MsKao2Nw_jP_p4AaABAg,2,C86ZXvgpejM,0,5,2020-04-30T20:53:16Z,"Exactly, as he mentions, you will need to add padding for that",2020-04-30T20:53:16Z
Ugzeg8MsKao2Nw_jP_p4AaABAg.97zR-kwba7g9C4VABU7mQz,@Joshua-dl3ns,Ugzeg8MsKao2Nw_jP_p4AaABAg,2,C86ZXvgpejM,0,0,2020-08-08T01:03:55Z,"essentially just applies filter, then pads such that the output image has same width and length as the input",2020-08-08T01:03:55Z
Ugyg9IpEq-jbPI5Pe7p4AaABAg,@kirandeepsingh9144,,1,C86ZXvgpejM,4,0,2020-04-17T15:14:35Z,I have a question. Let At first convolution layer if we apply 32 filters on a gray scale image then output of first layer would be 32 matrixes or say 32 filtered images. Then at second layer if we are applying 64 filters then does it mean that we are applying 64 different filters over each of 32 filtered images???? And output of second layer would be 64*32=2048 filtered images???. Plz let it clear if anyone can,2020-04-17T15:14:35Z
Ugyg9IpEq-jbPI5Pe7p4AaABAg.97Z2gqFv_aE9FoMHf26AmT,@manu1983manoj,Ugyg9IpEq-jbPI5Pe7p4AaABAg,2,C86ZXvgpejM,0,0,2020-11-08T19:24:47Z,you apply filter for feature extraction and not to recreate filtered images,2020-11-08T19:24:47Z
Ugyg9IpEq-jbPI5Pe7p4AaABAg.97Z2gqFv_aE9FoilxNQZRR,@kirandeepsingh9144,Ugyg9IpEq-jbPI5Pe7p4AaABAg,2,C86ZXvgpejM,0,0,2020-11-08T22:50:02Z,@@manu1983manoj then what would it be?,2020-11-08T22:50:02Z
Ugyg9IpEq-jbPI5Pe7p4AaABAg.97Z2gqFv_aE9FpQHr-q2hd,@manu1983manoj,Ugyg9IpEq-jbPI5Pe7p4AaABAg,2,C86ZXvgpejM,0,0,2020-11-09T05:19:00Z,@@kirandeepsingh9144 based on filters it will extract features which will give you scaled down martrices. Dimesnsions will depend on the filter dimensions.,2020-11-09T05:19:00Z
Ugyg9IpEq-jbPI5Pe7p4AaABAg.97Z2gqFv_aE9ffNVNvR6HD,@sahajpareek6352,Ugyg9IpEq-jbPI5Pe7p4AaABAg,2,C86ZXvgpejM,0,0,2022-09-07T09:49:52Z,"The 64 filters must have a lower dimensionality than the 32 activation maps...A simple rule is that when you decrease the dimensionality of a filter the no. of activation maps(outputs) from that filter increases keeping in mind a constant stride is taken into account. Basically to extract more precise features out of the input activation maps, you increase the no. of filters and reduce their dimensionality.",2022-09-07T09:51:45Z
UgwdykCAYBliInQtbAF4AaABAg,@fumihio,,1,C86ZXvgpejM,7,8,2019-12-11T01:00:09Z,"How to choose the number of filters? <a href=""https://www.youtube.com/watch?v=C86ZXvgpejM&amp;t=3m50s"">3:50</a><br>Why 1x1 uses 64, 3x3 uses 128, and so on?",2019-12-11T01:00:09Z
UgwdykCAYBliInQtbAF4AaABAg.92Nw9gIRIl694Uzi63I0P_,@akashkewar,UgwdykCAYBliInQtbAF4AaABAg,2,C86ZXvgpejM,0,9,2020-02-01T11:48:40Z,"well, there is no hard rule for that, Rule of thumb is, More the number of filters, More feature you are extracting. Also, keep in mind, not all the features are important (some people think more the features are better the model will be, this is not true at all) and this could lead to overfitting and computational overhead. And It is totally problem-specific (choosing filter size). It is hyper-parameter in itself. Lastly, You could do a hyper-parameter search to get the best filter size (that would be insane because you have multiple layers and each layer has a filter).",2020-02-01T11:52:04Z
UgwdykCAYBliInQtbAF4AaABAg.92Nw9gIRIl69Psr5nw0Joi,@tanhoang1022,UgwdykCAYBliInQtbAF4AaABAg,2,C86ZXvgpejM,0,0,2021-07-17T02:33:41Z,you can change P(padding) to have the same 28x28,2021-07-17T02:33:41Z
UgwdykCAYBliInQtbAF4AaABAg.92Nw9gIRIl69YrEM9EYzuw,@gourabmukhopadhyay7211,UgwdykCAYBliInQtbAF4AaABAg,2,C86ZXvgpejM,0,0,2022-02-25T04:09:42Z,"@@akashkewar Hey, could you explain how come 28*28 remains to be 28*28 after 3*3 filters and also for others? I get for 1*1 it remains to be 28*28 as it is (28-1+1)=<a href=""http://28.in/"">28.In</a> the similar manner is not it like( 28-3+1)=26 for 3*3?",2022-02-25T04:09:42Z
UgwdykCAYBliInQtbAF4AaABAg.92Nw9gIRIl69ZJoV6lhxRD,@RohanPaul-AI,UgwdykCAYBliInQtbAF4AaABAg,2,C86ZXvgpejM,0,2,2022-03-08T15:52:12Z,"@@gourabmukhopadhyay7211  Good point indeed.  <br><br>And this ( 28*28 remains to be 28*28 after 3*3 filters ) is done, by setting padding=&#39;same&#39;.<br><br>So every time the output shape will be 28 * 28.<br><br>Checkout out below code see the result.<br><br><br>```py<br><br>from keras.layers import Conv2D<br>from keras.models import Sequential<br><br>models = Sequential()<br><br>models.add(Conv2D(32, kernel_size=(3, 3), activation=&#39;relu&#39;, input_shape=(28, 28, 192), padding=&#39;same&#39;))<br><br>models.add(Conv2D(64, kernel_size=(3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;))<br><br>models.add(Conv2D(128, kernel_size=(3, 3), activation=&#39;relu&#39;, padding=&#39;same&#39;))<br><br>models.summary()<br><br>```<br><br>OUTPUT<br><br>```<br>Model: &quot;sequential_1&quot;<br><i>_______________________________________________________________</i><br> Layer (type)                Output Shape              Param #<br>=================================================================<br> conv2d_3 (Conv2D)           (None, 28, 28, 32)        55328<br><br> conv2d_4 (Conv2D)           (None, 28, 28, 64)        18496<br><br> conv2d_5 (Conv2D)           (None, 28, 28, 128)       73856<br><br>=================================================================<br>Total params: 147,680<br>Trainable params: 147,680<br>Non-trainable params: 0<br><i>_______________________________________________________________</i><br><br>```",2022-03-08T15:53:57Z
UgwdykCAYBliInQtbAF4AaABAg.92Nw9gIRIl69ZK2CNcGwSz,@gourabmukhopadhyay7211,UgwdykCAYBliInQtbAF4AaABAg,2,C86ZXvgpejM,0,1,2022-03-08T18:00:43Z,"@@RohanPaul-AI Yes, I also figured that out that padding was same. But still thank you for making  time to comment here as it helped me to confirm.",2022-03-08T18:00:43Z
UgwI8E4P7peP26TuaN14AaABAg,@kivique519,,1,C86ZXvgpejM,2,4,2019-06-14T06:07:32Z,Why the output dimension is still 28*28,2019-06-14T06:07:32Z
UgwI8E4P7peP26TuaN14AaABAg.8w9-F_tXYTH8y58F9A-QB9,@justforfun4680,UgwI8E4P7peP26TuaN14AaABAg,2,C86ZXvgpejM,0,3,2019-08-01T11:11:56Z,Same Padding. You add the exact amount of padding so that your output dimension is the same as your input,2019-08-01T11:11:56Z
UgwI8E4P7peP26TuaN14AaABAg.8w9-F_tXYTH9E-PWOuVFkU,@valentinfontanger4962,UgwI8E4P7peP26TuaN14AaABAg,2,C86ZXvgpejM,0,1,2020-09-24T18:41:06Z,@@justforfun4680 I also think so,2020-09-24T18:41:06Z
Ugz8sRXOEJSAFc2YYGh4AaABAg,@rushiagrawal9667,,1,C86ZXvgpejM,0,1,2019-06-01T07:28:02Z,Would have been nice if a comparison of computations required for 1x1 and 3x3 convolutions were provided,2019-06-01T07:28:02Z
UgwwKigkdmcGmkGQyNp4AaABAg,@marimbanation4118,,1,C86ZXvgpejM,2,23,2019-05-21T06:08:26Z,give this guy a good mic,2019-05-21T06:08:26Z
UgwwKigkdmcGmkGQyNp4AaABAg.8vBCH9xOJJ49GAEXzQlgsC,@aniketchavan6392,UgwwKigkdmcGmkGQyNp4AaABAg,2,C86ZXvgpejM,0,0,2020-11-17T16:39:38Z,üòÖ,2020-11-17T16:39:38Z
UgwwKigkdmcGmkGQyNp4AaABAg.8vBCH9xOJJ49LiAFhW0TCO,@niyazahmad9133,UgwwKigkdmcGmkGQyNp4AaABAg,2,C86ZXvgpejM,0,0,2021-04-04T12:52:34Z,ü§£lamo,2021-04-04T12:52:34Z
Ugx25tDzZoLqyGtrRQd4AaABAg,@pallawirajendra,,1,C86ZXvgpejM,1,1,2019-02-05T18:06:30Z,He keeps skipping most of the topics.,2019-02-05T18:06:30Z
Ugx25tDzZoLqyGtrRQd4AaABAg.8qz6zc6Bd008rCpk-kHAyH,@kushalmahindrakar8580,Ugx25tDzZoLqyGtrRQd4AaABAg,2,C86ZXvgpejM,0,1,2019-02-11T11:15:41Z,"No, he does not skip any topics. These videos are from coursera and have questions in between the videos so that is the reason there are cuts between the video.",2019-02-11T11:15:41Z
Ugye5fReyPJkE7fqSMh4AaABAg,@YigitMesci,,1,C86ZXvgpejM,5,1,2019-01-20T17:31:50Z,"What i dont understand is how an input image could have 192 multiple channels..? Is there a common type of  usage where inputs are not only consist of R, G and B channels?",2019-01-20T17:31:50Z
Ugye5fReyPJkE7fqSMh4AaABAg.8qKrIePNLti8qLhXgMgbr4,@kartikmadhira,Ugye5fReyPJkE7fqSMh4AaABAg,2,C86ZXvgpejM,0,4,2019-01-21T01:25:44Z,"I think the input layer he is talking about is the inception module that resides somewhat deeper in the inception network. If you look closely to the overall inception model, there is a lot of hidden layers before this model kicks in. So it&#39;s actually the &#39;general&#39; inception model that he is talking about rather than the overall architecture itself.",2019-01-21T01:25:44Z
Ugye5fReyPJkE7fqSMh4AaABAg.8qKrIePNLti8quY72PeqeD,@ANOUBHAVAGARWAALbeb,Ugye5fReyPJkE7fqSMh4AaABAg,2,C86ZXvgpejM,0,4,2019-02-03T23:27:23Z,"I think channels is a more general term .The input to first layer has 3 channels, which are actually the the numpy arrays corresponding to R, G and B respectively. However, in the later layers we have many channels, each channel corresponds to the output from separate kernels. The channels represent the feature extracted from the image by the kernels.",2019-02-03T23:27:23Z
Ugye5fReyPJkE7fqSMh4AaABAg.8qKrIePNLti8rCqN6-EqRz,@kushalmahindrakar8580,Ugye5fReyPJkE7fqSMh4AaABAg,2,C86ZXvgpejM,0,0,2019-02-11T11:21:10Z,"If you are familiar with the idea of edge detectors, then these 192 multiple channels are used to detect<br>many different features from the image or in other word extract features. I guess you are watching the videos from the middle I suggest you, go through the whole playlist and watch videos one by one.",2019-02-11T11:21:10Z
Ugye5fReyPJkE7fqSMh4AaABAg.8qKrIePNLti8uwq0YVv5YW,@angelachikaebirim8894,Ugye5fReyPJkE7fqSMh4AaABAg,2,C86ZXvgpejM,0,1,2019-05-15T06:56:34Z,Also don&#39;t forget that this 28x28x192 input could be the concatenated output from the previous inception module and probably occurs quite deep in the model so that&#39;s why the number of channels is high,2019-05-15T06:56:34Z
Ugye5fReyPJkE7fqSMh4AaABAg.8qKrIePNLti9yC-4ZqZVy-,@codderrrr606,Ugye5fReyPJkE7fqSMh4AaABAg,2,C86ZXvgpejM,0,0,2023-12-11T20:35:46Z,I was having the same doubt but here 192 represents the the concatenation of results from different kernals passed over the image,2023-12-11T20:35:46Z
Ugzd6kbfSk2knnNnvAF4AaABAg,@marcocaceres4867,,1,KfV8CJh7hE0,0,0,2023-08-23T06:39:16Z,How small the number of filters have to be in the 1 x 1 convolution? Why 192 -&gt; 16 -&gt; 32 instead of 192 -&gt; 1 -&gt; 32?,2023-08-23T06:39:16Z
UgwukvxIt5St0S6kbo14AaABAg,@sinarokhideh6794,,1,KfV8CJh7hE0,0,0,2022-11-23T15:41:25Z,Thanks a lot for sharing this.,2022-11-23T15:41:25Z
UgwJfSIUOTO2RtBlhKx4AaABAg,@alex_316,,1,KfV8CJh7hE0,0,0,2022-11-08T09:34:29Z,This looks like an autoML but for the Conv NN,2022-11-08T09:34:29Z
UgxzrNpF7O6Ku9AX2cN4AaABAg,@strongsyedaa7378,,1,KfV8CJh7hE0,0,0,2021-11-28T13:37:42Z,I haven&#39;t understood üòï <br>Why we are using different filters?,2021-11-28T13:37:42Z
Ugz1CICjxRb5F2clC7B4AaABAg,@shaelanderchauhan1963,,1,KfV8CJh7hE0,1,0,2021-10-01T12:21:10Z,What is the purpose of using Maxpooling if we are not reducing the height and width of the dimension? I guess in previous lectures Andrew Ng said that max pool reduces the dimension  such as 28*28*8 to 14*14*8 what is the purpose of applying it here is it to only keep the most important information by maxing it?,2021-10-01T12:21:10Z
Ugz1CICjxRb5F2clC7B4AaABAg.9SxakCVg7EM9gF7ANOSyBr,@aidynabirov7728,Ugz1CICjxRb5F2clC7B4AaABAg,2,KfV8CJh7hE0,0,0,2022-09-21T16:19:05Z,"Well, the purpose is not the actual reducing the height and width, it&#39;s more of taking Features(max values) from the activations, and leaving the unnecessary features. So, that&#39;s why, I guess, they are applying MaxPooling, in order to reduce some features, and applying padding at the same time not to reduce the dimension. It&#39;s just the assumption, please tell me know, if I am wrong  :)))",2022-09-21T16:20:37Z
UgzWbIIcFNteUEzMpLl4AaABAg,@beagle989,,1,KfV8CJh7hE0,0,0,2021-09-20T03:44:49Z,I love you and your videos.,2021-09-20T03:44:49Z
Ugx7fB7lXcSlyflgrXN4AaABAg,@scchouhansanjay,,1,KfV8CJh7hE0,0,1,2021-05-10T06:45:08Z,I was thinking of the movie as well but I was also thinking that I am stupid to think that such a important paper will have anything to do with a movie.,2021-05-10T06:45:08Z
Ugyc-spYb9dDaCcmJT14AaABAg,@iammakimadog,,1,KfV8CJh7hE0,1,0,2021-03-20T17:00:47Z,"<a href=""https://www.youtube.com/watch?v=KfV8CJh7hE0&amp;t=2m52s"">2:52</a> What&#39;s the purpose of &quot;maxpool -&gt; 1x1 conv&quot;? Seems like applying 1x1 conv directly is strictly better than that, coz some information will be lost in maxpool...",2021-03-20T17:00:47Z
Ugyc-spYb9dDaCcmJT14AaABAg.9L6zjTWDX1N9LYMTX6tgCC,@akashkewar,Ugyc-spYb9dDaCcmJT14AaABAg,2,KfV8CJh7hE0,0,0,2021-03-31T08:07:40Z,"information is always lost in pooling, we use the max pool to keep important information (it has got &quot;max&quot; in it, and hence we use pixel which has maximum information). We use 1x1 conv to change the depth (channel) of the output by max-pooling so that we could perform concatenation (require the same dimension). Additionally, not every piece of information is important, using too much information could result in overfitting and you have compensated for it either by using the max pool (could be treated as weak regularize, theoretically ), kernel regularizer, dropout and so on.",2021-03-31T08:07:40Z
UgxTdQtx4949LAmpmXB4AaABAg,@conorsmyth12358,,1,KfV8CJh7hE0,0,0,2021-02-24T21:18:46Z,This movie The Inception sounds great.,2021-02-24T21:18:46Z
Ugwc0mK1ODS1tBAyYo94AaABAg,@trexmidnite,,1,KfV8CJh7hE0,0,0,2021-02-10T10:05:23Z,VampireNet also good,2021-02-10T10:05:23Z
Ugy0i_JgweyT4LtUYdt4AaABAg,@sandipansarkar9211,,1,KfV8CJh7hE0,0,0,2021-01-04T16:50:26Z,very good explamnation.need to watch again,2021-01-04T16:50:26Z
UgxKr6FzM3ZF_RbbvxB4AaABAg,@piankk,,1,KfV8CJh7hE0,1,3,2020-12-05T17:41:01Z,"Great lecture! Thank you.<br>I have a question.<br><a href=""https://www.youtube.com/watch?v=KfV8CJh7hE0&amp;t=2m18s"">2:18</a><br>Can I move the 1x1 conv layer to before max-pooling layer to reduce channels, like the one before 3x3 and 5x5 conv?<br>What‚Äôs the difference?",2020-12-05T17:42:32Z
UgxKr6FzM3ZF_RbbvxB4AaABAg.9GtgsJRWIdm9pdgcdsEcmN,@Matttsight,UgxKr6FzM3ZF_RbbvxB4AaABAg,2,KfV8CJh7hE0,0,0,2023-05-13T07:21:13Z,"That&#39;s the same question i do have ,  do you got any clarity on that ?",2023-05-13T07:21:13Z
Ugyf1k2f5ke4690lJvt4AaABAg,@DevilErnest,,1,KfV8CJh7hE0,0,0,2020-11-25T07:56:53Z,"Padding is applied, isn‚Äôt it?",2020-11-25T07:56:53Z
UgwxMAk3wrvzzqfmxUJ4AaABAg,@anjithaanju2584,,1,KfV8CJh7hE0,0,0,2020-11-08T15:58:23Z,Can you make a video about Inception v4?,2020-11-08T15:58:23Z
UgwICvLvk-oWoNM24NF4AaABAg,@itohamza,,1,KfV8CJh7hE0,0,0,2020-11-02T10:24:50Z,how to concatenate 4 different data sizes?,2020-11-02T10:24:57Z
Ugz04E4A5npza5MqC094AaABAg,@ureunz,,1,KfV8CJh7hE0,0,1,2020-06-30T02:26:38Z,"really thanks Andrew. üôè Through your video, I totally understood what Inception network!! (including CNN)<br>Îã§Î•∏ ÌïúÍµ≠ ÏòÅÏÉÅÎì§ÏóêÏÑúÎäî Î≥¥Í∏∞ Ïñ¥Î†§Ïö¥ Ï≤¥Í≥ÑÏ†ÅÏù¥Í≥† + Ïâ¨Ïö¥ ÏÑ§Î™ÖÏûÖÎãàÎã§ ÏòÅÏÉÅ Í∞ïÎ†•Ï∂îÏ≤úÌï©ÎãàÎã§. üëç",2020-06-30T02:26:38Z
UgwDB0WjHfBWErFXN1p4AaABAg,@andrewwilliam2209,,1,KfV8CJh7hE0,0,0,2020-06-18T09:27:46Z,what are the max pools for if they don&#39;t reduce the size? (SAME max pooling),2020-06-18T09:27:46Z
UgzLLlSK3u-dNS7W9dx4AaABAg,@ericklestrange6255,,1,KfV8CJh7hE0,0,0,2020-06-05T06:11:05Z,"thanks, very useful",2020-06-05T06:11:05Z
UgyH7gnlqG_h9aJimwt4AaABAg,@DrN007,,1,KfV8CJh7hE0,0,3,2020-04-30T20:45:57Z,Better naming would&#39;ve been: Deep Modular Network,2020-04-30T20:45:57Z
Ugy2p4wp-DRL3MJkf_t4AaABAg,@thovinh5386,,1,KfV8CJh7hE0,1,1,2020-04-18T08:44:27Z,"From now on, I&#39;ll expect meme while reading papers",2020-04-18T08:44:27Z
Ugy2p4wp-DRL3MJkf_t4AaABAg.97_vqDnSwlP99WFO0c_J1q,@ericklestrange6255,Ugy2p4wp-DRL3MJkf_t4AaABAg,2,KfV8CJh7hE0,0,1,2020-06-05T06:10:33Z,millenial contributing in their (our) language,2020-06-05T06:10:33Z
UgxGaYG-uwJgaB_bz7B4AaABAg,@TheSalto66,,1,KfV8CJh7hE0,0,0,2020-02-11T19:04:19Z,"The film Inception means put inside other people/mind a external thought (virus) , and from that thought start a new way to see world",2020-02-11T19:05:16Z
Ugzvu1Q5161xXrnAcat4AaABAg,@ritapravadutta7939,,1,KfV8CJh7hE0,0,0,2020-02-04T10:07:58Z,"Implementation of GoogLeNet<br><a href=""https://www.kaggle.com/ritaprava95/gardennerd-googlenet"">https://www.kaggle.com/ritaprava95/gardennerd-googlenet</a>",2020-02-04T10:07:58Z
Ugy5E5hf9YlihDjRTd94AaABAg,@amineabid7220,,1,KfV8CJh7hE0,2,1,2019-12-10T14:44:14Z,How do we manage to train the intermediate forks (to do predictions from hidden layers)? do we stop the back propagation at the fork?,2019-12-10T14:44:14Z
Ugy5E5hf9YlihDjRTd94AaABAg.92MpffEPLuO92PaRoYqmYQ,@amineabid7220,Ugy5E5hf9YlihDjRTd94AaABAg,2,KfV8CJh7hE0,0,1,2019-12-11T16:28:51Z,"Besides, how to define a labeled sample? 1. Is it the same training sample (x,y), in which case what would be the impact of running two back propagation process on the same layers: all layers before the fork?<br>2. or is it (x&#39;,y) where x&#39; is the activation of the layer just before the fork? And here, I see a problem concerning the fork itself: for the very first training samples, the activation just before the fork deeply depends on the weights of all the previous layers, which are not well trained yet (still a random guess). This means that this activation is not, to some extent, a good representation of the input data in the first place. Using this &quot;bad/distorted&quot; data as an input to the forked network would make us train it on discriminating something that is completely different from our real input data!",2019-12-11T16:28:51Z
Ugy5E5hf9YlihDjRTd94AaABAg.92MpffEPLuO97TSWCGri2B,@mashmesh,Ugy5E5hf9YlihDjRTd94AaABAg,2,KfV8CJh7hE0,0,0,2020-04-15T11:04:45Z,I am also curious about this. I do not understand how the outputs from the forks are put together in end.,2020-04-15T11:04:45Z
UgyEo1tb__Sl-guscsJ4AaABAg,@user-tj4ut8ox9r,,1,KfV8CJh7hE0,0,40,2019-12-01T12:40:56Z,Didn&#39;t know one could cite memes in science papers üòÇ gonna do it in mine,2019-12-01T12:40:56Z
UgyBpj8zQxhlEG5y2el4AaABAg,@user-tj4ut8ox9r,,1,KfV8CJh7hE0,1,5,2019-12-01T12:29:42Z,I&#39;m so excited about this channel that I&#39;m actually a little paranoid that it will shut down before I can finish watching all of the videos,2019-12-01T12:29:42Z
UgyBpj8zQxhlEG5y2el4AaABAg.92-Q7O-M0dJ99VzTj1eg45,@ericklestrange6255,UgyBpj8zQxhlEG5y2el4AaABAg,2,KfV8CJh7hE0,0,1,2020-06-05T03:42:46Z,its a very new topic so no much material on it but as time progresses even if this video might be removed more and better videos probably would arise on the matter,2020-06-05T03:42:46Z
UgymJA91hMpxtzyIA714AaABAg,@aione7448,,1,KfV8CJh7hE0,2,1,2019-10-22T06:06:48Z,"I dint get the Inception , How can we stack convolved image after passing through different filter without pasdding since according to different filter dimension of convolved image too change",2019-10-22T06:06:48Z
UgymJA91hMpxtzyIA714AaABAg.90NjVzMtdcP90q-2ym6PIX,@MuhammadTalha-fz1it,UgymJA91hMpxtzyIA714AaABAg,2,KfV8CJh7hE0,0,0,2019-11-02T14:49:22Z,"hey, see in lecture there is same output shape coming from all filter 28*28 and stacking each output onto  other .",2019-11-02T14:49:22Z
UgymJA91hMpxtzyIA714AaABAg.90NjVzMtdcP92-RifpK7Zk,@user-tj4ut8ox9r,UgymJA91hMpxtzyIA714AaABAg,2,KfV8CJh7hE0,0,0,2019-12-01T12:43:40Z,They are padded,2019-12-01T12:43:40Z
UgwARAN60IUlA2Dytfd4AaABAg,@dcastudios7185,,1,KfV8CJh7hE0,0,9,2019-07-03T03:31:53Z,And I came here from - Inception movie explained üí§,2019-07-03T03:31:53Z
UgzDpRXZEliAYtxjypN4AaABAg,@vytasmatas,,1,KfV8CJh7hE0,0,0,2019-06-20T13:29:02Z,thank you very usefull,2019-06-20T13:29:02Z
UgyP4GdHhR8efeHIusp4AaABAg,@sebbecht,,1,KfV8CJh7hE0,0,20,2019-03-19T13:28:04Z,Yep I am totally going to find a way to cite a meme in one of my papers!,2019-03-19T13:28:04Z
UgyOacBmQ2vuhleTO1B4AaABAg,@shwethasubbu3385,,1,KfV8CJh7hE0,3,5,2019-01-30T17:46:48Z,"How do you know how small the bottleneck layer should be? And why would one want to shrink the number of channels as done in <a href=""https://www.youtube.com/watch?v=KfV8CJh7hE0&amp;t=8m46s"">8:46</a>, what is the benefit of doing this?<br>Also, instead of using a 1x1 as a bottleneck layer and then using 5x5 or 3x3 filters to reduce computational complexity, why can&#39;t we just use 1x1 filters throughout to get the required output dimensions?",2019-01-30T18:02:58Z
UgyOacBmQ2vuhleTO1B4AaABAg.8qjcy52inNs8r3dGj77Iie,@kishorekumarsingam,UgyOacBmQ2vuhleTO1B4AaABAg,2,KfV8CJh7hE0,0,1,2019-02-07T21:33:32Z,please let me know if anyone fimds the answer,2019-02-07T21:33:32Z
UgyOacBmQ2vuhleTO1B4AaABAg.8qjcy52inNs8rX_sodUwKe,@OneAndOnlyBigMax,UgyOacBmQ2vuhleTO1B4AaABAg,2,KfV8CJh7hE0,0,2,2019-02-19T12:41:08Z,"From what I&#39;ve understood from this video the idea is to just reduce the amount of computations needed. <br>Think of it as densely packing and combining all the features from the previous layer and proceeding to work with this &quot;dense/tight&quot; features - this is just computationaly cheaper.<br>You can&#39;t just throw away 3x3, 5x5 filters because they are useful for finding &quot;patterns&quot; in images, like lines, curves, etc. A 1x1 convolution only looks at 1 pixel at a time - and such a network would just be a MLP with extra steps.<br>This is just my intuition - feel free to add/correct something.",2019-02-19T12:41:08Z
UgyOacBmQ2vuhleTO1B4AaABAg.8qjcy52inNs8u4I0tPZKRB,@pushyashah1377,UgyOacBmQ2vuhleTO1B4AaABAg,2,KfV8CJh7hE0,0,1,2019-04-23T17:12:33Z,"3x3, 5x5 and like those filters used to learn edge detection and many more details whereas 1x1 are a really useful tool for transforming the number of channels without changing the spatial dimensions.",2019-04-23T17:12:33Z
UgxpFZQ7oL4Fvn2ehZB4AaABAg,@EranM,,1,KfV8CJh7hE0,0,6,2019-01-21T12:56:14Z,Know your meme! &lt;3 Andrew!,2019-01-21T12:56:14Z
UgwsTj5amr3ah3fvgEV4AaABAg,@navid2368,,1,KfV8CJh7hE0,0,42,2018-12-19T21:13:20Z,"Andrew teaching me about memes, epic! <br><br>thanks again for the amazing lecture",2018-12-19T21:13:20Z
UgzW0Cv5ZFRgrfALdSF4AaABAg,@dj_metanov,,1,KfV8CJh7hE0,0,12,2017-12-26T09:35:12Z,"Small typo @ <a href=""https://www.youtube.com/watch?v=KfV8CJh7hE0&amp;t=6m33s"">6:33</a> GooLeNet -&gt; GoogLeNet !!! ;) The inception architecture is a really nice way of using the power of CNN and your explanation make its understanding crystal clear! Che Che!",2017-12-26T09:35:12Z
Ugw0W_GhjCD4oHL76_54AaABAg,@Donaid,,1,cFFu__mcoIw,0,3,2020-03-09T12:16:43Z,"<a href=""https://www.youtube.com/watch?v=cFFu__mcoIw&amp;t=3m21s"">3:21</a> type &#39;s&#39; to skip the line by line and &#39;q&#39; to exit",2020-03-09T12:16:43Z
UgwAO0x_bu-nyRM7PdB4AaABAg,@trexmidnite,,1,FQM13HkEfBk,0,1,2021-02-10T22:31:52Z,Scary movie..p,2021-02-10T22:31:52Z
UgxG2oC7om9iWLAJV0t4AaABAg,@kumarsiddharth74,,1,FQM13HkEfBk,1,1,2021-01-26T06:34:30Z,just a funny observation...misty looks like a Dracula !!!,2021-01-26T06:34:30Z
UgxG2oC7om9iWLAJV0t4AaABAg.9IyOw8BJw2Y9JafWVTxokX,@trexmidnite,UgxG2oC7om9iWLAJV0t4AaABAg,2,FQM13HkEfBk,0,0,2021-02-10T21:57:47Z,Hahahahahahahhaahhahahah best comment,2021-02-10T21:57:47Z
Ugx65p8t0z4vjSZubXd4AaABAg,@shouryasrivastava3921,,1,FQM13HkEfBk,0,0,2020-09-08T12:19:59Z,does octave has any support for pretrained neuraln networks like matlab,2020-09-08T12:19:59Z
UgwRJRMmIqy8JjSTkNF4AaABAg,@lorenzoleongutierrez7927,,1,FQM13HkEfBk,0,0,2019-12-22T18:33:40Z,Thanks!!,2019-12-22T18:33:40Z
Ugy1xBU5lD6CbncSwUR4AaABAg,@imprakrut,,1,FQM13HkEfBk,0,0,2019-10-10T15:47:28Z,What&#39;s up Nirma fam!?,2019-10-10T15:47:28Z
UgwQDKmVjcB9sHgS_Cd4AaABAg,@habibmrad8116,,1,FQM13HkEfBk,2,0,2019-05-01T13:39:33Z,"ca someone help me . what Prof Andrew mean at <a href=""https://www.youtube.com/watch?v=FQM13HkEfBk&amp;t=4m05s"">4:05</a> when he is saying the following:<br><br><br>&quot;One of the trick that could speed up training is we just pre-compute that<br>layer, the features of re-activations from that layer and just save them to disk. What you&#39;re doing is using this fixed function, in this first part of the neural network, to take this input any image X and compute some feature vector for it and then you&#39;re training a shallow softmax model from this feature vector to make a prediction. One step that could help your computation as you just precompute that layers activation, for all the examples in training sets and save them to disk and then just train the softmax clause right on top of that. The advantage of the save to disk or the pre-compute method or the save to disk is that you don&#39;t need to recompute those activations every time you take a epoch or take a post through a training set. This is what you do if you have a pretty small training set for your task.&quot;",2019-05-01T13:40:28Z
UgwQDKmVjcB9sHgS_Cd4AaABAg.8uOW-ltOJYA8v9_t1cHz5Z,@brianc1306,UgwQDKmVjcB9sHgS_Cd4AaABAg,2,FQM13HkEfBk,0,1,2019-05-20T15:04:58Z,Hi Habib. I¬¥m a beginner in DL but hope I can help. I think is easier save your feature vector of all the training set and compile them as a new data and then training only with the predicted layer (softmax function) like a perceptron. Instead train with the whole NN every epoch. If I¬¥m wrong let me know :),2019-05-20T15:04:58Z
UgwQDKmVjcB9sHgS_Cd4AaABAg.8uOW-ltOJYA98ivf2f_N4Y,@wei-linchang652,UgwQDKmVjcB9sHgS_Cd4AaABAg,2,FQM13HkEfBk,0,0,2020-05-16T17:07:29Z,"I think what Prof. Andrew means is if we only consider the subset of frozen layers, then, theoretically, the relationship between inputs and outputs is a deterministic mapping. Therefore, if we can find a function to represent this mapping (which ideally should less complicated than the original layers), we don‚Äôt need to let the data flow through those frozen layers but just use the pre-calculated function.",2020-05-16T17:07:29Z
Ugz8szuMEKbus8RfMUh4AaABAg,@vascothemane5272,,1,FQM13HkEfBk,2,2,2018-09-27T06:29:46Z,"Is it helpful if we use frozen weights of one trained model for training a different dataset with help of transfer learning. <br>Example:<br>i have trained model of  cat, dog, car, truck.<br>and i will use frozen weights of this model to train a different dataset i.e. person, bicycle, ball etc<br>Will this make any difference in resluts",2018-09-27T06:29:46Z
Ugz8szuMEKbus8RfMUh4AaABAg.8lgZ6vX1_Ju8qhaMveKKe_,@bobcrunch,Ugz8szuMEKbus8RfMUh4AaABAg,2,FQM13HkEfBk,0,0,2019-01-29T22:45:38Z,"I&#39;m far from an expert, but my impression is that the early stages of a NN are primitives that the training process matches to the training data primitives; eg, the early stages of an image recognition NN are edges and other shapes that match the training data. Look at the application to see if was trained on data that matches your application data - the closer the better.",2019-01-29T22:45:38Z
Ugz8szuMEKbus8RfMUh4AaABAg.8lgZ6vX1_Ju8uwvq0Pnq6o,@angelachikaebirim8894,Ugz8szuMEKbus8RfMUh4AaABAg,2,FQM13HkEfBk,0,0,2019-05-15T07:47:26Z,"@@bobcrunch The NN is trained on IMAGENET <a href=""http://www.image-net.org/"">http://www.image-net.org/</a> which has a dataset in the millions, is one of the most widely used  and has 1000 classes of the most general categories usually shown in images.",2019-05-15T07:47:26Z
UgyrqonyuMUxYf1I-Vd4AaABAg,@jandroid33,,1,FQM13HkEfBk,1,9,2018-07-31T21:41:06Z,"How is the dimension reduction for the softmax done? I only found videos describing softmax as a probability normalization step, keeping all the dimensions. So if the final step had a 9-dimensional vector, how would you decrease it to 3 using softmax?<br>EDIT: Ok, from other videos I conclude that it&#39;s just a fully connected layer (FC) reduction step before the normalization.",2018-08-04T11:42:16Z
UgyrqonyuMUxYf1I-Vd4AaABAg.8jNqJ1Iyqd59D8PTXJLFbo,@valentinfontanger4962,UgyrqonyuMUxYf1I-Vd4AaABAg,2,FQM13HkEfBk,0,3,2020-09-03T10:02:29Z,thank you very much for the edit !,2020-09-03T10:02:29Z
UgwVoJGo6JECtlXUr2h4AaABAg,@arunyadav8773,,1,FQM13HkEfBk,1,0,2017-11-13T14:21:55Z,in transfer learning where would i use/apply the precomputed/learned weights ?,2017-11-13T14:21:55Z
UgwVoJGo6JECtlXUr2h4AaABAg.8Zu_MpMkrV18aTLn9KCWYM,@kunhongyu5053,UgwVoJGo6JECtlXUr2h4AaABAg,2,FQM13HkEfBk,0,9,2017-12-22T08:18:38Z,Treat them as initialization,2017-12-22T08:18:38Z
UgxZCgPnMGfKUa9HWZV4AaABAg,@user-em4sl8zl7z,,1,JI8saFjK84o,0,0,2021-10-16T10:13:05Z,Thank you~~~~~,2021-10-16T10:13:05Z
UgzxZSAKNu-tVN0jtTR4AaABAg,@saramessara4241,,1,JI8saFjK84o,2,0,2021-03-30T16:28:05Z,"how are RGB values supposed to be negative, or is it just an 8-bit signed representation?",2021-03-30T16:28:05Z
UgzxZSAKNu-tVN0jtTR4AaABAg.9LWfwiHwPv19M6rW0xa0zW,@mueez.mp4,UgzxZSAKNu-tVN0jtTR4AaABAg,2,JI8saFjK84o,0,0,2021-04-14T12:20:18Z,I think by the negative sign he meant to subtract that value from the current values.,2021-04-14T12:20:18Z
UgzxZSAKNu-tVN0jtTR4AaABAg.9LWfwiHwPv19VJMU-3xeWF,@chawza8402,UgzxZSAKNu-tVN0jtTR4AaABAg,2,JI8saFjK84o,0,0,2021-11-29T01:33:04Z,"I think it reverese the value of the pixel range. let say a pixel value in R is 25 in the range of 0 to 255. if we reverse it, the value would be 255 - 25 = 230. same apply on every pixel in each color layer",2021-11-29T01:33:04Z
UgwzBj-5XZmTFpNEGvJ4AaABAg,@sandipansarkar9211,,1,JI8saFjK84o,0,0,2021-01-10T14:52:56Z,nice explantion,2021-01-10T14:52:56Z
UgxkGzxhYT0xGPw-jUx4AaABAg,@user-vo9ov4dh8b,,1,JI8saFjK84o,1,0,2020-07-09T09:16:52Z,"I have a question.. when we separate &quot;conv&quot;model and &quot;softmax&quot;model and save last conv layer output in disk and then use this as input of softmax model as last video(transfer learning), can&#39;t we use data augmentation? I&#39;ve seen this information in &quot;Deep learning with python&quot; book but I can&#39;t understand why we can&#39;t use Data augmentation...",2020-07-09T09:16:52Z
UgxkGzxhYT0xGPw-jUx4AaABAg.9At7jN-5pRK9CZgqN2Fol_,@MubashirullahD,UgxkGzxhYT0xGPw-jUx4AaABAg,2,JI8saFjK84o,0,1,2020-08-20T03:51:07Z,"Your question is not clear and I dont remember the context of this video. <br>If I had to guess, in transfer learning we use the parameters trained in another model to initialize a new one. You can train this new model on the data you have and ofcourse you can augment it as well. <br>Let me know what your question was if this doesn&#39;t answer it.",2020-08-20T03:51:07Z
Ugx7gujYxBvqI4b4fo94AaABAg,@MubashirullahD,,1,JI8saFjK84o,1,0,2020-03-17T14:31:21Z,I wish I had exact numbers. How much is too much Augmentation?,2020-03-17T14:31:21Z
Ugx7gujYxBvqI4b4fo94AaABAg.96J962TW3kF9CZA5tdVibY,@quintonsmith7170,Ugx7gujYxBvqI4b4fo94AaABAg,2,JI8saFjK84o,0,3,2020-08-19T22:56:17Z,"Too much in the sense that it completely alters whatever is supposed to be represented in the image..So say a cat image where you shear it by an extreme amount such that the cat is no longer recognizable, so too much augmentation (shearing in this case)",2020-08-19T22:56:17Z
Ugwtg_CGqGO1SkGy6MN4AaABAg,@masakkali9996,,1,JI8saFjK84o,1,0,2019-05-28T16:15:45Z,Can you please share the code for color shifting?,2019-05-28T16:15:45Z
Ugwtg_CGqGO1SkGy6MN4AaABAg.8vUJLS8-pIa8wvP0QoNkZk,@1995pipo,Ugwtg_CGqGO1SkGy6MN4AaABAg,2,JI8saFjK84o,0,1,2019-07-03T10:35:26Z,The colors are usually 8-bit values (0-255) you just need to add those values (as in the video) to each channel,2019-07-03T10:35:26Z
UgxtsTC_rtku72f2b5F4AaABAg,@lene6641,,1,JI8saFjK84o,0,9,2019-04-27T19:14:00Z,&quot;Data augmentation or how to fake your data&quot; :),2019-04-27T19:14:00Z
Ugw2AkrIZvtg0lvy4R94AaABAg,@saswatapaladhi4608,,1,c3zw6KI6dLc,1,1,2021-08-01T06:17:50Z,"Wont data augmentation like in <a href=""https://www.youtube.com/watch?v=c3zw6KI6dLc&amp;t=9m47s"">9:47</a> would cause over-fitting of data?",2021-08-01T06:17:50Z
Ugw2AkrIZvtg0lvy4R94AaABAg.9QUsfcyyLl69TrXhM23QPi,@AhmedElsayed-ur1iy,Ugw2AkrIZvtg0lvy4R94AaABAg,2,c3zw6KI6dLc,0,0,2021-10-24T00:21:47Z,Why would that cause overfitting ur not training ur network on these images,2021-10-24T00:21:47Z
Ugz79JoZPYWjg3ZbY_h4AaABAg,@iammakimadog,,1,c3zw6KI6dLc,0,0,2021-03-20T17:17:24Z,Inspiring,2021-03-20T17:17:24Z
Ugwq0BO9O02v4ftDw1p4AaABAg,@ElectricCircuitsLAB-ProfHazemA,,1,GSwYGkTfOKk,0,0,2023-06-19T21:49:09Z,Thnaks a lot for useful and easy presentation,2023-06-19T21:49:09Z
UgwdUNFGvN9rw9W6wjZ4AaABAg,@valentino8625,,1,GSwYGkTfOKk,0,0,2022-07-26T07:40:28Z,Clear and Simple!!! Awesone lecture,2022-07-26T07:40:28Z
UgyiZsWGeBXhjn73vph4AaABAg,@seroshmannan,,1,GSwYGkTfOKk,0,0,2022-04-24T18:00:59Z,wonderful,2022-04-24T18:00:59Z
UgwOAFu4W6qwKBGTwn54AaABAg,@darinhitchings7104,,1,GSwYGkTfOKk,0,0,2021-10-03T08:06:28Z,this is super good content thanks so much,2021-10-03T08:06:28Z
UgzU2YfLZ5IqIZEvqkl4AaABAg,@praleen_,,1,GSwYGkTfOKk,1,0,2021-07-07T09:16:20Z,Hi! I am wondering why the background is not included in the vectors!,2021-07-07T09:16:20Z
UgzU2YfLZ5IqIZEvqkl4AaABAg.9PUpE8AGasJ9P_8lIn54DR,@bright5967,UgzU2YfLZ5IqIZEvqkl4AaABAg,2,GSwYGkTfOKk,0,1,2021-07-09T10:51:58Z,"I looked at it as just training with 3 classes and if it cant detect any of them, then it&#39;s a background",2021-07-09T12:38:24Z
UgwNNqVMoCnnlPHHyel4AaABAg,@keweml3544,,1,GSwYGkTfOKk,0,0,2021-06-15T13:57:54Z,Awesome!,2021-06-15T13:57:54Z
Ugw4Zb8x87sPejgfhtN4AaABAg,@tamerzah,,1,GSwYGkTfOKk,0,0,2021-05-29T23:12:19Z,Nice and clear explanation,2021-05-29T23:12:19Z
UgwUV0VIb9nLSaAE5sp4AaABAg,@dineshbh3837,,1,GSwYGkTfOKk,0,0,2021-04-02T20:33:48Z,"for object detection usually use &#39;blob &#39; , contors to separate objects from background and classify that slits",2021-04-02T20:33:48Z
UgzYt7EyP7Hp6vDmNLF4AaABAg,@swapnilgautam5252,,1,GSwYGkTfOKk,1,0,2021-03-16T09:35:42Z,but how do we get bx and by value ?,2021-03-16T09:35:42Z
UgzYt7EyP7Hp6vDmNLF4AaABAg.9Kwtc5QB71Z9dSluQb_6At,@EranM,UgzYt7EyP7Hp6vDmNLF4AaABAg,2,GSwYGkTfOKk,0,0,2022-07-14T09:59:43Z,"pixle of middle object / max pixel, both for x and y",2022-07-14T09:59:43Z
UgyZFbfGQ5pj5vjrH0Z4AaABAg,@samuelmatheson9655,,1,GSwYGkTfOKk,0,0,2021-03-06T20:12:24Z,Gonna make TCAS for blind people,2021-03-06T20:12:24Z
UgxoFenb-80vsawtC_F4AaABAg,@sandipansarkar9211,,1,GSwYGkTfOKk,1,0,2021-01-07T19:27:34Z,nice explanation .need to watch agaian,2021-01-07T19:27:34Z
UgxoFenb-80vsawtC_F4AaABAg.9IDrIYqw6oj9IN3DFAt-OG,@mayankmishra3875,UgxoFenb-80vsawtC_F4AaABAg,2,GSwYGkTfOKk,0,1,2021-01-11T09:13:36Z,You are consistent. Nice.,2021-01-11T09:13:36Z
Ugyd6imYhWdf_4mWqFl4AaABAg,@skaterope,,1,GSwYGkTfOKk,0,0,2020-09-19T22:10:17Z,makes sense,2020-09-19T22:10:17Z
Ugz_C3eqOxD9JjFlTah4AaABAg,@harishkumaranandan5946,,1,GSwYGkTfOKk,0,1,2020-07-12T16:02:49Z,"Hi everyone I am confused about the bbox part. How does the feature vector stack in final FC layer spit out some arbitrary 4 number that are bbox parameters even before backpropagation and L2 loss part. Are these initial bbox co-ordinates the one of the feature vector that has the object in it? Lets say in the case of localizing a car the final FC layer before softmax will have learnt high level features like car wheels, windshield etc and at the end these are stacked. Having said the bbox of the whole car will be different than the bbox of high level features like wheel, windshield etc. I am confused in this part of predicting the initial bbox of the whole car even though it might not be accurate initially bathos does the bbox of high level feature vector match the bbox of whole object. correct me if i were wrong somewhere.",2020-07-12T16:02:49Z
UgySNx6V2W7bF62_n_R4AaABAg,@user-vo9ov4dh8b,,1,GSwYGkTfOKk,2,1,2020-07-09T12:15:23Z,"In last part of this video, he said we can use softmax,  squared error, logistic regression loss. if I use that, I think there will be three different type loss. And then how should I do back prop? Just calculate loss matched each output neuron&#39;s loss fucntion?",2020-07-09T12:15:23Z
UgySNx6V2W7bF62_n_R4AaABAg.9AtS9yjP_tP9R3FhAtBu9F,@abubakarali6399,UgySNx6V2W7bF62_n_R4AaABAg,2,GSwYGkTfOKk,0,0,2021-08-15T09:20:25Z,Have you find the answer?,2021-08-15T09:20:25Z
UgySNx6V2W7bF62_n_R4AaABAg.9AtS9yjP_tP9R3JHoYSM7R,@user-vo9ov4dh8b,UgySNx6V2W7bF62_n_R4AaABAg,2,GSwYGkTfOKk,0,0,2021-08-15T09:51:46Z,"@@abubakarali6399 I found that yolo outputs multiple tensors. In other word, in last part in yolo there is 3 different type layers (may be more) which is p, box positions, clasees",2021-08-15T09:51:46Z
Ugw-OBWuWXwP0wvvTml4AaABAg,@wtfJonKnowNothing,,1,GSwYGkTfOKk,0,0,2020-07-05T06:43:06Z,"Everyone : Awesome ,very nice , great !!!<br>Me : That&#39;s why he is Andrew",2020-07-05T06:43:06Z
Ugw4LcgufCMYtKDHc7R4AaABAg,@harshitbad,,1,GSwYGkTfOKk,0,2,2020-06-21T05:49:38Z,Waah chacha kya tutorial diye hain!!,2020-06-21T05:49:38Z
UgwTo_uIliuGiyKnbS14AaABAg,@jasmineshaik4371,,1,GSwYGkTfOKk,0,0,2020-03-15T10:39:59Z,If there is a pedestrian and car in a frame ??? Is it applicable,2020-03-15T10:39:59Z
Ugw4J50_Sl34EBJXP6R4AaABAg,@ssverma80,,1,GSwYGkTfOKk,0,0,2020-01-24T11:52:35Z,awesome sir,2020-01-24T11:52:35Z
UgxNQlh0TjS1sSyXWEB4AaABAg,@faridalijani1578,,1,GSwYGkTfOKk,2,0,2019-12-11T15:27:29Z,how could one program &quot;don&#39;t care&quot; as an output of an image which contains no object?,2019-12-11T15:27:29Z
UgxNQlh0TjS1sSyXWEB4AaABAg.92PUQH-9pIC93PI1SQT_on,@francoisplessier9913,UgxNQlh0TjS1sSyXWEB4AaABAg,2,GSwYGkTfOKk,0,1,2020-01-05T10:10:38Z,"Pay attention at <a href=""https://www.youtube.com/watch?v=GSwYGkTfOKk&amp;t=8m59s"">8:59</a> . When pc_train==0, the loss function is calculated differently: only the object prediction pc_pred is used. So it really &quot;doesn&#39;t care&quot; about the values of bw_pred, bh_pred, etc... as there are not in the formula!",2020-01-05T10:19:24Z
UgxNQlh0TjS1sSyXWEB4AaABAg.92PUQH-9pIC9Dv43ODEIIz,@valentinfontanger4962,UgxNQlh0TjS1sSyXWEB4AaABAg,2,GSwYGkTfOKk,0,0,2020-09-22T16:57:26Z,"in the formula, &quot;don&#39;t care&quot; is defined as the &quot;1| _oobj&quot;",2020-09-22T16:57:26Z
UgxkVk6eEi56gnjItCV4AaABAg,@submagr,,1,GSwYGkTfOKk,5,7,2019-12-06T15:13:51Z,"As soon as I find a video by Prof Andrew on a topic I am looking for, I know this topic is so done for good.<br>Thanks, Prof for these wonderful lectures. I can&#39;t be enough grateful.",2019-12-06T15:13:51Z
UgxkVk6eEi56gnjItCV4AaABAg.92C_t4kDePJ9NoCuh6Emeb,@oscarcarson6215,UgxkVk6eEi56gnjItCV4AaABAg,2,GSwYGkTfOKk,0,0,2021-05-26T14:14:01Z,pro trick : you can watch series on Flixzone. Been using it for watching lots of of movies lately.,2021-05-26T14:14:01Z
UgxkVk6eEi56gnjItCV4AaABAg.92C_t4kDePJ9NqLxgzk3Yg,@landynbyron5728,UgxkVk6eEi56gnjItCV4AaABAg,2,GSwYGkTfOKk,0,0,2021-05-27T10:11:33Z,"@Oscar Carson yup, been watching on Flixzone} for since december myself :)",2021-05-27T10:11:33Z
UgxkVk6eEi56gnjItCV4AaABAg.92C_t4kDePJ9NqLxoHVaHB,@kendrickkillian2669,UgxkVk6eEi56gnjItCV4AaABAg,2,GSwYGkTfOKk,0,0,2021-05-27T10:11:34Z,"@Oscar Carson Definitely, I&#39;ve been using flixzone} for since november myself :D",2021-05-27T10:11:34Z
UgxkVk6eEi56gnjItCV4AaABAg.92C_t4kDePJ9NqLy7M3gA8,@davionkye9161,UgxkVk6eEi56gnjItCV4AaABAg,2,GSwYGkTfOKk,0,0,2021-05-27T10:11:36Z,"@Oscar Carson yea, I have been using flixzone} for months myself =)",2021-05-27T10:11:36Z
UgxkVk6eEi56gnjItCV4AaABAg.92C_t4kDePJ9NqLyDwVgIO,@kingbilly7986,UgxkVk6eEi56gnjItCV4AaABAg,2,GSwYGkTfOKk,0,0,2021-05-27T10:11:37Z,"@Oscar Carson Definitely, I&#39;ve been watching on Flixzone} for years myself :D",2021-05-27T10:11:37Z
UgzZu7MK7QsLqD2JiNN4AaABAg,@computer-sci8457,,1,GSwYGkTfOKk,0,0,2019-11-17T20:59:12Z,"bounding box data as input, while training a model is give after convolution operation , am I right ?, I have little confusion . :)",2019-11-17T21:00:26Z
UgwRVu33npeP1ihLkul4AaABAg,@coolamigo00,,1,GSwYGkTfOKk,1,1,2019-08-22T11:11:17Z,could Pc or C2 be between 0 and 1,2019-08-22T11:11:17Z
UgwRVu33npeP1ihLkul4AaABAg.8ywCrjqecex9OgZ88GDrkC,@robinmanchanda2884,UgwRVu33npeP1ihLkul4AaABAg,2,GSwYGkTfOKk,0,0,2021-06-17T11:25:42Z,"Pc will be the probability of having an object or not, so this neuron will work as logistics regression only, hence the output can be betwwen 0 and 1. For classes, the concept is almost same and it&#39;s like the output of softmax.",2021-06-17T11:25:42Z
UgzuU01_Qzn1pHKvQwp4AaABAg,@sudarsansudar2120,,1,GSwYGkTfOKk,1,1,2019-08-03T17:19:59Z,"What will be bx,by,bh,bw value in the output vector if multiple classes are present in the picture.",2019-08-03T17:19:59Z
UgzuU01_Qzn1pHKvQwp4AaABAg.8yAwxS-478798ZV5vRoy2I,@QuanNguyen-vo2xh,UgzuU01_Qzn1pHKvQwp4AaABAg,2,GSwYGkTfOKk,0,0,2020-05-12T15:54:13Z,This video is more about the basic idea of how people encode the training data so he only talks about the case of 1 class in each image. You will have to duplicate this array to support the multiple classes. He talks more about that in the following videos of the course.,2020-05-12T15:54:13Z
Ugz8RLw7XulDhP1y3O14AaABAg,@guardrepresenter5099,,1,GSwYGkTfOKk,0,0,2019-05-24T02:50:37Z,How pc variable know without calculating class labels.Because Andrew say if pc 0 the other variable dont care.But how pc know i am 0 or 1?????????,2019-05-24T02:50:37Z
UgyHGcqrMVo88iTBQg14AaABAg,@morsemo6966,,1,GSwYGkTfOKk,0,4,2019-04-23T03:12:34Z,I am a total beginner(even for python). <br>I couldn&#39;t understand the courses here one month ago. Then I took about 1 month to go around and try most of the popular algorithms examples (with GPU linux server). Then I come back and watch the courses. Now I could be more confident to continue the course journey with Andrew.,2019-04-23T03:12:34Z
UgyTuL0coqhiyjboi094AaABAg,@iiirannn1,,1,GSwYGkTfOKk,0,0,2019-04-01T17:11:56Z,great lecture,2019-04-01T17:11:56Z
Ugw2i_Ie2fJbmpw2zhB4AaABAg,@dr.swativijayshinde5423,,1,GSwYGkTfOKk,0,0,2018-12-11T11:57:30Z,"Please mail me the slides on swaatii.shinde@<a href=""http://gmail.com/"">gmail.com</a>",2018-12-11T11:57:30Z
UgxFbuCxNXU2J8x5kSp4AaABAg,@saikrishnadyavarasetti7833,,1,GSwYGkTfOKk,1,0,2018-11-23T18:05:37Z,"If there  &#39;n&#39; of objects in an image, then how the softmax output will be? will be same [pc, bx, by, bw,bh,c1,c2,c3]? How the output will be?",2018-11-23T18:05:37Z
UgxFbuCxNXU2J8x5kSp4AaABAg.8o-_3N0PMyF8oHfu6nB1P8,@raviiit6415,UgxFbuCxNXU2J8x5kSp4AaABAg,2,GSwYGkTfOKk,0,0,2018-11-30T18:51:43Z,"c1,c2.. extended to the no. of classes",2018-11-30T18:51:43Z
UgzMC5bF3GpJegOukcN4AaABAg,@AbhishekSinghSambyal,,1,GSwYGkTfOKk,0,0,2018-10-23T21:17:39Z,Can you name any training set which has the same classes and bounding boxes values to try this approach?,2018-10-23T21:17:39Z
UgxLXVBQFSicZIVajQt4AaABAg,@constructor365,,1,GSwYGkTfOKk,1,5,2018-09-27T11:17:36Z,"Since the loss function for the case when y1 =  0 includes only one term in contrast to the case when y1 = 0, isn&#39;t it kind of encouraging the network to predict that there is no object(background) over the other cases?",2018-09-27T11:17:36Z
UgxLXVBQFSicZIVajQt4AaABAg.8lh437bS1I898ZUhZ2n7wz,@QuanNguyen-vo2xh,UgxLXVBQFSicZIVajQt4AaABAg,2,GSwYGkTfOKk,0,0,2020-05-12T15:50:45Z,"Not really. When calculating the loss, it only ignores bx, by, bh, bw, c if the ground-truth value (y) = 0, not when your prediction (y hat) = 0. So if your model tries to predict y hat = 0 more, the loss function will still consider and compare your predicted bx, by, bh, bw, c with their ground-truth values even though y hat = 0.",2020-05-12T15:50:45Z
Ugxj-0CJN-6J1VJw8D14AaABAg,@muhammedbuyukknac2777,,1,GSwYGkTfOKk,0,0,2018-09-08T10:23:32Z,"You can check out my repository over object localization for SINGLE object. It is a ready-to-run repository.<br> <a href=""https://github.com/MuhammedBuyukkinaci/Object-Classification-and-Localization-with-TensorFlow"">https://github.com/MuhammedBuyukkinaci/Object-Classification-and-Localization-with-TensorFlow</a>",2018-09-08T10:23:32Z
UgzTT3qiMlg9JkC9jPF4AaABAg,@priyankasn4709,,1,GSwYGkTfOKk,2,1,2018-07-29T08:53:42Z,how we have given input image to each neuron,2018-07-29T08:53:42Z
UgzTT3qiMlg9JkC9jPF4AaABAg.8jHJtZs0hcl8lOPHfOEOm3,@dbzkidkev2,UgzTT3qiMlg9JkC9jPF4AaABAg,2,GSwYGkTfOKk,0,0,2018-09-19T19:58:17Z,you feed in pixels to the input neurons,2018-09-19T19:58:17Z
UgzTT3qiMlg9JkC9jPF4AaABAg.8jHJtZs0hcl8lf02crbpIs,@RobertLugg,UgzTT3qiMlg9JkC9jPF4AaABAg,2,GSwYGkTfOKk,0,0,2018-09-26T16:04:06Z,"Hi Priyanka, this is a good lecture, but I suggest you start with some that are more fundamental.¬† Here is a nice video: <a href=""https://youtu.be/2-Ol7ZB0MmU%C2%A0"">https://youtu.be/2-Ol7ZB0MmU¬†</a> I really like the way Luis explains things so you may start with a few of them first.",2018-09-26T16:04:06Z
UgwDbgK6tp8ZOQu5AjF4AaABAg,@PramodShetty,,1,rRB9iymNy1w,1,0,2023-08-08T21:00:55Z,so someone manually went through 1000s of images and outlined the eyes to create dataset with classes to train ai?,2023-08-08T21:00:55Z
UgwDbgK6tp8ZOQu5AjF4AaABAg.9tAAaMgcBJ_9v5OPdOg5Lw,@tiesetsomatsipa5402,UgwDbgK6tp8ZOQu5AjF4AaABAg,2,rRB9iymNy1w,0,0,2023-09-25T17:28:14Z,"Yep, or they hired people to do so.",2023-09-25T17:28:14Z
Ugyh7qfa5tsn0TsVECF4AaABAg,@elgs1980,,1,rRB9iymNy1w,0,0,2022-12-28T08:43:53Z,Are the landmark coordinates relative to the enclosing bounding box or the entire image?,2022-12-28T08:43:53Z
UgxWjC15s8fQkSl-PYh4AaABAg,@sandipansarkar9211,,1,rRB9iymNy1w,0,0,2021-01-07T19:51:16Z,nice explanation,2021-01-07T19:51:16Z
UgweZ7IXm3STjXS8xgR4AaABAg,@CyberWorxSystemCompany,,1,rRB9iymNy1w,0,0,2020-10-16T13:52:29Z,"Dr. Andrew started Coursera ,starting a revolution in MOOC...such a great visionary",2020-10-16T13:52:58Z
UgzGeISkaYoZwaUD8HF4AaABAg,@ManChoitube,,1,rRB9iymNy1w,0,2,2020-08-30T11:10:10Z,ÌïúÍµ≠Ïñ¥ ÏûêÎßâÏù¥ ÏûàÎÑ§Ïöî! Í≥†ÎßôÏäµÎãàÎã§. ÏµúÎßåÎìúÎ¶º,2020-08-30T11:10:10Z
Ugzn0KwArPMyL5gfmh14AaABAg,@harishkumaranandan5946,,1,rRB9iymNy1w,0,1,2020-07-12T16:13:20Z,So the catch here is data annotation and defining the o/p layer. lets say we want to detect the centroid of circles then we annotate the centroids and modify the o/p layer to give 2 numbers. Lets say we annotate out data in triangle shape (i know there might be less use cases) and modify o/p layer to spit 3 numbers ..then the network becomes triangle detector. is this the assumption?,2020-07-12T16:13:20Z
UgxnRhjEE02rAKyGGlN4AaABAg,@tusharnitharwal,,1,rRB9iymNy1w,3,1,2020-07-10T19:42:46Z,Where can i find good datasets for landmark detection for making a complex model with more than 100 keypoints?,2020-07-10T19:42:46Z
UgxnRhjEE02rAKyGGlN4AaABAg.9Awp9X0Rl499NERBuZwOnK,@prachimohnot5454,UgxnRhjEE02rAKyGGlN4AaABAg,2,rRB9iymNy1w,0,0,2021-05-12T07:26:56Z,Did you find one? Please let me know if you did,2021-05-12T07:26:56Z
UgxnRhjEE02rAKyGGlN4AaABAg.9Awp9X0Rl499NS2WrALNVj,@andihaki,UgxnRhjEE02rAKyGGlN4AaABAg,2,rRB9iymNy1w,0,0,2021-05-17T14:20:42Z,I want to please üôè,2021-05-17T14:20:42Z
UgxnRhjEE02rAKyGGlN4AaABAg.9Awp9X0Rl499Z1A1PuqCdP,@nid554,UgxnRhjEE02rAKyGGlN4AaABAg,2,rRB9iymNy1w,0,0,2022-03-01T10:03:33Z,@@andihaki mediapipe,2022-03-01T10:03:33Z
UgwiBe7HySlVCxEuKLx4AaABAg,@fenggeliu4241,,1,rRB9iymNy1w,0,2,2020-06-06T19:16:03Z,"I found it hard to watch, this is almost cyber bully",2020-06-06T19:16:03Z
Ugx4i71WbKKLY_pXx854AaABAg,@vishnubanna7869,,1,rRB9iymNy1w,7,10,2019-06-24T21:29:41Z,"this seems too simple, i feel like i am missing something...",2019-06-24T21:29:41Z
Ugx4i71WbKKLY_pXx854AaABAg.8w_OjPDsW9a8xDXIeFZzzO,@MattyHild,Ugx4i71WbKKLY_pXx854AaABAg,2,rRB9iymNy1w,0,3,2019-07-10T20:53:24Z,Wait til you have to implement it. You&#39;ll see where it gets complicated.,2019-07-10T20:53:24Z
Ugx4i71WbKKLY_pXx854AaABAg.8w_OjPDsW9a8yCBY10qZm0,@AhmedIsam,Ugx4i71WbKKLY_pXx854AaABAg,2,rRB9iymNy1w,0,1,2019-08-04T04:55:25Z,"Nope. It is indeed trivial. Once you have tons of annotated data, fitting a neural net doesn&#39;t require a data scientist. In reality, things are difficult because you don&#39;t have enough data to do what you want.",2019-08-04T04:55:25Z
Ugx4i71WbKKLY_pXx854AaABAg.8w_OjPDsW9a90YG9vpOdtM,@pedrobb7,Ugx4i71WbKKLY_pXx854AaABAg,2,rRB9iymNy1w,0,1,2019-10-26T08:13:17Z,"To make it in real time, best paper that describes  face aligment uses a much more complex method (an ensemble of regression trees trained by gradient boosting). It achieves ms performance.",2019-10-26T08:13:17Z
Ugx4i71WbKKLY_pXx854AaABAg.8w_OjPDsW9a9324G0hLVhb,@horkaichan8880,Ugx4i71WbKKLY_pXx854AaABAg,2,rRB9iymNy1w,0,2,2019-12-27T09:47:45Z,Andrew Ng said at the start of the course that Deep Learning sometimes seems miraculous because of the richness of the data. So it can be simple provided you have very good data with clear patterns for the network to tease out. Getting the data is another story.,2019-12-27T09:47:45Z
Ugx4i71WbKKLY_pXx854AaABAg.8w_OjPDsW9a99RSIL1J6yV,@sanjivgautam9063,Ugx4i71WbKKLY_pXx854AaABAg,2,rRB9iymNy1w,0,3,2020-06-03T09:27:09Z,Everything is simple once you understand it.,2020-06-03T09:27:09Z
UgxwUURNCzUanA6hxQJ4AaABAg,@kuipan5968,,1,rRB9iymNy1w,5,7,2019-02-02T07:20:49Z,"<a href=""https://www.youtube.com/watch?v=rRB9iymNy1w&amp;t=1m49s"">1:49</a>, that woman looks like a vampire...",2019-02-02T07:20:49Z
UgxwUURNCzUanA6hxQJ4AaABAg.8qqEhpqTx4i8rce6KO_Mje,@ukhu_pacha,UgxwUURNCzUanA6hxQJ4AaABAg,2,rRB9iymNy1w,0,0,2019-02-21T21:13:31Z,She is,2019-02-21T21:13:31Z
UgxwUURNCzUanA6hxQJ4AaABAg.8qqEhpqTx4i8tPydI_SeNj,@shwethasubbu3385,UgxwUURNCzUanA6hxQJ4AaABAg,2,rRB9iymNy1w,0,4,2019-04-07T06:46:20Z,That woman is his wife Carol Reiley,2019-04-07T06:46:20Z
UgxwUURNCzUanA6hxQJ4AaABAg.8qqEhpqTx4i8vEj8QEU5Lo,@dimitrisgkoumas2642,UgxwUURNCzUanA6hxQJ4AaABAg,2,rRB9iymNy1w,0,0,2019-05-22T15:02:03Z,@@shwethasubbu3385 HAHA,2019-05-22T15:02:03Z
UgxwUURNCzUanA6hxQJ4AaABAg.8qqEhpqTx4i8yCBKgmumHw,@AhmedIsam,UgxwUURNCzUanA6hxQJ4AaABAg,2,rRB9iymNy1w,0,0,2019-08-04T04:53:36Z,@@dimitrisgkoumas2642 It&#39;s true BTW,2019-08-04T04:53:36Z
UgxwUURNCzUanA6hxQJ4AaABAg.8qqEhpqTx4i95qAn3Iwxhs,@vsirius7732,UgxwUURNCzUanA6hxQJ4AaABAg,2,rRB9iymNy1w,0,0,2020-03-05T23:08:53Z,@@shwethasubbu3385 I knew it! when he drew a crown on her head I was like: that&#39;s probably his wife xp,2020-03-05T23:08:53Z
Ugz2r1QYy1jb30ZAwKt4AaABAg,@inquisitiverakib5844,,1,5e5pjeojznk,0,0,2022-07-15T06:28:20Z,"<a href=""https://www.youtube.com/watch?v=5e5pjeojznk&amp;t=1m32s"">1:32</a> Image classification at pixel level...",2022-07-15T06:28:20Z
UgwvnemYeWuWnXa2VVB4AaABAg,@ChristianBrugger,,1,5e5pjeojznk,0,0,2022-06-24T15:03:57Z,"I am using CNN&#39;s with a lot of layers. They use padding so that the input size doesn&#39;t shrink. This makes this approach not so straight forward. Any idea how to deal with that? Another case are Resnet like blocks, which have different convolutions on different paths merging. Without padding this is difficult, any idea?",2022-06-24T15:03:57Z
UgxPMH8AjKra8D9ucrJ4AaABAg,@aiduong7700,,1,5e5pjeojznk,0,0,2022-01-19T09:16:12Z,"These lectures are really amazing so far. Thank you so much, Sir.",2022-01-19T09:16:12Z
UgwQZI5UXkJ_fkz6_Up4AaABAg,@sandipansarkar9211,,1,5e5pjeojznk,0,0,2021-01-08T15:47:26Z,Very nice explanation.Slowly gaining confidence in deep learning.Please continue watching all the videos in this playlist,2021-01-08T15:47:26Z
Ugw2HQ1KU-Fo0IGwDoB4AaABAg,@sanketjadhav2799,,1,5e5pjeojznk,0,3,2020-07-31T14:04:16Z,Sir you are awesome.  i regret not visiting this channel earlier. Thanks a lot sir.,2020-07-31T14:04:16Z
UgyNnwgeFuFrM0G11PF4AaABAg,@lynngreen1714,,1,5e5pjeojznk,1,2,2020-05-11T15:19:47Z,"First, i think i just watch 1 video, now i watched 5 of them, and i still keep watching ...",2020-05-11T15:19:47Z
UgyNnwgeFuFrM0G11PF4AaABAg.98WrMsIUCPH9B0xNSQqH1r,@jesuispac,UgyNnwgeFuFrM0G11PF4AaABAg,2,5e5pjeojznk,0,1,2020-07-12T19:30:46Z,Exactly. Binge watching this series and I&#39;ve always hated learning for school. :o,2020-07-12T19:30:46Z
UgygCNelTsdHXgZRYW54AaABAg,@ssverma80,,1,5e5pjeojznk,1,1,2020-01-24T12:19:02Z,nice sir. But C4W305 is not available,2020-01-24T12:19:02Z
UgygCNelTsdHXgZRYW54AaABAg.94ARpYjynte94ASFewwcDF,@ssverma80,UgygCNelTsdHXgZRYW54AaABAg,2,5e5pjeojznk,0,3,2020-01-24T12:22:44Z,"<a href=""https://www.youtube.com/watch?v=gKreZOUi-O0"">https://www.youtube.com/watch?v=gKreZOUi-O0</a>",2020-01-24T12:22:44Z
Ugz7Gbw3lTyJMVueYHZ4AaABAg,@salmahayani7423,,1,5e5pjeojznk,0,1,2019-09-08T12:10:08Z,HEllo please how can we do our own implementation of Faster RCNN without using pre-trained models?,2019-09-08T12:10:08Z
UgwJIY0WVB53hGFLCC94AaABAg,@arjunbali9270,,1,5e5pjeojznk,2,0,2019-06-20T01:39:34Z,"If the covnet is trained for a specific size of the image, how will it predict 0 or 1 for a different size of the image when we increase the  size of the input image ?",2019-06-20T01:39:34Z
UgwJIY0WVB53hGFLCC94AaABAg.8wNyM7E2xG-8y7_OZdQ1u5,@tanmay8639,UgwJIY0WVB53hGFLCC94AaABAg,2,5e5pjeojznk,0,1,2019-08-02T09:56:22Z,i think u can pretty much resize the test images,2019-08-02T09:56:22Z
UgwJIY0WVB53hGFLCC94AaABAg.8wNyM7E2xG-90gCy02xAsl,@TL-fe9si,UgwJIY0WVB53hGFLCC94AaABAg,2,5e5pjeojznk,0,0,2019-10-29T19:38:29Z,deliated convolution tricks used in deeplab models can detect  certain features at different scales.,2019-10-29T19:38:29Z
UgwvsK9_KilFkxm_Abp4AaABAg,@carmelocalafiore7203,,1,5e5pjeojznk,1,4,2019-05-25T00:21:36Z,I have watched 25 videos that were very interesting but you so far have not addressed the issue of how to compute the gradients in CNNs,2019-05-25T00:22:13Z
UgwvsK9_KilFkxm_Abp4AaABAg.8vKslM9BvHP9ch4kozN_8w,@JohnZmith,UgwvsK9_KilFkxm_Abp4AaABAg,2,5e5pjeojznk,0,2,2022-06-25T12:10:23Z,It was discussed pretty much in course 1,2022-06-25T12:10:23Z
UgxXnH7IJZMszdiaon94AaABAg,@KevinKuei,,1,5e5pjeojznk,3,4,2017-12-03T02:11:14Z,I failed to find C4W3L05 video. Can anyone help?,2017-12-03T02:11:14Z
UgxXnH7IJZMszdiaon94AaABAg.8_gldZoPPLx8afbuAqCvOR,@dj_metanov,UgxXnH7IJZMszdiaon94AaABAg,2,5e5pjeojznk,0,4,2017-12-27T11:58:16Z,"<a href=""https://www.youtube.com/watch?v=gKreZOUi-O0"">https://www.youtube.com/watch?v=gKreZOUi-O0</a>",2017-12-27T11:58:16Z
UgxXnH7IJZMszdiaon94AaABAg.8_gldZoPPLx8b6sGBSyUfq,@masterRabbit78,UgxXnH7IJZMszdiaon94AaABAg,2,5e5pjeojznk,0,2,2018-01-07T11:19:57Z,"<a href=""https://www.youtube.com/watch?v=DFjHkXhkYzA"">https://www.youtube.com/watch?v=DFjHkXhkYzA</a>",2018-01-07T11:19:57Z
UgxXnH7IJZMszdiaon94AaABAg.8_gldZoPPLx8b8HqpiVLcr,@KevinKuei,UgxXnH7IJZMszdiaon94AaABAg,2,5e5pjeojznk,0,0,2018-01-08T00:31:31Z,Thanks!,2018-01-08T00:31:31Z
UgzpNknjT5gaOqCx-yN4AaABAg,@vent_srikar7360,,1,XdsmlBGOK-k,0,0,2023-04-29T06:33:45Z,how did we drop from 28 x 28 to 16 x 16,2023-04-29T06:33:45Z
UgwRwE2LLSMKOZ9SGix4AaABAg,@GK-jw8bn,,1,XdsmlBGOK-k,0,0,2022-12-28T06:48:57Z,thank you!,2022-12-28T06:48:57Z
UgyNU1zXNs3onn3IUA54AaABAg,@ChristianBrugger,,1,XdsmlBGOK-k,0,0,2022-06-24T15:03:07Z,"I am using CNN&#39;s with a lot of layers. They use padding so that the input size doesn&#39;t shrink. This makes this approach not so straight forward. Any idea how to deal with that? Another case are Resnet like blocks, which have different convolutions on different paths merging. Without padding this is difficult, any idea?",2022-06-24T15:03:29Z
Ugwvj4oUlAGBHyn1y0B4AaABAg,@tag_of_frank,,1,XdsmlBGOK-k,0,0,2022-04-17T13:39:52Z,How to build training data for this?!,2022-04-17T13:39:52Z
UgzbYgq2qqv9yj9uqZB4AaABAg,@maxzjj,,1,XdsmlBGOK-k,0,0,2022-01-28T09:37:08Z,"At the end of the video, the bounding box inaccuracy is mentioned. In addition, I&#39;d like to remark that the network can only recognize fully visible, unobscured cars at that moment, still.",2022-01-28T09:37:21Z
UgyK-Wxt4ny5TLESDdd4AaABAg,@touchyto,,1,XdsmlBGOK-k,0,0,2022-01-27T09:12:35Z,A question: slide window is the same that feature map that we get when apply a convolution filter? thank you,2022-01-27T09:12:35Z
UgyWXL2NkCtxGugJtcd4AaABAg,@andrei-robertalexandrescu5103,,1,XdsmlBGOK-k,0,0,2022-01-16T09:28:27Z,This is golden.,2022-01-16T09:28:27Z
Ugz3bbGbhlkSOaR5EnZ4AaABAg,@hackercop,,1,XdsmlBGOK-k,0,0,2022-01-11T17:54:34Z,"<a href=""https://www.youtube.com/watch?v=XdsmlBGOK-k&amp;t=8m19s"">8:19</a> wow thats amazing",2022-01-11T17:54:34Z
UgytAfZfimVpJtrVoaZ4AaABAg,@anushkajain9529,,1,XdsmlBGOK-k,0,0,2021-08-15T10:35:50Z,I didn&#39;t understand how convolutionally the number of iterations for a stride will be less ?,2021-08-15T10:35:50Z
UgyjuwtJcDf8XtJNqfh4AaABAg,@namlehai2737,,1,XdsmlBGOK-k,0,1,2021-06-19T16:02:07Z,"damn, whoever came up with this idea deserves a cookie",2021-06-19T16:02:07Z
UgyhohqNNsP3z8SXOy54AaABAg,@forestalauxhd2003,,1,XdsmlBGOK-k,1,0,2021-06-15T03:37:53Z,then the FCN are CNN?,2021-06-15T03:37:53Z
UgyhohqNNsP3z8SXOy54AaABAg.9Oa_0-_1nUi9WY-JzKywdc,@ihebbibani7122,UgyhohqNNsP3z8SXOy54AaABAg,2,XdsmlBGOK-k,0,0,2021-12-29T14:30:44Z,"I was reading about that yesterday. <br><br>Actually , <br><br>FCN stands Fully Connected Networks where you have ONLY Convolution operators.<br><br>CNN stands for Convolutional Neural Networks where you NOT ONLY Convolution operators but also contains Fully Connected Layer(s).<br><br>This is what I have understood.<br><br>Hope this is clear.",2021-12-29T14:30:44Z
UgwI_7ZO_57Zav5Mkjh4AaABAg,@deepeshmhatre4291,,1,XdsmlBGOK-k,0,1,2021-05-09T12:37:36Z,This left me more confused,2021-05-09T12:37:36Z
UgwcuYkX0bTHum7xDPh4AaABAg,@shuyuancai4504,,1,XdsmlBGOK-k,0,0,2021-04-16T06:51:08Z,"using the parameter setting in this example, the last 3 conv layers need more parameters than the last 3 fc layers‚Ä¶‚Ä¶am I wrong or it is actually this case",2021-04-16T06:51:08Z
UgzBQjJiXKsfMEeOV_t4AaABAg,@noorameera26,,1,XdsmlBGOK-k,0,1,2021-02-18T14:09:46Z,omg I couldn&#39;t completely get this in class just now but now I could! Thanks &lt;3,2021-02-18T14:09:46Z
UgzUgnSZ2huQNHhy8Ad4AaABAg,@manuel783,,1,XdsmlBGOK-k,0,2,2021-01-18T23:49:55Z,"Convolutional Implementation of Sliding Windows <b>CORRECTION</b><br><br>At <a href=""https://www.youtube.com/watch?v=XdsmlBGOK-k&amp;t=7m14s"">7:14</a>, Andrew should have said 2x2x400 instead of 2x2x40.<br><br>At <a href=""https://www.youtube.com/watch?v=XdsmlBGOK-k&amp;t=10m04s"">10:04</a> onward, the size of the second layer should be 24 x 24 instead of 16 x 16.",2021-01-18T23:49:55Z
Ugz1-EBTX5HrMxPi7jN4AaABAg,@sandipansarkar9211,,1,XdsmlBGOK-k,0,0,2021-01-08T15:58:42Z,suprb explanation,2021-01-08T15:58:42Z
Ugxll9SVdWIqDDEY7St4AaABAg,@Rajjain_,,1,XdsmlBGOK-k,0,1,2021-01-06T17:20:06Z,One problem I see in this implementation is that it may be the case that the model we trained for object detection that specific window size is not good for test object like if you trained for 14*14*3  it may be the case that car is covering 28*28*3 image whole area and model may perform poorly here!,2021-01-06T17:22:02Z
Ugynnv8gQjFFXdBzyQR4AaABAg,@debarunkumer2019,,1,XdsmlBGOK-k,0,0,2020-10-31T18:12:52Z,I am in love with this model,2020-10-31T18:12:52Z
UgyPRh1qz4XshCpfW4R4AaABAg,@anonimo-xz2tg,,1,XdsmlBGOK-k,1,1,2020-10-15T20:06:01Z,can someone please explain the last 6 minutes of the video? I cant follow any of it,2020-10-15T20:06:01Z
UgyPRh1qz4XshCpfW4R4AaABAg.9Eqcvd7djBI9LTHVEnD_Dn,@krishnar6717,UgyPRh1qz4XshCpfW4R4AaABAg,2,XdsmlBGOK-k,0,0,2021-03-29T08:48:01Z,Don&#39;t worry if you can&#39;t follow it,2021-03-29T08:48:01Z
Ugw35A8Qd7PyDTGLlnl4AaABAg,@LakshmikanthAyyadevara,,1,XdsmlBGOK-k,0,0,2020-08-23T12:23:03Z,extraordinary viedo,2020-08-23T12:23:03Z
UgzvbB9TgZkbj30-2Vp4AaABAg,@user-vo9ov4dh8b,,1,XdsmlBGOK-k,1,2,2020-07-10T06:21:50Z,"When 5x5x16 change to 1x1x400, I think this process should be linear. Then, Is there no ReLU function in this process?<br>(I meant only 5x5x16 -&gt; 1x1x400)",2020-07-10T07:37:19Z
UgzvbB9TgZkbj30-2Vp4AaABAg.9AvOVJkDUhX9lT20P8EJIh,@lilrun7741,UgzvbB9TgZkbj30-2Vp4AaABAg,2,XdsmlBGOK-k,0,0,2023-01-29T08:40:22Z,"it does, He skipped flatten layer and continued fc layer",2023-01-29T08:40:22Z
UgzisFEQiB-CNY4gIAZ4AaABAg,@guo7043,,1,XdsmlBGOK-k,2,0,2020-06-28T18:21:19Z,"C4W3L05, 720P https://www.youtube.com/watch?v=yo9S3eNtkXc",2023-11-05T09:16:47Z
UgzisFEQiB-CNY4gIAZ4AaABAg.9ASmISon6ys9Hpx-jUQvce,@adhoc3018,UgzisFEQiB-CNY4gIAZ4AaABAg,2,XdsmlBGOK-k,0,0,2020-12-29T03:16:24Z,Thanks!,2020-12-29T03:16:24Z
UgzisFEQiB-CNY4gIAZ4AaABAg.9ASmISon6ys9KIgQMudPwr,@2B_pencil,UgzisFEQiB-CNY4gIAZ4AaABAg,2,XdsmlBGOK-k,0,1,2021-02-28T09:31:30Z,720P is superior!!,2021-02-28T09:31:30Z
Ugxsy2vyE_Tyn6yyvb14AaABAg,@anupamsingh3732,,1,XdsmlBGOK-k,0,0,2020-05-17T15:13:16Z,"how to set size of sliding window in cnn,",2020-05-17T15:13:16Z
UgxB2owAA2hOBGvSS-x4AaABAg,@TheKovosh,,1,XdsmlBGOK-k,0,0,2020-05-10T15:27:09Z,I am pretty sure that the next video is not uploaded correctly. One video is missing and because of that the anchor box lecture dose not make sense.,2020-05-10T15:27:09Z
Ugwem6YrBYrHgO_xpG94AaABAg,@mailoisback,,1,XdsmlBGOK-k,1,0,2020-05-08T06:42:01Z,"Why, in sliding window approach, matching exact position of an object is a problem? If the stride is 1, then we cover each pixel of the image (let&#39;s say with a 14x14 box centered at each pixel of the image), so we cover all the possible locations in image and therefore we will match the exact position of an object (its center). The problem arises only when we use a bigger stride.",2020-05-08T06:42:01Z
Ugwem6YrBYrHgO_xpG94AaABAg.98OCiz1cA9b9izmoC6PKmF,@ahmadhesham1389,Ugwem6YrBYrHgO_xpG94AaABAg,2,XdsmlBGOK-k,0,0,2022-11-28T21:38:45Z,"A smaller stride = more computations. Also, the objects may show up with different aspect ratios, which would require using many sliding windows with different sizes to detect all of them, so you can imagine how badly this scales up when you combine it with a small stride.",2022-11-28T21:38:45Z
Ugy7sUYef2jVoPGSLfx4AaABAg,@souvikghosh1285,,1,XdsmlBGOK-k,0,1,2020-04-06T06:01:26Z,C4W3L05 ----&gt; https://www.youtube.com/watch?v=yo9S3eNtkXc,2023-10-30T16:42:39Z
UgzW7LF9lYU3_u1EmDV4AaABAg,@keshavkumar7769,,1,XdsmlBGOK-k,0,0,2019-12-21T20:21:50Z,"hello sir , i think  you have not provided  C4W3L04<br> video",2019-12-21T20:22:31Z
UgwarecgWEaGjfb9kcl4AaABAg,@temirlanseilov9715,,1,XdsmlBGOK-k,0,25,2019-11-13T04:01:14Z,Pictures the volume as the rectangle for simplification. Proceeds to draw the volume by hand :),2019-11-13T04:01:14Z
Ugwbf-Lv61yTSmK1TAh4AaABAg,@filippocastelli42,,1,XdsmlBGOK-k,1,0,2019-08-13T12:13:19Z,Anyone got some sort of written reference (books/papers) for this?,2019-08-13T12:13:19Z
Ugwbf-Lv61yTSmK1TAh4AaABAg.8y_8o7zQC-B8zoi1JV1tD7,@sandyz1000,Ugwbf-Lv61yTSmK1TAh4AaABAg,2,XdsmlBGOK-k,0,0,2019-09-13T09:49:49Z,Overfeat paper from the arxiv,2019-09-13T09:49:49Z
UgxmP9j_9-nV6_xKBcN4AaABAg,@OnlyLogicalTalk,,1,XdsmlBGOK-k,0,1,2019-06-12T08:03:10Z,"C4W3L05<br><a href=""https://www.youtube.com/watch?v=gKreZOUi-O0"">https://www.youtube.com/watch?v=gKreZOUi-O0</a>",2019-06-12T08:03:10Z
Ugzh6dRSC5Mahi_hfJt4AaABAg,@AseemPokharel,,1,XdsmlBGOK-k,0,1,2019-05-07T15:45:10Z,"For previsious video link : <a href=""https://www.youtube.com/watch?v=5e5pjeojznk"">https://www.youtube.com/watch?v=5e5pjeojznk</a> or search with title &quot;C4W3L03 Object Detection&quot;",2019-05-07T15:46:20Z
UgyOZQoMz7ykNDnqvcl4AaABAg,@qwewqeqweqwe8334,,1,XdsmlBGOK-k,0,1,2019-03-05T10:53:18Z,Wow!! Absolutely wow!,2019-03-05T10:53:18Z
UgwyKPlQGunfaQQe6qR4AaABAg,@Cliu960129,,1,XdsmlBGOK-k,0,0,2018-12-13T20:43:09Z,What if the dimension of the test image is smaller than that of training images? Do we use paddings?,2018-12-13T20:43:09Z
UgzXanwOU5GimKeCDbp4AaABAg,@aakashchawla5274,,1,XdsmlBGOK-k,0,0,2018-12-04T17:29:16Z,"A working link: <a href=""https://www.youtube.com/watch?v=gKreZOUi-O0&amp;ab_channel=intrigano"">https://www.youtube.com/watch?v=gKreZOUi-O0&amp;ab_channel=intrigano</a>",2018-12-04T17:29:16Z
UgyoMIOA1WEhPnxbHpp4AaABAg,@Sw3l,,1,XdsmlBGOK-k,4,3,2018-09-20T08:07:25Z,"I follow the idea, however I don&#39;t get how it can be implemented programmatically. <br>When you train your convolutional neural network, you define a input size. If a larger image is pushed trough the network, I assume an error on input dimensions will pop up. Can the dimensions be easily changed after training?",2018-09-20T08:07:25Z
UgyoMIOA1WEhPnxbHpp4AaABAg.8lPhiwu7FU38mzuS3itQRV,@mariama70,UgyoMIOA1WEhPnxbHpp4AaABAg,2,XdsmlBGOK-k,0,1,2018-10-29T15:21:51Z,You need to preprocess your image (cropping/resizing) to conform with the image size used in the training process.,2018-10-29T15:21:51Z
UgyoMIOA1WEhPnxbHpp4AaABAg.8lPhiwu7FU38n-gsOWPVWh,@elgs1980,UgyoMIOA1WEhPnxbHpp4AaABAg,2,XdsmlBGOK-k,0,0,2018-10-29T22:42:29Z,I have the same question. I really hope Andrew would talk more about the back propagation.,2018-10-29T22:42:29Z
UgyoMIOA1WEhPnxbHpp4AaABAg.8lPhiwu7FU38nXEkyHyR-X,@johnaremania7269,UgyoMIOA1WEhPnxbHpp4AaABAg,2,XdsmlBGOK-k,0,2,2018-11-11T23:22:15Z,"Since the idea is changing the FC layer to convolutional layer, we can easily train and test the model without specific size of width and height, for instance we can set the value of input dimension as None,None,3 in Keras. Remember, convolutional layer is different with FC, it shares the weight to each features map.",2018-11-11T23:22:15Z
UgyoMIOA1WEhPnxbHpp4AaABAg.8lPhiwu7FU38poE4mx8ZJi,@diegocifuentes6784,UgyoMIOA1WEhPnxbHpp4AaABAg,2,XdsmlBGOK-k,0,1,2019-01-07T16:05:28Z,"Yes, because you save the weights of the kernels, so when you&#39;re testing your network you never worry about the dimentions of the input size if they are larger than the dimentions used on training",2019-01-07T16:05:28Z
Ugxvf8p9JN0D0qzvdP14AaABAg,@banipreetsinghraheja8529,,1,XdsmlBGOK-k,1,0,2018-06-22T13:10:37Z,This video comes after the next video in the list. (26-&gt;25-&gt;27..... is the right sequence of videos specified in the course),2018-06-22T13:10:37Z
Ugxvf8p9JN0D0qzvdP14AaABAg.8hnVswRoN5a8r6Hicp7YNi,@bobcrunch,Ugxvf8p9JN0D0qzvdP14AaABAg,2,XdsmlBGOK-k,0,0,2019-02-08T22:14:14Z,"Slides are created/deleted/rearranged each session, but the material is more or less the same. What&#39;s really missing are the problem sets. They are quite difficult if you&#39;re a newbie, but with a lot of &#39;Net searching, they are solvable. If you just audit the course, you can&#39;t download the datasets, but you can search for equivalent datasets and use those.",2019-02-08T22:14:14Z
UgxfrBjyVpo6qi08Hvl4AaABAg,@xKira74,,1,XdsmlBGOK-k,4,31,2018-05-03T09:23:30Z,"C4W3L05 --&gt; <a href=""https://www.youtube.com/watch?v=DFjHkXhkYzA"">https://www.youtube.com/watch?v=DFjHkXhkYzA</a>",2018-05-03T09:23:30Z
UgxfrBjyVpo6qi08Hvl4AaABAg.8fmM8niJxu48ghpPYmncKD,@user-hi3ot5xo9k,UgxfrBjyVpo6qi08Hvl4AaABAg,2,XdsmlBGOK-k,0,0,2018-05-26T11:43:07Z,Thanks dude,2018-05-26T11:43:07Z
UgxfrBjyVpo6qi08Hvl4AaABAg.8fmM8niJxu48jPDZBup4C1,@csam11100,UgxfrBjyVpo6qi08Hvl4AaABAg,2,XdsmlBGOK-k,0,25,2018-08-01T10:32:16Z,"The link is dead, here is another link!<br><a href=""https://www.youtube.com/watch?v=gKreZOUi-O0&amp;t=0s&amp;index=6&amp;list=PL_IHmaMAvkVxdDOBRg2CbcJBq9SY7ZUvs"">https://www.youtube.com/watch?v=gKreZOUi-O0&amp;t=0s&amp;index=6&amp;list=PL_IHmaMAvkVxdDOBRg2CbcJBq9SY7ZUvs</a>",2018-08-01T10:32:16Z
UgxfrBjyVpo6qi08Hvl4AaABAg.8fmM8niJxu48s23KQEIjyh,@naineshhulke2896,UgxfrBjyVpo6qi08Hvl4AaABAg,2,XdsmlBGOK-k,0,1,2019-03-04T03:22:53Z,@@csam11100 Thanks a lot,2019-03-04T03:22:53Z
UgxfrBjyVpo6qi08Hvl4AaABAg.8fmM8niJxu48u4HU-hn49y,@isaacaddis8376,UgxfrBjyVpo6qi08Hvl4AaABAg,2,XdsmlBGOK-k,0,1,2019-04-23T17:07:48Z,@@csam11100 Thanks!,2019-04-23T17:07:48Z
Ugza8JGUiSf5UZPZBZZ4AaABAg,@RenzymEducation,,1,ANIzQ5G-XPE,0,0,2022-12-11T09:28:54Z,The C4W4L05 is missing on the playlist and channel,2022-12-11T09:28:54Z
UgxNRqrzbAU5YH94cLR4AaABAg,@usamazahid1,,1,ANIzQ5G-XPE,0,0,2022-12-02T06:03:45Z,concept delivered.....bullz eye in short span of time which is beautiful. Amazing stuff!!!,2022-12-02T06:03:45Z
UgyCIYrRKXrpStd5F2Z4AaABAg,@saadmunir1467,,1,ANIzQ5G-XPE,0,0,2022-03-10T01:30:51Z,thats amazing and simple explanation! thanksss,2022-03-10T01:30:51Z
UgyR2wn6J_jRpNBqxxJ4AaABAg,@freerockneverdrop1236,,1,ANIzQ5G-XPE,0,0,2021-11-16T03:22:24Z,"This is great! One question, YOLO split the picture into smaller one and look them only once. This seems better than that. Can you explain the difference? pros and cons? I&#39;m also not very clear about how to run with different smaller window size.",2021-11-16T03:22:24Z
UgzI1wtMVjf62bCyLpJ4AaABAg,@sheereenfathima,,1,ANIzQ5G-XPE,0,0,2021-09-06T19:59:38Z,You are just mind-blowing what a brilliant and talented teacher before learning all this Machine learning deep learning reinforcement learning we need to learn basics Algorithms first then only we can understand so many problems and formulas need to solve in this learnings..Bow down,2021-09-06T19:59:38Z
UgzmyOVpHVGgnpn-kJt4AaABAg,@noorameera26,,1,ANIzQ5G-XPE,0,0,2021-02-18T13:06:45Z,Great as always sir Andrew!,2021-02-18T13:06:45Z
UgyGtlCjcaoXDsS-YI14AaABAg,@sandipansarkar9211,,1,ANIzQ5G-XPE,0,0,2021-01-06T18:30:52Z,nice expression,2021-01-06T18:30:52Z
UgwsxNjSxIFw6OA0RJh4AaABAg,@MrSilentdeath1,,1,ANIzQ5G-XPE,0,0,2020-07-25T22:08:00Z,Andrew&#39;s desk always looks so empty.,2020-07-25T22:08:00Z
Ugwx598FB1xAD6rJ8ut4AaABAg,@anmjubaer,,1,ANIzQ5G-XPE,0,1,2020-04-07T18:27:59Z,Andrew is also fun. IoU I owe you.,2020-04-07T18:27:59Z
UgyY31VoDZIeUORmp5t4AaABAg,@jangasienica-jozkowy8764,,1,ANIzQ5G-XPE,1,1,2020-01-21T17:43:43Z,"What do you think about setting a threshold level below 0.5 in some specific tasks? Currently, I am training object detector for search and rescue drone, that will be looking for lost people. When I set the threshold level on lower level, for example 0.25, it works starts to look really better. I think it is because the main purpose, in this case of the detector, is to give a drone operator hint where a lost person could be, not to give him exact location. If the detector mark only half of the body of the lost person it still will be helpful for the operator. What do you think about it, could lowering of threshold level be useful and right in some specific tasks?",2020-01-21T17:43:43Z
UgyY31VoDZIeUORmp5t4AaABAg.943Iaziv7lz9OFeOCfoEc8,@SanjaySingh-ce6mp,UgyY31VoDZIeUORmp5t4AaABAg,2,ANIzQ5G-XPE,0,0,2021-06-06T15:21:35Z,"No, here we are training the algo and we need to improve the detection skill. Lowering the threshold will only result in a less effectively trained algo",2021-06-06T15:21:35Z
UgxO2UnrIMvhx_j3cEJ4AaABAg,@ilanaizelman3993,,1,ANIzQ5G-XPE,0,1,2019-08-10T14:53:35Z,"C4W3L05 <a href=""https://www.youtube.com/watch?v=gKreZOUi-O0"">https://www.youtube.com/watch?v=gKreZOUi-O0</a>",2019-08-10T14:53:35Z
Ugx8gra1P9vwp6SDMAt4AaABAg,@anandinamdar4054,,1,ANIzQ5G-XPE,1,0,2019-07-10T00:43:03Z,This will only work on rectangles. How to calculate IoU of image segment of different shape?,2019-07-10T00:43:03Z
Ugx8gra1P9vwp6SDMAt4AaABAg.8xBMmgdYCFe9OTlE2n2zvb,@jsarvesh,Ugx8gra1P9vwp6SDMAt4AaABAg,2,ANIzQ5G-XPE,0,0,2021-06-12T02:50:44Z,"output of the cnn is of the form(bx, by, bw, bw) which is a rectangle, so there will be no different shape.",2021-06-12T02:50:44Z
Ugx8lAs34fwIKuPg6sZ4AaABAg,@gauravchatterjee4313,,1,ANIzQ5G-XPE,1,24,2019-04-22T10:00:12Z,"I owe you, Andrew, you are an awesome teacher!",2019-04-22T10:00:12Z
Ugx8lAs34fwIKuPg6sZ4AaABAg.8u0wkJAvEW69n9WaVT7igi,@vaiebhavpatil2340,Ugx8lAs34fwIKuPg6sZ4AaABAg,2,ANIzQ5G-XPE,0,0,2023-03-12T11:45:34Z,üëè,2023-03-12T11:45:34Z
UgzLgxI2gjXxdB0VzaB4AaABAg,@EranM,,1,ANIzQ5G-XPE,0,3,2019-04-01T04:47:02Z,"<a href=""https://www.youtube.com/watch?v=ANIzQ5G-XPE&amp;t=3m45s"">3:45</a> omg the joke :&gt;&gt;&gt; Love you Andrew!",2019-04-01T04:47:02Z
UgwBhB5Ft6pCj4xB0V94AaABAg,@taihuahu5185,,1,ANIzQ5G-XPE,0,0,2019-03-06T01:12:36Z,"I owe U, boy",2019-03-06T01:12:36Z
Ugzp7XYHPLUhn6xSgxJ4AaABAg,@caducoelho2221,,1,ANIzQ5G-XPE,0,0,2019-02-18T17:10:17Z,"Thank you very much for the lectures! Some of the lectures in C4W3 are out of order, though. Keep up the great work and sharing it with the world!!",2019-02-18T17:10:17Z
UgxCbtnV-Bi5-WgvUxd4AaABAg,@muhammadharris4470,,1,ANIzQ5G-XPE,0,0,2019-01-16T13:05:18Z,"updated link to C4W3L05: <a href=""https://www.youtube.com/watch?v=gKreZOUi-O0"">https://www.youtube.com/watch?v=gKreZOUi-O0</a>",2019-01-16T13:05:18Z
UgxO1CeTM26njwD5dLx4AaABAg,@navid2368,,1,ANIzQ5G-XPE,0,45,2019-01-11T22:03:12Z,"Andrew, IoU for these awesome videos. :) Thanks!",2019-01-11T22:03:12Z
UgxZY44HiqLth8c0KUZ4AaABAg,@samaryousef7327,,1,ANIzQ5G-XPE,0,0,2018-08-28T01:11:27Z,"<a href=""https://www.youtube.com/watch?v=gKreZOUi-O0"">https://www.youtube.com/watch?v=gKreZOUi-O0</a>",2018-08-28T01:11:27Z
UgzFwXwYjCdL3EJYnw14AaABAg,@janir7886,,1,ANIzQ5G-XPE,1,0,2018-08-06T19:52:29Z,ground truth image means image in the training set right?,2018-08-06T19:52:29Z
UgzFwXwYjCdL3EJYnw14AaABAg.8jc5djCkDHS8piH2pJPSbR,@janvonschreibe3447,UgzFwXwYjCdL3EJYnw14AaABAg,2,ANIzQ5G-XPE,0,0,2019-01-05T08:35:59Z,Yes It&#39;s the label of a training instance. Here the coordinates of the bounding box,2019-01-05T08:35:59Z
UgxQuC3Srvj2_n6wmaB4AaABAg,@xKira74,,1,ANIzQ5G-XPE,0,8,2018-05-03T09:21:47Z,"C4W3L05 --&gt; <a href=""https://www.youtube.com/watch?v=DFjHkXhkYzA"">https://www.youtube.com/watch?v=DFjHkXhkYzA</a>",2018-05-03T09:21:47Z
UgzWWyO3L8ZvJSErUbh4AaABAg,@uqyge,,1,ANIzQ5G-XPE,0,2,2018-03-28T22:51:09Z,l5 is missing,2018-03-28T22:51:09Z
UgyuKrDAwFJnSoQ6GSp4AaABAg,@vrishabhjain9813,,1,ANIzQ5G-XPE,1,19,2017-11-08T06:06:24Z,Please upload C4W3L05,2017-11-08T06:06:24Z
UgyuKrDAwFJnSoQ6GSp4AaABAg.8Zgog5Ije6s8yShj6CvAjO,@ilanaizelman3993,UgyuKrDAwFJnSoQ6GSp4AaABAg,2,ANIzQ5G-XPE,0,7,2019-08-10T14:53:16Z,"<a href=""https://www.youtube.com/watch?v=gKreZOUi-O0"">https://www.youtube.com/watch?v=gKreZOUi-O0</a>",2019-08-10T14:53:16Z
Ugyh7I4MDcc6zPOdxw54AaABAg,@randalllionelkharkrang4047,,1,VAo84c1hQX8,1,0,2022-12-19T15:14:36Z,"Well, Why dont we just pick the bounding box with highest pc, instead of doing the second step, where we discard any other box intersecting with highest pc? seems unnecessary",2022-12-19T15:14:36Z
Ugyh7I4MDcc6zPOdxw54AaABAg.9jpAXuFOvi89kgieVpA3zY,@maxinelyu2693,Ugyh7I4MDcc6zPOdxw54AaABAg,2,VAo84c1hQX8,0,0,2023-01-10T04:59:42Z,Because you can have an object appearing in multiple places.,2023-01-10T04:59:42Z
UgwcsZAP6e2MnpKYG254AaABAg,@signature445,,1,VAo84c1hQX8,0,0,2021-10-05T06:16:28Z,"Sir ,what is the need of this NMS, why cant we take the box diretly with high probability score.",2021-10-05T06:16:28Z
UgxmRibyPH16Wwx9TOZ4AaABAg,@hafizyusufheraldi8975,,1,VAo84c1hQX8,0,2,2021-07-02T16:15:30Z,"great explanation, thank you, sir!",2021-07-02T16:15:30Z
Ugwr6VXwdWdVpYs48F54AaABAg,@harshays2873,,1,VAo84c1hQX8,1,1,2021-04-06T10:40:32Z,"As you said more IoU value gives a more accurate bounding box, but in this video you are discarding the boxes if IoU&gt;=0.5 ,  why?",2021-04-06T10:40:32Z
Ugwr6VXwdWdVpYs48F54AaABAg.9Ln4jHHv7Xe9MzyRTBl5CM,@rajkumarcm,Ugwr6VXwdWdVpYs48F54AaABAg,2,VAo84c1hQX8,0,3,2021-05-06T07:18:18Z,"Because we already have a bounding box with high objectness score, we want to remove the rest that heavily overlaps that. This means, you are removing redundant bounding boxes.",2021-05-06T07:18:18Z
UgwDIBFoADkMYAM404d4AaABAg,@jongseokchoi4038,,1,VAo84c1hQX8,0,4,2021-03-03T09:19:12Z,"So, the main idea is that, first: find the box which has the highest Pc value, no matter where that is in the image. Second, get the iou values of the boxes nearby and kill the boxes that are overlaped with the chosen box a lot (chosen due to the highest Pc as I mentioned) and repeat that with the boxes survived and one which has the second highest Px..",2021-03-03T16:50:04Z
UgxG70MBttFvXaZkVdl4AaABAg,@tomszwagier3010,,1,VAo84c1hQX8,4,15,2021-02-16T22:09:15Z,"PROBLEM OF UNDERSTANDING ?<br><br>if you don&#39;t understand why at <a href=""https://www.youtube.com/watch?v=VAo84c1hQX8&amp;t=0m28s"">0:28</a>, Andrew Ng introduces a grid that seems to come out of nowhere, or if you don&#39;t understand well the logical sequence of this week&#39;s videos, it is simply because the video C4W3L05 has been forgotten in this playlist !<br><br>Everything will be clearer if you look at that missing video<br><br>Regards",2021-02-16T22:09:15Z
UgxG70MBttFvXaZkVdl4AaABAg.9Jq8ajBLyzO9LBlvizl-kJ,@Dhanush-zj7mf,UgxG70MBttFvXaZkVdl4AaABAg,2,VAo84c1hQX8,0,3,2021-03-22T13:36:19Z,"I found the missing video - <a href=""https://www.youtube.com/watch?v=gKreZOUi-O0&amp;list=PL_IHmaMAvkVxdDOBRg2CbcJBq9SY7ZUvs&amp;t=656s"">https://www.youtube.com/watch?v=gKreZOUi-O0&amp;list=PL_IHmaMAvkVxdDOBRg2CbcJBq9SY7ZUvs&amp;t=656s</a> . Best Of Luck",2021-03-22T13:36:19Z
UgxG70MBttFvXaZkVdl4AaABAg.9Jq8ajBLyzO9h89thXXvay,@tadejristic9568,UgxG70MBttFvXaZkVdl4AaABAg,2,VAo84c1hQX8,0,0,2022-10-13T19:59:36Z,THANK YOU VERY MUCH!!!,2022-10-13T19:59:36Z
UgxG70MBttFvXaZkVdl4AaABAg.9Jq8ajBLyzO9kgaUTA9vJL,@maxinelyu2693,UgxG70MBttFvXaZkVdl4AaABAg,2,VAo84c1hQX8,0,0,2023-01-10T03:48:17Z,Thank you for this!,2023-01-10T03:48:17Z
UgxG70MBttFvXaZkVdl4AaABAg.9Jq8ajBLyzO9rLfaL0Xdlk,@senthilkumart.k8605,UgxG70MBttFvXaZkVdl4AaABAg,2,VAo84c1hQX8,0,0,2023-06-24T15:09:23Z,But this video is not available in youtube üò¢,2023-06-24T15:09:23Z
Ugxo-Ke0WY6wL_zzOXx4AaABAg,@sandipansarkar9211,,1,VAo84c1hQX8,0,0,2021-01-06T18:44:50Z,very nice expression,2021-01-06T18:44:50Z
UgwsgeFbCigLPU2Miyt4AaABAg,@siddharthsvnit,,1,VAo84c1hQX8,0,1,2019-06-11T15:24:55Z,"<a href=""https://www.youtube.com/watch?v=VAo84c1hQX8&amp;t=6m02s"">6:02</a> using IOU intuitively i think this helps in detecting close by objects of same type as we only discard the boxes that are trying to bound the same object leaving the one that is bounding a different one",2019-06-11T15:24:55Z
UgwWV5yRf-ZPnjtdBwp4AaABAg,@arunramsa,,1,VAo84c1hQX8,3,1,2019-06-01T15:29:07Z,"<a href=""https://www.youtube.com/watch?v=VAo84c1hQX8&amp;t=3m23s"">3:23</a> Get rid of anything with low Iou and high confidence he meant ?",2019-06-01T15:29:07Z
UgwWV5yRf-ZPnjtdBwp4AaABAg.8vdXBJrmuDr99Pqkks-2LR,@srishtikumar5544,UgwWV5yRf-ZPnjtdBwp4AaABAg,2,VAo84c1hQX8,0,7,2020-06-02T18:31:09Z,"No, he means to discard bounding boxes with high IOU. If there is a high IOU between 2 boxes, it is likely that they are trying to bound the same object, resulting in a unwanted duplicate box. So, discard one. (Conversely, if the IOU is low, then there is a higher chance that the boxes are for different objects since there is less overlap.) It confused me at first too.",2020-06-02T18:31:09Z
UgwWV5yRf-ZPnjtdBwp4AaABAg.8vdXBJrmuDr9JuNiFfMQeb,@noorameera26,UgwWV5yRf-ZPnjtdBwp4AaABAg,2,VAo84c1hQX8,0,0,2021-02-18T13:38:18Z,@@srishtikumar5544 nice one!,2021-02-18T13:38:18Z
UgwWV5yRf-ZPnjtdBwp4AaABAg.8vdXBJrmuDr9gHTDkPqsZf,@abhishekchaurasia3136,UgwWV5yRf-ZPnjtdBwp4AaABAg,2,VAo84c1hQX8,0,0,2022-09-22T14:10:16Z,@@srishtikumar5544 thank you,2022-09-22T14:10:16Z
UgxhwNyaicVl7TNxspV4AaABAg,@ANOUBHAVAGARWAALbeb,,1,VAo84c1hQX8,1,2,2019-01-29T13:58:17Z,how does it find the midpoint of the object in the first place? As midpoint is needed to know which grid cell the object belongs too,2019-01-29T13:58:17Z
UgxhwNyaicVl7TNxspV4AaABAg.8qge0VhXDPx8rdNs6oAKVI,@hcgaron,UgxhwNyaicVl7TNxspV4AaABAg,2,VAo84c1hQX8,0,3,2019-02-22T04:02:08Z,"ANOUBHAV AGARWAAL be16b002 this algorithm doesn‚Äôt use midpoint as a way to assign a grid cell, it uses P1. That is, many grid cells may make a prediction and be assigned the same object.  Non max suppression will eliminate all overlapping predictions and assign this prediction to a single grid cell. The presumption being that the most confident prediction with many overlapping boxes is likely the most localized area of an image.",2019-02-22T04:02:08Z
UgyEDn9dCNASwGBhHNl4AaABAg,@yuchenxiao232,,1,VAo84c1hQX8,2,2,2018-11-20T04:59:56Z,"What&#39;s the difference between the output box (bx,by,bh,bw) and anchor box mentioned in the previous lecture. Anchor box is predefined, so, here, for each grid cell, it outputs an anchor box? I am super confused about this. Besides, if we run a classification algorithm on each grid cell, how even possible the output box is bigger than the grid cell? Thank you!",2018-11-20T04:59:56Z
UgyEDn9dCNASwGBhHNl4AaABAg.8nrRlG8G32x8pX9Na-PnYw,@yumik4990,UgyEDn9dCNASwGBhHNl4AaABAg,2,VAo84c1hQX8,0,4,2018-12-31T15:38:01Z,"If I understood correctly, for each grid cell, YOLO outputs pre-specified number of anchor boxes, say 5 anchor boxes. And each of the anchor box can be a bounding box prediction.  So, for example if you have 3 x 3 grid cells and 5 anchor boxes, in total YOLO proposes 3 x 3 x 5 = 45 bounding boxes. Most bounding boxes found through anchor boxes are useless because they are overwrapping to each other (hence we need Nonmax suppression). <br><br>The number of anchor boxes is predefined. The &quot;specialization&quot; of anchor boxes is also predefeind.  (e.g. 1st anchor box tends to capture small bounding box, 2nd anchor box is specialized to capture narrow objects with narrow bounding box... the 5th anchor box is specialized to capture large objects with large bounding box). I tried to study the details of YOLO and wrote my learning progress at: <a href=""https://fairyonice.github.io/tag/object-detection-using-yolov2-on-pascal-voc2012-series.html"">https://fairyonice.github.io/tag/object-detection-using-yolov2-on-pascal-voc2012-series.html</a><br>Nonmax suppression is particularly discussed at  <a href=""https://fairyonice.github.io/Part_6_Object_Detection_with_Yolo_using_VOC_2012_data_inference_image.html"">https://fairyonice.github.io/Part_6_Object_Detection_with_Yolo_using_VOC_2012_data_inference_image.html</a>",2018-12-31T15:38:01Z
UgyEDn9dCNASwGBhHNl4AaABAg.8nrRlG8G32x99zmBaHXcIl,@lennonli9100,UgyEDn9dCNASwGBhHNl4AaABAg,2,VAo84c1hQX8,0,0,2020-06-17T02:43:10Z,"It only tells where is the enter, the bounding box is specified with the 4 numbers",2020-06-17T02:43:10Z
UgwzZemRkdUc2muAgpx4AaABAg,@AmanKhandelia,,1,VAo84c1hQX8,1,2,2018-08-02T13:30:56Z,My hunch is this only happens at the inference time. Right?,2018-08-02T13:30:56Z
UgwzZemRkdUc2muAgpx4AaABAg.8jS6naBfLEz8mwH1xiCdwx,@yumik4990,UgwzZemRkdUc2muAgpx4AaABAg,2,VAo84c1hQX8,0,0,2018-10-28T05:31:02Z,I believe so.,2018-10-28T05:31:02Z
Ugzm9yyIMnPDnjQ-rNx4AaABAg,@ShubhamKumar-me7xy,,1,RTlwl2bv0Tg,0,0,2022-07-12T21:00:28Z,Mid point of pedestrian :xd,2022-07-12T21:00:28Z
UgyrEiiJ2dihzwJwNR14AaABAg,@nithinmesingerme6976,,1,RTlwl2bv0Tg,0,0,2021-12-27T12:57:57Z,"As the size of anchor boxes are fixed.. how the same kind of  object,  one which very close and one which very far works??",2021-12-27T12:57:57Z
Ugx9LZ39rJfme3-Laxt4AaABAg,@rijulsingh9803,,1,RTlwl2bv0Tg,1,0,2021-06-29T20:14:20Z,"So the minimum bound on number of  anchor boxes is the number of classes present? Also, is there a way to optimize the size of anchor boxes? I&#39;m a little confused here. Everything else here is crystal clear, thank you so much for this tutorial!",2021-06-29T20:14:20Z
Ugx9LZ39rJfme3-Laxt4AaABAg.9PBPARpOf-Z9cNqwWKkvjV,@polimetakrylanmetylu2483,Ugx9LZ39rJfme3-Laxt4AaABAg,2,RTlwl2bv0Tg,0,1,2022-06-17T15:36:06Z,"If I understand it correctly, as for 1, no, you can specify any number of anchor boxes, and each one will output it&#39;s predictions for class. You can also only specify one or any arbitrarly low/high number of them - there is no relation between number of classes and number of anchor boxes.<br>As for 2, your NN will not output the entire bounding box, but instead it outputs the correction of an anchor box. They have to be defined when you create the model. What you can do is collect every bounding box from your dataset as width-height pair, and either plot it and look at it, or run some clustering algorithm to find optimal sizes",2022-06-17T15:36:06Z
UgyYcJzaHOAnSmdJv9V4AaABAg,@keweml3544,,1,RTlwl2bv0Tg,0,1,2021-06-15T13:47:30Z,I think anchor box algorithm is for those problems lying somewhere between image classification and pixel classification. Recognizing an object that is either the entire image or a pixel is really tricky.,2021-06-15T13:48:03Z
Ugw1hPBCH3vRRbWTWYx4AaABAg,@marcoburkhardt6496,,1,RTlwl2bv0Tg,0,0,2021-03-05T10:08:54Z,just good. thanks a lot :),2021-03-05T10:08:54Z
UgxQLA8JVFH1EOUa79x4AaABAg,@sandipansarkar9211,,1,RTlwl2bv0Tg,0,0,2021-01-06T19:14:40Z,nice explanation,2021-01-06T19:14:40Z
UgxUZE944LYmBc9hqMF4AaABAg,@sandipansarkar9211,,1,RTlwl2bv0Tg,0,0,2021-01-06T19:05:33Z,nice explanation,2021-01-06T19:05:33Z
Ugwmd2N6ZxeDGHJWlbh4AaABAg,@ganonlight,,1,RTlwl2bv0Tg,5,1,2020-10-28T17:09:04Z,These anchor boxes seem more like a workaround than an actual solution tbh,2020-10-28T17:09:04Z
Ugwmd2N6ZxeDGHJWlbh4AaABAg.9FMn02EawRv9H_NzJEXuY-,@vishaljain4915,Ugwmd2N6ZxeDGHJWlbh4AaABAg,2,RTlwl2bv0Tg,0,0,2020-12-22T16:53:47Z,"Agreed, do you have a better idea",2020-12-22T16:53:47Z
Ugwmd2N6ZxeDGHJWlbh4AaABAg.9FMn02EawRv9HcYasttKQq,@ganonlight,Ugwmd2N6ZxeDGHJWlbh4AaABAg,2,RTlwl2bv0Tg,0,1,2020-12-23T22:24:18Z,@@vishaljain4915 No not really,2020-12-23T22:24:18Z
Ugwmd2N6ZxeDGHJWlbh4AaABAg.9FMn02EawRv9Hdc1eKqX6e,@vishaljain4915,Ugwmd2N6ZxeDGHJWlbh4AaABAg,2,RTlwl2bv0Tg,0,0,2020-12-24T08:22:17Z,@@ganonlight üòÇüòÇüòÇ me neither aha,2020-12-24T08:22:17Z
Ugwmd2N6ZxeDGHJWlbh4AaABAg.9FMn02EawRv9HhavU4Yom8,@ganonlight,Ugwmd2N6ZxeDGHJWlbh4AaABAg,2,RTlwl2bv0Tg,0,0,2020-12-25T21:29:32Z,@@vishaljain4915 üòÖ,2020-12-25T21:29:32Z
Ugwmd2N6ZxeDGHJWlbh4AaABAg.9FMn02EawRv9JH33voSoCx,@akashkewar,Ugwmd2N6ZxeDGHJWlbh4AaABAg,2,RTlwl2bv0Tg,0,3,2021-02-02T21:48:16Z,"Anchor boxes are one of the many ways you can use for object detection. Algorithms like &quot;CornerNet&quot; don&#39;t use anchor boxes to locate objects but keypoints. Some algorithm also uses pose estimation or/and semantic segmentation to give you pretty accurate bounding boxes prediction like Pose2Seg and so on. Just google search &quot;anchorless object detection&quot;. Also, tbh most of the stuff you see in machine learning is &quot;workaround&quot;, but it&#39;s magic to see them work so great. There is no silver bullet that could solve all the problems, machine learning is all about choosing the right tools and being creative to the problem given in hand.",2021-02-02T21:55:25Z
Ugx08m0cjHDigpp-LzR4AaABAg,@heejuneAhn,,1,RTlwl2bv0Tg,0,1,2020-10-05T05:36:26Z,"Thank you, Prof. Ng, I learned a lot. One question or request for clarification.   Is it that the anchor box shapes should be taken into account  to the network receptive field?  So we need to use non-squared convolutional filters?  Thanks.",2020-10-05T05:36:26Z
UgzH0_WqfOIcsWmW0al4AaABAg,@sanjivgautam9063,,1,RTlwl2bv0Tg,0,1,2020-06-06T18:25:42Z,"The anchor box concept is not clear. Hands down to great explanation till date though. I want to share few ideas here. During training, the label that contains bx,by,bh,bw is changed to be between 0 and 1. Obviously, bh and bw can be greater than 1. So for each of those &quot;normalized&quot;  bounding boxes, we try to determine which of the predefined anchor box is suitable. How do we define the &quot;suitability&quot;? The IOU. So if we choose 5 anchor boxes, we check our normalized bounding box against all those 5 anchor box and determine which one has highest IOU, so we choose that anchor box as what Andrew NG has explained above. Also the loss function is bit of a headache to explain, here in comment. But would be great if Andrew had explained it himself. Nevermind though, we are getting videos from AI god himself! &lt;3",2020-06-06T18:25:42Z
Ugz7tNyippYtxe_Ng8J4AaABAg,@adityarajora7219,,1,RTlwl2bv0Tg,3,5,2020-06-03T08:36:08Z,"how it can predict bounding box larger than grid cell................explain, please.....if anyone knows YOLO",2020-06-03T08:36:08Z
Ugz7tNyippYtxe_Ng8J4AaABAg.99RMSYan7cY99Tarh32j11,@sanjivgautam9063,Ugz7tNyippYtxe_Ng8J4AaABAg,2,RTlwl2bv0Tg,0,3,2020-06-04T05:29:15Z,"Here is that thing. We actually have bx and by which falls between 0 and 1. However, the bw and bh (width and height) can have values more than 1, so that any object that goes beyond the grid cell is incorporated with that bh and bw. Did you get the point? In one of his videos, he explains how bx and by falls between 0 and 1 whilst bh and bw can go higher than 1.",2020-06-04T05:29:15Z
Ugz7tNyippYtxe_Ng8J4AaABAg.99RMSYan7cY99TkRoSNpgF,@adityarajora7219,Ugz7tNyippYtxe_Ng8J4AaABAg,2,RTlwl2bv0Tg,0,1,2020-06-04T06:52:58Z,@@sanjivgautam9063 thanks......but still I didn&#39;t get intuition.......could you give that video reference.,2020-06-04T06:52:58Z
Ugz7tNyippYtxe_Ng8J4AaABAg.99RMSYan7cY99TmF8-1Ju7,@sanjivgautam9063,Ugz7tNyippYtxe_Ng8J4AaABAg,2,RTlwl2bv0Tg,0,4,2020-06-04T07:08:42Z,"@@adityarajora7219 <a href=""https://youtu.be/gKreZOUi-O0?list=PL_IHmaMAvkVxdDOBRg2CbcJBq9SY7ZUvs&amp;t=656"">https://youtu.be/gKreZOUi-O0?list=PL_IHmaMAvkVxdDOBRg2CbcJBq9SY7ZUvs&amp;t=656</a>. I think you are following a playlist that doesn&#39;t have one video in it. The video in this link explains the bounding box rules. &lt;3",2020-06-04T07:08:42Z
UgzoJWneWZEFsYQ01wN4AaABAg,@TheKovosh,,1,RTlwl2bv0Tg,2,4,2020-05-18T14:22:19Z,One video is missed that&#39;s why I have problem understanding the rest.,2020-05-18T14:22:19Z
UgzoJWneWZEFsYQ01wN4AaABAg.98nmM6i5Zv798se5zwhdWH,@rohitborra2507,UgzoJWneWZEFsYQ01wN4AaABAg,2,RTlwl2bv0Tg,0,0,2020-05-20T11:46:25Z,if u find it please keep the link bro,2020-05-20T11:46:25Z
UgzoJWneWZEFsYQ01wN4AaABAg.98nmM6i5Zv79DIA1gA3TyJ,@aymannaeem22,UgzoJWneWZEFsYQ01wN4AaABAg,2,RTlwl2bv0Tg,0,4,2020-09-07T05:00:01Z,"<a href=""https://www.youtube.com/watch?v=gKreZOUi-O0&amp;feature=youtu.be&amp;list=PL_IHmaMAvkVxdDOBRg2CbcJBq9SY7ZUvs&amp;t=656"">https://www.youtube.com/watch?v=gKreZOUi-O0&amp;feature=youtu.be&amp;list=PL_IHmaMAvkVxdDOBRg2CbcJBq9SY7ZUvs&amp;t=656</a>",2020-09-07T05:00:01Z
UgyfojvImExqRRpCPNx4AaABAg,@TheKovosh,,1,RTlwl2bv0Tg,1,1,2020-04-30T15:49:44Z,"if I have a fixed size anchor box, then what is the point of bw and bh",2020-04-30T15:50:00Z
UgyfojvImExqRRpCPNx4AaABAg.984a2_3zW_S9Ds82FE9uuh,@thomasqiao916,UgyfojvImExqRRpCPNx4AaABAg,2,RTlwl2bv0Tg,0,1,2020-09-21T13:34:31Z,bw and bh define the anchor box,2020-09-21T13:34:31Z
UgxRsyUerMOHRrqK_F94AaABAg,@MG5350,,1,RTlwl2bv0Tg,2,40,2020-02-28T01:39:02Z,"I feel that there are a lot of intricacies that are not explained. Great lecture hands down, but I&#39;m starting to feel that I need concrete examples or implementation to understand many of these subtleties.",2020-02-28T01:39:02Z
UgxRsyUerMOHRrqK_F94AaABAg.95ZQPcQVP_n98J423KnvVe,@dhidhi1000,UgxRsyUerMOHRrqK_F94AaABAg,2,RTlwl2bv0Tg,0,6,2020-05-06T06:49:54Z,"This is a video series, there is like 9 other videos explaining",2020-05-06T06:49:54Z
UgxRsyUerMOHRrqK_F94AaABAg.95ZQPcQVP_n9VXnrfM1flP,@davidvultur8704,UgxRsyUerMOHRrqK_F94AaABAg,2,RTlwl2bv0Tg,0,0,2021-12-04T16:10:29Z,"<a href=""https://www.youtube.com/playlist?list=PL_IHmaMAvkVxdDOBRg2CbcJBq9SY7ZUvs"">https://www.youtube.com/playlist?list=PL_IHmaMAvkVxdDOBRg2CbcJBq9SY7ZUvs</a> This seems to be the one",2021-12-04T16:10:29Z
UgzdRLuOS0nzbLAVtRV4AaABAg,@anujk.9893,,1,RTlwl2bv0Tg,1,1,2019-09-20T11:51:08Z,"If we define the shape and size of anchor boxes, won&#39;t we need only 2 outputs to identify it. Bx and By would be enough. We should not need Bh and Bw ?<br>Please explain if someone knows",2019-09-20T11:51:08Z
UgzdRLuOS0nzbLAVtRV4AaABAg.9-5xTw5dqUG9-Q2961Www8,@tomvandewiele7031,UgzdRLuOS0nzbLAVtRV4AaABAg,2,RTlwl2bv0Tg,0,1,2019-09-28T07:05:32Z,"We predict an arbitrary height and width so we do still have to output Bh and Bw. With anchor boxes, the IoU is used to pick the best matching anchor box shape of the labeled data. The target shape (together with Bx, By and the class) is only set as a target for the best matching anchor box.",2019-09-28T07:05:32Z
UgzdX7JLV3fXZaRBkeV4AaABAg,@weat2006,,1,RTlwl2bv0Tg,1,0,2019-08-01T07:13:16Z,"There seems to be a mistake here compared to the YOLO paper. In the paper, there is only one output of classes irrespectively of the number of boxes. See Section 2 in <a href=""https://arxiv.org/pdf/1506.02640.pdf"">https://arxiv.org/pdf/1506.02640.pdf</a> Quote: &quot;We only predict one set of class probabilities per grid cell, regardless of the number of boxes B&quot;. So in the example of the video, the output should be 3x3x(2x5+3) = 3x3x13 instead of 3x3x16.",2019-08-01T07:13:16Z
UgzdX7JLV3fXZaRBkeV4AaABAg.8y4hw-LPzvb99Ts3f4WEm4,@SpWxScorpion,UgzdX7JLV3fXZaRBkeV4AaABAg,2,RTlwl2bv0Tg,0,4,2020-06-04T07:59:34Z,"Anchor boxes were introduced in yolo v2, you are referring to the first version of yolo.",2020-06-04T07:59:34Z
UgxzBIHtbK2alEvK2aN4AaABAg,@dota2islife262,,1,RTlwl2bv0Tg,1,0,2019-07-16T10:49:24Z,what is the name of the course on Coursera,2019-07-16T10:49:24Z
UgxzBIHtbK2alEvK2aN4AaABAg.8xRtx15E1Yh9PENzB6vRhW,@maxbaugh9372,UgxzBIHtbK2alEvK2aN4AaABAg,2,RTlwl2bv0Tg,0,0,2021-07-01T00:01:38Z,Deep Learning Specialization - Course 4: Convolutional Neural Networks,2021-07-01T00:01:38Z
UgyPWtBz1pA9svfcNAF4AaABAg,@guardrepresenter5099,,1,RTlwl2bv0Tg,1,0,2019-06-15T04:49:50Z,"What is pc  and how pc know himself 0,1  before c1,c2,c3  are unknown????",2019-06-15T04:49:50Z
UgyPWtBz1pA9svfcNAF4AaABAg.8wBR9JKgeOU99RMgK6Q4xR,@adityarajora7219,UgyPWtBz1pA9svfcNAF4AaABAg,2,RTlwl2bv0Tg,0,1,2020-06-03T08:38:09Z,"PC shows there is &quot;something&quot; with probability and c1,c2,c3 describes what this &quot;something&quot; actually is.",2020-06-03T08:38:09Z
UgxX78cAHbyKV_KjoQl4AaABAg,@EranM,,1,RTlwl2bv0Tg,2,5,2019-04-01T05:07:49Z,"<a href=""https://www.youtube.com/watch?v=RTlwl2bv0Tg&amp;t=0m25s"">0:25</a> right in the nuts",2019-04-01T05:07:49Z
UgxX78cAHbyKV_KjoQl4AaABAg.8tALaQOumoB8tg1IbGLG0J,@HabibRK,UgxX78cAHbyKV_KjoQl4AaABAg,2,RTlwl2bv0Tg,0,0,2019-04-13T21:45:25Z,it&#39;s a she,2019-04-13T21:45:25Z
UgxX78cAHbyKV_KjoQl4AaABAg.8tALaQOumoB90Mn2jR9fET,@lovemormus,UgxX78cAHbyKV_KjoQl4AaABAg,2,RTlwl2bv0Tg,0,0,2019-10-21T21:18:31Z,@@HabibRK how do you know it&#39;s a she,2019-10-21T21:18:31Z
UgyAgSYIGm1w7BLlMCB4AaABAg,@nidhihada1122,,1,RTlwl2bv0Tg,0,2,2019-03-07T11:03:29Z,"One doubt. if we are specifying Bx By Bh Bw then we can specify any anchor box. Then for an image where two objects are present in same grid cell, sharing same shape of anchor box, even this can be solved by using their respective bx, by, bh, bw in output. Where in both anchor box have their own bx by bh bw. I could not understand why andrew says it can not be solved.",2019-03-07T11:03:29Z
Ugw5EIWWGeKa-FVRAdF4AaABAg,@nischalkhadgi8128,,1,RTlwl2bv0Tg,0,2,2018-12-15T04:27:18Z,Great one. Was really helpful. Hope you put some demonstration as well.,2018-12-15T04:27:18Z
UgytdRlfOdcXVOVD7Hp4AaABAg,@koeficientas,,1,RTlwl2bv0Tg,0,0,2018-11-27T07:08:53Z,"If I have only 2 classes, I can give hardwired anchor for each class per grid cell and deny the c1 c2 c3? So the output vector can be y=[pc1 bx by bh bw, pc2 bx by bh bw]? pc1 - probability of perestrian, pc2 - probability of car.",2018-11-27T07:11:03Z
UgxJhzrHQ0w9GeACfRt4AaABAg,@cheerguo3343,,1,RTlwl2bv0Tg,2,4,2018-07-18T09:14:50Z,cool,2018-07-18T09:14:50Z
UgxJhzrHQ0w9GeACfRt4AaABAg.8iq1ZjjP_XE8lccg4QWSJK,@cameronfife8757,UgxJhzrHQ0w9GeACfRt4AaABAg,2,RTlwl2bv0Tg,0,1,2018-09-25T17:52:41Z,indeed,2018-09-25T17:52:41Z
UgxJhzrHQ0w9GeACfRt4AaABAg.8iq1ZjjP_XE8ooQE8_cfbK,@Cliu960129,UgxJhzrHQ0w9GeACfRt4AaABAg,2,RTlwl2bv0Tg,0,0,2018-12-13T21:20:13Z,agreed,2018-12-13T21:20:13Z
UgyBvt8qJGbHvbXbMXd4AaABAg,@user-on7ok2gq7k,,1,9s_FpMpdYW8,0,0,2023-05-17T01:31:23Z,"<a href=""https://www.youtube.com/watch?v=9s_FpMpdYW8&amp;t=2m24s"">2:24</a>",2023-05-17T01:31:23Z
UgwP4DXBwWMJySCsh7R4AaABAg,@Sniper-rl3xq,,1,9s_FpMpdYW8,0,0,2023-04-18T17:18:06Z,Amazing tutorial!! thank you so muchh,2023-04-18T17:18:06Z
UgwE0zwbZvecI47rWKp4AaABAg,@lorryzou9367,,1,9s_FpMpdYW8,0,0,2023-03-03T21:53:00Z,"If we divide the image into 3*3=9 small boxes, why do we still need bx, by, bh, bw these box coordinate variables?",2023-03-03T21:53:00Z
UgxfbZtqBt6pnjyZdDZ4AaABAg,@manikantabandla3923,,1,9s_FpMpdYW8,0,0,2023-02-21T17:45:57Z,Is Non-Max suppression used during training?,2023-02-21T17:45:57Z
Ugyn3TR_HuhZNVhbefF4AaABAg,@RH-mk3rp,,1,9s_FpMpdYW8,3,0,2022-10-16T00:00:10Z,what are the values of don&#39;t care question marks? Is it up to the labeler or is there a convention?,2022-10-16T00:00:10Z
Ugyn3TR_HuhZNVhbefF4AaABAg.9hDk0O8p0EQ9uVeoEgMyx9,@vaneEAE,Ugyn3TR_HuhZNVhbefF4AaABAg,2,9s_FpMpdYW8,0,0,2023-09-11T01:49:08Z,Did you get the answer?,2023-09-11T01:49:08Z
Ugyn3TR_HuhZNVhbefF4AaABAg.9hDk0O8p0EQ9xpjQwLTiNE,@jamieabw4517,Ugyn3TR_HuhZNVhbefF4AaABAg,2,9s_FpMpdYW8,0,0,2023-12-02T19:47:44Z,"@@vaneEAE from my research it seems its just up to the labeler, i havent found any convention anywhere",2023-12-02T19:47:44Z
Ugyn3TR_HuhZNVhbefF4AaABAg.9hDk0O8p0EQ9xwTczEpQ8r,@vaneEAE,Ugyn3TR_HuhZNVhbefF4AaABAg,2,9s_FpMpdYW8,0,0,2023-12-05T10:35:39Z,"@@jamieabw4517 I saw that these terms are not considered in the loss function. Therefore, it is of no interest to know what value these terms take.",2023-12-05T10:35:39Z
Ugx2QCw5hKzJ8W9mHNF4AaABAg,@alexdalton4535,,1,9s_FpMpdYW8,1,0,2022-07-26T20:22:18Z,what if an object spans more than one grid cell?,2022-07-26T20:22:18Z
Ugx2QCw5hKzJ8W9mHNF4AaABAg.9dxmgprzd3Q9nUxhZDdr4r,@ab452,Ugx2QCw5hKzJ8W9mHNF4AaABAg,2,9s_FpMpdYW8,0,0,2023-03-20T19:35:15Z,"They often do, bh and bw ground truths are defined taking into account the size of the orignal image. Meaning that one object on a cell can have bh, and bw that go behind  the boundaries of the cell. That&#39;s not a problem because you do regression towards these values. the cell serves only to mark where the object should be detected. If the center point of the object is one cell then, the target vector for that cell is the only one that will have bh bw x, y for that object.",2023-03-20T19:35:15Z
Ugx4iarNo3iU3fSyJrh4AaABAg,@mihirchauhan9703,,1,9s_FpMpdYW8,0,0,2022-04-05T10:41:40Z,Loda heran karas tu machine learning bhanai ne,2022-04-05T10:41:40Z
Ugzb00Y6ekqTay1UcqR4AaABAg,@danielkusuma6473,,1,9s_FpMpdYW8,2,0,2021-11-10T16:08:10Z,"Thanks for the video, it brought me back to light:)<br>I however still have a question: In the Yolo v1 paper it is described that the final convolutional output layer is a tensor of 7x7x1024 dimension (Darknet), then the detection follows, where grid cells dimension of 7x7 are defined. My assumption here is, since the dimension of the conv output the same as the grid cell&#39;s, can one say that one grid cell represents one pixel, hence the detection proceeds one &#39;pixel&#39; at a time?",2021-11-10T16:08:10Z
Ugzb00Y6ekqTay1UcqR4AaABAg.9U_-WioYEiN9og5UQ95w_a,@MrAmgadHasan,Ugzb00Y6ekqTay1UcqR4AaABAg,2,9s_FpMpdYW8,0,0,2023-04-19T09:14:14Z,"One grid cell represents a small &#39;crop&#39; (e.g. 20x20 pixels) of the image, not necessarily a single pixel.<br> Another thing to note: the algorithms processes all grid cells simultaneously in one shot. It doesn&#39;t process them sequentiall.",2023-04-19T09:14:14Z
Ugzb00Y6ekqTay1UcqR4AaABAg.9U_-WioYEiN9p4g76kS_rc,@supriamir5251,Ugzb00Y6ekqTay1UcqR4AaABAg,2,9s_FpMpdYW8,0,0,2023-04-29T07:44:07Z,@@MrAmgadHasan how the yolo can predict the final output for 3 different scale?  Yolov3 have 3 scale with different feature map,2023-04-29T07:44:07Z
UgwX3nsDjjgwo5m0WC54AaABAg,@ricoaditya1,,1,9s_FpMpdYW8,1,0,2021-05-29T07:40:13Z,"How to get value c1, c2, c3?",2021-05-29T07:40:13Z
UgwX3nsDjjgwo5m0WC54AaABAg.9NvEE4yBg6D9Rmk5RL_y3l,@polimetakrylanmetylu2483,UgwX3nsDjjgwo5m0WC54AaABAg,2,9s_FpMpdYW8,0,0,2021-09-02T10:39:49Z,"c1 c2 and c3 are the classification part of an algorithm. They basically mean &#39;if the bounding box intersects an object, what is its type&#39;. During training, your data should be annotated, so each bbox should have position and class if applicable. When you train your nn, you check if a box is over some iou with an object, and if it is then you train c1 c2 c3 like any other classifier",2021-09-02T10:39:49Z
Ugwjey89tF1SzaleIY54AaABAg,@ujjalkrdutta7854,,1,9s_FpMpdYW8,0,5,2021-05-16T16:41:41Z,"i have read multiple blog posts on yolo, along with the original paper, but this video provides the intuition at a different level. amazing !",2021-05-16T16:41:41Z
UgxDKRLhfZFRcQf6b2t4AaABAg,@sahil-7473,,1,9s_FpMpdYW8,0,1,2021-04-15T19:07:55Z,I am not clear how will it&#39;s work at Inference time? How can I get model output BB into original image format? Kindly give me the mathematics how to compute it?,2021-04-15T19:07:55Z
UgyUgCwfXuYsuSHSx054AaABAg,@manuel783,,1,9s_FpMpdYW8,0,1,2021-01-18T23:51:23Z,"YOLO algorithm <b>CORRECTION</b><br><br>At time <a href=""https://www.youtube.com/watch?v=9s_FpMpdYW8&amp;t=5m00s"">5:00</a>, for the slide titled &quot;Outputting the non-max suppressed output&quot; the text should read &quot;For each grid cell&quot; instead of &quot;For each grid call&quot;.",2021-01-18T23:51:23Z
Ugxcu8lxEEncJ7VMNrl4AaABAg,@ritwek98,,1,9s_FpMpdYW8,0,0,2021-01-18T08:52:09Z,Thank you!!,2021-01-18T08:52:09Z
UgxY1QOHOzZdZKSYPih4AaABAg,@sandipansarkar9211,,1,9s_FpMpdYW8,0,1,2021-01-11T14:01:38Z,great explanation,2021-01-11T14:01:38Z
UgyPwjS5a4U56IGxTi94AaABAg,@BSelm05,,1,9s_FpMpdYW8,0,4,2020-12-11T11:19:48Z,"the best AI teacher, thank you",2020-12-11T11:19:48Z
UgxnsCHYafzxo7Rj5Vd4AaABAg,@lakshmanvengadesan9096,,1,9s_FpMpdYW8,1,0,2020-11-08T15:40:11Z,"Let&#39;s say I have an object in 3 of the grid cells. Then, the outputs of all the 3 of the grid cells should be identical, with the same values of bx,by, bh,bw. Am I correct?",2020-11-08T15:40:11Z
UgxnsCHYafzxo7Rj5Vd4AaABAg.9Fnx_geQHE49og5jKhLN6M,@MrAmgadHasan,UgxnsCHYafzxo7Rj5Vd4AaABAg,2,9s_FpMpdYW8,0,0,2023-04-19T09:16:25Z,Not really. The object should be assigned to the cell that contains the object&#39;s center. The remaining cells should predict &#39;background&#39;,2023-04-19T09:16:25Z
UgzdXhnTIMSLJA8JDP94AaABAg,@GaganDaroach,,1,9s_FpMpdYW8,0,1,2020-10-12T23:06:03Z,Is this a graduate or undergraduate level course?,2020-10-12T23:06:03Z
UgxkUugEFLTRW1RK-Ol4AaABAg,@tayyabahayat6898,,1,9s_FpMpdYW8,0,0,2020-08-21T14:37:29Z,"Best video on RseNet Architecture. Click on the link and learn ResNet in easiest wording.<br><a href=""https://www.youtube.com/watch?v=fvrIqFCUWV4&amp;t=44s"">https://www.youtube.com/watch?v=fvrIqFCUWV4&amp;t=44s</a>",2020-08-21T14:37:29Z
UgxuyFhLpDJABTr1fB94AaABAg,@zatizsumkoolshyte,,1,9s_FpMpdYW8,0,1,2020-06-20T15:47:49Z,amazing educator,2020-06-20T15:47:49Z
UgxtRl8qNwPEiH3ZR9t4AaABAg,@adityarajora7219,,1,9s_FpMpdYW8,1,0,2020-06-03T08:21:16Z,"at <a href=""https://www.youtube.com/watch?v=9s_FpMpdYW8&amp;t=6m01s"">6:01</a> how this lady&#39;s bounding box is made.......because there is separate CNN for each grid cell....can somebody explain ?",2020-06-03T08:21:16Z
UgxtRl8qNwPEiH3ZR9t4AaABAg.99RKkf3Kcyk99TuUN6i0gc,@sanjivgautam9063,UgxtRl8qNwPEiH3ZR9t4AaABAg,2,9s_FpMpdYW8,0,0,2020-06-04T08:20:41Z,2 bounding boxes from 2 anchor boxes. Maybe this question comes because of your previous question in previous video.,2020-06-04T08:20:41Z
UgzyFXusSz2aWytCA4V4AaABAg,@andresfernandoaranda5498,,1,9s_FpMpdYW8,0,19,2020-05-26T00:08:15Z,"Same concept is used in YOLO v3, but instead of softmax activation for all classes, logistic regression is applied to each class (meaning there can be an object belonging to two classes)",2020-05-26T00:08:15Z
UgyfMxNCbmsL61ZOHQd4AaABAg,@dhidhi1000,,1,9s_FpMpdYW8,0,0,2020-05-08T15:50:48Z,"How is this grid cell segmentation actually encoded in the neural network? Is it encoded at all? <br>If I understood correctly, the segmentation is only encoded into the training data, and the network is supposed to &quot;learn&quot; to output the y=3x3x16 that matches the locations of the objects relative to the grid cell on the training data. In other words, the network has no information about any image grid.",2020-05-08T15:50:48Z
UgxyxV7GhJw2r9ltJQ54AaABAg,@munzutai,,1,9s_FpMpdYW8,1,0,2020-05-01T01:47:16Z,"Just wanted to let you know that this video has been ripped and re-uploaded:<br><a href=""https://www.youtube.com/watch?v=3Pv66biqc1E"">https://www.youtube.com/watch?v=3Pv66biqc1E</a>",2020-05-01T01:47:16Z
UgxyxV7GhJw2r9ltJQ54AaABAg.985eR1V9gxF98t5cxwSOAx,@neileapenninan8706,UgxyxV7GhJw2r9ltJQ54AaABAg,2,9s_FpMpdYW8,0,0,2020-05-20T15:55:43Z,"I know I thought that too! Actually Andrew Ng is the founder of <a href=""http://deeplearning.ai/"">Deeplearning.ai</a> so technically it isn&#39;t a reupload he must&#39;ve just want to consolidate everything",2020-05-20T15:55:43Z
UgyrUHM90b7qzTiHu_V4AaABAg,@ngantrieuninh9871,,1,9s_FpMpdYW8,0,0,2020-04-17T16:17:33Z,"I read some documents and I know yolo use HSV, can you explain for me why?",2020-04-17T16:17:33Z
UgzKByMzxeRnUemtlsp4AaABAg,@zhangshizhao8773,,1,9s_FpMpdYW8,0,0,2020-02-14T12:19:16Z,"Videos in coursera is too slow, It&#39;s very nice of <a href=""http://deeplearning.ai/"">Deeplearning.ai</a> to release these video on youtube",2020-02-14T12:19:16Z
UgxHyMnDPiMeG1AZ6u14AaABAg,@nipunaviduranga6614,,1,9s_FpMpdYW8,0,0,2020-02-09T04:14:03Z,How to define anchors boxes boundary,2020-02-09T04:14:03Z
UgwXrtMeRlDziH1Lm5B4AaABAg,@maximlopin,,1,9s_FpMpdYW8,0,0,2019-11-22T19:45:27Z,thank you,2019-11-22T19:45:27Z
UgzG1ovN-tnLejCTr1R4AaABAg,@alexter-sarkisov8321,,1,9s_FpMpdYW8,1,0,2019-11-13T13:14:58Z,"OK, so how many objects can one cell of YOLOv1 predict? The article says &#39;we only predict one set of class probabilities per grid cell regardless of the number of boxes&#39;? It seems that the article skirts around the fact that the model can only predict at most 1 object/cell, but the wording above does not exclude, for example, the case when all B objects belong to the same class. So how many?",2019-11-13T13:14:58Z
UgzG1ovN-tnLejCTr1R4AaABAg.91H9-FItbZd9hmb4AyE8Ey,@mager8460,UgzG1ovN-tnLejCTr1R4AaABAg,2,9s_FpMpdYW8,0,0,2022-10-29T22:14:42Z,"I think the answer is: One cell can predict, at maximum, one object for every anchor box.",2022-10-29T22:14:59Z
UgzAqyKztXKljkwmvbd4AaABAg,@Mohsinbajwa14,,1,9s_FpMpdYW8,0,0,2019-09-18T13:34:27Z,source code?,2019-09-18T13:34:27Z
UgxLHcJXipKGx--WMM14AaABAg,@vaibhavsingh1049,,1,9s_FpMpdYW8,0,4,2019-06-28T18:00:44Z,"So,  at <a href=""https://www.youtube.com/watch?v=9s_FpMpdYW8&amp;t=1m49s"">1:49</a> we give the pc value to the 2nd anchor box because it had more IoU and not to the 1st. So to generalize, check if there&#39;s something worth in the grid; if there is, assign the associated pc value to anchor box with the highest IoU.",2019-06-28T18:00:44Z
UgzQYqfRlPDpRtjl9ox4AaABAg,@guardrepresenter5099,,1,9s_FpMpdYW8,1,0,2019-06-13T00:07:41Z,Is someone else tell me training time we are using anchor box terminology become boundingbox in prediction time is that right?Prediction time acnhorbox not using only boundingbox right?,2019-06-13T00:07:41Z
UgzQYqfRlPDpRtjl9ox4AaABAg.8w5mH1F-8QS94Qa8twEA64,@gandhamvignesh300,UgzQYqfRlPDpRtjl9ox4AaABAg,2,9s_FpMpdYW8,0,0,2020-01-30T18:48:18Z,"Yes you are correct.Anchor box is only used to see the IOU matching with the ground truth bounding box. If the value of IOU between anchorbox and ground truth box of particular object  is greater than 0.5 then we will consider the anchor and for that classlabels are [object confidence as 1(object with which IOU&gt;0.5),bounding box coordinates of that object,classlabel as 1 for that object and zero for remaining].",2020-01-30T18:48:18Z
UgzZxu1iuohCSAC8-BN4AaABAg,@Denmark_,,1,9s_FpMpdYW8,0,1,2019-06-12T11:50:36Z,"Is this YOLO or YOLO 9000? According to the YOLO paper,  I think the y should be 3x3x((2x5)+3), so y is 3x3x13. Is this right?",2019-06-12T11:50:36Z
UgxoGebFDrA7pY1CgV94AaABAg,@haojiechen4284,,1,9s_FpMpdYW8,0,1,2019-04-17T02:24:28Z,Clear and good ecough. Thank you.,2019-04-17T02:24:28Z
UgzeyuHopk3SGxdHJGB4AaABAg,@waqasmalik4657,,1,9s_FpMpdYW8,0,2,2019-04-03T12:51:47Z,Is yolo is a deep learning algorithm???,2019-04-03T12:51:47Z
Ugw3dkC_K-3MO59Kd554AaABAg,@PoRouS22,,1,9s_FpMpdYW8,1,7,2019-02-11T18:27:06Z,Thank you very much for all your YOLO videos. They are just great :),2019-02-11T18:27:06Z
Ugw3dkC_K-3MO59Kd554AaABAg.8rDb6dpYsgV9M_AI12my1N,@PoRouS22,Ugw3dkC_K-3MO59Kd554AaABAg,2,9s_FpMpdYW8,0,0,2021-04-25T21:31:07Z,Kohen Dominick ...,2021-04-25T21:31:07Z
UgwDI0SqDfmb6zu-d354AaABAg,@omihalikar7799,,1,9s_FpMpdYW8,0,0,2019-01-20T18:10:35Z,"what happens when the expected training output was close to bounding box 1, but the output of the network was 2 and coordinates of the box on expected output were incorrectly marked close to 1 whereas they should have been close to 2",2019-01-20T18:10:35Z
Ugw06gsAcIltvjYGd-Z4AaABAg,@mehranmehralian4608,,1,9s_FpMpdYW8,2,8,2018-10-22T23:34:43Z,"@<a href=""https://www.youtube.com/watch?v=9s_FpMpdYW8&amp;t=0m56s"">0:56</a> I think something is wrong. According to YOLO paper we have [S,S,(B * 5 + C)] which means each cell has C classes but here you said that each anchor box has C classes or [S,S,B*(5+C)].",2018-10-22T23:34:43Z
UgwG3t1DA2MmM8m5aGF4AaABAg,@vladimirbosinceanu5778,,1,6ykvU9WuIws,0,0,2022-12-08T13:42:05Z,Always a pleasure to land here. Thank you,2022-12-08T13:42:05Z
Ugxy3oCZHoo4UAeUab54AaABAg,@usamazahid1,,1,6ykvU9WuIws,0,1,2022-12-02T04:41:17Z,sir u make things simple and easy....great work,2022-12-02T04:41:17Z
UgxaUP4EkOpkBXBvGch4AaABAg,@pythonwithnabhan6705,,1,6ykvU9WuIws,0,0,2022-11-21T17:52:55Z,it is an amzing video thank you very much ..,2022-11-21T17:52:55Z
UgxPVnYSgT0tnqTZbqt4AaABAg,@krishnakrish9658,,1,6ykvU9WuIws,0,0,2022-02-24T10:15:48Z,How it choose only few on what bases,2022-02-24T10:15:48Z
UgyX6-kGzjb2IhToYbx4AaABAg,@sakshamtikoo9046,,1,6ykvU9WuIws,0,2,2021-01-23T18:21:54Z,Could you please put the links for these papers in comments or in about section of their respective videos? Would be really helpful.,2021-01-23T18:21:54Z
UgwqpqMtLBieR8kG22V4AaABAg,@khanwaqar7703,,1,6ykvU9WuIws,0,1,2020-03-27T02:11:11Z,So nice and wonderful. looking forward for more.,2020-03-27T02:11:11Z
UgxpgBsd8IlHardZ0cl4AaABAg,@manhtieu6569,,1,6ykvU9WuIws,5,0,2019-11-30T16:52:18Z,thanks sir . And where can i have program exercises ?,2019-11-30T16:52:18Z
UgxpgBsd8IlHardZ0cl4AaABAg.91yJNqoe0Px97qXuVvycbV,@thovinh5386,UgxpgBsd8IlHardZ0cl4AaABAg,2,6ykvU9WuIws,0,0,2020-04-24T19:33:40Z,"c·∫≠u l√™n github √Ω, c√≥ nhi·ªÅu ng∆∞·ªùi ƒë√£ l√†m b√†i t·∫≠p v√† post ƒë√°p √°n. Th√¨ c·∫≠u download b√†i t·∫≠p v·ªÅ, tr∆∞·ªõc khi l√†m th√¨ x√≥a ƒë√°p √°n ƒëi v√† l√†m. Hi·ªáu qu·∫£ c√≥ th·ªÉ kh√¥ng b·∫±ng b·∫£n kh√¥ng c√≥ ƒë√°p √°n nh∆∞ng c√≥ v·∫´n h∆°n kh√¥ng.",2020-04-24T19:33:40Z
UgxpgBsd8IlHardZ0cl4AaABAg.91yJNqoe0Px9BbyoKd4cBQ,@RinkiKumari-us4ej,UgxpgBsd8IlHardZ0cl4AaABAg,2,6ykvU9WuIws,0,0,2020-07-27T13:54:27Z,take the paid course,2020-07-27T13:54:27Z
UgxpgBsd8IlHardZ0cl4AaABAg.91yJNqoe0Px9CLwXPAlA6x,@vishxl,UgxpgBsd8IlHardZ0cl4AaABAg,2,6ykvU9WuIws,0,1,2020-08-14T19:38:50Z,"On Coursera or <a href=""http://deeplearning.ai/"">deeplearning.ai</a>",2020-08-14T19:38:50Z
UgxpgBsd8IlHardZ0cl4AaABAg.91yJNqoe0Px9CMeC8D_0Zr,@RinkiKumari-us4ej,UgxpgBsd8IlHardZ0cl4AaABAg,2,6ykvU9WuIws,0,1,2020-08-15T02:17:53Z,@@vishxl coursera,2020-08-15T02:17:53Z
UgxpgBsd8IlHardZ0cl4AaABAg.91yJNqoe0Px9EbE6Z0l5hp,@anirudhsilverking5761,UgxpgBsd8IlHardZ0cl4AaABAg,2,6ykvU9WuIws,0,2,2020-10-09T20:31:50Z,"Pay for it please, so he can keep educating :)",2020-10-09T20:31:50Z
Ugysu21TztoGfUXufgh4AaABAg,@thegorillaz4759,,1,6ykvU9WuIws,0,0,2019-04-21T12:44:28Z,thank you sir,2019-04-21T12:44:28Z
UgwJjtjM8FuWeTLPvBJ4AaABAg,@sathyanarayanankulasekaran1674,,1,6ykvU9WuIws,0,2,2019-01-27T13:46:59Z,"Came in thinking Region Proposal Network, Faster RCNN....but it&#39;s more of Selective search..",2019-01-27T13:46:59Z
UgyvCExRTYFMmeB00PN4AaABAg,@ramkumarmitra7970,,1,6ykvU9WuIws,0,0,2018-11-30T14:44:10Z,Wonderful,2018-11-30T14:44:10Z
UgyBf0zfKbIyp27n4U94AaABAg,@hanweijie8092,,1,6ykvU9WuIws,1,2,2018-08-30T14:53:35Z,Which approach would you recommend to use for object detection using deep learning? Using YOLO?,2018-08-30T14:55:31Z
UgyBf0zfKbIyp27n4U94AaABAg.8k_MWXRNphL8tzeoUWNjcX,@thegorillaz4759,UgyBf0zfKbIyp27n4U94AaABAg,2,6ykvU9WuIws,0,0,2019-04-21T12:45:00Z,yes yolo is the most feasible,2019-04-21T12:45:00Z
UgwykMm8G4kQdY8VckN4AaABAg,@Pratapsingh-ng7pr,,1,-FfMVnwXrZ0,0,0,2021-09-30T01:49:28Z,demo is cool but you are coolerüòçüòçüòçüòç,2021-09-30T01:49:28Z
Ugz5IT0H4ch9rIAPV2d4AaABAg,@sandipansarkar9211,,1,-FfMVnwXrZ0,0,0,2021-01-26T17:37:05Z,nice explanation,2021-01-26T17:37:05Z
UgwnpNjdcWLgtkVcrLh4AaABAg,@apsincsoros1538,,1,-FfMVnwXrZ0,0,0,2019-11-30T07:09:40Z,Â§ßÁ•ûÂê¥ÊÅ©Ëææ,2019-11-30T07:09:40Z
Ugy6lrNNlvrERMmoO0R4AaABAg,@jandroid33,,1,-FfMVnwXrZ0,7,8,2018-08-04T09:02:19Z,What if you hold up your phone showing a video of the other person?,2018-08-04T09:02:19Z
Ugy6lrNNlvrERMmoO0R4AaABAg.8jWmdy6vJs38q-hj21i9J9,@navid2368,Ugy6lrNNlvrERMmoO0R4AaABAg,2,-FfMVnwXrZ0,0,2,2019-01-12T12:24:08Z,genius,2019-01-12T12:24:08Z
Ugy6lrNNlvrERMmoO0R4AaABAg.8jWmdy6vJs38q6BKyvy8VU,@bobcrunch,Ugy6lrNNlvrERMmoO0R4AaABAg,2,-FfMVnwXrZ0,0,1,2019-01-15T00:47:02Z,The answer here is to train it to reject phone images with faces using a million examples of phone images with faces.,2019-01-15T00:47:02Z
Ugy6lrNNlvrERMmoO0R4AaABAg.8jWmdy6vJs397Y-w8TTYk6,@vishalsubedi,Ugy6lrNNlvrERMmoO0R4AaABAg,2,-FfMVnwXrZ0,0,0,2020-04-17T05:31:13Z,It still wont work because the algorithm used by liveness detection will classify it as non-living,2020-04-17T05:31:13Z
Ugy6lrNNlvrERMmoO0R4AaABAg.8jWmdy6vJs39A1hQ4bHVax,@benjaminbenjamin8834,Ugy6lrNNlvrERMmoO0R4AaABAg,2,-FfMVnwXrZ0,0,0,2020-06-18T05:59:10Z,"@@navid2368 distance matters also as it considers so many aspect of the person in front of the camera like angle, lightning, movement,distance, surrounding etc etc, so these are things that they must have considered , its  not a big deal.",2020-06-18T06:00:05Z
Ugy6lrNNlvrERMmoO0R4AaABAg.8jWmdy6vJs39P4w6EFHWcz,@osiris1102,Ugy6lrNNlvrERMmoO0R4AaABAg,2,-FfMVnwXrZ0,0,1,2021-06-27T07:56:10Z,@@vishalsubedi but the person in mobile&#39;s screen is live,2021-06-27T07:56:10Z
Ugwl7WyyKFfoTJjPS_h4AaABAg,@atulsain6170,,1,96b_weTZb2w,0,0,2023-09-08T15:34:42Z,He uploaded this video 5 years ago. üòÖ<br>I am learning machine learning for more than a year and I learned this technique today.,2023-09-08T15:34:42Z
UgwW9ZyjYuWDiEUFfOh4AaABAg,@fratcetinkaya8538,,1,96b_weTZb2w,0,0,2022-09-08T18:04:57Z,"Does those similarity function work on another things, daily prodoucts etc. for example..",2022-09-08T18:04:57Z
UgzwsHFBYZL1gvHGerJ4AaABAg,@MrMikael1337,,1,96b_weTZb2w,1,1,2021-05-31T23:50:41Z,"I understand that a similarity function could discriminate the new class from previous classes. But still, doesnt this require that the model has a very good &quot;understanding&quot; (i.e been trained on a lot of samples) of the previous classes? Otherwise, it wont understand what a face even is.",2021-06-01T00:06:40Z
UgzwsHFBYZL1gvHGerJ4AaABAg.9O16siciJtr9P4y2r40M57,@osiris1102,UgzwsHFBYZL1gvHGerJ4AaABAg,2,96b_weTZb2w,0,0,2021-06-27T08:13:11Z,You can train the network on many face images from the internet then it would be ready to tell if the two images are of the same person or not.,2021-06-27T08:13:11Z
Ugz0xJyBcv4JTd47VpB4AaABAg,@SalteRage,,1,96b_weTZb2w,0,4,2021-04-03T10:22:54Z,Isn&#39;t this the description of similarity (or metric) learning? How is one-shot learning different?,2021-04-03T10:22:54Z
UgzkKky23lHtZhrVRqx4AaABAg,@mofiro6758,,1,96b_weTZb2w,2,2,2021-03-29T23:25:46Z,"Doesn&#39;t it need to retrain the network when adding a new person to the database? If so, what if we add like 10 people or 100 new people?",2021-03-29T23:25:46Z
UgzkKky23lHtZhrVRqx4AaABAg.9LUqx5ysDLn9beRgFibsyz,@petarulev6977,UgzkKky23lHtZhrVRqx4AaABAg,2,96b_weTZb2w,0,1,2022-05-30T15:01:37Z,"No. You would need to do it if you had a classification task (i.e you would need that your final dense layer has x+1 output probabilities after you add 1 more person on top of the database with x people). Not a good idea, since each class would have to see at least a couple of examples. On the other hand, you can see this as regression - have just a normal dense layer without activation that outputs a distance. I am speculating this distance is just the probability of that the pair is of the same person, but im not sure.",2022-05-30T15:01:37Z
UgzkKky23lHtZhrVRqx4AaABAg.9LUqx5ysDLn9vw8PrgLzJO,@Vinay1272,UgzkKky23lHtZhrVRqx4AaABAg,2,96b_weTZb2w,0,0,2023-10-16T14:27:26Z,"The network still needs to learn the facial structure of the new person, right? In fact, the network needs to learn the facial structure of all the people in the database do calculate the differences. Isn&#39;t it?@@petarulev6977",2023-10-16T14:27:26Z
UgwkmXio3-1EtLJ3tKh4AaABAg,@user-vl7mi3dx9j,,1,96b_weTZb2w,0,0,2021-03-23T17:01:01Z,"Chinese girl looks the same, but with flipped picture",2021-03-23T17:04:15Z
UgyZC4HOUaLhoqdzrxJ4AaABAg,@sandipansarkar9211,,1,96b_weTZb2w,0,0,2021-01-10T15:24:29Z,nice explanation,2021-01-10T15:24:29Z
Ugz2u8cwkZQ-0oTdqi94AaABAg,@debarunkumer2019,,1,96b_weTZb2w,1,1,2020-11-04T15:36:40Z,How do we determine the threshold value for every data input ?,2020-11-04T15:36:40Z
Ugz2u8cwkZQ-0oTdqi94AaABAg.9Fde-RyOyrp9H5ZrqkhkG9,@MuhannadGhazal,Ugz2u8cwkZQ-0oTdqi94AaABAg,2,96b_weTZb2w,0,1,2020-12-10T17:41:10Z,"the function will return the face distance and you will check this number with your own threshold. if it&#39;s below 0.4 then it&#39;s the same person, if above then it&#39;s a different person.",2020-12-10T17:41:10Z
UgzguQdrjbb7j1RA8bd4AaABAg,@MrAcenit,,1,96b_weTZb2w,1,2,2020-10-04T21:33:57Z,Isnt this just knn classification?,2020-10-04T21:33:57Z
UgzguQdrjbb7j1RA8bd4AaABAg.9EPTF69MPhh9K0_um9u145,@Jononor,UgzguQdrjbb7j1RA8bd4AaABAg,2,96b_weTZb2w,0,2,2021-02-21T08:48:17Z,"With kNN the distance metric is a standard function such as euclidean/cosine/manhattan distance, where as here the distance function is learned from data (using a neural network). This makes this approach work much better for complex high-dimensional data, such as images, audio etc.",2021-02-21T08:48:17Z
UgxG4f8n4kv79H5_Gm14AaABAg,@mahmoudfathy2074,,1,96b_weTZb2w,0,14,2020-08-10T20:12:24Z,I like the fact that I can not see them as the same person while the algorithm will learn better than me ü§£<br>Danielle&#39;s looking great in the second photo though üòÅ,2020-08-10T20:12:24Z
UgyeS6tZ_MSDn1XAQj54AaABAg,@a.yashwanth,,1,96b_weTZb2w,1,2,2020-02-20T16:02:45Z,What is the girl name on top right?üòú,2020-02-20T16:02:45Z
UgyeS6tZ_MSDn1XAQj54AaABAg.95GMtkRYxK39NHnT5BNg9J,@alik6283,UgyeS6tZ_MSDn1XAQj54AaABAg,2,96b_weTZb2w,0,2,2021-05-13T14:47:59Z,Men of Cultures&#39; Meet,2021-05-13T14:47:59Z
UgyFpUEdulSpcrO9oJB4AaABAg,@donghunpark379,,1,96b_weTZb2w,0,6,2019-08-16T13:30:22Z,"In summary, rather than training a classifier that can classify a database by label, training a &#39;similarity function&#39; that can &#39;distinguish&#39; between different images makes (recognition)system free to the number of databases. Good Idea.",2019-08-16T13:33:31Z
Ugy6OB4tqAA15TC9s3t4AaABAg,@thiliniyatanwala2349,,1,96b_weTZb2w,0,2,2019-04-28T01:23:16Z,Thank you for sharing the knowledge ..Can you please give me some idea how zero shot/one shot learning can be used to apply in the area edge computing ? will edge computing be benefited from zero shot learning ?,2019-04-28T01:23:16Z
Ugzu2NG1kwem3rUOK9x4AaABAg,@ammarazlan2919,,1,96b_weTZb2w,1,2,2019-03-02T08:45:55Z,Could you recommend an established model (like alexnet for image recognition) for time series forecasting?,2019-03-02T08:45:55Z
Ugzu2NG1kwem3rUOK9x4AaABAg.8ryUhaxyBD29EB-p2FeAEu,@RinkiKumari-us4ej,Ugzu2NG1kwem3rUOK9x4AaABAg,2,96b_weTZb2w,0,2,2020-09-29T06:47:29Z,he is not going to reply youüòÇüòÇ,2020-09-29T06:47:29Z
Ugw4uN8RpDL8tlSAYsN4AaABAg,@adamlee9347,,1,96b_weTZb2w,1,31,2018-12-29T03:57:45Z,Danielle.. lol her second photo looks so much better,2018-12-29T03:57:45Z
Ugw4uN8RpDL8tlSAYsN4AaABAg.8pQkdvxA7J79B25ClyNkUO,@tarat.techhh,Ugw4uN8RpDL8tlSAYsN4AaABAg,2,96b_weTZb2w,0,0,2020-07-13T06:07:12Z,lol true dat,2020-07-13T06:07:12Z
UgwQF8YCRsPR37GGP6l4AaABAg,@tsunghan_yu,,1,96b_weTZb2w,3,1,2018-11-02T17:03:46Z,is it like nearest neighbors?,2018-11-02T17:03:46Z
UgwQF8YCRsPR37GGP6l4AaABAg.8n9OHvXDLhn8upDNv9y3IB,@CyborgGaming99,UgwQF8YCRsPR37GGP6l4AaABAg,2,96b_weTZb2w,0,3,2019-05-12T07:55:33Z,"I can see why you would think that, but no, it is not. The basis of KNN is that it measures Euclidean Distance of one point in comparison to others, and here we do NO such thing. Here, you just measure the similarity of two compared images, no distance between them, or nothing like that which you would find in KNN or some clustering algorithms",2019-05-12T07:55:33Z
UgwQF8YCRsPR37GGP6l4AaABAg.8n9OHvXDLhn9-Hbg4D6LZ9,@ta6847,UgwQF8YCRsPR37GGP6l4AaABAg,2,96b_weTZb2w,0,1,2019-09-25T00:31:34Z,"It depends on how the difference function is implemented. You can imagine representing each face as some embedding or encoding, and then using some distance metric to determine similarity.",2019-09-25T00:31:34Z
UgwQF8YCRsPR37GGP6l4AaABAg.8n9OHvXDLhn9-HboZ4Gda6,@ta6847,UgwQF8YCRsPR37GGP6l4AaABAg,2,96b_weTZb2w,0,1,2019-09-25T00:32:44Z,"Apparently that&#39;s exactly what&#39;s described here: <a href=""https://www.youtube.com/watch?v=6jfw8MuKwpI"">https://www.youtube.com/watch?v=6jfw8MuKwpI</a><br>Again, not nearest neighbor exactly, but definitely the same flavor.",2019-09-25T00:32:44Z
UgyN8j3Sc2HPiEujCRx4AaABAg,@trident8638,,1,96b_weTZb2w,0,1,2018-09-09T07:46:52Z,how to implement this using python and tensorflow?,2018-09-09T07:46:52Z
UgzgDDBX-cJLojKydnJ4AaABAg,@madhivarman508,,1,96b_weTZb2w,2,0,2018-03-19T13:09:11Z,what if the person wears hat and goggles? does it work in that case?,2018-03-19T13:09:11Z
UgzgDDBX-cJLojKydnJ4AaABAg.8dytCJlLQSV8gOm59WJNbq,@donm7906,UgzgDDBX-cJLojKydnJ4AaABAg,2,96b_weTZb2w,0,12,2018-05-18T16:49:19Z,"to some degree, I&#39;m sure it won&#39;t work if the person wears mask",2018-05-18T16:49:19Z
UgzgDDBX-cJLojKydnJ4AaABAg.8dytCJlLQSV92GZFOHH5_o,@PandemicGameplay,UgzgDDBX-cJLojKydnJ4AaABAg,2,96b_weTZb2w,0,1,2019-12-08T04:16:31Z,Usually they would require you to not wear stuff when getting a photo ID for a job or working somewhere for that exact reason.,2019-12-08T04:16:31Z
UgxK9TO45shYOnmv6tN4AaABAg,@user-zo2sc5uf9z,,1,6jfw8MuKwpI,0,0,2023-10-05T00:15:30Z,Thank you so much to provide this nice video,2023-10-05T00:15:30Z
UgwOmZf0CRwChsF-_el4AaABAg,@kounkouvincent5672,,1,6jfw8MuKwpI,0,0,2022-06-09T08:00:27Z,"Should we need a huge data to a similarity of two different signals? For example I‚Äôm having two signals and I want to ensure they are both similar or not. In this case, while using Siamese network, these two signals are enough to input in the network with only one label of (x1, x2, 0) or I need to define more labels to train the network and compute the similarity? How many datas samples are required?",2022-06-09T08:01:33Z
Ugxpwirw-3SaW5dIfol4AaABAg,@poojakabra1479,,1,6jfw8MuKwpI,0,1,2022-03-09T23:26:24Z,But why do we need a new architecture for that. Wont the embeddings be far away for two dissimilar images with any neural network typically?,2022-03-09T23:26:24Z
UgxGrZDlrUbVH0GoPdp4AaABAg,@himanshuwadhwa6265,,1,6jfw8MuKwpI,1,2,2022-02-03T14:35:01Z,what is meant by the subscript 2 in the norm term?,2022-02-03T14:35:01Z
UgxGrZDlrUbVH0GoPdp4AaABAg.9XzhQp38OT59usyIO-qCiC,@jackcashman1190,UgxGrZDlrUbVH0GoPdp4AaABAg,2,6jfw8MuKwpI,0,0,2023-09-20T12:21:11Z,"The subscript two represents the l-2 (or Euclidean norm). A norm is nothing but a mapping from a vector space to the positive reals. There are many norms, so a subscript lets us distinguish between them (at least for the p-norms).",2023-09-20T12:21:46Z
UgwoiBpq12uSodiglch4AaABAg,@lucamatteobarbieri2493,,1,6jfw8MuKwpI,0,0,2021-12-09T19:49:25Z,There is a high pitch sound in the background,2021-12-09T19:49:25Z
UgwMPs0mO_fxkDsCDKt4AaABAg,@sandipansarkar9211,,1,6jfw8MuKwpI,0,0,2021-01-10T15:29:56Z,nice expalantion,2021-01-10T15:29:56Z
Ugxi-8V5Rqit0XB7mhd4AaABAg,@debarunkumer2019,,1,6jfw8MuKwpI,0,3,2020-11-04T15:36:51Z,How do we determine the threshold value for every data input ?,2020-11-04T15:36:51Z
UgwRDv74kK3nCXXoyAp4AaABAg,@playerplayeronetime,,1,6jfw8MuKwpI,0,0,2020-10-15T10:25:49Z,So u better have a really good CNN structure loool,2020-10-15T10:25:49Z
UgwNw3rcDkpkMF3-lWZ4AaABAg,@benedictwilkins,,1,6jfw8MuKwpI,0,0,2020-09-27T11:49:48Z,"If anyone is interested I have written a blog post about implementing Siamese Networks in Pytorch, all the code is available, check it out:  <a href=""https://benedictwilkinsai.github.io/post/siamese-networks/"">https://benedictwilkinsai.github.io/post/siamese-networks/</a>",2020-09-27T11:49:48Z
Ugy2_tc62K7Au06AP1t4AaABAg,@altunbikubra,,1,6jfw8MuKwpI,1,12,2020-01-14T06:50:01Z,Why his voice makes me sleep ?,2020-01-14T06:50:01Z
Ugy2_tc62K7Au06AP1t4AaABAg.93l6Dz4UdGu96twZfq1SD4,@-long-,Ugy2_tc62K7Au06AP1t4AaABAg,2,6jfw8MuKwpI,0,17,2020-04-01T06:44:12Z,"wake up lady, you&#39;ve missed one great lecture",2020-04-01T06:44:12Z
Ugz06h08IMZV-6h7tPd4AaABAg,@krishna7440,,1,6jfw8MuKwpI,1,0,2019-11-26T06:30:55Z,"Shall we use this siamese network for identifying two samole audio belongs to same person or not <br><br>Or audio recognition  , ??",2019-11-26T06:30:55Z
Ugz06h08IMZV-6h7tPd4AaABAg.91mu5BIH2pw96kJm1QXeqm,@atheeth2189,Ugz06h08IMZV-6h7tPd4AaABAg,2,6jfw8MuKwpI,0,1,2020-03-28T13:03:20Z,"yes, theoretically siamese networks should be able to find similarity between any two samples from the same data distribution.",2020-03-28T13:03:20Z
UgynLMzJEwrt72vwC0x4AaABAg,@xNiickT,,1,6jfw8MuKwpI,5,3,2018-10-15T08:26:27Z,"What&#39;s the benefit of having the same model twice? All I see is loss in memory. <br>Also, do feature vectors, or these encodings, get saved so they won&#39;t have to be encoded each time which is more time effecient",2018-10-15T08:26:27Z
UgynLMzJEwrt72vwC0x4AaABAg.8mQ6mDmUcQA8pN7jL6eL4L,@JoeJimson,UgynLMzJEwrt72vwC0x4AaABAg,2,6jfw8MuKwpI,0,6,2018-12-27T18:11:15Z,"So, you only have the same weights stored once. You don&#39;t have twice as many parameters, so there is no &quot;memory loss&quot;.  It is functionally the same as running two different images through one neural network and then taking the feature vectors at the output and comparing them",2018-12-27T18:11:15Z
UgynLMzJEwrt72vwC0x4AaABAg.8mQ6mDmUcQA8tuyM_OZ-qR,@sadenb,UgynLMzJEwrt72vwC0x4AaABAg,2,6jfw8MuKwpI,0,0,2019-04-19T16:59:37Z,@@JoeJimson There is a difference. The backpropagation is happening differently.,2019-04-19T16:59:37Z
UgynLMzJEwrt72vwC0x4AaABAg.8mQ6mDmUcQA8z62m-zSVO3,@deekshantmalvi4612,UgynLMzJEwrt72vwC0x4AaABAg,2,6jfw8MuKwpI,0,0,2019-08-26T16:14:46Z,@@sadenb I think there is no training ... it is pre-trained neural network model.. we just calculate the encodings of the input images by running through them.,2019-08-26T16:14:46Z
UgynLMzJEwrt72vwC0x4AaABAg.8mQ6mDmUcQA95w-OcJevf1,@CristianGarcia,UgynLMzJEwrt72vwC0x4AaABAg,2,6jfw8MuKwpI,0,0,2020-03-08T05:24:44Z,"@@deekshantmalvi4612 This is not true. Embeddings from pretrained models don&#39;t have these metric properties, you have to train the embeddings for your task.",2020-03-08T05:24:44Z
UgynLMzJEwrt72vwC0x4AaABAg.8mQ6mDmUcQA9B_bBZZ-Ne8,@arjunashok4956,UgynLMzJEwrt72vwC0x4AaABAg,2,6jfw8MuKwpI,0,5,2020-07-26T15:49:34Z,"‚Äã@@sadenb Once the 2 images are fed in, the derivative of the loss function will be used for both the images and the same network is updated correspondingly. It&#39;s like one training pair contains 2 images instead of an image and a label. That&#39;s all.",2020-07-26T15:49:34Z
UgyiA6lQ_4oovPlr29x4AaABAg,@iamsiddhantsahu,,1,6jfw8MuKwpI,3,4,2018-05-12T04:15:25Z,How are we going to train the network with just one input image?,2018-05-12T04:15:25Z
UgyiA6lQ_4oovPlr29x4AaABAg.8g7z29Lh0a28hPObI6TJcS,@rajaasim8229,UgyiA6lQ_4oovPlr29x4AaABAg,2,6jfw8MuKwpI,0,2,2018-06-12T19:06:01Z,You just compute encodings of image using convnets and then apply triplet loss function to classify.,2018-06-12T19:06:01Z
UgyiA6lQ_4oovPlr29x4AaABAg.8g7z29Lh0a28ow0GeUuJ30,@Throwingness,UgyiA6lQ_4oovPlr29x4AaABAg,2,6jfw8MuKwpI,0,0,2018-12-16T20:07:17Z,So does the model need to be trained in any way? Would a pretrained resnet model work better than a rondomly innitialized one?,2018-12-16T20:07:17Z
UgyiA6lQ_4oovPlr29x4AaABAg.8g7z29Lh0a28q0m3JQoEU3,@ArtyomPalvelev,UgyiA6lQ_4oovPlr29x4AaABAg,2,6jfw8MuKwpI,0,1,2019-01-12T22:21:14Z,‚Äã@@Throwingness yes and yes,2019-01-12T22:21:14Z
Ugxgeu08XA0aTWuvWa14AaABAg,@arisioz9360,,1,d2XB5-tuCWU,1,0,2023-04-26T21:42:56Z,Is this your wife?,2023-04-26T21:42:56Z
Ugxgeu08XA0aTWuvWa14AaABAg.9ozSj3Eexfv9tpEgQ57ajJ,@jsonbourne8122,Ugxgeu08XA0aTWuvWa14AaABAg,2,d2XB5-tuCWU,0,0,2023-08-25T05:04:47Z,"You thought it was his wife, but it was me, Alpharius!",2023-08-25T05:04:57Z
UgxGFamdryCiNp6Zx8Z4AaABAg,@songpandy9590,,1,d2XB5-tuCWU,0,1,2023-04-20T03:01:08Z,Clearly explained. Thank you.,2023-04-20T03:01:08Z
UgyMcpwxVT5McD38sjZ4AaABAg,@sharadchandakacherla8268,,1,d2XB5-tuCWU,0,0,2023-02-28T05:11:25Z,Thank you sir.,2023-02-28T05:11:25Z
UgwTBXy4ui1wolcf6Bx4AaABAg,@linzhu5178,,1,d2XB5-tuCWU,0,0,2022-12-11T08:00:29Z,How do we differentiate this loss?,2022-12-11T08:00:29Z
UgyfiKN2CLoUCVnl7BJ4AaABAg,@petarulev6977,,1,d2XB5-tuCWU,1,0,2022-07-04T08:48:54Z,"I dont understand why the loss should be minimzed instead of maximized. After all, we want the difference between f(true) - f(neg) to be as large as possible.",2022-07-04T08:48:54Z
UgyfiKN2CLoUCVnl7BJ4AaABAg.9d2tqxUO60t9wrSiCGjHEG,@Frosp,UgyfiKN2CLoUCVnl7BJ4AaABAg,2,d2XB5-tuCWU,0,1,2023-11-08T15:20:02Z,because you want to minimize f(true) and maximize f(neg) therefore minimize -f(neg),2023-11-08T15:20:02Z
Ugz3Caqf6hhb3UKEJUJ4AaABAg,@sylus121,,1,d2XB5-tuCWU,0,0,2022-07-02T10:45:48Z,Good for facial expression recognition,2022-07-02T10:45:48Z
UgyEEMwuizhTg_WKFY94AaABAg,@fabiansvensson9588,,1,d2XB5-tuCWU,0,1,2022-03-03T19:52:21Z,"Hello! Why is it mandatory to have multiple images of the same person for the training? I&#39;m creating an algorithm where I want to use SNNs to map photos of a product to a system-genereted image of the same product. The problem is that the products are personalized, so each product is unique. I therefore only have one image of each product. Why can I not simply create triplets with tons of different images. Why is it mandatory to have several photos of the same person/product?",2022-03-03T19:52:21Z
Ugzwzr783zLHf-Npnb14AaABAg,@logicboard7746,,1,d2XB5-tuCWU,0,1,2022-01-08T21:06:10Z,The fun fact at the end is mind blowing :-),2022-01-08T21:06:10Z
UgxgENN1bHiBvfn--Jt4AaABAg,@julessci2716,,1,d2XB5-tuCWU,0,0,2021-12-17T02:37:04Z,Nobody explains like A. Ng,2021-12-17T02:37:04Z
UgzvpL0nTj8nQf44u1Z4AaABAg,@IgneousGorilla,,1,d2XB5-tuCWU,1,1,2021-11-19T20:21:53Z,"Why is the squared norm used instead of just the norm, the actual euclidean distance?",2021-11-19T20:21:53Z
UgzvpL0nTj8nQf44u1Z4AaABAg.9Uwchs2sFrm9Wtr9yXLT9L,@Darkev77,UgzvpL0nTj8nQf44u1Z4AaABAg,2,d2XB5-tuCWU,0,0,2022-01-07T11:33:15Z,If you get an answer please lmk,2022-01-07T11:33:15Z
UgzaW16GLWNmVXPjOdJ4AaABAg,@ahhhwhysocute,,1,d2XB5-tuCWU,1,3,2021-08-29T15:51:33Z,"Thank you, this was very well explained and easy to understand !",2021-08-29T15:51:33Z
UgzaW16GLWNmVXPjOdJ4AaABAg.9Rd-a9_8-4y9V6Lm0fZvG6,@allancentis300,UgzaW16GLWNmVXPjOdJ4AaABAg,2,d2XB5-tuCWU,0,0,2021-11-24T00:16:48Z,very nicely done :),2021-11-24T00:16:48Z
UgyJ0deuO18Cske0khx4AaABAg,@Acha413,,1,d2XB5-tuCWU,2,1,2021-08-14T14:44:08Z,"Hello Professor,<br><br>I have a qeary.<br>Why do we use squared norms to compute the distance between two examples (A,P or A,N).<br>Isn&#39;t cosine a better way to compute the similarity between two examples¬†(A,P or A,N).<br>Because squared norms might have larger magnitude, even if they were closer to each other (that is angle between them is smaller), <br>Hence , is cos(A,N)  &lt;= cos (A,P) a better loss function ?<br><br>Will be Nice if you can cover this topic in some area of discussion.<br> Thank you.",2021-08-14T14:44:55Z
UgyJ0deuO18Cske0khx4AaABAg.9R1FxJ4PzVf9WtrEv-74GB,@Darkev77,UgyJ0deuO18Cske0khx4AaABAg,2,d2XB5-tuCWU,0,0,2022-01-07T11:33:56Z,Please lmk if you found an answer,2022-01-07T11:33:56Z
UgyJ0deuO18Cske0khx4AaABAg.9R1FxJ4PzVf9ZqYEOLpkoF,@Acha413,UgyJ0deuO18Cske0khx4AaABAg,2,d2XB5-tuCWU,0,2,2022-03-21T18:15:33Z,"we use square in the distance (f(A) - f(P))^2 because we do not want -ve values. In other word distance between (3-5)^2 = (5-3)^2 are same because we took square. In Machine Learning, we want to compute the gradient (1st order derivative) of this function for minimising the loss. For that purpose, we square the loss function and then minimize it. Also we can consider absolute value but first order derivative of absolute value at 0 does not exist. Hence even though abs(loss) is continuous, it is still not differentiable at 0. Hence Square is easier to differentiate and also it will square the error and. choose a model which minimizes the larger errors more than smaller errors. Due to these 2 reasons, i think square is a better choice for loss function.",2022-03-21T18:17:24Z
UgxquyWIC1FgayQpObd4AaABAg,@gorgolyt,,1,d2XB5-tuCWU,2,3,2021-06-26T12:26:33Z,Why don&#39;t we just seek to always minimise |f(A) - f(P)|^2 - |f(A) - f(N)|^2 ?<br>Instead of the max method which only minimises this when it&#39;s &gt;= -alpha.,2021-06-26T12:26:33Z
UgxquyWIC1FgayQpObd4AaABAg.9P2qFfVMndf9WtrXyq3Ias,@Darkev77,UgxquyWIC1FgayQpObd4AaABAg,2,d2XB5-tuCWU,0,0,2022-01-07T11:36:32Z,If you found the answer please lmk,2022-01-07T11:36:32Z
UgxquyWIC1FgayQpObd4AaABAg.9P2qFfVMndf9YXUECLRH7h,@samuelleecong4585,UgxquyWIC1FgayQpObd4AaABAg,2,d2XB5-tuCWU,0,1,2022-02-17T02:44:22Z,"From my understanding it&#39;s to ensure that there is a larger difference between the positive and negative examples, so as to train your model to be more sensitive in identifying differences, forcing the difference function for the positive and negative functions to have more than a small difference i.e. 0.1, to the alpha value of maybe 5 or 6.",2022-02-17T02:44:22Z
UgzxfbJzSl8w0mECTlB4AaABAg,@AvinashSingh-bk8kg,,1,d2XB5-tuCWU,4,0,2021-06-24T12:47:57Z,"@<a href=""https://www.youtube.com/watch?v=d2XB5-tuCWU&amp;t=08m15s"">08:15</a> - <a href=""https://www.youtube.com/watch?v=d2XB5-tuCWU&amp;t=9m21s"">9:21</a> , We need multiple samples of a person in our database to train the model using triple loss while only one sample image of a person while testing. Is it what Mr Andrew meant to say? If that is the case how can we call it one shot learning as we are training our model on multiple images of a person. Kindly clarify.",2021-06-24T12:47:57Z
UgzxfbJzSl8w0mECTlB4AaABAg.9Oyj6eKTwA-9P522Bh1cD8,@osiris1102,UgzxfbJzSl8w0mECTlB4AaABAg,2,d2XB5-tuCWU,0,0,2021-06-27T08:56:47Z,I think we only need to train the network once and you can use random pictures from the internet  to train it so that it can tell us that the two given pictures are of the same person or not.<br><br>Then we can give it two images of the same person and it should be able to tell us if that&#39;s the same person or not.,2021-06-27T08:56:47Z
UgzxfbJzSl8w0mECTlB4AaABAg.9Oyj6eKTwA-9Q6EzQyJVjl,@nidanoorain6339,UgzxfbJzSl8w0mECTlB4AaABAg,2,d2XB5-tuCWU,0,0,2021-07-22T16:40:30Z,"Triplet loss:it helps in updating hyper parameters such as weights and bias of the network.When a new face is added we dont retrain the network since it requires huge calculations.We train when large data is added.Normally the output of the model is not a classification but a function(which can generate encoding (128d) for faces).<br>One-shot: The new face is given to the network with same architecture with same weights and biases(trained with triplet loss) and similarity is calculated between the new and old faces using a similarity function which gives true if same face or false if different, then we can add the new face by giving the image to network to generate embedding. Here instead of retraining the model we can just create the embedding of image with pretrained model and dump to pickle file or any for classification.Correct me if am wrong hope it helps..",2021-07-22T16:40:30Z
UgzxfbJzSl8w0mECTlB4AaABAg.9Oyj6eKTwA-9R0XSAObGrm,@ajaykannan6031,UgzxfbJzSl8w0mECTlB4AaABAg,2,d2XB5-tuCWU,0,0,2021-08-14T07:57:48Z,"@@nidanoorain6339 &quot;then we can add the new face by giving the image to network to generate embedding. &quot; - So, in one shot, is the network adding the new Images and then training them too during the testing phase?",2021-08-14T07:57:48Z
UgzxfbJzSl8w0mECTlB4AaABAg.9Oyj6eKTwA-9RB7c6iYV55,@nidanoorain6339,UgzxfbJzSl8w0mECTlB4AaABAg,2,d2XB5-tuCWU,0,1,2021-08-18T10:43:45Z,"@@ajaykannan6031 it doesn&#39;t train in one-shot.. its like a classification task.for example if a new face needs to be added  then give image to the network or model it creates embedding..now compare the embedding with previous embedding(ie..the embedding of the previous faces should also be saved in a file) by using similarity function keep some threshold, if the embedding similarity say is &lt; 0.5 add the new face label and its embedding in the previous saved feature file...all together one-shot  says if its same person or not we need to write condition to save the person to database with its embedding...hope it helps",2021-08-18T10:43:45Z
Ugx_OBEbgNF6uuE825h4AaABAg,@phoenix-hg8oq,,1,d2XB5-tuCWU,0,1,2021-06-14T08:29:01Z,Thanks a lot sir....sir  what is the significance of anchor here?why we choose anchor and positive from same class?,2021-06-14T08:29:01Z
UgySQvMFzYThP5pUg_V4AaABAg,@vikramsandu6054,,1,d2XB5-tuCWU,0,0,2021-03-25T08:50:03Z,Well explained. Thanks for the video.,2021-03-25T08:50:03Z
UgwPNQG9dvmuaq-BNYl4AaABAg,@gabrielwong1991,,1,d2XB5-tuCWU,0,1,2021-03-22T00:22:26Z,Choose triplets that are hard to train on....<br>So use entire training set as asian because we all look the same :D? haha,2021-03-22T00:22:26Z
UgwbyvAmL2KyzflDvjp4AaABAg,@sandipansarkar9211,,1,d2XB5-tuCWU,0,0,2021-01-11T13:08:02Z,nice explantion .,2021-01-11T13:08:02Z
UgxE8Qh22cJvKEw0klJ4AaABAg,@alessandrocornacchia8125,,1,d2XB5-tuCWU,0,1,2020-11-27T15:53:53Z,Thanks for your clear explanation,2020-11-27T15:53:53Z
Ugyudh1QjbdXy1FpexF4AaABAg,@meghnavasudeva4898,,1,d2XB5-tuCWU,1,3,2020-11-22T12:49:23Z,Now I can understand how DeepFakes would have been named :D,2020-11-22T12:49:32Z
Ugyudh1QjbdXy1FpexF4AaABAg.9GMh9ymX9J39Im9x8042-9,@furkatsultonov9976,Ugyudh1QjbdXy1FpexF4AaABAg,2,d2XB5-tuCWU,0,1,2021-01-21T12:32:41Z,or it could have been named as FakeNet lol,2021-01-21T12:32:41Z
Ugz5fiFx2zMVZ2o0ASp4AaABAg,@debarunkumer2019,,1,d2XB5-tuCWU,0,1,2020-11-08T22:16:30Z,What if the pictures are of the same person from two different timelines? Will the model still work?,2020-11-08T22:16:30Z
Ugwomln2hRK2pAdxwAx4AaABAg,@hiankun,,1,d2XB5-tuCWU,0,8,2020-11-02T05:51:56Z,"To force the net to learn better, choose Andrew Yang as the negative sample for Andrew Ng. :-p",2020-11-02T05:51:56Z
Ugz8HXyWKt604v-zyJ14AaABAg,@nailcankara8164,,1,d2XB5-tuCWU,0,0,2020-10-30T00:35:38Z,Can I choose big margin for hard train?,2020-10-30T00:35:38Z
UgxpzHEvuVy8fnYTNbt4AaABAg,@harry41108,,1,d2XB5-tuCWU,1,0,2020-07-22T10:54:48Z,"thanks for the nice presentation, when i load the facenet model by tf.keras.models.load_model(&#39;facenet_keras.h5&#39;) with tensorflow 2.2, it keeps raising error (ValueError: bad marshal data (unknown type code), may i know is there any idea to mitigate it?",2020-07-22T10:54:48Z
UgxpzHEvuVy8fnYTNbt4AaABAg.9BPmH5-ex5Z9Q5Hl230LXH,@nidanoorain6339,UgxpzHEvuVy8fnYTNbt4AaABAg,2,d2XB5-tuCWU,0,0,2021-07-22T07:45:30Z,For anyone who is trying to load the model try it with keras 2.3.1 if it didnt then downgrade tf to 2.0.0 and keras 2.3.1 hope it helps,2021-07-22T07:45:30Z
Ugy3Gjqb0WScf1vbpex4AaABAg,@black-snow,,1,d2XB5-tuCWU,0,0,2020-07-17T14:30:41Z,"damn, upvote 665, off by one",2020-07-17T14:30:41Z
Ugx-vkHtt5JCNCZRICh4AaABAg,@abdengineer6225,,1,d2XB5-tuCWU,1,1,2020-07-04T21:03:55Z,hello can i detect the person wich wear mask,2020-07-04T21:03:55Z
Ugx-vkHtt5JCNCZRICh4AaABAg.9AhWfddM6dP9Fh_VUcPlBB,@nayeonhan1406,Ugx-vkHtt5JCNCZRICh4AaABAg,2,d2XB5-tuCWU,0,0,2020-11-06T04:14:19Z,"@abd engineer Yeah you can detect people wearing masks!!<br>You can detect whether the person is wearing a mask or not here: <a href=""https://www.pyimagesearch.com/2020/05/04/covid-19-face-mask-detector-with-opencv-keras-tensorflow-and-deep-learning/"">https://www.pyimagesearch.com/2020/05/04/covid-19-face-mask-detector-with-opencv-keras-tensorflow-and-deep-learning/</a><br>and you can detect the person wearing masks here: <a href=""https://openaccess.thecvf.com/content_cvpr_2017/papers/Ge_Detecting_Masked_Faces_CVPR_2017_paper.pdf"">https://openaccess.thecvf.com/content_cvpr_2017/papers/Ge_Detecting_Masked_Faces_CVPR_2017_paper.pdf</a><br><br>you can also get datasets of people wearing masks in here: <a href=""https://datatang.ai/dataset/info/image/1084"">https://datatang.ai/dataset/info/image/1084</a><br><br>These are only a few models and papers I searched, you may find many other models than these! Hope this will help you",2020-11-06T04:14:19Z
UgziBOWjqFnYhI9dfNt4AaABAg,@LeenaGurgPhysics,,1,d2XB5-tuCWU,2,1,2020-06-09T12:31:19Z,Can I use one of these face recognition pre-trained models to recognise plants?,2020-06-09T12:31:19Z
UgziBOWjqFnYhI9dfNt4AaABAg.99gE8Jr4oPP99z-GT8cYZ1,@TimeKnowledgePower,UgziBOWjqFnYhI9dfNt4AaABAg,2,d2XB5-tuCWU,0,1,2020-06-16T19:26:55Z,"@leena perhaps the first few layers since they are looking for patterns of complex shapes such as faces, but the deeper the layers go the less likely you are to have a super relatable model.",2020-06-16T19:26:55Z
UgziBOWjqFnYhI9dfNt4AaABAg.99gE8Jr4oPP9A-2ACFCx_a,@LeenaGurgPhysics,UgziBOWjqFnYhI9dfNt4AaABAg,2,d2XB5-tuCWU,0,0,2020-06-17T05:11:31Z,@@TimeKnowledgePower  Thank you for your suggestion. Will try this!,2020-06-17T05:11:31Z
Ugw43Zt_PGhq_GxFrLB4AaABAg,@jaswant2578,,1,d2XB5-tuCWU,0,6,2020-02-27T15:50:39Z,Explained Crystal clearly  !!,2020-02-27T15:50:39Z
Ugw8UtycRwFOXnwQmeV4AaABAg,@clemsch90,,1,d2XB5-tuCWU,2,13,2020-02-03T11:43:00Z,"If you train a neural network that&#39;s detecting throats, is it called &quot;deepthroat&quot;?",2020-02-03T11:43:00Z
Ugw8UtycRwFOXnwQmeV4AaABAg.94_7ePoEdQL95BIhJQBuqx,@WooblyBoobly,Ugw8UtycRwFOXnwQmeV4AaABAg,2,d2XB5-tuCWU,0,4,2020-02-18T16:49:54Z,someone&#39;s asking the real questions,2020-02-18T16:49:54Z
Ugw8UtycRwFOXnwQmeV4AaABAg.94_7ePoEdQL95HfPXxi82Y,@kaustubhparmar4274,Ugw8UtycRwFOXnwQmeV4AaABAg,2,d2XB5-tuCWU,0,1,2020-02-21T04:12:30Z,ballsDeep,2020-02-21T04:12:30Z
UgyFZsRVITv92VuNPBR4AaABAg,@sadema9968,,1,d2XB5-tuCWU,0,0,2019-04-11T10:14:52Z,"Thanks so much, briliant, please add some python code",2019-04-11T10:14:52Z
UgyWboGhfd3kZzobsBl4AaABAg,@md.rijoanrabbi99,,1,d2XB5-tuCWU,0,0,2019-03-11T20:24:49Z,may i encode my own image using 2 layer neural network? instead of inception block ?is it use of supervise learning or on encoding occured in the inception or facenet unit?,2019-03-11T20:24:49Z
UgydSaPbw5AeZKA3EaJ4AaABAg,@masbro1901,,1,0NSLgoEtdnw,0,0,2023-08-10T11:44:16Z,"<a href=""https://www.youtube.com/watch?v=0NSLgoEtdnw&amp;t=1m42s"">1:42</a> isn&#39;t called euclidean distance?",2023-08-10T11:44:16Z
Ugz-1kBOYem_W1W6ISF4AaABAg,@EranM,,1,0NSLgoEtdnw,0,0,2022-09-01T12:13:37Z,What about cosine similarity ?,2022-09-01T12:13:37Z
UgzSQ0MvQx1-w1yZqgt4AaABAg,@jeremynx,,1,0NSLgoEtdnw,0,0,2022-05-05T18:09:51Z,Good explanation. Thanks,2022-05-05T18:09:51Z
Ugyb8mR3cBAj1G5up814AaABAg,@alh7839,,1,0NSLgoEtdnw,0,1,2022-02-15T11:23:35Z,"hello, great video thanks. I have a question, how to implement this last part (the logistic gregression neuron)",2022-02-15T11:23:35Z
UgwOKD2YqWDbRP8mDpp4AaABAg,@HellDragonvolt,,1,0NSLgoEtdnw,0,1,2021-03-08T23:47:05Z,"Thank you very much, helped me a lot for my computer vision exam!",2021-03-08T23:47:05Z
UgzRTbcTDaLe68kmTJt4AaABAg,@trexmidnite,,1,0NSLgoEtdnw,0,0,2021-02-20T22:30:42Z,Are you making this all up?,2021-02-20T22:30:42Z
Ugyb5QiWDkTHu1rniM14AaABAg,@sandipansarkar9211,,1,0NSLgoEtdnw,0,0,2021-01-10T15:19:52Z,nice explantion,2021-01-10T15:19:52Z
Ugzqz1Ji48LqecVWy8p4AaABAg,@faridalijani1578,,1,0NSLgoEtdnw,2,0,2019-12-20T10:29:43Z,"2 questions?<br><br>1. In statistics and literature, chi square = (Observed - Expected)^2/Expected, whereas in here you&#39;re pointing it out as chi square = (Observed - Expected)^2/(Observed+Expected)! How?<br><br>2. In DeepFace paper, they only use weighted chi-square, meaning to multiply weight (w) to the absolute differences, whereas you have also considered bias (b)! why?",2019-12-20T10:59:50Z
Ugzqz1Ji48LqecVWy8p4AaABAg.92l7VINM5s49BqFC-D2h3y,@akashkewar,Ugzqz1Ji48LqecVWy8p4AaABAg,2,0NSLgoEtdnw,0,1,2020-08-02T02:55:44Z,"1) Looks like you have missed few words, he said &quot;chi-squared similarity&quot; and not chi-squared goodness of fit. (<a href=""https://slideplayer.com/slide/6243657/21/images/6/Similarity+Metrics+Histogram+Intersection+Chi-square+distance.jpg)"">https://slideplayer.com/slide/6243657/21/images/6/Similarity+Metrics+Histogram+Intersection+Chi-square+distance.jpg)</a>. The denominator is just normalizing factor, World won&#39;t collapse even if you &quot;Expected&quot; in the denominator.<br><br>2) Using bias gives you much more flexibility (degree of freedom) than not using bias (imagine doing regression with a line whose origin is always 0, this is what without bias looks like). Also, I didn&#39;t read the DeepFace paper, but are they using matrix notation? because sometimes they add additional bias term in the matrix &quot;w&quot; itself.",2020-08-02T02:55:44Z
Ugzqz1Ji48LqecVWy8p4AaABAg.92l7VINM5s49e9N0FMauah,@waleedaiad3411,Ugzqz1Ji48LqecVWy8p4AaABAg,2,0NSLgoEtdnw,0,0,2022-07-31T17:39:17Z,Can i talk with you on whatsapp or any way else because i have quastion about triplet lose and face net.<br>Thanksüå∫üåπ,2022-07-31T17:39:17Z
Ugw8PJpLeaJlLhCRqYt4AaABAg,@user-dv3bf7yp2r,,1,0NSLgoEtdnw,0,1,2019-04-04T05:09:49Z,"As we have already trained the encoder with the lost function L=d(A, P)-d(A, N)+alpha, how can we train the network with another target x, y?",2019-04-04T05:09:49Z
Ugysxg0O90MCJGG23Zd4AaABAg,@sau002,,1,0NSLgoEtdnw,1,0,2018-10-07T16:11:53Z,"Hi All, Could somebody please clarify if we need to retrain the neural network every time a new empoyee is added to the organization OR do we have 1 dedicated neural network model per employee?",2018-10-07T20:18:50Z
Ugysxg0O90MCJGG23Zd4AaABAg.8m6LgE_6FFS8m93wm32YO3,@maheshwaranumapathy4678,Ugysxg0O90MCJGG23Zd4AaABAg,2,0NSLgoEtdnw,0,0,2018-10-08T17:34:35Z,I would recommend you to watch no 33 one shot learning where Andrew explains about the particular constrain your concerned about,2018-10-08T17:34:35Z
UgzGYpfFz85W7U_F5WF4AaABAg,@sau002,,1,0NSLgoEtdnw,0,0,2018-10-07T16:10:49Z,Excellent video.,2018-10-07T16:10:49Z
UgzIIxuMB097pjkyHId4AaABAg,@benikm91,,1,0NSLgoEtdnw,3,12,2018-07-24T19:44:31Z,Souldn&#39;t it be w_k instead of w_i?,2018-07-24T19:44:31Z
UgzIIxuMB097pjkyHId4AaABAg.8j5bOuGgRzi8jWq3594VPK,@jandroid33,UgzIIxuMB097pjkyHId4AaABAg,2,0NSLgoEtdnw,0,1,2018-08-04T09:32:05Z,"Yea, must be just a simple mistake by Ng.",2018-08-04T09:32:05Z
UgzIIxuMB097pjkyHId4AaABAg.8j5bOuGgRzi8m6Lpp8sD7E,@sau002,UgzIIxuMB097pjkyHId4AaABAg,2,0NSLgoEtdnw,0,0,2018-10-07T16:13:11Z,Yes. I think w_k.,2018-10-07T16:13:11Z
UgzIIxuMB097pjkyHId4AaABAg.8j5bOuGgRzi8tI2xZMQBDp,@user-dv3bf7yp2r,UgzIIxuMB097pjkyHId4AaABAg,2,0NSLgoEtdnw,0,0,2019-04-04T04:58:52Z,same confusion to u,2019-04-04T04:58:52Z
UgxRdWwfK1Zmj8T-go94AaABAg,@ashiqks9034,,1,0NSLgoEtdnw,1,3,2018-07-23T18:55:53Z,Can Siamese network be used for different classes other than face?,2018-07-23T18:55:53Z
UgxRdWwfK1Zmj8T-go94AaABAg.8j2x1wRADn_8sJq0zlRObd,@sinanozgun1621,UgxRdWwfK1Zmj8T-go94AaABAg,2,0NSLgoEtdnw,0,2,2019-03-11T01:04:14Z,of course. we are currently doing something similar,2019-03-11T01:04:14Z
UgyHgu7xSAsGbPJtIUd4AaABAg,@satyajitkamble1646,,1,0NSLgoEtdnw,1,0,2017-12-15T03:41:44Z,where can I get a dataset to train my model using the loss function mentioned in this video???,2017-12-15T03:41:44Z
UgyHgu7xSAsGbPJtIUd4AaABAg.8aApXz27UjZ8rfqsp2FL4U,@hcgaron,UgyHgu7xSAsGbPJtIUd4AaABAg,2,0NSLgoEtdnw,0,0,2019-02-23T03:02:51Z,-- maybe ‚Äúlabeled faces in the wild‚Äù would work.,2019-02-23T03:02:51Z
UgzrLb_fXNgRO6A-1Ex4AaABAg,@sandipansarkar9211,,1,R39tWYYKNcI,0,2,2021-02-05T18:23:13Z,great explanation,2021-02-05T18:23:13Z
UgxVFSBEsE5QMVD5PhZ4AaABAg,@sandipansarkar9211,,1,ChoV5h7tw5A,0,0,2021-02-05T18:34:53Z,great explanation,2021-02-05T18:34:53Z
UgyauByR-eNkH7xrzUl4AaABAg,@kihongkim8726,,1,ChoV5h7tw5A,1,0,2021-01-02T16:25:54Z,&quot;Pick a unit in layer 1&quot; means  110x110x1   from  110 x 110 x 96 ???,2021-01-02T16:28:51Z
UgyauByR-eNkH7xrzUl4AaABAg.9I0eXcn4QiW9M7RaJ6kpsV,@shaleenparikh2750,UgyauByR-eNkH7xrzUl4AaABAg,2,ChoV5h7tw5A,0,3,2021-04-14T17:44:20Z,A unit is just one neuron,2021-04-14T17:44:20Z
UgxNw0z7dBy53lrkJfF4AaABAg,@aayushpaudel2379,,1,ChoV5h7tw5A,0,1,2020-08-31T03:19:07Z,my logic of understanding- the further you are from images- the more (wider) you see!! :D,2020-08-31T03:19:07Z
Ugxr2hQjJ39HZfJ68KR4AaABAg,@thovinh5386,,1,ChoV5h7tw5A,1,0,2020-05-05T07:44:23Z,"I understand every English words he said in this video, I just don&#39;t understand the content.",2020-05-05T07:44:23Z
Ugxr2hQjJ39HZfJ68KR4AaABAg.98GaUB-7E5F9Xez5lFyBvo,@xl0xl0xl0,Ugxr2hQjJ39HZfJ68KR4AaABAg,2,ChoV5h7tw5A,0,1,2022-01-26T13:25:22Z,Do you understand it now?,2022-01-26T13:25:22Z
UgxkAu6TpvwkYbPX1qt4AaABAg,@MG5350,,1,ChoV5h7tw5A,1,3,2020-02-28T02:56:01Z,I can&#39;t understand how these visualizations can be real if images are progressively being convoluted and have less and less resolution throughout the convnet,2020-02-28T02:56:18Z
UgxkAu6TpvwkYbPX1qt4AaABAg.95ZZDUurLCP99Yty-rXc1K,@JIMMYLIU5,UgxkAu6TpvwkYbPX1qt4AaABAg,2,ChoV5h7tw5A,0,9,2020-06-06T06:52:20Z,You go backwards to find the patch in original image that is giving maximum response at a certain layer.,2020-06-06T06:52:20Z
UgzEwTcy3lm5mkpiStp4AaABAg,@hirakmondal6174,,1,ChoV5h7tw5A,2,3,2019-12-15T14:40:51Z,Who on earth gives picture of his wife in examples..?üòÇ,2020-01-21T14:43:11Z
UgzEwTcy3lm5mkpiStp4AaABAg.92ZhGBOKKbk93bR3nGzC7P,@udaykadam5455,UgzEwTcy3lm5mkpiStp4AaABAg,2,ChoV5h7tw5A,0,0,2020-01-10T12:39:43Z,How is this a problem when our country is going bananas.<br>Let&#39;s get to this when we solve like millions of actual problems in our lives.,2020-01-10T12:43:24Z
UgzEwTcy3lm5mkpiStp4AaABAg.92ZhGBOKKbk9fataEJarva,@psibarpsi,UgzEwTcy3lm5mkpiStp4AaABAg,2,ChoV5h7tw5A,0,0,2022-09-05T16:02:49Z,Andrew Ng.,2022-09-05T16:02:49Z
UgwOAxS0UtFgDFZnVe54AaABAg,@emmanueltd7628,,1,ChoV5h7tw5A,6,1,2019-10-06T15:36:16Z,why does the first layer see only a little of the image? it convolves through the entire image right?,2019-10-06T15:36:16Z
UgwOAxS0UtFgDFZnVe54AaABAg.9-kYxtfKz2r90fMwn4q6pA,@lizeng489,UgwOAxS0UtFgDFZnVe54AaABAg,2,ChoV5h7tw5A,0,7,2019-10-29T11:46:27Z,"You are thinking the deep CN learning as a &quot;forwarding process&quot;,  but it is actually a &quot;backwarding process&quot;. Instead of thinking the first layer params are generated from a convolution of the image, better think the first layer params are told to be so by the second layer which is again told to be so by higher layers all the way to the loss function of input data. It is this structure that decided the first layer better only &quot;see only a litter fraction of the image&quot; will perform the best for the purpose.",2019-10-29T11:46:27Z
UgwOAxS0UtFgDFZnVe54AaABAg.9-kYxtfKz2r94mI8z6ANDA,@puneetsingh5219,UgwOAxS0UtFgDFZnVe54AaABAg,2,ChoV5h7tw5A,0,1,2020-02-08T14:24:49Z,"@@lizeng489 So, in a way, the CNN in breaking the image down moving from higher level to lower level layers?",2020-02-08T14:24:49Z
UgwOAxS0UtFgDFZnVe54AaABAg.9-kYxtfKz2r95iJjrhQYab,@abdulmukit4420,UgwOAxS0UtFgDFZnVe54AaABAg,2,ChoV5h7tw5A,0,0,2020-03-02T21:53:10Z,"It is due to something called the receptive field.  Look at this documentation from cs231n.<br><a href=""http://cs231n.github.io/convolutional-networks/"">http://cs231n.github.io/convolutional-networks/</a>",2020-03-02T21:53:33Z
UgwOAxS0UtFgDFZnVe54AaABAg.9-kYxtfKz2r9DBQnGYCfjw,@pablopicasso2208,UgwOAxS0UtFgDFZnVe54AaABAg,2,ChoV5h7tw5A,0,0,2020-09-04T14:11:46Z,"It convolves through the entire image but with it&#39;s filters i.e. the weights that are only looking for pattern in the whole image like a diagonal or a straight line we can only see the edges(Activation only values it as edge or not edge).Next is pooling, Imagine it as something that reduces the resolution but shows the same image(The image hear being the edges but just in a smaller resolution).We convolve it again  and  start looking for shapes like circle through the whole image features which we got from the previous result(i.e. the images) and it goes .LMK if it makes sense",2020-09-04T14:11:46Z
UgwOAxS0UtFgDFZnVe54AaABAg.9-kYxtfKz2r9I-QG6Vm9pc,@gorgolyt,UgwOAxS0UtFgDFZnVe54AaABAg,2,ChoV5h7tw5A,0,1,2021-01-02T04:53:12Z,"@@lizeng489 Not sure why so many upvotes, this answer is just wrong and irrelevant to the question.",2021-01-02T04:53:12Z
Ugw7H19j_YPFA01J4aF4AaABAg,@ahmedyehia5553,,1,ChoV5h7tw5A,0,0,2018-02-27T15:11:15Z,"<a href=""https://www.youtube.com/watch?v=ChoV5h7tw5A&amp;t=3m00s"">3:00</a>",2018-02-27T15:11:15Z
UgykEI4_4w2YPxNunBh4AaABAg,@gabrielwong1991,,1,xY-DMAJpIP4,0,0,2021-03-22T01:34:28Z,Is there any relationships between Neural Style Transfer and Generalized Adversarial Network?,2021-03-22T01:34:37Z
UgxNjdGT9Tx3oLoK5Ll4AaABAg,@sandipansarkar9211,,1,xY-DMAJpIP4,0,0,2021-02-05T18:39:06Z,great explantion,2021-02-05T18:39:06Z
UgykUxMryVwc0pDud094AaABAg,@djethereal99,,1,xY-DMAJpIP4,0,0,2020-12-04T03:44:18Z,great stuff,2020-12-04T03:44:18Z
Ugzu5DaqO0bDgrAkP1t4AaABAg,@LeenaGurgPhysics,,1,xY-DMAJpIP4,0,0,2020-06-10T07:16:10Z,"Was wondering is the reverse is also possible, can you extract an object from its background?",2020-06-10T07:16:10Z
Ugxsshgz8BH6sGtLJ6V4AaABAg,@thomasrossimel743,,1,xY-DMAJpIP4,0,0,2018-04-08T16:54:58Z,amazing,2018-04-08T16:54:58Z
UgyGfXBiS2pQ-RnNzWp4AaABAg,@haroldsu1696,,1,xY-DMAJpIP4,0,0,2018-03-10T02:11:56Z,very good explanation for the Neural style transfer,2018-03-10T02:11:56Z
Ugzb3bPPV5sbz2ItTcN4AaABAg,@sandipansarkar9211,,1,b1I5X3UfEYI,0,0,2021-01-23T19:12:56Z,nice explntion,2021-01-23T19:12:56Z
UgxFjFpDSAt98yqSU7x4AaABAg,@PixelPulse168,,1,QgkLfjfGul8,0,0,2022-10-03T17:14:34Z,what parameters does it train?,2022-10-03T17:14:34Z
Ugw2EmzwSs6bLVYO2a54AaABAg,@manuel783,,1,QgkLfjfGul8,1,0,2021-01-18T23:58:39Z,"Style Cost <b>CORRECTION</b><br><br>Please note that at around <a href=""https://www.youtube.com/watch?v=QgkLfjfGul8&amp;t=8m50s"">8:50</a> when Andrew wrote down the second formula of matrix, the second factor of the multiplication should be on index k&#39; (k prime), not k (otherwise it does not calculate any kind of covariance). This is shown in black below.<br><br>ÔΩàÔΩîÔΩîÔΩêÔΩìÔºöÔºèÔºèÔΩÑÔºìÔΩÉÔºìÔºìÔΩàÔΩÉÔΩáÔΩâÔΩóÔΩÖÔΩñÔºìÔºéÔΩÉÔΩåÔΩèÔΩïÔΩÑÔΩÜÔΩíÔΩèÔΩéÔΩîÔºéÔΩéÔΩÖÔΩîÔºèÔΩâÔΩçÔΩÅÔΩáÔΩÖÔº°ÔΩìÔΩìÔΩÖÔΩîÔº∞ÔΩíÔΩèÔΩòÔΩôÔºéÔΩñÔºëÔºèÔºßÔºñÔº∫ÔΩÅÔº¥ÔΩíÔΩöÔΩÅÔº•ÔΩÖÔΩçÔΩìÔºñÔº¢Ôº¨ÔºîÔº∞ÔΩôÔº•ÔΩóÔºøÔº°ÔºøÔΩÑÔºêÔΩÑÔºêÔºíÔΩÖÔºëÔºëÔΩÇÔºôÔΩÜÔºêÔºñÔºìÔºìÔºôÔºñÔºîÔΩÇÔΩÑÔºêÔΩÅÔºôÔΩÖÔΩÇÔΩÇÔΩÜÔΩÖÔΩÇÔºóÔΩÑÔΩÇÔºøÔΩìÔΩîÔΩôÔΩåÔΩÖÔºéÔΩêÔΩéÔΩáÔºüÔΩÖÔΩòÔΩêÔΩâÔΩíÔΩôÔºùÔºëÔºñÔºëÔºëÔºëÔºêÔºêÔºòÔºêÔºêÔºêÔºêÔºêÔºÜÔΩàÔΩçÔΩÅÔΩÉÔºùÔºëÔΩîÔº≤ÔºëÔΩéÔΩíÔº¨ÔΩàÔº¥ÔΩãÔΩèÔΩÉÔº§ÔºßÔºëÔºøÔº¢ÔΩìÔº©ÔºòÔºïÔΩéÔº±Ôº®ÔΩãÔºóÔºµÔΩåÔΩöÔΩåÔº¥ÔΩÑÔΩëÔº°Ôº¨ÔΩòÔΩñÔº§ÔΩëÔº®ÔΩôÔΩôÔº•",2021-01-18T23:58:39Z
Ugw2EmzwSs6bLVYO2a54AaABAg.9Iff3baX0-X9IffN8hMzFV,@manuel783,Ugw2EmzwSs6bLVYO2a54AaABAg,2,QgkLfjfGul8,0,0,2021-01-19T00:01:18Z,"Also at <a href=""https://www.youtube.com/watch?v=QgkLfjfGul8&amp;t=11m08s"">11:08</a> the style cost function formula should be the squared difference instead of just the difference.",2021-01-19T00:01:18Z
UgxfHBktr00AaEqqi4l4AaABAg,@gorgolyt,,1,QgkLfjfGul8,0,20,2021-01-02T20:42:57Z,"In case anybody gets confused, there&#39;s quite a big editing mistake in this video -- everything from <a href=""https://www.youtube.com/watch?v=QgkLfjfGul8&amp;t=8m11s"">8:11</a> to <a href=""https://www.youtube.com/watch?v=QgkLfjfGul8&amp;t=13m06s"">13:06</a> is repetition, so just skip to the end of that part.",2021-01-02T20:42:57Z
UgxfLLh_3jHp0aDrtQt4AaABAg,@dfincher6,,1,QgkLfjfGul8,0,1,2020-07-16T02:54:56Z,There&#39;re lots of NG takes :),2020-07-16T02:54:56Z
UgzV2maNxwn2Hg1IRzd4AaABAg,@keshavbansal5148,,1,QgkLfjfGul8,0,1,2020-07-03T07:33:54Z,"No idea what went on in this video, seems a bit too complex",2020-07-03T07:33:54Z
UgzZtqcXS_ODjrHAd1p4AaABAg,@DrN007,,1,QgkLfjfGul8,0,1,2020-05-02T15:51:28Z,"Style Cost Function is highly subjective, unless we were to find the ground truth for source images of each painting. PERIOD.",2020-05-02T15:51:28Z
UgzJLSMj28jYrq_9yL94AaABAg,@atreyamajumdar9836,,1,QgkLfjfGul8,1,1,2020-01-12T08:53:28Z,Isn&#39;t he defining the non-correlation with the definition of anti-correlation?,2020-01-12T08:53:28Z
UgzJLSMj28jYrq_9yL94AaABAg.93gAlRfN9PZ9I18I9y04cC,@gorgolyt,UgzJLSMj28jYrq_9yL94AaABAg,2,QgkLfjfGul8,0,1,2021-01-02T20:54:40Z,"Yes, it would be easy to mistake him there. He means to say that whenever one texture is present, the other texture is no more or less present than usual.",2021-01-02T20:54:40Z
UgwdUsRBpfcC1CBBJS14AaABAg,@Scaryder92,,1,QgkLfjfGul8,2,0,2019-10-20T18:56:20Z,"Great video as always, thanks! Since the inner product is symmetric, aren&#39;t we calculating twice the same thing? (k=1,k&#39;=2    and k=2, k&#39;=1 gives the same result, no?)",2019-10-20T18:56:20Z
UgwdUsRBpfcC1CBBJS14AaABAg.90JxzTbZkBb92ss8hQRo4H,@ish694,UgwdUsRBpfcC1CBBJS14AaABAg,2,QgkLfjfGul8,0,0,2019-12-23T10:40:45Z,Yeah..seems like you are right. The gram matrix is computed as the unnormalized covariance matrix (as referred earlier) and a covar matrix is always symmetric. So its transpose should be equal to the actual matrix.,2019-12-23T10:40:45Z
UgwdUsRBpfcC1CBBJS14AaABAg.90JxzTbZkBb9KKQeSrwqNQ,@2B_pencil,UgwdUsRBpfcC1CBBJS14AaABAg,2,QgkLfjfGul8,0,0,2021-03-01T01:43:30Z,"I&#39;m guessing you&#39;re still expected to double-sum (k=1,k&#39;=2 and k=2, k&#39;=1). That is why there is a &quot;2&quot; squared in the denominator in the equation at <a href=""https://www.youtube.com/watch?v=QgkLfjfGul8&amp;t=15m40s"">15:40</a>. Again, just my guess.",2021-03-01T01:43:30Z
UgxiyHM9TyjgudUA2pR4AaABAg,@lana9459,,1,QgkLfjfGul8,0,2,2019-08-06T10:27:02Z,wonderful,2019-08-06T10:27:02Z
UgxazvxEh1Vgn5F9fT94AaABAg,@jerrylin5089,,1,QgkLfjfGul8,1,9,2019-07-21T22:21:59Z,"I think the equation at <a href=""https://www.youtube.com/watch?v=QgkLfjfGul8&amp;t=15m02s"">15:02</a> is missing a square exponent",2019-07-21T22:21:59Z
UgxazvxEh1Vgn5F9fT94AaABAg.8xf0AzQ5lMi97YOUT6-xtp,@hanifr8380,UgxazvxEh1Vgn5F9fT94AaABAg,2,QgkLfjfGul8,0,2,2020-04-17T09:05:45Z,"tru, there&#39;s actually a correction about it on coursera",2020-04-17T09:05:45Z
Ugz3OE1O6c_-r8hrSvN4AaABAg,@elgs1980,,1,QgkLfjfGul8,2,11,2018-11-01T21:04:20Z,I&#39;m totally lost in this video.,2018-11-01T21:04:20Z
Ugz3OE1O6c_-r8hrSvN4AaABAg.8n7F12CdaMR8uscZY_uoHy,@CyborgGaming99,Ugz3OE1O6c_-r8hrSvN4AaABAg,2,QgkLfjfGul8,0,1,2019-05-13T15:42:03Z,"Haha it repeats itself from <a href=""https://www.youtube.com/watch?v=QgkLfjfGul8&amp;t=8m15s"">8:15</a>, but not entirely",2019-05-13T15:42:03Z
Ugz3OE1O6c_-r8hrSvN4AaABAg.8n7F12CdaMR9I13ZVNCjl9,@gorgolyt,Ugz3OE1O6c_-r8hrSvN4AaABAg,2,QgkLfjfGul8,0,0,2021-01-02T20:13:21Z,"Watch it twice, I don&#39;t think it&#39;s too difficult.",2021-01-02T20:13:21Z
UgzH0AhGkJtMUCR69Lp4AaABAg,@kaitaoyang15,,1,QgkLfjfGul8,0,0,2017-12-30T16:05:40Z,Is there a typo of the Style cost function? Should be the power of the difference between the two style matrices?,2017-12-30T16:05:40Z
UgwUvviBL01E_2oOjKx4AaABAg,@KevinKuei,,1,QgkLfjfGul8,1,1,2017-12-13T00:35:43Z,"The two equations (@<a href=""https://www.youtube.com/watch?v=QgkLfjfGul8&amp;t=14m17s"">14:17</a> &amp; @<a href=""https://www.youtube.com/watch?v=QgkLfjfGul8&amp;t=14m39s"">14:39</a>) seems to be different.",2017-12-13T00:35:43Z
UgwUvviBL01E_2oOjKx4AaABAg.8a5LeoRUzZY8dSNsiMJHay,@CygnusX211,UgwUvviBL01E_2oOjKx4AaABAg,2,QgkLfjfGul8,0,2,2018-03-06T12:51:48Z,"@<a href=""https://www.youtube.com/watch?v=QgkLfjfGul8&amp;t=14m39s"">14:39</a> there should be a ^2 on the element wise matrix difference",2018-03-06T12:51:48Z
UgzpKS2YETeh1qhoa1R4AaABAg,@sagnikkayal782,,1,Cn8AtS-9Nwc,0,0,2023-10-24T07:43:13Z,"Thank you for this lecture series. It was very much needeed for me<a href=""about:invalid#zCSafez""></a>",2023-10-24T07:43:13Z
UgwEtQjllSj0L-Ohnyp4AaABAg,@muazzamali9511,,1,Cn8AtS-9Nwc,0,1,2023-01-22T23:03:39Z,"If tasks along with these tutorials were also available, it would be amazing üòç Anyway, I appreciate the fact that this course is accessible to all. <br>Thanks to the professor and the entire deep learning community for their efforts.",2023-01-22T23:09:35Z
UgzISk_YeFpKvIcj_Ch4AaABAg,@arkadipbasu828,,1,Cn8AtS-9Nwc,0,0,2022-12-10T03:44:09Z,Thank you professor Andrew for making it accessible to all.,2022-12-10T03:44:09Z
Ugw-AK6DsMslFcWqOWN4AaABAg,@hoangyennguyen975,,1,Cn8AtS-9Nwc,0,0,2022-04-09T03:33:24Z,Thank you so much. You save my future!!,2022-04-09T03:33:24Z
Ugz6HpZOkZoGXlpDfth4AaABAg,@farzanayesmin5033,,1,Cn8AtS-9Nwc,0,0,2021-09-17T20:21:31Z,Thank you so much Sir,2021-09-17T20:21:31Z
UgzrojQx3rLRFs0H5ed4AaABAg,@giathinhnguyen1800,,1,Cn8AtS-9Nwc,0,0,2021-09-12T18:11:04Z,"Thank you so much, Andrew!",2021-09-12T18:11:04Z
Ugy32TL3ivpNiA9u4cB4AaABAg,@yoyirodriguez02,,1,Cn8AtS-9Nwc,0,0,2021-08-11T22:14:00Z,"Much appreciated, Andrew!",2021-08-11T22:14:00Z
Ugy6d3hmuzkkyn2Ro514AaABAg,@osiris1102,,1,Cn8AtS-9Nwc,0,1,2021-06-27T14:40:30Z,Thank you professor Andrew for all your hardwork.,2021-06-27T14:40:30Z
UgyUakloogNpFBRWroV4AaABAg,@sandipansarkar9211,,1,Cn8AtS-9Nwc,0,0,2021-01-28T17:51:31Z,nice explanation,2021-01-28T17:51:31Z
UgxvJeyLIqHCU4UPqWB4AaABAg,@shivtejful,,1,Cn8AtS-9Nwc,0,0,2020-09-23T04:44:59Z,Can images with different pixel spacing in training have any impact on model generation/performance?,2020-09-23T04:44:59Z
UgxgAGeXoKqZ6j7se_14AaABAg,@_ABDULGHANI,,1,Cn8AtS-9Nwc,0,1,2020-08-27T16:38:02Z,"Thank you for all these useful videos, and I wish to see more, you describe everything in a simple way.",2020-08-27T16:38:02Z
UgzThslZlFG8pckBc3t4AaABAg,@shivtejful,,1,Cn8AtS-9Nwc,0,1,2020-08-10T04:40:04Z,"Anyone here interested to discuss Computer vision over chat, for more knowledge sharing?",2020-08-10T04:40:04Z
Ugy6XexfTE6dgNvZuPZ4AaABAg,@lmadriles,,1,Cn8AtS-9Nwc,0,2,2020-07-05T03:49:58Z,"Thank you, Professor Andrew. I will try to spread the knowledge adquired at these lessons as much as I am able.",2020-07-05T03:49:58Z
UgwMJ0T-qCHb9huIqlB4AaABAg,@zahrahaghgu6115,,1,Cn8AtS-9Nwc,0,2,2020-04-10T19:52:47Z,It was a great course. Thank you so much Andrew!,2020-04-10T19:52:47Z
UgwDaNVfzUCRFyIr6zZ4AaABAg,@abdulmukit4420,,1,Cn8AtS-9Nwc,0,3,2020-03-03T00:06:27Z,Andrew Ng. You are a gift to this world. Really. Thank you.,2020-03-03T00:06:27Z
UgyWWZ54jzT19cD77BB4AaABAg,@zakariatolba6600,,1,Cn8AtS-9Nwc,0,0,2020-02-19T12:31:44Z,"you are a great teacher , thank you .",2020-02-19T12:31:44Z
UgzhPHM7jk2up-72JRd4AaABAg,@zizhewang,,1,Cn8AtS-9Nwc,0,0,2020-02-06T09:34:17Z,Thank you very much! Ë∞¢Ë∞¢ÔºÅ,2020-02-06T09:34:17Z
UgzUD3ngkOZdG2uIJvF4AaABAg,@khushbootaneja6739,,1,Cn8AtS-9Nwc,0,1,2019-12-09T09:53:17Z,"Thank you so much Sir, you have simplified a lot of things for us. I am humbled and grateful towards you",2019-12-09T09:53:17Z
Ugx2ynrMEJxYIH5-tyN4AaABAg,@yaram.bahram6715,,1,Cn8AtS-9Nwc,0,0,2019-08-19T11:00:43Z,thanks.,2019-08-19T11:00:43Z
UgzOFmOvhFxz437FjQt4AaABAg,@sushruthprasannakumar8079,,1,Cn8AtS-9Nwc,0,0,2019-05-20T01:33:31Z,"totally understood the concept but how do we implement it,kind of seem lost :(",2019-05-20T01:33:31Z
UgxqAFQOuLARIOCu1c54AaABAg,@kld0093,,1,Cn8AtS-9Nwc,0,0,2019-03-19T06:51:12Z,Amazing course &lt;3 much love. Now I continue your other coursera course,2019-03-19T06:51:12Z
Ugy8oTxzbp7QI2fhawt4AaABAg,@aramnasser268,,1,Cn8AtS-9Nwc,0,1,2019-02-17T16:54:49Z,"Amazing set of tutorials. <br>You made these fuzzy concepts crystal clear, thanks.",2019-02-17T16:54:49Z
UgxDhJv21J8Tx4FLMYJ4AaABAg,@ainurkazykhanov1052,,1,Cn8AtS-9Nwc,0,2,2018-12-01T20:52:04Z,"Thank you so much, Andrew! It`s definitely the best course about Deep Learning!",2018-12-01T20:52:04Z
UgwjvjAD2K3VbK4aYNh4AaABAg,@elgs1980,,1,Cn8AtS-9Nwc,0,1,2018-11-01T20:58:02Z,Where can we find the details of the back propagation while training the CNN?,2018-11-01T20:58:02Z
UgzWBl0rEYC_cizNsLF4AaABAg,@SheIsSinging,,1,Cn8AtS-9Nwc,0,0,2018-08-13T18:02:15Z,Really a great course. Many thanks.,2018-08-13T18:02:15Z
UgwNQ1W5F1nUnnK220V4AaABAg,@wajidali2673,,1,Cn8AtS-9Nwc,0,4,2018-08-11T08:07:47Z,"Thank you, dear professor Andrew, you are one of the great teacher in my life, yours way of taught is awesome and great, Wish you a best and healthy life...",2018-08-11T08:07:47Z
UgzPuYMjLrq7t3AZErJ4AaABAg,@jamesang7861,,1,Cn8AtS-9Nwc,0,0,2018-07-29T13:52:08Z,Thanks a lot Andrew! Learnt  a  lot!,2018-07-29T13:52:08Z
UgybvK_I-L97eyUnRNN4AaABAg,@JanVincentLatzko,,1,Cn8AtS-9Nwc,1,0,2018-07-25T09:40:12Z,"I am sorry, but I disagree. In signal processing, convolution is carefully designed ( type f(t)\ast g(t) = \int_{-\infty}^{\infty}f(\tau)g(t-\tau)d\tau in your LaTeX environment). In detail, the support of the two functions / data series to be convolved is important. You argue that convolving a 14x1 with 5x1 gives 10x1 when it really does not*. It gives nonzero results for a range of 19x1 segment (5/2 + 14 + 5/2). <br><br>Of course, adapting what we have learned to 1D conv, you are correct - but it&#39;s far, very far, from universal. <br>Thank you for understanding :-) <br><br>* this has been a source for trouble for me, coming from DSP to CV - the &quot;valid&quot; conv operation is just not natural to me",2018-07-25T09:40:12Z
UgybvK_I-L97eyUnRNN4AaABAg.8j761eHrL4M8j76NK5eHfN,@JanVincentLatzko,UgybvK_I-L97eyUnRNN4AaABAg,2,Cn8AtS-9Nwc,0,0,2018-07-25T09:43:09Z,"See this animation from <a href=""https://en.wikipedia.org/wiki/Convolution#Compactly_supported_functions"">https://en.wikipedia.org/wiki/Convolution#Compactly_supported_functions</a> for visualisation: <a href=""https://en.wikipedia.org/wiki/File:Convolution_of_spiky_function_with_box2.gif"">https://en.wikipedia.org/wiki/File:Convolution_of_spiky_function_with_box2.gif</a>",2018-07-25T09:43:09Z
Ugwfi9H16rsbRm79W4p4AaABAg,@alphan.9066,,1,Cn8AtS-9Nwc,0,1,2018-02-01T20:49:51Z,I don&quot;t see any implementation or code for the neural network? How can i design it?,2018-02-01T20:49:51Z
Ugyj0f3jSsWy3ytuhY14AaABAg,@tbru92,,1,Cn8AtS-9Nwc,0,15,2018-02-01T11:06:48Z,Thank you for this amazing course Andrew!! :),2018-02-01T11:06:48Z
UgxlrcQSzI9rJLU0VXN4AaABAg,@selvz3931,,1,Cn8AtS-9Nwc,0,2,2017-12-06T00:09:58Z,"Yes, thank you Andrew for enabling learning",2017-12-06T00:09:58Z
Ugyk5_ChE6wsgzjP_3F4AaABAg,@abady2001,,1,Cn8AtS-9Nwc,0,4,2017-11-16T14:45:00Z,"Thank you Andrew, you are awesome!",2017-11-16T14:45:00Z
UgyjA3RXruNFkGbd-eF4AaABAg,@sepehrsarjami,,1,OT91E6_Qm1A,0,0,2023-08-15T07:24:19Z,"He mentioned dialouge systems five years ago, hope to know his idea about ChatGPT right now:)",2023-08-15T07:24:19Z
UgxdWyFVyLATPYiVijZ4AaABAg,@vtrandal,,1,OT91E6_Qm1A,0,0,2022-01-03T04:36:28Z,"Main points. 1. GPUs ==&gt; straight back propagation with much shorter training times. 2. Unsupervised learning is where advancements are needed. 3. Trends (in 2016): Deep Reinforcement Learning, Reasoning and Natural Language Understanding (Processing?), Learning from fewer examples (without lots of labeled examples).",2022-01-03T04:47:33Z
UgzDMRR7diNs1JJFYHl4AaABAg,@duykhanh7746,,1,OT91E6_Qm1A,0,1,2021-10-19T16:35:47Z,A hero of DL making videos about &quot;Heroes of DL&quot;,2021-10-19T16:35:47Z
UgwFcH5qpAxXLaLxGmR4AaABAg,@evankim4096,,1,OT91E6_Qm1A,0,0,2020-05-17T19:08:27Z,I wish Ruslan got asked more about deep reinforcement learning!,2020-05-17T19:08:27Z
UgwEWMyTmXNVyLmRJ6d4AaABAg,@FidelaBohemia,,1,OT91E6_Qm1A,0,0,2019-03-18T00:29:38Z,"If you want to discuss this topic, you can read this article ... it&#39;s very interesting  <a href=""https://www.linkedin.com/pulse/deep-learning-ai-bubble-bursting-samer-l-hijazi/"">https://www.linkedin.com/pulse/deep-learning-ai-bubble-bursting-samer-l-hijazi/</a>",2019-03-18T00:29:38Z
UgyI0wjS47zZ3bad0Zh4AaABAg,@berkakipek8991,,1,OT91E6_Qm1A,0,0,2018-07-26T19:37:50Z,So motivational video. thanks for share.,2018-07-26T19:37:50Z
UgzcV2adPnYTdT72pVN4AaABAg,@argynkuketayev4166,,1,OT91E6_Qm1A,1,2,2017-10-15T00:17:04Z,"At <a href=""https://www.youtube.com/watch?v=OT91E6_Qm1A&amp;t=1m50s"">1:50</a> which paper exactly they&#39;re talking about? Is it &quot;Reducing the Dimensionality of Data with Neural Networks&quot; in Science mag?",2017-10-15T00:17:04Z
UgzcV2adPnYTdT72pVN4AaABAg.8YiOcY6EH8i8aisfkZ7cmo,@sawanrai6424,UgzcV2adPnYTdT72pVN4AaABAg,2,OT91E6_Qm1A,0,3,2017-12-28T18:22:34Z,"<a href=""https://dl.acm.org/citation.cfm?id=1273596"">https://dl.acm.org/citation.cfm?id=1273596</a>",2017-12-28T18:22:34Z
UgwgErKFtlYbjjvtQ7R4AaABAg,@machinistnick2859,,1,dwFcodBz_2I,0,0,2021-03-30T11:19:52Z,Thanks,2021-03-30T11:19:52Z
UgzPmuRxlACepywhnB54AaABAg,@davidmudou3215,,1,dwFcodBz_2I,0,4,2019-01-14T15:04:05Z,English pronounciation is not good .,2019-01-14T15:04:05Z
Ugy3_Emd5_Bwn5JvPP54AaABAg,@Sonsequence,,1,dqwx-F7Eits,0,4,2022-06-13T00:34:18Z,But really I&#39;d love to know why and how he doesn&#39;t blink. It seems improbable that it&#39;s unrelated to the prodigious intellect.,2022-06-13T00:34:18Z
UgwGCRGJXzDK-zA-hPp4AaABAg,@williamzheng5918,,1,dqwx-F7Eits,0,16,2019-12-05T15:36:08Z,"<a href=""https://www.youtube.com/watch?v=dqwx-F7Eits&amp;t=0m18s"">0:18</a> How did you get into Deep Learning (DL)? <br><a href=""https://www.youtube.com/watch?v=dqwx-F7Eits&amp;t=2m53s"">2:53</a> How did you come up with GANs? <br><a href=""https://www.youtube.com/watch?v=dqwx-F7Eits&amp;t=4m24s"">4:24</a> A serious medical diagnosis and its impact on Ian<br><a href=""https://www.youtube.com/watch?v=dqwx-F7Eits&amp;t=5m28s"">5:28</a> the Future of GANs<br><a href=""https://www.youtube.com/watch?v=dqwx-F7Eits&amp;t=7m24s"">7:24</a> Ian&#39;s book and its different approach on introducing Math<br><a href=""https://www.youtube.com/watch?v=dqwx-F7Eits&amp;t=9m24s"">9:24</a> How AI and DL have evolved over the last 10 years?<br><a href=""https://www.youtube.com/watch?v=dqwx-F7Eits&amp;t=11m22s"">11:22</a> Advice for people new on AI<br><a href=""https://www.youtube.com/watch?v=dqwx-F7Eits&amp;t=13m20s"">13:20</a> On adversarial examples and Machine Learning Security",2019-12-05T15:36:08Z
Ugx3_BhZOljgG_E5xzJ4AaABAg,@piyushjaininventor,,1,dqwx-F7Eits,0,13,2019-08-24T19:41:57Z,he dont blink!,2019-08-24T19:41:57Z
UgwDpzPLrEevddK4bZh4AaABAg,@clapdrix72,,1,dqwx-F7Eits,0,7,2019-06-23T02:46:01Z,Why does Goodfellow look like he&#39;s blind,2019-06-23T02:46:01Z
UgykgUyxv7N3QBQ1R0d4AaABAg,@dipakagrawal5741,,1,dqwx-F7Eits,0,11,2018-10-07T12:37:01Z,nice to see u two legends of AI at one place,2018-10-07T12:37:01Z
UgzA50ag_cognQVYC7l4AaABAg,@user-ok4yh1gl3o,,1,oJFShOfCZiA,0,0,2022-03-26T03:56:02Z,üåêYoshua Bengia üåêDeeprununig Future Innovation üåüAIüåüCharlieChoi 2022 march 26,2022-03-26T03:56:02Z
UgypV6SFND9ZIwUQQ-54AaABAg,@arindamsarkar9009,,1,oJFShOfCZiA,0,2,2020-11-01T12:06:47Z,Prof.Andrew Ng has defined one of the greatest part in Computer Scince and statistics as LDA with Micheal Jordan.But how humble he is while asking question.This also teaches a lot.,2020-11-01T12:06:47Z
UgwF2L0T8iuMfqFOAgh4AaABAg,@williamzheng5918,,1,oJFShOfCZiA,0,5,2019-12-06T05:02:54Z,"<a href=""https://www.youtube.com/watch?v=oJFShOfCZiA&amp;t=0m25s"">0:25</a> How did you get into Deep Learning (DL)? <br><a href=""https://www.youtube.com/watch?v=oJFShOfCZiA&amp;t=2m22s"">2:22</a> How has neural network (NN) evolved over last several decades?<br><a href=""https://www.youtube.com/watch?v=oJFShOfCZiA&amp;t=3m09s"">3:09</a> What&#39;s the biggest mistakes you&#39;ve made?<br><a href=""https://www.youtube.com/watch?v=oJFShOfCZiA&amp;t=4m24s"">4:24</a> What&#39;s the connection between NN and the brain?<br><a href=""https://www.youtube.com/watch?v=oJFShOfCZiA&amp;t=6m28s"">6:28</a> What are your most proud inventions?<br><a href=""https://www.youtube.com/watch?v=oJFShOfCZiA&amp;t=8m55s"">8:55</a> Tell more about DL and the brain.<br><a href=""https://www.youtube.com/watch?v=oJFShOfCZiA&amp;t=11m25s"">11:25</a> Your perspective on Unsupervised Learning.<br><a href=""https://www.youtube.com/watch?v=oJFShOfCZiA&amp;t=14m44s"">14:44</a> What&#39;s in DL today that excites you?<br><a href=""https://www.youtube.com/watch?v=oJFShOfCZiA&amp;t=19m21s"">19:21</a> Your thoughts on the science (not engineering) of DL<br><a href=""https://www.youtube.com/watch?v=oJFShOfCZiA&amp;t=21m20s"">21:20</a> Advice for people new to AI/DL",2019-12-06T05:03:21Z
UgyT3R6HZ3x5KbLRS0F4AaABAg,@memoryoftime0602,,1,oJFShOfCZiA,0,1,2019-01-18T21:47:41Z,"Thanks for doing this! It‚Äôs fascinating to get to know more about the big names in this field. I was searching for their images yesterday and surprisingly found these interviews done by <a href=""http://deeplearning.ai/"">Deeplearning.ai</a>. Great Job!",2019-01-18T21:47:41Z
UgxLQChi3Q4KjclEUAp4AaABAg,@Huru_,,1,LpAiPYNnxW0,0,0,2023-08-16T16:44:38Z,Binging these. Thank you for keeping this channel all these years.,2023-08-16T16:44:38Z
UgwJAY3mST1RXFO-yHt4AaABAg,@johanverm90,,1,LpAiPYNnxW0,0,0,2019-04-22T21:34:22Z,Respect ...,2019-04-22T21:34:22Z
UgxWA9-1BBl3zJ58Jrp4AaABAg,@DominikSipowicz,,1,xxu4IqwKw0w,0,3,2022-12-13T02:40:37Z,legend,2022-12-13T02:40:37Z
UgzBps4I9RMFcumBUqR4AaABAg,@JapiSandhu,,1,xxu4IqwKw0w,0,2,2021-04-10T09:49:06Z,I am also from Toronto Canada !! WOW ITS SO INSPIRING BEING FROM TORONTO AND STUDYING AI <br><br>Knowing Geoff Hinton is the godfather of deep learning and seeing Andrej Karpathy WIN makes me believe in my self so much because I am also from Toronto. <br><br>Thank you for putting Toronto on the map as a leader of AI. <br><br>wow this is amazing thank you so much for such a in inspiring life changing discussion for real.,2021-04-10T09:49:06Z
UgwYHcb26P-JhmJrawt4AaABAg,@regularjoe5055,,1,xxu4IqwKw0w,0,0,2021-04-05T01:06:33Z,"Yea, what he said",2021-04-05T01:06:33Z
UgyDp-OMdObitxsCD1t4AaABAg,@devihomes,,1,xxu4IqwKw0w,0,2,2020-09-01T19:08:39Z,Life changer,2020-09-01T19:08:39Z
UgxngZDizgKwasByBu94AaABAg,@d.ahmedsow7798,,1,xxu4IqwKw0w,0,11,2018-11-05T18:21:12Z,My hero! Hope i will be like you :),2018-11-05T18:21:12Z
Ugxjs51xwD1AXIT2di94AaABAg,@thibautmodrzyk6215,,1,JS12eb1cTLE,0,0,2023-03-12T20:09:01Z,Thank you for this interview it was so interesting,2023-03-12T20:09:01Z
UgzUc068LRMnc6ASIjx4AaABAg,@javqui1102,,1,JS12eb1cTLE,0,0,2021-04-29T10:25:39Z,"<a href=""https://www.youtube.com/watch?v=JS12eb1cTLE&amp;t=21m20s"">21:20</a> interesting vision on corporate research",2021-04-29T10:25:58Z
Ugyd4oFnm2K3dqdD20B4AaABAg,@trexmidnite,,1,JS12eb1cTLE,0,0,2021-02-18T02:01:22Z,Im at the edge of my seat with excitement,2021-02-18T02:01:22Z
UgywJjgiluVEf6wKzRV4AaABAg,@editorijsmi7830,,1,JS12eb1cTLE,0,2,2019-04-09T02:34:39Z,"Deep learning models are widely used in different fields due to its capability to handle large and complex datasets and produce the desired results with more accuracy at a greater speed. In Deep learning models, features are selected automatically through the iterative process wherein the model learns the features by going deep into the dataset and selects the features to be modeled. In the traditional models the features of the dataset needs to be specified in advance. The Deep Learning algorithms are derived from Artificial Neural Network concepts and it is a part of broader Machine Learning Models. <br>This book intends to provide an overview of Deep Learning models, its application in the areas of image recognition &amp; classification, sentiment analysis, natural language processing, stock market prediction using R statistical software package, an open source software package. <br>The book also includes an introduction to python software package which is also open source software for the benefit of the users.<br>Editor<br>International Journal of Statistics and Medical Informatics<br><a href=""http://www.ijsmi.com/book.php"">www.ijsmi.com/book.php</a>",2019-04-09T02:34:39Z
UgxIxkoGKKdsiTg3-IJ4AaABAg,@Meowmix8088,,1,JS12eb1cTLE,0,0,2018-09-05T07:14:49Z,So awesome.,2018-09-05T07:14:49Z
UgwFfy40AafJEu7DQ5l4AaABAg,@ahmet9446,,1,JS12eb1cTLE,2,0,2018-06-07T21:24:26Z,Why Andrew is thanking for Lecunn being a leader of Deep Learning?,2018-06-07T21:24:26Z
UgwFfy40AafJEu7DQ5l4AaABAg.8hClTdmD8o_8t0-vjVUhLC,@bharindrakamanditya4302,UgwFfy40AafJEu7DQ5l4AaABAg,2,JS12eb1cTLE,0,2,2019-03-28T04:46:04Z,Yann Lecunn made LeNet. The first CNN. You can find more answers by googling it.,2019-03-28T04:46:04Z
UgwFfy40AafJEu7DQ5l4AaABAg.8hClTdmD8o_9JXeZqOmG9y,@uocommonsense,UgwFfy40AafJEu7DQ5l4AaABAg,2,JS12eb1cTLE,0,3,2021-02-09T08:32:32Z,"Because Andrew is not an idiot... If you don&#39;t understand why he is thanking Lecun, don&#39;t worry about it.",2021-02-09T08:32:32Z
UgyGYeZNMNRwMP__-v94AaABAg,@prashantsingh1096,,1,JS12eb1cTLE,0,0,2018-04-29T14:57:00Z,"Oh my people! Yann work in those days when internet was a rare <a href=""http://thing.it/"">thing.It</a> must be hard to develop a concept. Great.",2018-04-29T14:57:00Z
UgwhlgVlqR6ChWwmv_14AaABAg,@MrSushant3,,1,JS12eb1cTLE,0,7,2018-04-08T13:13:26Z,"I wanted to know what Yann thinks about the recent <b>Facebook&#39;s Cambridge Analytica</b> Scandal ? How does he feel when technologies developed by smart people like him is used to display ads, collect data illegally and all in all destroy the social fabric of mankind ?",2018-04-08T13:13:26Z
UgyX5vVa-vKHDU1y2GF4AaABAg,@malanjing3658,,1,JS12eb1cTLE,0,1,2018-04-06T16:46:41Z,Good video.,2018-04-06T16:46:41Z
UgyeBGosNbXmEfxt_qd4AaABAg,@eason_longleilei,,1,JS12eb1cTLE,0,5,2018-04-06T12:28:01Z,Â§™ÂèäÊó∂‰∫ÜÔºåÂ§™Áî®ÂøÉ‰∫Ü„ÄÇDeepLearning.AIÁúüÁöÑÂæàÁî®ÂøÉÊù•ÂÅöËøô‰∫õ„ÄÇ,2018-04-06T12:28:01Z
UgyjycT3TfEeGuTIB9x4AaABAg,@BenDavisUSC08,,1,JS12eb1cTLE,0,2,2018-04-05T13:28:58Z,finally :),2018-04-05T13:28:58Z
Ugz9HJV3PW8hr_TGlER4AaABAg,@ersanoztavli5090,,1,JS12eb1cTLE,0,2,2018-04-05T06:58:42Z,That was fantastic üëç,2018-04-05T06:58:42Z
Ugxjbrs2Wr8tOYlc2414AaABAg,@chrischappell7643,,1,JS12eb1cTLE,0,2,2018-04-05T05:06:44Z,plz more :*,2018-04-05T05:06:44Z
UgybF94rkUd2vJiNU514AaABAg,@oryxchannel,,1,eMh5YqKopjE,0,0,2023-10-05T00:25:25Z,"The way I use quantum is the ability for one element (data contained &quot;on&quot; an atomic particle) to exist apart and separate from the identical element but effectually no where near where its original &quot;twin&quot; emanates from.<br>The identical pair if explored correctly smacks of ancient feats...of metaphysics...of controversy.<br>(The belief of &quot;bilocation&quot;.... using the apex of temples (monoliths) concentrated technology to be in two places at once.)<br>Coming back down to earth, advanced modeling of the fundamental model of quantum mechanics (parallelism) resembles the two hemispheres of the brain.<br>They also have the ability to exist (co-exist) in two places at once.<br>If we get this right...and with quantum computers forte of modeling almost anything then we will succeed at at least modeling the human brain better than A.I. by itself.<br>The two are bride and groom and the dutiful groom is standing by waiting for his blushing bride.<br>Edit: Certain shapes have symmetries to them. Some shapes have such sophisticated symmetries to them that you can use the shape itself as context to form topological representations. Consider the movie Inner Worlds Outer Worlds for some &quot;shapes&quot;.",2023-10-05T00:37:13Z
UgyxEmEtTzxDbLkMVqd4AaABAg,@postnetwork,,1,eMh5YqKopjE,0,0,2023-08-02T15:42:26Z,Inspiring interview.,2023-08-02T15:42:26Z
Ugwk0eQmURbxR9G23eN4AaABAg,@frostman7593,,1,eMh5YqKopjE,0,0,2023-03-08T21:23:03Z,"Its good to see her thriving in her field of expertise, but i would like to point out that intelligence has no gender. Those who have been enghlightened in human history have said so. If we think in polarities we can never really be united as beongs of this existence.",2023-03-08T21:23:03Z
Ugybumlj3hmk50LqYbl4AaABAg,@FezanRafique,,1,eMh5YqKopjE,0,0,2021-12-22T08:03:02Z,Thank you Andrew for arranging such wonderful talks by heros.,2021-12-22T08:03:02Z
UgxjEda-9fvnaQOBqlJ4AaABAg,@trangle-kc2kk,,1,eMh5YqKopjE,0,11,2019-05-27T03:55:45Z,This woman is so inspiring,2019-05-27T03:55:45Z
UgyGc2l3tN8ei4bwTHp4AaABAg,@aidenstill7179,,1,eMh5YqKopjE,1,0,2019-05-10T19:43:45Z,what do i need to know to create my own python deep learning framework? tell me the books and courses to get knowledge for this.,2019-05-10T19:43:45Z
UgyGc2l3tN8ei4bwTHp4AaABAg.8ulKq554P6T8zRyoFT_1y8,@arjunsubedi745,UgyGc2l3tN8ei4bwTHp4AaABAg,2,eMh5YqKopjE,0,0,2019-09-04T04:34:41Z,"Aiden Still look into <a href=""http://deeplearning.ai/"">deeplearning.ai</a> course of Andrew Ng. He teaches from scratch. Best of luck",2019-09-04T04:34:41Z
Ugw9D1EuJ2zWRK3KH4B4AaABAg,@shrikantsawarkar3929,,1,eMh5YqKopjE,1,0,2018-11-22T17:28:43Z,Does we need to know breff info. Of  calculus in machine learning formula &#39;s ( gradient decent  ) like how does the calculus working behind it or we can just implement that formula without knowing the deep calculous and continue learning ahead,2018-11-22T17:28:43Z
Ugw9D1EuJ2zWRK3KH4B4AaABAg.8nxw2DNq0v-8trevFSSxYd,@VishalSingh-dl8oy,Ugw9D1EuJ2zWRK3KH4B4AaABAg,2,eMh5YqKopjE,0,0,2019-04-18T10:12:00Z,"you need to understand the basics of gradients and rest would work out. <a href=""https://www.youtube.com/watch?v=vsWrXfO3wWw"">https://www.youtube.com/watch?v=vsWrXfO3wWw</a>",2019-04-18T10:12:00Z
Ugxs2Gdx_DXbOTLzNiR4AaABAg,@hannahhumphreys3002,,1,eMh5YqKopjE,0,1,2018-10-05T21:12:12Z,"Advanced AI: Deep Reinforcement Learning in Python<br><br>&gt; Build various deep learning agents<br>&gt; Q-Learning with Deep Neural Networks<br>&gt; Policy Gradient Methods with Neural Networks<br>&gt; Reinforcement Learning with RBF Networks<br><br><a href=""http://bit.ly/2DV171o"">http://bit.ly/2DV171o</a>",2018-10-05T21:12:12Z
Ugw8BZBbFuW7mf9ZGHt4AaABAg,@machinistnick2859,,1,y7RfAwltHTw,0,0,2021-03-30T11:51:39Z,Thanks,2021-03-30T11:51:39Z
UgywzfQdRNlZFj2y_Q94AaABAg,@rajivsen3123,,1,y7RfAwltHTw,0,2,2020-02-04T01:18:56Z,Gods of the emergent field together. ü§©,2020-02-04T01:18:56Z
UgxHIEthiUFcby6Bhdd4AaABAg,@onamixt,,1,-eyhCTvrEtE,0,0,2023-11-01T08:38:05Z,"I watched the video as a part of Deep Learning Specialization. Sadly, it&#39;s way way over my head to comprehend much of what was said in the video.",2023-11-01T08:38:05Z
UgxCdcGX3J908oDyUVd4AaABAg,@jsfnnyc,,1,-eyhCTvrEtE,0,0,2023-10-07T16:34:44Z,"Best research advice ever!! &quot;Read the literature, but not too much of it.&quot;",2023-10-07T16:34:44Z
UgziW3I2mVitt3J_DBB4AaABAg,@surkewrasoul4711,,1,-eyhCTvrEtE,0,0,2023-09-05T17:51:34Z,"Hey And , Do you still accept donations<br> by any chance, I am hoping for 720p videos from now on.",2023-09-05T17:51:34Z
Ugwq9_HZuA8XEsiTeGt4AaABAg,@briancase9527,,1,-eyhCTvrEtE,0,0,2023-07-25T00:22:23Z,"I so agree with Hinton: have an idea and go for it. I took this approach with something other than AI, but it also worked. What do I mean? I mean, even though my idea wasn&#39;t revolutionary and totally worthwhile, I LEARNED A LOT by just going for it and programming the heck out of it. The practical experience I gained served me well--very well--in my first jobs. Remember: your purpose is to learn, and you can do that following your intuition--which is fun--or following someone else&#39;s--which is less fun.",2023-07-25T00:22:23Z
UgyAJIjaNJK3UzEl7cN4AaABAg,@PaulHigginbothamSr,,1,-eyhCTvrEtE,0,0,2023-07-20T14:34:28Z,I think the difference between wake and sleep is during sleep it is in the testing phase and during wake it is the operative phase of learning.,2023-07-20T14:34:28Z
Ugy77B1U3-Yi5c9d0JR4AaABAg,@wk4240,,1,-eyhCTvrEtE,0,0,2023-07-05T18:21:20Z,Seriously doubt Geoffrey Hinton considers himself a hero - more like Dr. Frankenstein now.  He&#39;s doing his part to spread the word on the dangers of reliance on AI.,2023-07-05T18:21:20Z
Ugyyv4MUmIAjrcBih194AaABAg,@Gabcikovo,,1,-eyhCTvrEtE,1,1,2023-04-16T11:28:17Z,"<a href=""https://www.youtube.com/watch?v=-eyhCTvrEtE&amp;t=38m10s"">38:10</a> a thought is just a great big vector of neural activity",2023-04-16T11:28:17Z
Ugyyv4MUmIAjrcBih194AaABAg.9oZbRZ-V2Xp9oZcS0wSxPk,@Gabcikovo,Ugyyv4MUmIAjrcBih194AaABAg,2,-eyhCTvrEtE,0,1,2023-04-16T11:37:05Z,"<a href=""https://www.youtube.com/watch?v=-eyhCTvrEtE&amp;t=38m19s"">38:19</a> people who thought that thoughts were symbolic expressions made a huge mistake.. what comes in is a string of words, and what comes out is a string of words, and because of that, strings of words are the obvious way to represent things, so they thought what must be in between was a string of words or something alike.. Hinton thinks there&#39;s nothing like a string of words in between, he thinks thinking of it as of some kind of language is as silly as the idea that understanding the layout of a spacial scene must be in pixels :))",2023-04-16T11:37:05Z
Ugw_160BMUhA6P8INyp4AaABAg,@Gabcikovo,,1,-eyhCTvrEtE,1,1,2023-04-16T11:23:49Z,"<a href=""https://www.youtube.com/watch?v=-eyhCTvrEtE&amp;t=35m08s"">35:08</a> our relationship to computers has changed..  instead of programming them, we show them, and they figure it out",2023-04-16T11:23:49Z
Ugw_160BMUhA6P8INyp4AaABAg.9oZavqH6TSq9oZb3wuHAp0,@Gabcikovo,Ugw_160BMUhA6P8INyp4AaABAg,2,-eyhCTvrEtE,0,1,2023-04-16T11:25:03Z,"<a href=""https://www.youtube.com/watch?v=-eyhCTvrEtE&amp;t=36m04s"">36:04</a> :D",2023-04-16T11:25:03Z
UgxjxKuptB6GawFKHf94AaABAg,@Gabcikovo,,1,-eyhCTvrEtE,0,0,2023-04-16T11:05:07Z,"<a href=""https://www.youtube.com/watch?v=-eyhCTvrEtE&amp;t=18m00s"">18:00</a> 2007 ignored Hinton and Bengio picked it up layer on",2023-04-16T11:05:07Z
UgxeMrAqfe9_-pSgSLN4AaABAg,@Gabcikovo,,1,-eyhCTvrEtE,1,0,2023-04-16T10:51:58Z,"<a href=""https://www.youtube.com/watch?v=-eyhCTvrEtE&amp;t=0m19s"">0:19</a> Godfather üòé",2023-04-16T10:51:58Z
UgxeMrAqfe9_-pSgSLN4AaABAg.9oZYHUQahu69oZ_ctTDTiy,@Gabcikovo,UgxeMrAqfe9_-pSgSLN4AaABAg,2,-eyhCTvrEtE,0,1,2023-04-16T11:12:29Z,"<a href=""https://www.youtube.com/watch?v=-eyhCTvrEtE&amp;t=25m33s"">25:33</a>",2023-04-16T11:12:29Z
UgzW5iL8RI3lZD1bLu94AaABAg,@MilanAndric,,1,-eyhCTvrEtE,0,0,2022-09-01T03:59:15Z,"Fav quote, little after minute 30... &quot;Either your intuition is good or its not. If its good you should follow them and eventually you will be successful. If they are no good it doesn&#39;t matter what you do. There&#39;s no point in not trusting your intuitions.&quot;",2022-09-01T03:59:45Z
UgwEuRH02oT1QjLym9l4AaABAg,@mahdiamrollahi8456,,1,-eyhCTvrEtE,0,0,2022-07-14T17:07:22Z,Great,2022-07-14T17:07:22Z
UgzibuOYUSch9M-5OeZ4AaABAg,@thesuryapolisetty,,1,-eyhCTvrEtE,1,18,2021-11-18T19:42:03Z,"<a href=""https://www.youtube.com/watch?v=-eyhCTvrEtE&amp;t=00m30s"">00:30</a> How Hinton‚Äôs fascination with the brain led him to explore AI<br><a href=""https://www.youtube.com/watch?v=-eyhCTvrEtE&amp;t=3m33s"">3:33</a> The story behind his seminal 1986 paper on backpropagation that he wrote with David Rumelhart<br><a href=""https://www.youtube.com/watch?v=-eyhCTvrEtE&amp;t=8m16s"">8:16</a> The invention Hinton is still most excited about<br><a href=""https://www.youtube.com/watch?v=-eyhCTvrEtE&amp;t=12m55s"">12:55</a> Hinton‚Äôs work on ReLU activations<br><a href=""https://www.youtube.com/watch?v=-eyhCTvrEtE&amp;t=25m35s"">25:35</a> How Hinton‚Äôs understanding of AI has changed over the decades<br><a href=""https://www.youtube.com/watch?v=-eyhCTvrEtE&amp;t=15m27s"">15:27</a> Hinton‚Äôs thoughts on the relationship between the brain and backpropagation<br><a href=""https://www.youtube.com/watch?v=-eyhCTvrEtE&amp;t=19m09s"">19:09</a> Hinton‚Äôs work on dealing with multiple time scales<br><a href=""https://www.youtube.com/watch?v=-eyhCTvrEtE&amp;t=20m43s"">20:43</a> Hinton‚Äôs ongoing research on capsules<br><a href=""https://www.youtube.com/watch?v=-eyhCTvrEtE&amp;t=29m40s"">29:40</a> Hinton‚Äôs advice for someone who wants to break into AI<br><a href=""https://www.youtube.com/watch?v=-eyhCTvrEtE&amp;t=37m15s"">37:15</a> Hinton‚Äôs thoughts on the paradigm shift in AI",2021-11-18T19:42:03Z
UgzibuOYUSch9M-5OeZ4AaABAg.9UtzMJNwGRm9gkUZ6KXIHp,@srikararepalli,UgzibuOYUSch9M-5OeZ4AaABAg,2,-eyhCTvrEtE,0,0,2022-10-04T05:59:08Z,Thank you!,2022-10-04T05:59:08Z
Ugyvtg8RB3VdMx9INcR4AaABAg,@thegamechanger7157,,1,-eyhCTvrEtE,0,0,2021-11-13T14:33:35Z,"Yes, I learned from his tutorial in Coursera in data science and technology",2021-11-13T14:33:35Z
Ugyxxpw19eG3mMp4Vit4AaABAg,@sujoyparikh5362,,1,-eyhCTvrEtE,0,0,2021-10-28T18:13:40Z,"Absolutely love this, but Andrew, please stop saying &quot;I see&quot; constantly",2021-10-28T18:13:40Z
UgwBeAqXTWD7REQyCq14AaABAg,@MattRiddell,,1,-eyhCTvrEtE,0,0,2021-08-19T23:30:37Z,Wow - the capsule concept is pretty close to the thousand brains idea!,2021-08-19T23:30:37Z
Ugxj-yrNe6cfdVdFF194AaABAg,@Level6,,1,-eyhCTvrEtE,0,1,2020-12-06T08:27:26Z,"ÌûåÌäºÏùò Ï°∞Ïñ∏ : <br># 1-Î¨∏ÌóåÏùÑ ÏùΩÎêò ÎÑàÎ¨¥ ÎßéÏù¥ ÏùΩÏßÄ ÎßàÏã≠ÏãúÏò§. <br># 2-Ï∞ΩÏùòÏ†ÅÏù∏ Ïó∞Íµ¨ÏûêÎì§ÏóêÍ≤å,  ÏÇ¨ÎûåÎì§Ïù¥ Ï¢ãÏßÄ ÏïäÎã§Í≥† ÎßêÌï† Îïå .. Í∑∏ÎÉ• Í≥ÑÏÜçÌïòÏã≠ÏãúÏò§. Í∑∏Î¶¨Í≥† Ï†ÄÎäî ÏÇ¨ÎûåÎì§Ïù¥ Í∑∏Í≤ÉÏùÑ ÏßÄÌÇ§ÎèÑÎ°ù ÎèïÎäî ÏïÑÏ£º Ï¢ãÏùÄ ÏõêÏπôÏùÑ Í∞ÄÏßÄÍ≥† ÏûàÏäµÎãàÎã§. Ï¶â, ÏßÅÍ¥ÄÏù¥ Ï¢ãÍ±∞ÎÇò Í∑∏Î†áÏßÄ ÏïäÏäµÎãàÎã§. ÎãπÏã†Ïùò ÏßÅÍ¥ÄÏù¥ Ï¢ãÎã§Î©¥ ÎãπÏã†ÏùÄ Í∑∏Í≤ÉÏùÑ Îî∞ÎùºÏïº ÌïòÎ©∞ Í≤∞Íµ≠ ÏÑ±Í≥µÌï† Í≤ÉÏûÖÎãàÎã§. ÎãπÏã†Ïùò ÏßÅÍ∞êÏù¥ Ï¢ãÏßÄ ÏïäÎã§Î©¥ ÎãπÏã†Ïù¥ Î¨¥ÏóáÏùÑ ÌïòÎì† ÏÉÅÍ¥Ä ÏóÜÏäµÎãàÎã§. <br># 3-ÌîÑÎ°úÍ∑∏ÎûòÎ∞çÏùÑ Î©àÏ∂îÏßÄ ÎßàÏã≠ÏãúÏò§!<br># 4-ÏßÅÍ¥ÄÏùÑ ÏåìÍ∏∞ ÏãúÏûëÌï† ÎßåÌÅº Ï∂©Î∂ÑÌûà ÎèÑÎã¨ Ìïú Îã§Ïùå, ÏßÅÍ∞êÏùÑ ÎØøÍ≥† Ïã§ÌñâÌï¥Ïïº ÌïúÎã§Í≥† ÏÉùÍ∞ÅÌï©ÎãàÎã§. Í∑∏Î¶¨Í≥† Îã§Î•∏ ÏÇ¨ÎûåÎì§Ïù¥ ÎßêÎèÑ ÏïàÎêúÎã§Í≥† Ìï¥ÎèÑ ÎÑàÎ¨¥ Í±±Ï†ïÌïòÏßÄ ÎßàÏÑ∏Ïöî. <br># 5-ÎãπÏã†Ïù¥ Í∑∏Í≤ÉÏù¥ Ï†ïÎßê Ï¢ãÏùÄ ÏïÑÏù¥ÎîîÏñ¥ÎùºÍ≥† ÏÉùÍ∞ÅÌïòÍ≥† Îã§Î•∏ ÏÇ¨ÎûåÎì§Ïù¥ Í∑∏Í≤ÉÏù¥ ÏôÑÏ†ÑÌûà ÎÑåÏÑºÏä§ÎùºÍ≥† ÎßêÌïúÎã§Î©¥, ÎãπÏã†ÏùÄ ÎãπÏã†Ïù¥ Ï†ïÎßêÎ°ú Î¨¥Ïñ∏Í∞ÄÎ•º ÌïòÍ≥† ÏûàÎã§Îäî Í≤ÉÏùÑ ÏïïÎãàÎã§. <br># 6-ÏÉàÎ°úÏö¥ ÎåÄÌïôÏõêÏÉùÏùÑ ÏúÑÌïú Ï¢ãÏùÄ Ï°∞Ïñ∏ Ìïú Í∞ÄÏßÄ, ÎãπÏã†Í≥º ÎπÑÏä∑Ìïú Ïã†ÎÖêÏùÑ Í∞ÄÏßÑ Ï°∞Ïñ∏ÏûêÎ•º Ï∞æÏùÑ Ïàò ÏûàÎäîÏßÄ ÌôïÏù∏ÌïòÏÑ∏Ïöî. ÎãπÏã†Ïù¥ Ï°∞Ïñ∏ÏûêÍ∞Ä ÎãπÏã†Ïóê ÎåÄÌï¥ ÍπäÏù¥ ÎäêÎÅºÎäî ÏùºÏùÑ ÌïòÎ©¥ Ï¢ãÏùÄ Ï°∞Ïñ∏Í≥º ÏãúÍ∞ÑÏùÑ ÎßéÏù¥ ÏñªÏùÑ Ïàò ÏûàÍ∏∞ ÎïåÎ¨∏ÏûÖÎãàÎã§.",2020-12-06T08:27:26Z
UgxXcMxUi1RrRN6aoQd4AaABAg,@asutoshmittapalli,,1,-eyhCTvrEtE,0,1,2020-10-07T10:35:30Z,All rise for the Godfather,2020-10-07T10:35:30Z
UgzSBixSy6q4oMswjIF4AaABAg,@haoshidi,,1,-eyhCTvrEtE,0,0,2020-08-04T05:32:59Z,Concretely,2020-08-04T05:32:59Z
Ugzg0z6oPnPBiPB4Pqt4AaABAg,@evankim4096,,1,-eyhCTvrEtE,0,0,2020-06-04T15:24:44Z,"WOW I can&#39;t believe Hinton et al came up with an algorithm for STDP decades before neuroscientists came up with the concept....He is talking about this algorithm that came in the late 1980s, while STDP arrived on the scene in the early-mid 2000s",2020-06-04T15:24:44Z
UgyyvcL4DAYJEKpP25h4AaABAg,@azr_sd,,1,-eyhCTvrEtE,0,7,2020-05-02T23:13:44Z,Andrew looking at Hinton Like how we all see Andrew when learning from him.. Huge respect for everyone who contributed to AI. :),2020-05-02T23:13:44Z
UgzUk66DJzHUR5Xh9el4AaABAg,@mehedihasanbijoy6609,,1,-eyhCTvrEtE,0,0,2020-01-23T18:06:00Z,listening to Geoff is something really fancy and super exciting.,2020-01-23T18:06:00Z
UgzxkPKzqdTDRxSE32Z4AaABAg,@Global_Pivot,,1,-eyhCTvrEtE,0,2,2019-12-15T15:00:33Z,"&quot;When you have something you think is a good idea and other people think it&#39;s a complete nonsense, then you know you are onto something&quot;",2019-12-15T15:00:33Z
Ugy3PAz0cxVmYhi7HAZ4AaABAg,@alexandeap,,1,-eyhCTvrEtE,0,1,2019-09-21T22:39:01Z,"Dear Andrew, first of all I wanted to thank you and the entire coursera team for the great academic contribution they give us. Secondly, I wanted to ask you to put the subtitles where possible so that we can enjoy 100% Spanish and South American speaking. finally ask you to include the course of neural networks of Jeoffrey Hinton since when you search through the search engine of coursera it does not find it. I will thank you for correcting this error because when I tried to search for the courses offered by the University of Toronto, I did not have a positive success either. Thanks again to you and the coursera team for the great innovative academic contribution and scientific and technological research.",2019-09-21T22:39:01Z
UgzdA1s0pDBT9Rc7Zt14AaABAg,@johningham1880,,1,-eyhCTvrEtE,0,1,2019-08-16T07:43:37Z,I wish my neurones could remember what they were doing when they pop out of a recursive call...,2019-08-16T07:43:37Z
UgywPPQU8RxJPCtShrV4AaABAg,@morebaie3412,,1,-eyhCTvrEtE,0,1,2019-07-18T14:20:03Z,"This interview is highly insightful and helpful for deep learners, recommended watching!",2019-07-18T14:20:03Z
UgzAsUW3uUtSnYdlTXh4AaABAg,@billykotsos4642,,1,-eyhCTvrEtE,0,0,2019-06-23T12:32:32Z,Andrew &quot;I see&quot; Ng,2019-06-23T12:32:32Z
UgzeeeM56-H84Em7M3d4AaABAg,@jindagi_ka_safar,,1,-eyhCTvrEtE,0,0,2019-04-23T15:05:49Z,Thanks for introducing us to the heroes of DL like Geoffrey,2019-04-23T15:05:49Z
UgyevV_PebhgPTqH1ql4AaABAg,@VineetBhatawadekar,,1,-eyhCTvrEtE,0,0,2019-04-07T06:39:38Z,Legend.,2019-04-07T06:39:38Z
UgzeAw-iMJPuiPtKCU94AaABAg,@mdougf,,1,-eyhCTvrEtE,0,3,2019-01-11T21:27:56Z,"Thanks for this interview, Andrew! Hey, fellow learners, if anyone is interested in joining my weekly Machine Learning Research Paper reading and discussion group, let me know!",2019-01-11T21:27:56Z
Ugxhza3f-8IqxYcvU8J4AaABAg,@sivaprasadml6582,,1,-eyhCTvrEtE,1,0,2019-01-11T14:51:19Z,"@ <a href=""https://www.youtube.com/watch?v=-eyhCTvrEtE&amp;t=8m34s"">8:34</a> what was Geoffrey mentioning ? Which algorithm ?",2019-01-11T14:51:19Z
Ugxhza3f-8IqxYcvU8J4AaABAg.8pyOm3ttoQK8wZngEqQuxp,@tommygunhunter,Ugxhza3f-8IqxYcvU8J4AaABAg,2,-eyhCTvrEtE,0,0,2019-06-24T15:57:12Z,boltzmann machines,2019-06-24T15:57:12Z
Ugz46J0LLXcs1gmgyfR4AaABAg,@aliasad8342,,1,-eyhCTvrEtE,4,148,2018-12-11T14:00:03Z,"Hinton&#39;s Advice: <br><br>#1 - Read the literature but don&#39;t read too much of it.<br><br>#2 -  For creative researchers, I think what you want to do is to read a little bit of the literature and notice something that you think everybody is doing wrong and contrarian in that sense, you look at it and it just doesn&#39;t feel right and then figure out how to do it right, and when people tell you that&#39;s no good....just keep at it. And I have a very good principle for helping people keep at it. Which is, either your intuitions are good or they&#39;re not. If your intuitions are good, you should follow them and you will eventually be successful. If your intuitions are not good, it doesn&#39;t matter what you do.<br><br>#3 - Never stop programming!<br><br>#4 - I think one should reach enough to start building intuitions and then trust your intuitions and go for it. And, don&#39;t be too worried if everybody else says is nonsense.<br><br>#5 -  If you think its a really good idea and other people tell you it&#39;s complete nonsense, then you know you&#39;re really on to something. <br><br>#6 - one good piece of advice for new grad students, see if you can find an adviser who has beliefs similar to yours because if you work on stuff that your adviser feels deeply about you&#39;ll get a lot of good advice and time from your adviser.",2018-12-11T14:00:03Z
Ugz46J0LLXcs1gmgyfR4AaABAg.8oiUGV0do5m94c-E7ul4Gn,@prathyusha5393,Ugz46J0LLXcs1gmgyfR4AaABAg,2,-eyhCTvrEtE,0,3,2020-02-04T14:27:06Z,The 2nd one!,2020-02-04T14:27:06Z
Ugz46J0LLXcs1gmgyfR4AaABAg.8oiUGV0do5m9oZ_r7MSphY,@Gabcikovo,Ugz46J0LLXcs1gmgyfR4AaABAg,2,-eyhCTvrEtE,0,1,2023-04-16T11:14:26Z,"#2 üëè <a href=""http://www.youtube.com/results?search_query=%23tom%C3%A1%C5%A1mikolov"">#Tom√°≈°Mikolov</a>",2023-04-16T11:14:26Z
Ugz46J0LLXcs1gmgyfR4AaABAg.8oiUGV0do5m9oZaC75WHeY,@Gabcikovo,Ugz46J0LLXcs1gmgyfR4AaABAg,2,-eyhCTvrEtE,0,2,2023-04-16T11:17:26Z,"<a href=""https://www.youtube.com/watch?v=-eyhCTvrEtE&amp;t=29m59s"">29:59</a> this is where Hinton actually says that",2023-04-16T11:17:26Z
Ugz46J0LLXcs1gmgyfR4AaABAg.8oiUGV0do5m9rnL__SOuI2,@wk4240,Ugz46J0LLXcs1gmgyfR4AaABAg,2,-eyhCTvrEtE,0,0,2023-07-05T18:23:45Z,Good principals to follow. Regardless of  what you are doing.,2023-07-05T18:23:45Z
Ugw94092NwThhcGlRmB4AaABAg,@dileepjayamal9968,,1,-eyhCTvrEtE,0,1,2018-12-02T16:38:36Z,"Still there are 17 dislikes, don&#39;t know why.. may be outliers...",2018-12-02T16:38:36Z
Ugw6GQ_ExlmMK3j0uPp4AaABAg,@brishtiteveja,,1,-eyhCTvrEtE,0,1,2018-10-15T15:35:08Z,I love Andrew so much. :),2018-10-15T15:35:08Z
Ugx5FJndEFi9irXTbvF4AaABAg,@Joe-yr1em,,1,-eyhCTvrEtE,0,0,2018-10-03T10:39:27Z,Thank you for this wonderful interview.,2018-10-03T10:39:27Z
Ugxum0qDPuBfA8Cdt8N4AaABAg,@georgemaratos1122,,1,-eyhCTvrEtE,0,0,2018-09-01T17:30:19Z,thank you so much for doing this interview,2018-09-01T17:30:19Z
UgxUxiKNmIY8kB7cvrZ4AaABAg,@KulvinderSingh-pm7cr,,1,-eyhCTvrEtE,0,0,2018-07-17T19:45:02Z,Enlightened !!,2018-07-17T19:45:02Z
Ugx1Z19ecasgxCzkVKh4AaABAg,@ehfo,,1,-eyhCTvrEtE,0,1,2018-06-15T13:14:19Z,I wish someone post the link to all the paper mentioned in the interview,2018-06-15T13:14:19Z
UgwAXygA9RwuJ6R965t4AaABAg,@wajdanali1354,,1,-eyhCTvrEtE,0,0,2018-06-09T21:30:23Z,"honoured to listen to this discussion , subhanallah",2018-06-09T21:30:23Z
UgzmmtSjj85dXrVVfqp4AaABAg,@salvatortermination4681,,1,-eyhCTvrEtE,0,0,2018-05-13T07:23:13Z,"alien language to me right now, still it&#39;s great haha",2018-05-13T07:23:13Z
UgznkO_cz2bIN-n41aN4AaABAg,@yuwuxiong1165,,1,-eyhCTvrEtE,0,0,2018-05-12T10:59:06Z,Excellent interview...and very good advises from Hinton!,2018-05-12T10:59:06Z
UgynVIKHP_Bzz_IUPrF4AaABAg,@machinistnick2859,,1,6joSL0CUNtA,0,0,2021-03-30T11:52:53Z,Thanks,2021-03-30T11:52:53Z
UgytS6bugltqirNAXeN4AaABAg,@howrobotics2052,,1,6joSL0CUNtA,0,0,2020-02-24T20:52:06Z,very amazing!,2020-02-24T20:52:06Z
UgwaYY9k4DmrpATyT4V4AaABAg,@hrishikeshmukherjee8988,,1,dFX8k1kXhOw,0,0,2022-01-06T18:39:59Z,Wo,2022-01-06T18:39:59Z
Ugw0TngX8RWTcs66xbR4AaABAg,@sandipansarkar9211,,1,dFX8k1kXhOw,1,0,2021-01-11T14:05:03Z,nice explanation,2021-01-11T14:05:03Z
Ugw0TngX8RWTcs66xbR4AaABAg.9IN_ZpjauCO9uBVd98dbhQ,@ermano5586,Ugw0TngX8RWTcs66xbR4AaABAg,2,dFX8k1kXhOw,0,0,2023-09-03T05:55:25Z,I am making notes,2023-09-03T05:55:25Z
Ugyuww7EST3uRSo_wp54AaABAg,@sunilkumarsamji8507,,1,dFX8k1kXhOw,3,0,2019-10-03T01:49:29Z,Does this course has programing assignments ?,2019-10-03T01:49:29Z
Ugyuww7EST3uRSo_wp54AaABAg.9-bLxgPjif995i2rk7iliD,@534A53,Ugyuww7EST3uRSo_wp54AaABAg,2,dFX8k1kXhOw,0,0,2020-03-02T19:25:42Z,Yes,2020-03-02T19:25:42Z
Ugyuww7EST3uRSo_wp54AaABAg.9-bLxgPjif99JMqUtTplVY,@abdulrahmanelsayed5464,Ugyuww7EST3uRSo_wp54AaABAg,2,dFX8k1kXhOw,0,0,2021-02-05T03:45:04Z,No,2021-02-05T03:45:04Z
Ugyuww7EST3uRSo_wp54AaABAg.9-bLxgPjif99PrDso_Z679,@marcintabaka1188,Ugyuww7EST3uRSo_wp54AaABAg,2,dFX8k1kXhOw,0,0,2021-07-16T11:23:00Z,No. Only quizzes.,2021-07-16T11:23:00Z
Ugxakr-HqsTd2gTh48F4AaABAg,@pankajsaini3673,,1,dFX8k1kXhOw,0,5,2019-09-06T07:54:51Z,"Wow , my brain on fire now after finding this source !",2019-09-06T07:54:51Z
Ugyskjx6bcemphr4bjl4AaABAg,@user-cn2ft7ir1g,,1,dFX8k1kXhOw,5,4,2017-12-26T07:44:37Z,Any reason why course 3 maximum resolution was only 360p instead of 720?,2017-12-26T07:44:37Z
Ugyskjx6bcemphr4bjl4AaABAg.8aca4XKpr3Y8lMBX_-NmFz,@CG-vf5sw,Ugyskjx6bcemphr4bjl4AaABAg,2,dFX8k1kXhOw,0,4,2018-09-18T23:19:38Z,Non-optimal reconstruction loss...,2018-09-18T23:19:38Z
Ugyskjx6bcemphr4bjl4AaABAg.8aca4XKpr3Y8rY7IhQH336,@JadtheProdigy,Ugyskjx6bcemphr4bjl4AaABAg,2,dFX8k1kXhOw,0,1,2019-02-19T17:41:54Z,@@CG-vf5sw LOOOL,2019-02-19T17:41:54Z
Ugyskjx6bcemphr4bjl4AaABAg.8aca4XKpr3Y8xW3XNmAt-D,@tuanbui-yg2po,Ugyskjx6bcemphr4bjl4AaABAg,2,dFX8k1kXhOw,0,0,2019-07-18T01:38:50Z,i have no clue about it =)),2019-07-18T01:38:50Z
Ugyskjx6bcemphr4bjl4AaABAg.8aca4XKpr3Y953ZjaIMCuK,@syedaqib2912,Ugyskjx6bcemphr4bjl4AaABAg,2,dFX8k1kXhOw,0,3,2020-02-15T16:44:50Z,Because he wants to save your data,2020-02-15T16:44:50Z
Ugyskjx6bcemphr4bjl4AaABAg.8aca4XKpr3Y9PQJMI6XeL6,@tuvu8394,Ugyskjx6bcemphr4bjl4AaABAg,2,dFX8k1kXhOw,0,0,2021-07-05T15:12:07Z,"To be fair most of his lectures contain text only, so low resolution shouldn&#39;t really be an issue.",2021-07-05T15:12:07Z
Ugyz_Xw3hcFbp_HFAqJ4AaABAg,@ivanstepanov1497,,1,UEtvV1D6B3s,0,0,2023-12-13T01:45:26Z,Disagree,2023-12-13T01:45:26Z
Ugw5QLXeRKe5FNUf6sV4AaABAg,@matthiashertel2820,,1,UEtvV1D6B3s,0,1,2020-06-28T09:40:43Z,"Thank you for sharing your knowledge with us in this course!<br>I find the term ‚Äòorthogonalization‚Äô a bit misleading: if one knob on the TV changes 0.5 times the image width and 0.5 times the trapezoidality, and another knob changes 0.5 times the image width and -0.5 times the trapezoidality, they are mathematically orthogonal, but I would have a hard time optimizing my TV image with them. As you say at <a href=""https://www.youtube.com/watch?v=UEtvV1D6B3s&amp;t=4m06s"">4:06</a>, we seek for controls which are aligned with one aspect of performance, so I think the term ‚Äòalignment‚Äô would be better to use here.<br>Nevertheless, thank you for the good explanation of how evaluating on a development and test set shows which actions can be taken to improve the model.",2020-06-28T09:40:43Z
UgzSgfLTQsZprEQQNb54AaABAg,@valente.victor,,1,UEtvV1D6B3s,1,4,2020-02-24T14:07:24Z,"So, basically Orthogonalization is an abstraction that compares model performance in its various facets (training perf., validation perf., real world perf., etc) to vectors that should be orthogonal to each other in the model perfomance space.<br><br>If orthogonalization between perfomance vectors were to be achieved, it would be simpler to tune the model to achieve the desired performance in a specific axis. For example, if training performance and dev performance vectors are orthogonal, we can tune one of those without compromising the other.",2020-02-24T14:07:24Z
UgzSgfLTQsZprEQQNb54AaABAg.95QSsHv-Ckp9WB70UAc6Vs,@travel6142,UgzSgfLTQsZprEQQNb54AaABAg,2,UEtvV1D6B3s,0,0,2021-12-20T17:15:26Z,"Thank you for this explanation but I have some difficulties the get this part: &quot;For example, if training performance and dev performance vectors are orthogonal, we can tune one of those without compromising the other.&quot; What we are tuning here, tuning is not something that we apply while training. What really means tuning dev?",2021-12-20T17:15:26Z
Ugxdk9bM4igalib66cZ4AaABAg,@chesterkylescolita3393,,1,UEtvV1D6B3s,1,0,2018-08-29T00:08:29Z,i have been reading a lot about orthogonalization since i studied linear algebra but this video made it easier to explain it. *mindblown,2018-08-29T00:08:29Z
Ugxdk9bM4igalib66cZ4AaABAg.8kWCQyoaFhQ9wJJvwhf8kg,@hamza1543,Ugxdk9bM4igalib66cZ4AaABAg,2,UEtvV1D6B3s,0,0,2023-10-25T23:49:51Z,This has nothing to do with the linear algebra concept of orthogonalization.,2023-10-25T23:49:51Z
Ugz_mhNn1F3kaB9u2P14AaABAg,@_taylor_v,,1,UEtvV1D6B3s,0,12,2018-07-11T01:09:02Z,The reasoning for why he doesn&#39;t use early stopping in algorithms just blew my mind. I&#39;m never using early stopping again.,2018-07-11T01:09:02Z
UgwKjxyjtgkEZTaHMet4AaABAg,@isarizvi9184,,1,UEtvV1D6B3s,0,1,2018-03-09T14:08:18Z,Great lecture.. but where i can see this applications applied on real datasets.,2018-03-09T14:08:18Z
UgwJVrRgMWzGt-tLPud4AaABAg,@anarbay24,,1,sofffBNhVSo,0,0,2020-08-01T10:41:58Z,Best Love from China!,2020-08-01T10:41:58Z
UgwbbTkAWIeeU-faH8Z4AaABAg,@merrilalmeida5982,,1,sofffBNhVSo,0,6,2019-02-02T11:37:54Z,thanks for mentioning india. Big fan from india.,2019-02-02T11:37:54Z
Ugzejd2F8WuHZ0bgM3N4AaABAg,@wangtony3543,,1,BH9mlmdXzzI,5,12,2018-08-09T09:15:43Z,You really surprised me when you wrote Chinese .ÁâõÈÄº,2018-08-09T09:15:43Z
Ugzejd2F8WuHZ0bgM3N4AaABAg.8jig9WheegA8k6yrgHNebL,@zhiwang6425,Ugzejd2F8WuHZ0bgM3N4AaABAg,2,BH9mlmdXzzI,0,1,2018-08-19T05:00:11Z,haha,2018-08-19T05:00:11Z
Ugzejd2F8WuHZ0bgM3N4AaABAg.8jig9WheegA8kgHHHd3XGs,@raviteja5125,Ugzejd2F8WuHZ0bgM3N4AaABAg,2,BH9mlmdXzzI,0,2,2018-09-02T07:22:30Z,"exactly, he wrote very fast!!",2018-09-02T07:22:30Z
Ugzejd2F8WuHZ0bgM3N4AaABAg.8jig9WheegA8ou2XSgCoMg,@saanvisharma2081,Ugzejd2F8WuHZ0bgM3N4AaABAg,2,BH9mlmdXzzI,0,1,2018-12-16T01:48:35Z,Chinese people are intelligent though,2018-12-16T01:48:35Z
Ugzejd2F8WuHZ0bgM3N4AaABAg.8jig9WheegA993ubKTYOa-,@user-qf5il7uq9m,Ugzejd2F8WuHZ0bgM3N4AaABAg,2,BH9mlmdXzzI,0,0,2020-05-25T06:01:31Z,amazing,2020-05-25T06:01:31Z
Ugzejd2F8WuHZ0bgM3N4AaABAg.8jig9WheegA9L62Qmigxjt,@fredkilner2299,Ugzejd2F8WuHZ0bgM3N4AaABAg,2,BH9mlmdXzzI,0,0,2021-03-20T08:13:48Z,San Yue wo ting wo kan jungwo-hwa keshr bu-shr jungo-ren. 2007-nyan wo gen wode beibao chu le jungwo. Tsingtao hau he - baudz hau chr. I noticed Chinese system on loading big Semi trucks full of rocks in W. China is if the axle hasn&#39;t broken it isn&#39;t overloaded.,2021-03-20T08:13:48Z
Ugyxim6JiPjoEf2Ak0N4AaABAg,@meandkg,,1,M3qpIzy4MQk,0,1,2022-04-02T16:48:40Z,"3 months wasted is not bad compared to approx. 1 year for me (I&#39;m still a student, better to make this mistakes now rather than later)",2022-04-02T16:48:40Z
UgxBZ854ceEnHiramTx4AaABAg,@ninalee7833,,1,M3qpIzy4MQk,0,0,2022-03-12T20:44:31Z,What&#39;s methods can be used to identify/check the distribution difference between training and testing datasets?,2022-03-12T20:44:31Z
UgxVy7fBej5yH23Q8tt4AaABAg,@DistortedV12,,1,M3qpIzy4MQk,0,2,2020-12-03T03:47:59Z,Where is the video where he talks about the training distribution?,2020-12-03T03:47:59Z
Ugx9bQl9BtulFGYVYFB4AaABAg,@user-jn3dl6pj6e,,1,M3qpIzy4MQk,1,0,2019-08-05T23:20:14Z,"What exactly does the distribution mean? I suppose it&#39;s the distribution of the feature. However, most people talking about one feature distribution but what about we have many features? One answer in my head is joint kernel density estimation + KL divergence. It would be quite expensive though. I am not sure. Someone have the answerÔºü",2019-08-05T23:20:14Z
Ugx9bQl9BtulFGYVYFB4AaABAg.8yGjlpvxkP796W3gXTqHal,@rjohnson0186,Ugx9bQl9BtulFGYVYFB4AaABAg,2,M3qpIzy4MQk,0,2,2020-03-22T14:54:10Z,"Èü©ÊØÖ It refers to the data generating process (DGP). You want to train a model on data that looks just like the data you will observe in production. A simple way is to randomize your data and then split into training, test, etc. But there are also times when you might need to do stratified sampling because you might have a rare class and you want to ensure it is present across all splits",2020-03-22T14:54:10Z
UgzFEm9PbvelSj5zd1l4AaABAg,@prempotabatti7615,,1,_Fe5kKmFieg,2,0,2019-03-09T17:18:55Z,Why not do k fold cross validation?,2019-03-09T17:18:55Z
UgzFEm9PbvelSj5zd1l4AaABAg.8sGQz-srowp8uVx2Guc7rb,@saurabhbhagvatula6865,UgzFEm9PbvelSj5zd1l4AaABAg,2,_Fe5kKmFieg,0,6,2019-05-04T10:59:14Z,Suppose you have 10M records and considering 10-k cross-validation. Let the split ratio of train : dev = 99%:1% =&gt; size(train set) = 9.9M and size(dev set) = 100k.<br>Do you really want to do 10-k cross-validation in this scenario with deep learning where such complex computation and huge computing power (GPU) is involved? <br>I don&#39;t think it will be a good idea.,2019-05-04T10:59:14Z
UgzFEm9PbvelSj5zd1l4AaABAg.8sGQz-srowp9aGU_pEkpzP,@kamilk77777,UgzFEm9PbvelSj5zd1l4AaABAg,2,_Fe5kKmFieg,0,0,2022-04-26T01:54:33Z,K fold is normally good tool to use when you have smaller training sets in order to efficiently use the data. But when you have a huge training set there is no much need for k fold,2022-04-26T01:54:33Z
UgyR0M370NhxgPI6bDh4AaABAg,@boshi3513,,1,DFUqMbWs5d8,0,1,2023-08-20T07:15:17Z,Pussy cat classifier,2023-08-20T07:15:17Z
Ugx2wjmmIiYvlgdkYkN4AaABAg,@jesuscriesuwu4580,,1,DFUqMbWs5d8,0,2,2023-01-02T13:22:30Z,Ah I see you are a classifier of culture as well,2023-01-02T13:22:30Z
UgzTIX9Kss802Uu9jkN4AaABAg,@osiris1102,,1,DFUqMbWs5d8,0,0,2021-05-31T11:39:20Z,( Õ°¬∞ Õú ñ Õ°¬∞),2021-05-31T11:39:20Z
Ugz6blxcdXyeJyxuyO94AaABAg,@mayursonowal,,1,DFUqMbWs5d8,0,6,2021-02-14T18:13:12Z,so it seems it has learnt the real meaning of the word :P,2021-02-14T18:13:12Z
UgwuugrNAKkWQfSXSd54AaABAg,@mohammadesmaily6857,,1,DFUqMbWs5d8,0,1,2020-09-12T16:25:45Z,( Õ°¬∞ Õú ñ Õ°¬∞),2020-09-12T16:25:45Z
UgwRwOdXIVBqth4NNtl4AaABAg,@saileshganeshan1160,,1,DFUqMbWs5d8,0,1,2020-08-27T04:57:06Z,( Õ°¬∞ Õú ñ Õ°¬∞),2020-08-27T04:57:06Z
Ugye2RVZabIKjBvz3rd4AaABAg,@sourabhpatil7309,,1,DFUqMbWs5d8,1,9,2020-07-18T14:01:15Z,Cat classifier identifying pornographic image wrongly probably mistook the meaning of pussey.,2020-07-18T14:01:15Z
Ugye2RVZabIKjBvz3rd4AaABAg.9BFoR9TTg-W9D72cUkptSv,@wadyn95,Ugye2RVZabIKjBvz3rd4AaABAg,2,DFUqMbWs5d8,0,3,2020-09-02T21:23:37Z,( Õ°¬∞ Õú ñ Õ°¬∞),2020-09-02T21:23:37Z
UgxXqz2lcpE-H2fkkJF4AaABAg,@qkloh6804,,1,DFUqMbWs5d8,0,0,2020-07-14T17:34:32Z,( Õ°¬∞ Õú ñ Õ°¬∞),2020-07-14T17:34:32Z
UgxB6adFbv1m33ZZGSh4AaABAg,@pinyiwang2325,,1,DFUqMbWs5d8,0,0,2020-07-11T10:18:18Z,( Õ°¬∞ Õú ñ Õ°¬∞),2020-07-11T10:18:18Z
Ugw9DO6yF0eEWqkMZY14AaABAg,@waasefiqbal7080,,1,DFUqMbWs5d8,0,0,2020-06-10T16:53:01Z,( Õ°¬∞ Õú ñ Õ°¬∞),2020-06-10T16:53:01Z
Ugw1rk8gqpSptWKb8f54AaABAg,@vijithaisuru6766,,1,DFUqMbWs5d8,0,0,2020-06-04T18:56:51Z,( Õ°¬∞ Õú ñ Õ°¬∞),2020-06-04T18:56:51Z
Ugx7_iMaHB9xwHJaZMl4AaABAg,@jakubcaputa9265,,1,DFUqMbWs5d8,0,0,2020-05-16T14:22:20Z,( Õ°¬∞ Õú ñ Õ°¬∞),2020-05-16T14:22:20Z
Ugys_gjpnUiLZsJtw7Z4AaABAg,@tsunamio7750,,1,DFUqMbWs5d8,0,0,2020-05-15T19:38:51Z,( Õ°¬∞ Õú ñ Õ°¬∞),2020-05-15T19:38:51Z
UgxUz-UbZpIMkMVKtBJ4AaABAg,@patrickprakash8,,1,DFUqMbWs5d8,0,0,2020-05-03T10:39:41Z,( Õ°¬∞ Õú ñ Õ°¬∞),2020-05-03T10:39:41Z
UgzKWF4D3qIosDYaVgB4AaABAg,@funnystreet4086,,1,DFUqMbWs5d8,1,0,2020-04-11T11:05:02Z,( Õ°¬∞ Õú ñ Õ°¬∞),2020-04-11T11:05:02Z
UgzKWF4D3qIosDYaVgB4AaABAg.97J9Mo3DUNG9AFPWFsWnGp,@swarup765,UgzKWF4D3qIosDYaVgB4AaABAg,2,DFUqMbWs5d8,0,0,2020-06-23T13:43:21Z,( Õ°¬∞ Õú ñ Õ°¬∞),2020-06-23T13:43:21Z
UgxJSoiSEaEWPS6iJN94AaABAg,@MG5350,,1,DFUqMbWs5d8,0,1,2020-02-26T22:54:34Z,( Õ°¬∞ Õú ñ Õ°¬∞),2020-02-26T22:54:34Z
UgygPdcZaGsqlvLEIa54AaABAg,@jorjiang1,,1,DFUqMbWs5d8,0,5,2019-11-11T21:17:42Z,"(   Õ° Õú¬∞   ñ Õú Õ°¬∞) me as a user, prefer algorithm A",2019-11-11T21:18:45Z
Ugw8v4VOX43jrT6Rf8p4AaABAg,@VivekGangwar02,,1,DFUqMbWs5d8,0,2,2019-09-23T15:21:27Z,<b>( Õ°¬∞ Õú ñ Õ°¬∞)</b>,2019-09-23T15:21:27Z
UgytCO6IdJyzc2sRLIl4AaABAg,@ramansingh3853,,1,DFUqMbWs5d8,0,4,2019-07-11T06:40:01Z,( Õ°¬∞ Õú ñ Õ°¬∞),2019-07-11T06:40:01Z
UgwVW8SJqPL0gxrSUA94AaABAg,@IgorAherne,,1,DFUqMbWs5d8,3,28,2017-12-26T21:29:46Z,( Õ°¬∞ Õú ñ Õ°¬∞),2017-12-26T21:29:46Z
UgwVW8SJqPL0gxrSUA94AaABAg.8ae3W5jyD5Q8qqm8p0IcPe,@merrilalmeida5982,UgwVW8SJqPL0gxrSUA94AaABAg,2,DFUqMbWs5d8,0,0,2019-02-02T12:21:44Z,may i knw how u did that?,2019-02-02T12:21:44Z
UgwVW8SJqPL0gxrSUA94AaABAg.8ae3W5jyD5Q8wFGHlew6dP,@czyzolex,UgwVW8SJqPL0gxrSUA94AaABAg,2,DFUqMbWs5d8,0,1,2019-06-16T16:31:49Z,@@merrilalmeida5982 he just used very specific unicode characters. You can simply copy-paste them in order to use them in a different place.,2019-06-16T16:31:49Z
UgwVW8SJqPL0gxrSUA94AaABAg.8ae3W5jyD5Q8wSxbC3oE3T,@jerrylin5089,UgwVW8SJqPL0gxrSUA94AaABAg,2,DFUqMbWs5d8,0,0,2019-06-22T00:09:13Z,best comment i&#39;ve seen on an andrew ng video,2019-06-22T00:09:13Z
Ugy7KdooTNLtL6LSvXV4AaABAg,@ramansingh3853,,1,J3HHOwcrkK8,1,0,2019-07-11T06:52:46Z,( Õ°¬∞ Õú ñ Õ°¬∞),2019-07-11T06:52:46Z
Ugy7KdooTNLtL6LSvXV4AaABAg.8xEatX17oi19O-pPPh6HHo,@osiris1102,Ugy7KdooTNLtL6LSvXV4AaABAg,2,J3HHOwcrkK8,0,0,2021-05-31T11:50:01Z,( Õ°¬∞ Õú ñ Õ°¬∞),2021-05-31T11:50:01Z
Ugwbs7uxkS4hxoglkJZ4AaABAg,@osiris1102,,1,CZf3oo0fuh0,0,0,2021-05-31T12:14:46Z,( Õ°¬∞ Õú ñ Õ°¬∞),2021-05-31T12:14:46Z
UgyRRVXy18ojv4X4ltV4AaABAg,@7810,,1,CZf3oo0fuh0,0,1,2020-10-07T14:39:06Z,Good to know. Thanks for the great lesson!,2020-10-07T14:39:06Z
UgwcgYRNTTy5Ao8kRyJ4AaABAg,@pinyiwang2325,,1,CZf3oo0fuh0,0,0,2020-07-11T10:47:58Z,( Õ°¬∞ Õú ñ Õ°¬∞),2020-07-11T10:47:58Z
UgzF9XY3XYQxeYJlTXF4AaABAg,@ramansingh3853,,1,CZf3oo0fuh0,0,1,2019-07-11T06:56:40Z,( Õ°¬∞ Õú ñ Õ°¬∞),2019-07-11T06:56:40Z
UgznR4sT9n09gTv0phl4AaABAg,@danieltian5513,,1,CZf3oo0fuh0,0,4,2018-10-07T07:34:10Z,Âê¨Âêõ‰∏ÄÂ∏≠ËØùÔºåËÉúËØªÂçÅÂπ¥‰π¶„ÄÇ,2018-10-07T07:34:10Z
UgwC7DbOCdBojx11UhZ4AaABAg,@franckspike,,1,NUmbgp1h64E,0,0,2023-01-12T16:34:27Z,Could Bayes theorem be used to help finding the Bayes error ??,2023-01-12T16:34:27Z
UgwVPKSLmQgUL-R9aL94AaABAg,@ramansingh3853,,1,NUmbgp1h64E,0,0,2019-07-12T05:52:03Z,"[&quot;amazon&quot;,&quot;apple&quot;,&quot;facebook&quot;,&quot;google&quot;,&quot;leetcode&quot;]<br>[&quot;lo&quot;,&quot;eo&quot;]",2019-07-12T05:52:03Z
UgxGqHU_k_SFoSWIUdR4AaABAg,@yhu221300,,1,NUmbgp1h64E,1,9,2018-12-17T17:19:53Z,study before enrolling :),2018-12-17T17:19:53Z
UgxGqHU_k_SFoSWIUdR4AaABAg.8oyHuRgzQTz8ozv-Urh-QJ,@saanvisharma2081,UgxGqHU_k_SFoSWIUdR4AaABAg,2,NUmbgp1h64E,0,1,2018-12-18T08:29:29Z,Same here!!! About to start Coursera,2018-12-18T08:29:29Z
UgwXW9UjHIjc6-ZStFZ4AaABAg,@jllhrmonica,,1,NUmbgp1h64E,0,0,2018-10-01T04:54:47Z,very helpful!,2018-10-01T04:54:47Z
UgzbgO7gJRezk8AFIHJ4AaABAg,@sanjivgautam9063,,1,dM0exrbVZ08,2,1,2020-05-29T06:53:29Z,"A bit of confusion. If you can surpass Human Level performance which indeed is a proxy for Bayes Optimal Error which is something that cannot be surpassed, but you somehow surpassed it, so we update the Bayesian Optimal Error to new minimum or am I guessing something wrong here?",2020-05-29T06:53:29Z
UgzbgO7gJRezk8AFIHJ4AaABAg.99EIjKGHaSf9B5fRypCCw9,@sarahsmith44,UgzbgO7gJRezk8AFIHJ4AaABAg,2,dM0exrbVZ08,0,3,2020-07-14T15:30:18Z,"Hi. I think Human-Level performance is not equal to the Bayes Optimal Error (it is always worse or equal). So a model can do better than the human-level performance, but not better than the Bayes error.",2020-07-14T15:30:18Z
UgzbgO7gJRezk8AFIHJ4AaABAg.99EIjKGHaSf9F4FFYPqisq,@Wherrimy,UgzbgO7gJRezk8AFIHJ4AaABAg,2,dM0exrbVZ08,0,0,2020-10-21T12:19:01Z,"Bayes error itself never changes, it&#39;s an unestimatable performance level. Only our perception of where it might be changes, with the first approximation being human level, and going down as we surpass it.",2020-10-21T12:19:01Z
Ugy0OjNYz20UOjs03414AaABAg,@anjulubis6949,,1,zg26t-BH7ao,0,0,2022-12-09T06:29:58Z,yang nanya oooo,2022-12-09T06:29:58Z
Ugx73J2vGZSPk4tUs4d4AaABAg,@FirasShamasnehM,,1,zg26t-BH7ao,3,4,2019-06-21T14:34:27Z,Is it the video or my eyes?,2019-06-21T14:34:27Z
Ugx73J2vGZSPk4tUs4d4AaABAg.8wRvpTtSjcx9Lao1r-l09z,@neuron8186,Ugx73J2vGZSPk4tUs4d4AaABAg,2,zg26t-BH7ao,0,1,2021-04-01T16:15:01Z,you going blind may god bless you :(,2021-04-01T16:15:01Z
Ugx73J2vGZSPk4tUs4d4AaABAg.8wRvpTtSjcx9_4YJJUF6U6,@multitrickfox,Ugx73J2vGZSPk4tUs4d4AaABAg,2,zg26t-BH7ao,0,0,2022-03-27T14:04:50Z,or is it in brain,2022-03-27T14:04:50Z
Ugx73J2vGZSPk4tUs4d4AaABAg.8wRvpTtSjcx9jPU_qJXLCX,@anjulubis6949,Ugx73J2vGZSPk4tUs4d4AaABAg,2,zg26t-BH7ao,0,0,2022-12-09T06:30:16Z,yang nanya oo,2022-12-09T06:30:16Z
UgwTvkkc_wvOVRtPVHB4AaABAg,@kld0093,,1,zg26t-BH7ao,1,14,2019-03-18T05:51:36Z,I thought my laptop shut down,2019-03-18T05:51:36Z
UgwTvkkc_wvOVRtPVHB4AaABAg.8sbNTpO3ULd9-EILPQJWxT,@VivekGangwar02,UgwTvkkc_wvOVRtPVHB4AaABAg,2,zg26t-BH7ao,0,0,2019-09-23T17:36:08Z,lol,2019-09-23T17:36:08Z
UgwaptZ0aOsPsO7hFox4AaABAg,@jianchenhu5238,,1,zg26t-BH7ao,2,8,2019-01-28T12:14:10Z,Bug with this video?,2019-01-28T12:14:10Z
UgwaptZ0aOsPsO7hFox4AaABAg.8qdtIxm7L878qvsC5YcS1x,@kushalmahindrakar8580,UgwaptZ0aOsPsO7hFox4AaABAg,2,zg26t-BH7ao,0,0,2019-02-04T11:50:49Z,yes,2019-02-04T11:50:49Z
UgwaptZ0aOsPsO7hFox4AaABAg.8qdtIxm7L879DGSeI_dL8O,@rafayel.mkrtchyan,UgwaptZ0aOsPsO7hFox4AaABAg,2,zg26t-BH7ao,0,0,2020-09-06T13:04:14Z,It&#39;s bugging me,2020-09-06T13:04:14Z
Ugzmuyxa9Vq-n4N5bxR4AaABAg,@dick00627,,1,JoAxZsdw_3w,0,0,2022-07-07T20:42:15Z,How do you classify the images into the different categories after you discovered the patterns of error in practice? Wouldn&#39;t that be their own classification problems?,2022-07-07T20:42:15Z
UgwLNevpH9ZHzDjuF514AaABAg,@sandipansarkar9211,,1,JoAxZsdw_3w,0,0,2020-12-31T15:00:35Z,great explanation.Need to watch again,2020-12-31T15:00:35Z
UgxEt4Rbb3dpRCQ7ZCt4AaABAg,@slava-keshkov,,1,JoAxZsdw_3w,1,0,2019-02-20T10:31:37Z,How would you suggest to fix the dog problem- by creating an extra dog class or simply adding more data for cats?,2019-02-20T10:31:56Z
UgxEt4Rbb3dpRCQ7ZCt4AaABAg.8rZvr-aeaiv9E03VbQ-umh,@imanshojaei7784,UgxEt4Rbb3dpRCQ7ZCt4AaABAg,2,JoAxZsdw_3w,0,2,2020-09-25T00:48:00Z,I think adding more data for cats does not help that much as we assume there are enough cats already in the data set. Probably adding more examples of dog will help the algorithm to learn dogs are different from cats. We do not need an extra dog class and it would be enough to have cat versus non-cat classes.,2020-09-25T00:48:00Z
UgyjKF8-0Pu5wMq42x54AaABAg,@choice_of_royals5268,,1,jyjJ-RpQ5zQ,0,0,2022-11-10T23:49:17Z,very clear and to-the-point explanation. thnaks,2022-11-10T23:49:17Z
UgwGsp7atP9HuMtsKcJ4AaABAg,@sandipansarkar9211,,1,jyjJ-RpQ5zQ,0,0,2021-01-03T19:20:13Z,very good explnation,2021-01-03T19:20:13Z
UgzNTNc5JuRKiD-5va14AaABAg,@raszagal1000,,1,jyjJ-RpQ5zQ,2,2,2017-12-19T10:43:27Z,By assigning 0.6 percent to errors due to incorrect labels we are disregarding the effect the incorrect labels had on the weights during training which may have caused the model to perform more poorly on other classes as well?,2017-12-19T10:43:27Z
UgzNTNc5JuRKiD-5va14AaABAg.8aLszC0IMlv9NAWa8Ho2Ff,@rodrixar,UgzNTNc5JuRKiD-5va14AaABAg,2,jyjJ-RpQ5zQ,0,0,2021-05-10T18:57:06Z,"0.6% error attribution is from dev set alone, so it had zero effect on training the learnable params. Yes, could be that some percentage of mislabeled samples in the training set messed up the model, but that&#39;s not what the error analysis described aims to solve.",2021-05-10T18:57:06Z
UgzNTNc5JuRKiD-5va14AaABAg.8aLszC0IMlv9RpwORSHQSc,@a.j.noushin1071,UgzNTNc5JuRKiD-5va14AaABAg,2,jyjJ-RpQ5zQ,0,0,2021-09-03T16:24:59Z,"I think the key point here is that the mislabeled training samples are in essence absolutely RANDOM i.e. they are sprinkled here and there.  Therefore any well trained classifier that is not OVERFIT, ignores these points unless they happen to be very close to a decision boundary.  This means that the weights are not effected by these randomly mislabeled examples.  Of course the situation is different if there is any systemic mislabeling, in which case the weights are chosen (by the optimization algorithm) to learn the label of these examples, thus effecting the performance of the classifier on other correctly labeled examples.",2021-09-03T16:24:59Z
Ugwhx3NOR1o1PQo3T9h4AaABAg,@arjungoud3450,,1,HfM8UIohGE0,0,0,2022-04-05T00:31:50Z,"Does it mean, build algo, to analyse errors",2022-04-05T00:31:50Z
Ugx2xeIfyGwEgUz2HXl4AaABAg,@sanjivgautam9063,,1,HfM8UIohGE0,1,4,2020-05-29T08:41:59Z,"When you listen to his ah, am, oh and realize Youtube subtitles already have them means Google has already implemented them",2020-05-29T08:41:59Z
Ugx2xeIfyGwEgUz2HXl4AaABAg.99EV92rhEwB9a1Na8NyYBV,@AbhinavSingh-oq7dk,Ugx2xeIfyGwEgUz2HXl4AaABAg,2,HfM8UIohGE0,0,0,2022-04-20T05:04:49Z,Was thinking the same.,2022-04-20T05:04:49Z
UgxK4D6-zskwu5pR0Ft4AaABAg,@TheRetrobek,,1,sfk5h0yC67o,0,0,2022-03-09T06:27:25Z,"So basically, the idea is to create dev/test sets with distributions that your model will see in production/after deployment. Thanks!",2022-03-09T06:27:25Z
UgwqSxPKbMhf9fXGS-l4AaABAg,@sarahsmith44,,1,2BH49JG_sTs,2,0,2020-07-14T17:56:39Z,"Did I miss the part on how to get the human-level error in previous videos? I believe it is very difficult to have the human-level error, especially for non-classification problems; even for classification, I think it is too difficult to put it to a number? I wish this point was addressed in more detail.",2020-07-14T17:56:39Z
UgwqSxPKbMhf9fXGS-l4AaABAg.9B5wBnWjzMn9DI_QXk8kdT,@aayushpaudel2379,UgwqSxPKbMhf9fXGS-l4AaABAg,2,2BH49JG_sTs,0,3,2020-09-07T08:50:36Z,"It is easy to surpass human level performance on structural data (like data stored in databases: numbers and figures) as algorithms can look at large amount of data in relatively short time and find patterns in them while is very difficult for human to do the same. On the other hand, human are exceptionally good at natural perception task like looking at pictures and listening to sounds and generalizing them, this task is indeed difficult for machines/algorithms.  But nowadays, machine are becoming better in such task due to advance in computation and better algorithms and advance NN architecture. I hope it make sense!",2020-09-07T08:50:36Z
UgwqSxPKbMhf9fXGS-l4AaABAg.9B5wBnWjzMn9KjPgd_wEDd,@MohakNarang07,UgwqSxPKbMhf9fXGS-l4AaABAg,2,2BH49JG_sTs,0,1,2021-03-11T03:55:18Z,"For non-classification problems (i.e. real-valued-output or regression problems), it might not be a good idea to try and collect human-level error for the task, however, we can collect human-level error for classification problems by asking a group of humans to label the data from the test set and then obtain an average of how well they performed.",2021-03-11T03:55:18Z
UgzyQK1aJIpSyEyNpER4AaABAg,@ahn19c,,1,2BH49JG_sTs,2,1,2020-02-10T00:36:13Z,"Isn&#39;t this strange? &#39;<a href=""https://www.youtube.com/watch?v=2BH49JG_sTs&amp;t=09m52s"">09:52</a> so the only way for that to be a huge gap here for the to much better on the dev set and the test set is it somehow managed to over-fit the dev set&#39;",2020-02-10T00:40:11Z
UgzyQK1aJIpSyEyNpER4AaABAg.94pxunIzKM79DIaJteh8WS,@aayushpaudel2379,UgzyQK1aJIpSyEyNpER4AaABAg,2,2BH49JG_sTs,0,0,2020-09-07T08:58:26Z,"he is assuming if there is huge gap, but in face there is no gap. just in case!",2020-09-07T08:58:26Z
UgzyQK1aJIpSyEyNpER4AaABAg.94pxunIzKM79JEQWr2y6Qi,@vipinamar8323,UgzyQK1aJIpSyEyNpER4AaABAg,2,2BH49JG_sTs,0,0,2021-02-01T21:15:29Z,In cases when the distribution of data in dev and test is different than that in some sense can lead to higher test error only when you have overfitted on the dev set,2021-02-01T21:15:29Z
UgzRoE2xEG6sQYlBqiV4AaABAg,@kuldeepSingh-to5dr,,1,2BH49JG_sTs,1,0,2019-07-27T11:53:31Z,shouln&#39;t it be a avoidable bias instead of variance,2019-07-27T11:53:31Z
UgzRoE2xEG6sQYlBqiV4AaABAg.8xtL1JWekdj8xtLWUcjBEN,@kuldeepSingh-to5dr,UgzRoE2xEG6sQYlBqiV4AaABAg,2,2BH49JG_sTs,0,1,2019-07-27T11:57:47Z,ya ya.. stupid of me. i think my mind is getting blurry after each cat example i am using.,2019-07-27T11:57:47Z
UgxTZezD0-g-qdPuXtp4AaABAg,@DreamFrame-Studio,,1,sn_QSB7T1xo,1,2,2019-12-19T18:58:36Z,Maybe we can add car noise to clean hours <br><br>I mean if we added car noise to clean environment hours we can also transform our dataset to a noisy one <br><br>thank you for the lessons,2019-12-19T18:58:36Z
UgxTZezD0-g-qdPuXtp4AaABAg.92jSwXz7J4Y9xZqL8jjx9z,@ermano5586,UgxTZezD0-g-qdPuXtp4AaABAg,2,sn_QSB7T1xo,0,0,2023-11-26T06:21:01Z,"Hello, it is been 3 years that left comment, did you achieve results in this sphere?",2023-11-26T06:21:01Z
UgwnyTgA5Mv_WE-lW3Z4AaABAg,@waliullahmahir869,,1,yofjFQddwHE,0,0,2023-11-19T07:33:05Z,Nice explanation üòç,2023-11-19T07:33:05Z
UgymGgLUbshkCn5FUFN4AaABAg,@user-bg6oq4zq4i,,1,yofjFQddwHE,0,0,2023-10-20T10:48:58Z,Don&#39;t know why people appreciate him. He does not break down complex concepts in simpler terms at all.,2023-10-20T10:48:58Z
Ugxlr7ewydL8-EALsdJ4AaABAg,@hazema.6150,,1,yofjFQddwHE,0,0,2023-05-23T06:20:59Z,"Wonderful, thanks for uploading this video",2023-05-23T06:20:59Z
Ugxr-mtLoqKaFkgJ8ut4AaABAg,@THEGASDRIP,,1,yofjFQddwHE,0,0,2023-01-25T04:18:52Z,this is cool,2023-01-25T04:18:52Z
UgwLpdVoMQdTteaffUF4AaABAg,@swagatggautam6630,,1,yofjFQddwHE,0,0,2023-01-19T03:15:24Z,Time to reshoot the video with higher quality camera...,2023-01-19T03:15:24Z
UgwOv8JbihQbLJcVQbV4AaABAg,@salehjamali6716,,1,yofjFQddwHE,0,0,2023-01-09T15:39:57Z,Thank you alot for summarizing the whole concept in one small video. ‚ù§Ô∏è,2023-01-09T15:39:57Z
Ugy7NFWIR444XJ14byh4AaABAg,@736939,,1,yofjFQddwHE,0,0,2022-09-05T08:27:15Z,"OK, now how to program it in pytorch. Update the architecture of the NN and train it on the different model. HOW?",2022-09-05T08:27:15Z
Ugwfk7t01MIyDmWdJ-F4AaABAg,@johncsheath5037,,1,yofjFQddwHE,0,0,2022-06-09T11:10:22Z,"Brilliant, Andrew, thank you",2022-06-09T11:10:22Z
UgxF-G2nFq3SoWOcaGV4AaABAg,@StefanBrock_PL,,1,yofjFQddwHE,0,0,2022-04-07T10:55:22Z,Very usefull background.,2022-04-07T10:55:22Z
Ugx2W44mzmzJxwttAjV4AaABAg,@kabokbl2412,,1,yofjFQddwHE,0,0,2022-02-25T16:31:28Z,Doesn&#39;t retraining the dataset simply preserve the model architecture (i.e the sequence and types of layers) since the wieghts and biases are retrained/fineTuned?,2022-02-25T16:31:28Z
UgztDBR288TCEh_lVYF4AaABAg,@Pussyfer,,1,yofjFQddwHE,0,0,2021-03-09T22:51:10Z,Can anyone answer this please.<br>Is it better to consider transfer learning over reinforcement learning for a Mobile edge computing paradigm ? usually to solve computation offlaoding and resource allocation schemes in a MEC environement.,2021-03-09T22:51:10Z
UgzhQJXJDzGBsh931tN4AaABAg,@nickbelanger5225,,1,yofjFQddwHE,0,0,2021-02-25T00:56:10Z,Very nice explanation,2021-02-25T00:56:10Z
Ugxq5aO0Lpw4mlaXAUJ4AaABAg,@Fatima-kj9ws,,1,yofjFQddwHE,0,0,2021-01-26T07:46:42Z,Great Thanks,2021-01-26T07:46:42Z
UgyftKLtJEE9QvH6uJd4AaABAg,@arpege3618,,1,yofjFQddwHE,0,0,2020-12-14T22:09:16Z,man thanks for the info i like your explaining and manner<br>thank you   again mister,2020-12-14T22:09:16Z
Ugw_ozAZinfj6qDmVmF4AaABAg,@shigstsuru765,,1,yofjFQddwHE,2,0,2020-11-13T09:08:12Z,"Got a question:<br>Does transfer learning work, if task a and b has same input but different column varieties?<br>So let‚Äôs say A and B‚Äôs task is to detect emotion (let‚Äôs say if the person likes it or dislikes it)<br>A has better detection rate than B and I‚Äôm trying to transfer the high detection rate of A to B.<br>Data A has anger, sorrow, joy, excitement, and Data B has anger, joy, excitement.<br>I am super-amateur in this field so I‚Äôm not sure if I‚Äôm talking about anything plausible but it‚Äôs be a great help if I the scenario is plausible or not.<br><br>Many thanks",2020-11-13T09:08:12Z
Ugw_ozAZinfj6qDmVmF4AaABAg.9G-7h5uvp-l9GgVK7Z80u4,@nitishjaiswal6610,Ugw_ozAZinfj6qDmVmF4AaABAg,2,yofjFQddwHE,0,0,2020-11-30T14:41:13Z,"I guess that&#39;s exactly what transfer learning is about! From his example as well, the image recognition dataset will have low level features which are used during radiology diagnosis. Similarly in your example, if you train using 5 emotions, there&#39;ll be low level features which will help you to detect a different dataset (with 3 emotions) as well. We just might need to retrain the network as the new dataset doesn&#39;t contain the 2 dropped emotions so we need to make adjustments to the previous training to accommodate all the test data in the new classes",2020-11-30T14:41:13Z
Ugw_ozAZinfj6qDmVmF4AaABAg.9G-7h5uvp-l9IZO5rz4nnA,@andrewkreisher689,Ugw_ozAZinfj6qDmVmF4AaABAg,2,yofjFQddwHE,0,0,2021-01-16T04:06:59Z,yep thats pretty much what i would use it for,2021-01-16T04:06:59Z
UgwjilHXptgb0U6q04d4AaABAg,@miketsui3a,,1,yofjFQddwHE,1,1,2020-10-02T03:29:13Z,"now we are in 2020, but this vid is still in 360p",2020-10-02T03:29:13Z
UgwjilHXptgb0U6q04d4AaABAg.9EINWZsJxLW9cUKXgaivdl,@poojakabra1479,UgwjilHXptgb0U6q04d4AaABAg,2,yofjFQddwHE,0,0,2022-06-20T03:58:54Z,"Ikr, at first I suspected this wasn‚Äôt the original channel",2022-06-20T03:58:54Z
UgzjvHRvyRUCV0Id6rd4AaABAg,@saurabhagarwal8970,,1,yofjFQddwHE,0,2,2020-09-15T10:45:54Z,Code for Transfer Learning anyone ??,2020-09-15T10:45:54Z
Ugwj1F9YkLZIR2RF1Vd4AaABAg,@arnabmondal601,,1,yofjFQddwHE,0,1,2020-06-25T22:31:26Z,Very clear explanation.,2020-06-25T22:31:26Z
Ugw7LxKb8bA4vm96gwN4AaABAg,@rogerab1792,,1,yofjFQddwHE,1,0,2020-06-24T19:42:19Z,"What if you trained the network on both sets at once, keeping the two different output layers? This way the common net doesn&#39;t get biased towards one set or the other and maybe even generalises better to new data for both sets. Would be like a regularization technique where you update the weights to both fitting on one set and regularizing on the other. If this technique already exists someone please reply, I&#39;d like to see the results and wether it is useful for regularization.",2020-06-24T19:42:19Z
Ugw7LxKb8bA4vm96gwN4AaABAg.9AIcOGJHONC9ApjV3TvOMN,@rogerab1792,Ugw7LxKb8bA4vm96gwN4AaABAg,2,yofjFQddwHE,0,0,2020-07-08T01:38:36Z,multi-task learning,2020-07-08T01:38:36Z
UgzcToG4psJ3SEh1OCl4AaABAg,@manojsriramula2355,,1,yofjFQddwHE,0,0,2020-06-02T11:32:50Z,A big thanks,2020-06-02T11:32:50Z
Ugy3edWK3budC3SXJsZ4AaABAg,@myj313,,1,yofjFQddwHE,0,2,2020-03-17T23:46:22Z,Pretty intuitive. I luv it :),2020-03-17T23:46:22Z
UgzKuufG5bEEmNRwKHx4AaABAg,@xDevoneyx,,1,yofjFQddwHE,0,1,2020-03-12T09:30:50Z,"Assuming in this example, because it is about images, we are talking about neural networks with convolution layers, right? Then I think of the visualizations of the filters in the convolution layers. And I do not understand how images of cats, have similar structures to images of cells/tissue/bones in radiology. I can imagine that a network which is trained on lots of pictures of pebbles could help pre-training for images of cell tissue, because of the somewhat similar circular/elliptical structure. Could you comment on this?<br><br>Another thing I am confused about is that you mention you could only retrain the last layer. Typically in a convnet this is a dense layer. Does that mean that there are cases in which no convolution layers are retrained, yet the network is effective in predicting types of images it have never seen, by just retraining the dense layer?<br><br><br>Thanks for the video, much appreciated!",2020-03-12T09:31:39Z
Ugw45ZkY3O5ws2KiRih4AaABAg,@sehaba9531,,1,yofjFQddwHE,0,5,2020-02-04T17:33:17Z,"Very clear and simple explanation, thank you so much",2020-02-04T17:33:17Z
Ugz1pacVExTcWlFOr_V4AaABAg,@shahi_gautam,,1,yofjFQddwHE,1,0,2019-08-04T20:12:37Z,can we use the concept of transfer learning on SVM?,2019-08-04T20:12:37Z
Ugz1pacVExTcWlFOr_V4AaABAg.8yDpVlZRDbc9-WunjRwL46,@linachato5817,Ugz1pacVExTcWlFOr_V4AaABAg,2,yofjFQddwHE,0,2,2019-09-30T23:07:15Z,"Yes, you can use the pre-trained model for feature extraction and then use the features matrix in training SVM, NN,....",2019-09-30T23:07:15Z
UgxfVF2-WVTuxRMpd4B4AaABAg,@shashanksharma7202,,1,yofjFQddwHE,1,0,2019-05-13T07:00:58Z,"How to handle input data if the aspect ratio of pre-trained models are different than input images?? for example, Say aspect ratio for Task A image recognition is 224 x 224 and aspect ratio for Task B diagnosis is 250 x 125",2019-05-13T07:00:58Z
UgxfVF2-WVTuxRMpd4B4AaABAg.8urgvuwOF6l9-WvBAVPc6s,@linachato5817,UgxfVF2-WVTuxRMpd4B4AaABAg,2,yofjFQddwHE,0,1,2019-09-30T23:10:35Z,"by resizing the dataset (scaling or crop). if opposite  situation, you can add a border to each image!",2019-09-30T23:10:35Z
UgyAyfWdVnC4JBWxKCx4AaABAg,@MOHSINALI-bk2qo,,1,yofjFQddwHE,0,1,2019-03-13T14:21:18Z,thank you sir,2019-03-13T14:21:18Z
Ugyf8xUH3KtlCVbXGet4AaABAg,@rogerab1792,,1,yofjFQddwHE,0,2,2019-03-12T19:46:27Z,"Transfer learning is the key to AGI, once a Neural Network learns the patterns of logical relationships and it is able to transfer that learning and apply it to new problems an AI will be able to draw intelligent conclusions. All that is needed is an AI that picks patterns in logical problems and learns from it&#39;s conclusions, once it has learned it needs to pick similarities between new problems and the old already solved ones to transfer it&#39;s neural pathways but also COMBINE them to deduct new conclusions( combine them taking into consideration the problem that is being aimed to solve ), conclusions which will be useful to solve new problems and so on... ( The key concept here is to find a way to &#39;COMBINE&#39; trained neural nets to build newer, smarter and more general ones, an AI should be trained to learn to combine specific neural nets to solve new problems related to the ones already solved, then use that AI that combines pathways to assist in the combination of neural nets for different problems, combining not only neural nets themselves but the neural nets that were used to combine nets in the past to create better more general combinations of nets ). All this will keep building on itself and AGI will become more capable faster and faster as time passes by.",2019-03-12T19:46:27Z
Ugxm51aRa3s05nXlq0d4AaABAg,@spacecapitalism7152,,1,yofjFQddwHE,2,18,2018-11-27T14:30:55Z,"Video is done at <a href=""https://www.youtube.com/watch?v=yofjFQddwHE&amp;t=1m25s"">1:25</a> Lol!! he explained it so simply.",2018-11-27T14:30:55Z
Ugxm51aRa3s05nXlq0d4AaABAg.8o9UfOX6_2i9Jmv6_xGnz0,@trexmidnite,Ugxm51aRa3s05nXlq0d4AaABAg,2,yofjFQddwHE,0,0,2021-02-15T16:04:56Z,Maybe your brain is full at that,2021-02-15T16:04:56Z
Ugxm51aRa3s05nXlq0d4AaABAg.8o9UfOX6_2i9KgfsYEMpCt,@MrZouzan,Ugxm51aRa3s05nXlq0d4AaABAg,2,yofjFQddwHE,0,1,2021-03-10T02:27:46Z,@@trexmidnite rude,2021-03-10T02:27:46Z
UgwwnBhpvefShT_T8qJ4AaABAg,@nands4410,,1,yofjFQddwHE,0,2,2018-10-27T17:34:18Z,amazing!,2018-10-27T17:34:18Z
Ugw2KTXorPUjF5jXjm54AaABAg,@mdasadullahturja1481,,1,yofjFQddwHE,0,3,2018-06-14T19:52:45Z,Great explanation !!,2018-06-14T19:52:45Z
Ugy0iiBWj0eFIEzmBLp4AaABAg,@raulmaldonado3477,,1,yofjFQddwHE,2,7,2018-03-31T20:18:25Z,is this video part of a bigger course?,2018-03-31T20:18:25Z
Ugy0iiBWj0eFIEzmBLp4AaABAg.8eTYrbtRAu58eZICi332sc,@dtienloi,Ugy0iiBWj0eFIEzmBLp4AaABAg,2,yofjFQddwHE,0,0,2018-04-03T01:48:19Z,Raul Maldonado yes,2018-04-03T01:48:19Z
Ugy0iiBWj0eFIEzmBLp4AaABAg.8eTYrbtRAu58iaAamtZpDG,@AnshumanKumar007,Ugy0iiBWj0eFIEzmBLp4AaABAg,2,yofjFQddwHE,0,1,2018-07-12T05:25:54Z,It&#39;s a part of the course on Coursera,2018-07-12T05:25:54Z
UgwF5rXmjVfnTl7l0rp4AaABAg,@muhammadal-qurishi252,,1,UdXfsAr4Gjw,1,1,2023-07-18T16:25:47Z,"What have been explained in this video is not a multi-task, it seems to be a multi classification. In the following link you will find the correct explanation of multi-task learning.<br><a href=""https://www.youtube.com/watch?v=Tjtzml4PQWE"">https://www.youtube.com/watch?v=Tjtzml4PQWE</a>",2023-07-18T16:25:47Z
UgwF5rXmjVfnTl7l0rp4AaABAg.9sJbPpQOX7d9wascbhbVIy,@AG-sj6ll,UgwF5rXmjVfnTl7l0rp4AaABAg,2,UdXfsAr4Gjw,0,0,2023-11-02T04:48:07Z,Second this.,2023-11-02T04:48:07Z
UgwZ7bI2QiiyLnnZnTh4AaABAg,@CC-uk5bv,,1,UdXfsAr4Gjw,1,0,2021-12-06T10:52:43Z,"I don&#39;t understand @<a href=""https://www.youtube.com/watch?v=UdXfsAr4Gjw&amp;t=8m47s"">8:47</a>. So suppose each task have 1000 examples, why would the previous 99000 samples help the last one? These are different Xs, Ys. The samples are independent. How would labels in previous 99 tasks help the final one? You won&#39;t even have the label for the last class.",2021-12-06T10:52:43Z
UgwZ7bI2QiiyLnnZnTh4AaABAg.9VbO54DCzTc9hLh1R3H5ww,@lucianoinso,UgwZ7bI2QiiyLnnZnTh4AaABAg,2,UdXfsAr4Gjw,0,0,2022-10-19T02:08:01Z,"Hi, if I understood correctly, assuming we are starting the training from 0, supposing it&#39;s a neural network that does image classification, the previous 99 tasks with 99000 samples could help on improving the convolutional layers of the network, the one&#39;s that are in charge of feature extraction (like detecting edges, horizontal lines and so forth) so the advantage would come from learning to interpret the basic geometries of images in general, and then you could change the final layer so it detects whatever you wish, taking advantage of that acquired knowledge, it would be similar as in transfer learning,  my interpretation might be wrong tho but hope it helps.",2022-10-19T02:08:01Z
UgyM7xsgl4R6uGITkQV4AaABAg,@peregudovoleg,,1,UdXfsAr4Gjw,0,0,2021-11-18T11:14:59Z,This and a few other videos in week 2 are gone from coursera.,2021-11-18T11:14:59Z
UgxCvj07SMsqBW0LhvF4AaABAg,@Pratapsingh-ng7pr,,1,UdXfsAr4Gjw,0,0,2021-09-16T03:23:48Z,i am fed up with GreatLearning ads specially with kumar mutthuraman üòÇüòÇ,2021-09-16T03:23:48Z
Ugw_y7kelo93qQ5eZUF4AaABAg,@nurnafiiyah,,1,UdXfsAr4Gjw,0,0,2021-09-10T11:22:57Z,terima kasih banyak atas ilmu yang telah dijelaskan,2021-09-10T11:22:57Z
UgyYaBJE81RgRWspIqN4AaABAg,@lifeonahilltop,,1,UdXfsAr4Gjw,2,1,2021-07-13T07:35:18Z,"At the end of the video, it was said that transfer learning is used much more often than multitask learning. But I feel like wherever transfer learning is applied, multitask learning can be applied too. For example, if you have a large and a small dataset, instead of training a model on the large dataset and transferring it to the small dataset, why not do multitask learning on them both? The resulting model should be better than the one using transfer learning, right (especially given the commonality of good performance using multitask learning mentioned in the video)?",2021-07-13T07:35:18Z
UgyYaBJE81RgRWspIqN4AaABAg.9Pj5RSegs_Y9Pj5t3elM4e,@lifeonahilltop,UgyYaBJE81RgRWspIqN4AaABAg,2,UdXfsAr4Gjw,0,1,2021-07-13T07:39:13Z,"Ah okay, maybe the model trained on both using multitask learning would not be better than the one trained through transferring from the large to the small dataset *for the small dataset*, because in the latter case the training is targeted at the small dataset while the former is targeted at both...",2021-07-13T07:39:37Z
UgyYaBJE81RgRWspIqN4AaABAg.9Pj5RSegs_Y9pxOWkKeLyq,@rasulosmanbeyli35,UgyYaBJE81RgRWspIqN4AaABAg,2,UdXfsAr4Gjw,0,0,2023-05-20T22:59:04Z,"Actually, this is true but in this case, you need to train the model on the whole dataset again. So, imagine you have 1 million images of cats, dogs and etc. and 1 thousand x-ray images. You would need to train your model using multitask learning on the 1 million and 1 thousand total images. And it will take a lot of time",2023-05-20T22:59:04Z
UgzkVBJJM2rMM3bgwAp4AaABAg,@fikadumlakumlaku819,,1,UdXfsAr4Gjw,0,0,2021-06-19T12:23:25Z,can help show how practical implement in python,2021-06-19T12:23:25Z
Ugw3oS_nfcUovtldHA94AaABAg,@apixpa1478,,1,UdXfsAr4Gjw,0,0,2021-04-06T13:45:15Z,Ïù¥Í≤å Î©ÄÌã∞ÌÉúÏä§ÌÅ¨ Îü¨ÎãùÏù¥ÎùºÍ≥†?;;;;;;;; Î≠îÍ∞Ä Ïù¥ÏÉÅÌïúÎç∞,2021-04-06T13:45:15Z
UgzBYFU3SW3AXmcq0Vx4AaABAg,@domg4743,,1,UdXfsAr4Gjw,0,7,2021-02-15T01:55:52Z,Such a relaxing voice,2021-02-15T01:55:52Z
UgzXnDJC1-AlcLisG654AaABAg,@jeffgalef121,,1,UdXfsAr4Gjw,2,0,2020-08-31T20:18:48Z,Which type of activation function is used to get the 1&#39;s and 0&#39;s for the final layer?,2020-08-31T20:18:48Z
UgzXnDJC1-AlcLisG654AaABAg.9D1mby0JCYz9DIrrWD8EGb,@aayushpaudel2379,UgzXnDJC1-AlcLisG654AaABAg,2,UdXfsAr4Gjw,0,0,2020-09-07T11:31:42Z,sigmoid,2020-09-07T11:31:42Z
UgzXnDJC1-AlcLisG654AaABAg.9D1mby0JCYz9DYw_Eg5Lwa,@sadokziwziw,UgzXnDJC1-AlcLisG654AaABAg,2,UdXfsAr4Gjw,0,0,2020-09-13T17:20:45Z,"@jeff Galef usually a sigmoid, so we can interpret it as P(y/x)",2020-09-13T17:20:45Z
UgyeH6Eh1KzADQ46rW54AaABAg,@user-zg6nm3bu4e,,1,UdXfsAr4Gjw,0,9,2020-07-29T05:39:54Z,ÌïúÍµ≠Ïñ¥ ÏûêÎßâ Îã¨ÏïÑÏ£ºÏã†Î∂Ñ Ï†ïÎßê Í∞êÏÇ¨ÎìúÎ¶ΩÎãàÎã§ (_ _ ),2020-07-29T05:39:54Z
Ugx2pHXQXhBD8KthjK54AaABAg,@baqirhusain5652,,1,UdXfsAr4Gjw,1,15,2020-04-29T06:26:47Z,There must be a place dedicated in heaven ...... I pray for your long happy health life..... I loveeee uuuuuu.....Its decided..... i am going to put his picture in my room......,2020-04-29T06:26:47Z
Ugx2pHXQXhBD8KthjK54AaABAg.981-p_hh6v49C_wgoO8bFS,@hananemeftahi202,Ugx2pHXQXhBD8KthjK54AaABAg,2,UdXfsAr4Gjw,0,2,2020-08-20T15:28:52Z,Lol i&#39;m goind to do the same thing üòÇüòÇ,2020-08-20T15:28:52Z
UgzFL7HymojFN-ht7UF4AaABAg,@DistortedV12,,1,UdXfsAr4Gjw,1,0,2020-04-16T05:46:15Z,Can&#39;t you do transfer learning in text with multi-task learning?,2020-04-16T05:46:15Z
UgzFL7HymojFN-ht7UF4AaABAg.97VSrGeNaaD98Xljne-vfO,@vinayaksingh9639,UgzFL7HymojFN-ht7UF4AaABAg,2,UdXfsAr4Gjw,0,0,2020-05-11T23:49:51Z,"Yes here is an example - <a href=""https://www.youtube.com/watch?v=KUGGuJ0aTL8"">https://www.youtube.com/watch?v=KUGGuJ0aTL8</a>",2020-05-11T23:49:51Z
UgzgLAZdLDQErOZ5kOF4AaABAg,@internationalscholarhw,,1,UdXfsAr4Gjw,0,1,2020-02-15T09:13:33Z,Good üëç,2020-02-15T09:13:33Z
UgzdncGmT389eMvObvV4AaABAg,@jonatan01i,,1,UdXfsAr4Gjw,0,2,2020-01-21T16:26:00Z,"So this is Binary classification.<br>I would say that Multitask Learning is when you train a network with multiple tasks to solve like Classification, Detection, Segmentation and anything you might think of.",2020-01-21T16:26:00Z
UgzmFjbkXK6VQbQgUc54AaABAg,@phuccoiinkorea3341,,1,UdXfsAr4Gjw,2,0,2019-12-15T11:03:39Z,"Can we have multiple &quot;x&quot; at <a href=""https://www.youtube.com/watch?v=UdXfsAr4Gjw&amp;t=2m24s"">2:24</a>?",2019-12-15T11:03:39Z
UgzmFjbkXK6VQbQgUc54AaABAg.92ZJPPXko6n92ksSr9HIIG,@vikashkumar-sk7ng,UgzmFjbkXK6VQbQgUc54AaABAg,2,UdXfsAr4Gjw,0,0,2019-12-20T08:09:35Z,"No, at a time only one x is input data to the neural networks. Mukti label can be present in that input, maximum 4 in this case. Like that there will be m such input x that&#39;s why we got output as 4*m",2019-12-20T08:09:35Z
UgzmFjbkXK6VQbQgUc54AaABAg.92ZJPPXko6n9JFCC16f4nE,@XX-vu5jo,UgzmFjbkXK6VQbQgUc54AaABAg,2,UdXfsAr4Gjw,0,0,2021-02-02T04:29:33Z,Use more than one network if you want more x instances at the same time. LOL,2021-02-02T04:29:33Z
UgxRNtmsn8obnbHTSqd4AaABAg,@jeanchindeko5477,,1,UdXfsAr4Gjw,0,4,2019-12-03T16:46:20Z,Is it possible to combine both?,2019-12-03T16:46:20Z
Ugxroix5RDP-nCX6aOV4AaABAg,@karthicharish2027,,1,UdXfsAr4Gjw,3,0,2019-07-01T13:33:37Z,what do i and j represent?,2019-07-01T13:33:37Z
Ugxroix5RDP-nCX6aOV4AaABAg.8wqZogII7VP8x5-jzBAF26,@michaelg3573,Ugxroix5RDP-nCX6aOV4AaABAg,2,UdXfsAr4Gjw,0,1,2019-07-07T13:26:15Z,they don&#39;t really represent anything. they&#39;re just used to loop through all the training examples ( i ) and the output variable that contains the presence/absence of the four objects ( j ),2019-07-07T13:26:15Z
Ugxroix5RDP-nCX6aOV4AaABAg.8wqZogII7VP8x6PxL9IHgB,@karthicharish2027,Ugxroix5RDP-nCX6aOV4AaABAg,2,UdXfsAr4Gjw,0,0,2019-07-08T02:34:30Z,"@@michaelg3573 got it, thank you!",2019-07-08T02:34:30Z
Ugxroix5RDP-nCX6aOV4AaABAg.8wqZogII7VP9VsBK93QopA,@todneubig4829,Ugxroix5RDP-nCX6aOV4AaABAg,2,UdXfsAr4Gjw,0,0,2021-12-12T23:28:16Z,bruh...,2021-12-12T23:28:16Z
UgwYMwMX8HiF9D-hizV4AaABAg,@jameshuang2677,,1,ImUoubi_t7s,1,10,2020-07-13T07:50:21Z,Rest of the world: Asians look the same<br>Asia: Facial Recognition tech,2020-07-13T07:50:21Z
UgwYMwMX8HiF9D-hizV4AaABAg.9B2H0DLYX7H9Nu6VJnB7ep,@goksuceylan8844,UgwYMwMX8HiF9D-hizV4AaABAg,2,ImUoubi_t7s,0,0,2021-05-28T21:13:26Z,All same except Jackie Chan,2021-05-28T21:13:26Z
UgyN8hy0LyHiGfDnkCh4AaABAg,@lizijian7090,,1,ImUoubi_t7s,2,2,2019-07-04T12:51:08Z,Baidu is so going to fail. All its world-topest level scientists are leaving....,2019-07-04T12:51:08Z
UgyN8hy0LyHiGfDnkCh4AaABAg.8wyDL91cZCk8xeMO6u5AI6,@-long-,UgyN8hy0LyHiGfDnkCh4AaABAg,2,ImUoubi_t7s,0,17,2019-07-21T16:16:46Z,"If you come to this video to learn then stick your ass to the chair and learn, don&#39;t pretend to be omniscient. Having hard time away from keyboard?",2019-07-21T16:16:46Z
UgyN8hy0LyHiGfDnkCh4AaABAg.8wyDL91cZCk9M2H_dIVtNB,@dkoli,UgyN8hy0LyHiGfDnkCh4AaABAg,2,ImUoubi_t7s,0,0,2021-04-12T17:40:39Z,@@-long- Triggered much lol,2021-04-12T17:40:39Z
UgxX3eCJT5BzP2tlrn94AaABAg,@ericxu7681,,1,ImUoubi_t7s,0,5,2019-06-22T19:43:18Z,The face is so cute hhhhhh,2019-06-22T19:43:18Z
UgzLOh8paR4v6-tnxvN4AaABAg,@timothywang9709,,1,ImUoubi_t7s,0,0,2019-03-24T06:56:23Z,brilliant,2019-03-24T06:56:23Z
UgyCOFRJExMNs5ktSux4AaABAg,@tathagatverma1806,,1,ImUoubi_t7s,0,13,2018-12-24T05:08:39Z,"&quot;crime scene investigation task&quot; xD  @ <a href=""https://www.youtube.com/watch?v=ImUoubi_t7s&amp;t=9m42s"">9:42</a>",2018-12-24T05:08:39Z
UgwmRVrIUb6kQlzbcVJ4AaABAg,@tiesetsomatsipa5402,,1,l_-CUyEx_x4,0,0,2023-09-21T15:54:44Z,"It seems Tesla has achieved this end to end deep learning on their FSD V12 because of having the abundance of video data.<br><br>Replying to time stamp - <a href=""https://www.youtube.com/watch?v=l_-CUyEx_x4&amp;t=09m02s"">09:02</a><br><br>Because of this milestone achievement, I tend to believe most if not all automobile companies will start to install lots of cameras in their cars, from the cheapest to the most expensive, just to collect video data for their own autopilot technologies.<br><br>Just my speculation: Probably by 2025 or 2026, Tesla would have reached and shipped their level 5 autopilot version.",2023-09-21T15:54:44Z
UgyWBabASXWlkgTZxOV4AaABAg,@osiris1102,,1,l_-CUyEx_x4,0,8,2021-06-02T13:47:01Z,"<a href=""https://www.youtube.com/watch?v=l_-CUyEx_x4&amp;t=1m06s"">1:06</a> Andrew roasts all linguists üòÇ",2021-06-02T13:48:03Z
Ugx5f6iAldu_Itd6qTN4AaABAg,@aayushpaudel2379,,1,l_-CUyEx_x4,0,0,2020-09-07T12:44:47Z,"<a href=""http://drive.ai/"">drive.ai</a> is his wifey company, I reckon!",2020-09-07T12:44:47Z
Ugyj2tcSJrqxR_WtLqB4AaABAg,@brijeshvishwakarma9509,,1,l_-CUyEx_x4,0,6,2020-06-25T19:45:29Z,"This series of lectures have certainly  answered some of my doubts and taught me some of important tips and tricks to deal with your model and your data, thanks for all this.",2020-06-25T19:45:29Z
UgyXXrLhCq5Y83v0zNh4AaABAg,@TheDukeGreat,,1,l_-CUyEx_x4,2,3,2019-08-26T01:48:21Z,"Phonemes are not just a linguist&#39;s dream, there are languages that have alphabets fully based on phonemes. Example is Serbian, where every letter is one phoneme, so when you write something in Serbian i.e. Novak ƒêokoviƒá, if you learn Serbian alphabet, you can easily pronounce it, and pronounce any word in Serbian that you want.",2019-08-26T01:48:21Z
UgyXXrLhCq5Y83v0zNh4AaABAg.8z4Vc7AUiPt98ySbqLW-PO,@sidesplitter9497,UgyXXrLhCq5Y83v0zNh4AaABAg,2,l_-CUyEx_x4,0,3,2020-05-22T17:52:45Z,I think the point is that phonemes are just the way our brain&#39;s work and not necessarily applicable to machine learning models,2020-05-22T17:52:45Z
UgyXXrLhCq5Y83v0zNh4AaABAg.8z4Vc7AUiPt9EJzCkEN0kT,@siddhantpathak3162,UgyXXrLhCq5Y83v0zNh4AaABAg,2,l_-CUyEx_x4,0,1,2020-10-02T18:26:32Z,"Bruh !! also, almost every Indian language and dialect (1600 +) is based on phonemes",2020-10-02T18:46:51Z
UgzZmVQ0BqcEeoqGExB4AaABAg,@yongz3493,,1,l_-CUyEx_x4,1,0,2019-01-12T03:24:33Z,I am thinking about how to combine learning from raw data and hand-design features to achieve better performances ...,2019-01-12T03:24:33Z
UgzZmVQ0BqcEeoqGExB4AaABAg.8pzjyyNz1Wu9-H86PnkMge,@Predatorgrr,UgzZmVQ0BqcEeoqGExB4AaABAg,2,l_-CUyEx_x4,0,5,2019-09-24T20:04:25Z,why would you even put that in a comment?,2019-09-24T20:04:25Z
Ugz-__20r8Jr2vV030l4AaABAg,@anushka.narsima,,1,1waHlpKiNyY,0,1,2023-06-20T05:50:41Z,Thank you so much sir! I&#39;m running a study group on DL &amp; your teaching is how I&#39;m managing it!,2023-06-20T05:50:41Z
UgyRXtpkfDOnx_YWRr54AaABAg,@bbayat4093,,1,1waHlpKiNyY,1,0,2022-06-25T23:38:53Z,"Let me give you some feedback Teaching is like giving directions. You can use longitude and latitude measurements to give directions as well as nautical coordinates, but this is useless for novices such as me. Your english for teaching is too technical. I fell asleep. You need to tell a story if you want me to learn. If you wanna show me how much YOU know then continue with your current method.",2022-06-25T23:38:53Z
UgyRXtpkfDOnx_YWRr54AaABAg.9ciJYWSsSXG9vI6chBSkty,@2Abdullah,UgyRXtpkfDOnx_YWRr54AaABAg,2,1waHlpKiNyY,0,0,2023-09-30T16:02:59Z,"He did give the information in story like way. You didn&#39;t bother to listen to his previous course which is for &quot;novices&quot; such as yourself. So not only is your &quot;advice&quot; useless but it&#39;s also wrong. This is obvious from the like dislike ratio too, clowns such as yourself are very few in number thankfully.",2023-09-30T16:02:59Z
UgxYAVQyAtkk4D1JN-94AaABAg,@codewithmorris6492,,1,1waHlpKiNyY,0,0,2021-02-19T08:54:02Z,great explanation,2021-02-19T08:54:02Z
Ugy1fmCjwlswpDPsPCB4AaABAg,@noorameera26,,1,1waHlpKiNyY,0,3,2021-02-07T06:08:51Z,Thank you so much Mr Andrew!!!!,2021-02-07T06:09:01Z
Ugzc-9Z4zRqNwx4E5Yx4AaABAg,@sandipansarkar9211,,1,1waHlpKiNyY,0,0,2021-01-01T16:28:45Z,Great ecplanamtion.Need to watch again,2021-01-01T16:28:45Z
UgwQRdZKbWBeduvKim54AaABAg,@exampreparationonline4166,,1,1waHlpKiNyY,0,9,2020-07-23T07:45:13Z,"Summarization based on understanding<br><br>70% to 30% train to test division<br><br>or 60-20-20 (train, test, validation)<br><br>for big data we may consider the ratio to be 98 / 1 / 1 for millions of data<br><br>Dev and training set come from the same distribution, i.e. for cat image classification, the mismatch is when the training set is considered from the web, which has much higher resolution, whereas the test set is from mobile camera taken in casual mode",2020-07-23T07:45:13Z
UgwrBNhR_nWNG8Eipu54AaABAg,@rvg296,,1,1waHlpKiNyY,1,0,2020-04-22T21:20:02Z,"Where can we get the course slides? I looked for them in Coursera while auditing the course, but couldn&#39;t find lecture notes slides. Anyone have them?",2020-04-22T21:20:02Z
UgwrBNhR_nWNG8Eipu54AaABAg.97l_UqcUWOF98BNTNUeOvP,@pranavanand2399,UgwrBNhR_nWNG8Eipu54AaABAg,2,1waHlpKiNyY,0,0,2020-05-03T07:05:44Z,you find that when click on the download button in pdf or pptx format,2020-05-03T07:05:44Z
Ugy0Ql9gcFvvABZmkvR4AaABAg,@DeepLearninginHindi,,1,1waHlpKiNyY,0,30,2019-09-16T15:11:05Z,Thanks Andrew for making such wonderful courses available online for free!,2019-09-16T15:11:05Z
Ugx8BBL_hxYiBFQz0Ll4AaABAg,@tableauvizwithvineet148,,1,1waHlpKiNyY,2,1,2018-11-21T16:27:20Z,it means that Dev set can be used for training the model also?,2018-11-21T16:27:20Z
Ugx8BBL_hxYiBFQz0Ll4AaABAg.8nvFDmEMK058uLwjMNSWjS,@susnatodhar7197,Ugx8BBL_hxYiBFQz0Ll4AaABAg,2,1waHlpKiNyY,0,1,2019-04-30T13:44:07Z,"Yes you should use them if you have multiple models and you want to select the best one ,I think that you should use give more priority to Dev set than test set",2019-04-30T13:44:07Z
Ugx8BBL_hxYiBFQz0Ll4AaABAg.8nvFDmEMK058x4YA_UZ2ia,@m4ng4n,Ugx8BBL_hxYiBFQz0Ll4AaABAg,2,1waHlpKiNyY,0,9,2019-07-07T09:07:52Z,"Late but better than never: NO, you only train models on the train set. Say you trained 50 different models on the train set, you keep the one with the best performance on validation/dev set (only forward pass and calculation of Cost function, no learning). Once you have the final model, you evaluate it on the test set and keep that performance as the unbiased estimator of how good it is.",2019-07-07T09:07:52Z
Ugwh4_idxvEInKKS0CZ4AaABAg,@kuettanoydebnath1887,,1,1waHlpKiNyY,2,3,2018-08-07T06:32:49Z,"do you please upload the video of Sequence Models (Course 5),sir?? please ,,it will be a great help..",2018-08-07T06:33:10Z
Ugwh4_idxvEInKKS0CZ4AaABAg.8jdEvgDalUl9BlGyuxaaNE,@youroldman8129,Ugwh4_idxvEInKKS0CZ4AaABAg,2,1waHlpKiNyY,0,3,2020-07-31T04:35:06Z,If there are any missing videos on YouTube these courses are also on Coursera. I believe you can do a course audit to view the videos for free there; you just have to pay if you want to take the tests and get certified through the site.,2020-07-31T04:35:06Z
Ugwh4_idxvEInKKS0CZ4AaABAg.8jdEvgDalUl9YeUT6eDSZo,@viv30406,Ugwh4_idxvEInKKS0CZ4AaABAg,2,1waHlpKiNyY,0,0,2022-02-20T05:20:20Z,"<a href=""https://youtube.com/playlist?list=PL1w8k37X_6L_s4ncq-swTBvKDWnRSrinI"">https://youtube.com/playlist?list=PL1w8k37X_6L_s4ncq-swTBvKDWnRSrinI</a>",2022-02-20T05:20:20Z
UgyM5EZBRgFYtwPQe1F4AaABAg,@kaitaoyang15,,1,1waHlpKiNyY,0,0,2018-04-18T20:07:04Z,"Monthly Deep Learning training in the Netherlands. Early birds get 85% OFF. Please sign up from here: <a href=""https://dlapplied.com/training-history-deep-learning/"">https://dlapplied.com/training-history-deep-learning/</a>",2018-04-18T20:07:04Z
Ugz5xkAgEWU0M8ST2OJ4AaABAg,@akashdas3446,,1,1waHlpKiNyY,2,3,2017-10-01T08:15:53Z,sir cau you please upload videos on Maximum Likelihood estimation,2017-10-01T08:15:53Z
Ugz5xkAgEWU0M8ST2OJ4AaABAg.8YACIEohQNA8aXwxxeU1mI,@kunhongyu5053,Ugz5xkAgEWU0M8ST2OJ4AaABAg,2,1waHlpKiNyY,0,0,2017-12-24T03:09:07Z,"See this lecture notes:<a href=""http://cs229.stanford.edu/notes/cs229-notes1.pdf"">http://cs229.stanford.edu/notes/cs229-notes1.pdf</a>",2017-12-24T03:09:07Z
Ugz5xkAgEWU0M8ST2OJ4AaABAg.8YACIEohQNA8enDmIYSgjm,@suharsh96,Ugz5xkAgEWU0M8ST2OJ4AaABAg,2,1waHlpKiNyY,0,0,2018-04-08T20:58:14Z,mechanical se CS mein kaise bro ?,2018-04-08T20:58:14Z
Ugz4Pp8cbWXZwgVIYmR4AaABAg,@lafcadiothelion,,1,SjQyLhQIXSM,0,0,2023-12-10T18:11:44Z,The audio hurts my ears.,2023-12-10T18:11:44Z
Ugw8igu_kQNRRbS0rmR4AaABAg,@khaledsrrr,,1,SjQyLhQIXSM,0,0,2023-06-12T11:30:20Z,The best and easiest explanation of bias variance tradeoff ‚ù§‚ù§,2023-06-12T11:30:20Z
Ugyw4Bd4NQUBl3qo6eN4AaABAg,@plttji2615,,1,SjQyLhQIXSM,0,0,2022-01-03T17:28:51Z,"Thank you for the video, can you help me how to prove that is unbiased in this question? Question: Compare the average height of employees in Google with the average height in the United States, do you think it is an unbiased estimate? If not, how to prove it is not matched?",2022-01-03T17:28:51Z
UgyCYa02bpfmMurdWDd4AaABAg,@feedtowin1309,,1,SjQyLhQIXSM,0,0,2021-12-11T09:01:26Z,"Thank you so much for your content, sir.",2021-12-11T09:01:26Z
UgxTXUEH_9Ifddfav1N4AaABAg,@poojakabra1479,,1,SjQyLhQIXSM,0,0,2021-10-21T00:01:50Z,You are God,2021-10-21T00:01:50Z
Ugxlzd_wlnHEw2zrupN4AaABAg,@hamzaamjad699,,1,SjQyLhQIXSM,0,22,2021-01-31T08:33:17Z,High bias----&gt; underfitting -----&gt; More train set error<br>High variance -----&gt; overfitting -----&gt; More dev set error,2021-06-13T14:26:07Z
UgwNvEAMyIE1YqUJ3Fd4AaABAg,@Sam-ne9ns,,1,SjQyLhQIXSM,0,3,2021-01-07T15:46:50Z,What is this mess?! You actually charge people for this crap?!!!,2021-01-07T15:46:50Z
Ugw61aqz_VBBmBJkweF4AaABAg,@sandipansarkar9211,,1,SjQyLhQIXSM,0,0,2020-12-29T14:08:36Z,Very nice explanation .Need to watch again,2020-12-29T14:08:36Z
Ugyqqqx4YGdDLdbe-Id4AaABAg,@exampreparationonline4166,,1,SjQyLhQIXSM,0,6,2020-07-23T07:50:42Z,"In Deep learning era, we can overcome the bias-variance trade-off<br><br><b>*bias variance trade-off*</b><br>the¬†‚Äì¬†is the property of a set of predictive models whereby models with a lower¬†¬†in parameter estimation have a higher¬†<br><br><br><br>¬†<br><br><b>*high variance *</b><br><br>when there is a huge difference between training set error and validation error<br><br>train : 1% error<br><br>dev / test : 11 % error<br><br><b>*high bias*</b><br><br>when the training set error doesn&#39;t even results in proper classification, maybe particular class is being predicted more i.e. false positive<br><br>train : 15%<br><br>dev : 16%<br><br><b>*high bias and high variance*</b><br><br>when the error on training set is poor, and there is a huge difference between training and validation error<br><br>train : 15%<br><br>dev : 30 %<br><br> <br><br><b>*low bias and low variance*</b><br><br>when both the error on training set and validation set is less<br><br>train : 1%<br><br>dev : 2 %",2020-07-23T07:56:48Z
UgwRu1kyPwFwU4RvNyB4AaABAg,@quietkael7349,,1,SjQyLhQIXSM,2,37,2020-05-22T13:36:31Z,"I think it would be important to explain why the terms ‚Äúbias‚Äù and ‚Äúvariance‚Äù are used to describe these phenomena. Without explaining the context that our overall training algorithm is sampling specific outcome models from a distribution over all possible models that our algorithm might train, it‚Äôs not very clear what insight these terms add beyond the simpler concepts of overfitting and underfitting.",2020-05-22T13:36:31Z
UgwRu1kyPwFwU4RvNyB4AaABAg.98y-I8d0rol99zQ0KgH7xq,@MrCmon113,UgwRu1kyPwFwU4RvNyB4AaABAg,2,SjQyLhQIXSM,0,1,2020-06-16T23:20:39Z,Yeah.<br>What&#39;s central to understanding this is imagining other possible training sets.,2020-06-16T23:20:39Z
UgwRu1kyPwFwU4RvNyB4AaABAg.98y-I8d0rol9FRrv0_kmRS,@bpc1570,UgwRu1kyPwFwU4RvNyB4AaABAg,2,SjQyLhQIXSM,0,2,2020-10-30T16:28:08Z,"What you are describing is related to notion of empirical risk minimization, which is explained in his cs229 class (lec 9 I believe) also searchable from here",2020-10-30T16:28:08Z
UgzJqG1Wq2x3Hv1OPDh4AaABAg,@PabbaANUBHARATH,,1,SjQyLhQIXSM,0,0,2019-09-04T12:48:52Z,wow.  clear explanation,2019-09-04T12:48:52Z
UgxB0CWeKn3JqjUhWGB4AaABAg,@Rkv224,,1,SjQyLhQIXSM,0,8,2019-02-20T08:46:16Z,Thank You very much for making these concepts that easy to understand,2019-02-20T08:46:16Z
UgxT_a7yRurFkCbc_WR4AaABAg,@siabikebenezer,,1,SjQyLhQIXSM,1,1,2018-12-20T15:21:15Z,Please is it possible to calculate bias for the Actual and predicted values,2018-12-20T15:21:15Z
UgxT_a7yRurFkCbc_WR4AaABAg.8p4ni7iiATo8vmLkEjeDfd,@saanvisharma2081,UgxT_a7yRurFkCbc_WR4AaABAg,2,SjQyLhQIXSM,0,0,2019-06-05T01:42:19Z,"Yes we can!!!! <br>I know how to do that in linear regression, but have to relate it with multiple regression/complex algorithms",2019-06-05T01:42:19Z
UgwqC6kfQVkd-BdQQRB4AaABAg,@jorikchamberik4848,,1,SjQyLhQIXSM,3,19,2017-12-08T10:28:52Z,Is the dev set the same as validation set?,2017-12-08T10:28:52Z
UgwqC6kfQVkd-BdQQRB4AaABAg.8_uXZmKOtFF8aF8pkjTiee,@raghavgupta2794,UgwqC6kfQVkd-BdQQRB4AaABAg,2,SjQyLhQIXSM,0,19,2017-12-16T19:56:01Z,"Yes, it&#39;s just another name for validation set",2017-12-16T19:56:01Z
UgwqC6kfQVkd-BdQQRB4AaABAg.8_uXZmKOtFF95rvykeb47r,@paradise_relaxation,UgwqC6kfQVkd-BdQQRB4AaABAg,2,SjQyLhQIXSM,0,0,2020-03-06T15:29:09Z,yes,2020-03-06T15:29:09Z
UgwqC6kfQVkd-BdQQRB4AaABAg.8_uXZmKOtFF99zQEKdDBf5,@MrCmon113,UgwqC6kfQVkd-BdQQRB4AaABAg,2,SjQyLhQIXSM,0,0,2020-06-16T23:22:33Z,"Yes, this applies equally to the test set or some completely external population, though.",2020-06-16T23:22:33Z
UgwaNFhC3jcL1UqWBnx4AaABAg,@retr0foxx_osu,,1,C1N_PDHuJ6Q,0,0,2023-09-10T14:48:28Z,"i get confuse bcz when &quot;bias&quot; i think of &quot;the neural netowrk is <b>biased</b> towards the training dataset&quot; but it not that, that&#39;s variance instead.",2023-09-10T14:48:28Z
UgygeezsKC-ew-nmkml4AaABAg,@ahmedb2559,,1,C1N_PDHuJ6Q,0,0,2023-01-15T11:27:19Z,Thank you !,2023-01-15T11:27:19Z
UgzQx6Jli4Guj-jbIiR4AaABAg,@muhammadahmedshuja4689,,1,C1N_PDHuJ6Q,0,0,2021-10-05T13:16:37Z,Why regularization is only for Overfitting?,2021-10-05T13:16:37Z
UgyZlx6UPAxGkryVGiV4AaABAg,@sandipansarkar9211,,1,C1N_PDHuJ6Q,0,0,2020-12-29T14:19:05Z,great explanation .need to watch again,2020-12-29T14:19:05Z
UgwzmGInWtvkDKjX-iJ4AaABAg,@vincentpun123,,1,C1N_PDHuJ6Q,0,0,2020-08-02T02:58:18Z,Thanks!,2020-08-02T02:58:18Z
UgwdpUhXJ2sfJRJoMDl4AaABAg,@kleemc,,1,C1N_PDHuJ6Q,1,0,2019-03-23T08:51:48Z,What about dropouts?,2019-03-23T08:51:48Z
UgwdpUhXJ2sfJRJoMDl4AaABAg.8so_42W7U2n8zRgHgJdimH,@chancychan7175,UgwdpUhXJ2sfJRJoMDl4AaABAg,2,C1N_PDHuJ6Q,0,0,2019-09-04T01:52:49Z,as well as BN?,2019-09-04T01:52:49Z
Ugy3OWz82hl2jtqLS794AaABAg,@chitralalawat8106,,1,C1N_PDHuJ6Q,2,1,2019-03-20T06:58:40Z,Bigger network doesn&#39;t mean collecting more data?,2019-03-20T06:58:40Z
Ugy3OWz82hl2jtqLS794AaABAg.8sgdjpfScsF8tRFYK9gW-L,@arunsiddharth852,Ugy3OWz82hl2jtqLS794AaABAg,2,C1N_PDHuJ6Q,0,2,2019-04-07T18:42:03Z,It means having more hidden layers and more number of hidden units.,2019-04-07T18:42:03Z
Ugy3OWz82hl2jtqLS794AaABAg.8sgdjpfScsF8tRJPKW-TMO,@chitralalawat8106,Ugy3OWz82hl2jtqLS794AaABAg,2,C1N_PDHuJ6Q,0,0,2019-04-07T19:15:46Z,@@arunsiddharth852 do u know everything about deep learning?,2019-04-07T19:15:46Z
UgzD4bx8UR6tqCIURwp4AaABAg,@Has-01,,1,C1N_PDHuJ6Q,3,1,2018-11-14T15:20:10Z,"at <a href=""https://www.youtube.com/watch?v=C1N_PDHuJ6Q&amp;t=0m54s"">0:54</a>, What does &quot;training longer&quot; mean?",2018-11-14T15:20:10Z
UgzD4bx8UR6tqCIURwp4AaABAg.8nd5ycIzotf8opWoLDTROe,@muhammadsohaildanish3832,UgzD4bx8UR6tqCIURwp4AaABAg,2,C1N_PDHuJ6Q,0,1,2018-12-14T07:36:58Z,I think it means increasing the number of iterations while training the model,2018-12-14T07:36:58Z
UgzD4bx8UR6tqCIURwp4AaABAg.8nd5ycIzotf8r8HaHY5oPk,@nianli2793,UgzD4bx8UR6tqCIURwp4AaABAg,2,C1N_PDHuJ6Q,0,4,2019-02-09T16:51:34Z,You could train on your training data over and over again until a decent training accuracy has reached. Training one entire training data is normally called &quot;an epoch&quot;.,2019-02-09T16:51:34Z
UgzD4bx8UR6tqCIURwp4AaABAg.8nd5ycIzotf95UF2FNDYrg,@anuragpandey9327,UgzD4bx8UR6tqCIURwp4AaABAg,2,C1N_PDHuJ6Q,0,5,2020-02-26T01:23:31Z,"Train longer means increasing the number of times your model gets to see each example during the training process aka increasing epochs. So maybe we are performing poorly on training data because we have not seen training data enough to learn the weights appropriately, so instead of changing the network architecture we just increase number of epochs.",2020-02-26T01:23:31Z
Ugw528w0m5AGimsp0it4AaABAg,@shwethasubbu3385,,1,C1N_PDHuJ6Q,2,0,2018-07-10T17:16:42Z,How does a bigger network reduce bias?,2018-07-10T17:16:42Z
Ugw528w0m5AGimsp0it4AaABAg.8iXIM77wKyR8pq-Khfo7cd,@subhrajitmitra8329,Ugw528w0m5AGimsp0it4AaABAg,2,C1N_PDHuJ6Q,0,4,2019-01-08T08:35:03Z,This might be too late for a reply. But I feel bcoz adding more layers leads to the increase in the complexity of the function that the neural network represents.,2019-01-08T08:35:03Z
Ugw528w0m5AGimsp0it4AaABAg.8iXIM77wKyR8r8Hwb8iAEz,@nianli2793,Ugw528w0m5AGimsp0it4AaABAg,2,C1N_PDHuJ6Q,0,4,2019-02-09T16:54:37Z,"High bias causes underfitting, which means your function cannot fit the training data well even you have trained for a long time and you have enough data. Therefore, it has a high probability that the function is not complex enough. By moving to a bigger neural network, you will have a more complex function to fit.",2019-02-09T16:54:37Z
Ugw5rJBgt_e5K7Pmsgt4AaABAg,@RedShipsofSpainAgain,,1,C1N_PDHuJ6Q,1,7,2018-04-01T16:38:11Z,"<a href=""https://www.youtube.com/watch?v=C1N_PDHuJ6Q&amp;t=5m14s"">5:14</a> So basically one advantage of deep learning is that we can have a model with BOTH low bias AND low variance?  We can have our proverbial cake and eat it too?",2018-04-01T16:38:11Z
Ugw5rJBgt_e5K7Pmsgt4AaABAg.8eVjSR1ommh9978fmLG0SI,@ruancomelli,Ugw5rJBgt_e5K7Pmsgt4AaABAg,2,C1N_PDHuJ6Q,0,5,2020-05-26T12:10:55Z,"Actually, many other different machine learning techniques may offer both low bias and low variance if they are fit to your problem. The problem is that, whenever either bias or variance are too high, reducing one of them often means increasing the other. This is the tradeoff. One advantage of deep learning is that you have very simple approaches in which this tradeoff does not happen, or rather is not that bad. For instance, reducing bias can be as simple as adding another dense layer to your net, and preventing an increase in variance can be as simple as adding a regularization layer.",2020-05-26T12:10:55Z
UgwTa6EH1cyHcpt0dDJ4AaABAg,@user-cp5qh5uc9n,,1,6g0t3Phly2M,1,1,2022-02-08T22:35:11Z,"If we add bias regularization, won&#39;t we essentially set it to be equal to zero because it would be the most &#39;optimal&#39; decision in terms of loss minimization?",2022-02-08T22:35:11Z
UgwTa6EH1cyHcpt0dDJ4AaABAg.9YCRM6-58w79u-mkbH3EnW,@swfsql,UgwTa6EH1cyHcpt0dDJ4AaABAg,2,6g0t3Phly2M,0,0,2023-08-29T16:42:50Z,"I think this would be the optimal just in that extra term. But looking at the whole cost function, the optimal may still be for some non-zero bias.",2023-08-29T16:42:50Z
UgwRsAfvpxVgCwAdUhV4AaABAg,@brodie_brodes,,1,6g0t3Phly2M,1,0,2021-07-21T19:03:30Z,"What is the mathematical term and meaning for the funny looking R symbol at <a href=""https://www.youtube.com/watch?v=6g0t3Phly2M&amp;t=1m08s"">1:08</a>?",2021-07-21T19:03:30Z
UgwRsAfvpxVgCwAdUhV4AaABAg.9Q3vYroTBGA9QctQsuigon,@almoni127,UgwRsAfvpxVgCwAdUhV4AaABAg,2,6g0t3Phly2M,0,0,2021-08-04T18:17:35Z,The set of real numbers. b is a real numbers and w is a vector of real numbers.,2021-08-04T18:17:35Z
Ugxr7IBuLQ_b8UjVei14AaABAg,@sayantanmazumdar9371,,1,6g0t3Phly2M,1,0,2021-03-30T05:54:54Z,"Doubt :-<br><br>If there was l1 regularization, then would the formula be <br><br>dwl=dwl+(lambda/2m) * (wl)/(|wl)<br><br>I think my answers would be right  as per the derivatives , but i still l want to check it . Can someone help me out ?",2021-03-30T10:11:09Z
Ugxr7IBuLQ_b8UjVei14AaABAg.9LVYU7QEJJ99u-nIOawf0L,@swfsql,Ugxr7IBuLQ_b8UjVei14AaABAg,2,6g0t3Phly2M,0,0,2023-08-29T16:47:35Z,"In that case I think the derivative would be plus or minus 1, that is |w| / w",2023-08-29T16:47:35Z
UgwkpGVS9mqAAoVk9N94AaABAg,@AvinashSingh-bk8kg,,1,6g0t3Phly2M,0,0,2021-01-24T04:54:44Z,Why we always focus on decreasing the weights? We already consider small random weights.,2021-01-24T04:54:44Z
UgxSBUTo3PKa-xmZ03d4AaABAg,@manuel783,,1,6g0t3Phly2M,1,11,2021-01-18T22:17:28Z,"Clarification about Regularization<br><br>Please note that at <a href=""https://www.youtube.com/watch?v=6g0t3Phly2M&amp;t=5m45s"">5:45</a>, the Frobenius norm formula should be the following:<br><br>                nÀ° n[À°‚Åª¬π]<br>||w[À°]||¬≤ = ‚ÖÄ  ‚ÖÄ(w[À°]·µ¢,‚±º)¬≤<br>               ·µ¢‚Çå‚ÇÅ ‚±º‚Çå‚ÇÅ<br><br>The limit of summation of i should be from 1 to n[À°],<br><br>The limit of summation of j should be from 1 to n[À°‚Åª¬π],<br><br>(it&#39;s flipped in the video). The rows &quot;i&quot; of the matrix should be the number of neurons in the current layer n[À°];<br><br>whereas the columns &quot;j&quot; of the weight matrix should equal the number of neurons in the previous layer n[À°‚Åª¬π].",2021-01-18T22:17:28Z
UgxSBUTo3PKa-xmZ03d4AaABAg.9IfUUaP1vf39srahpcN4-x,@KountayDwivedi,UgxSBUTo3PKa-xmZ03d4AaABAg,2,6g0t3Phly2M,0,0,2023-08-01T06:33:03Z,"Yes. The dimensions of W_[l] = (n_[l] , n_[l-1]).<br>Thanks for pointing out.<br>:-}",2023-08-01T11:02:48Z
UgzbvION4qEDRpSjgsZ4AaABAg,@sandipansarkar9211,,1,6g0t3Phly2M,0,0,2020-12-29T14:53:05Z,Very nice explanation.Thanks,2020-12-29T14:53:05Z
Ugzhj0pEXppl97cAmgR4AaABAg,@mittalparikh,,1,6g0t3Phly2M,0,0,2020-11-01T13:15:25Z,"To understand this better first go through this mathematics of weight decay  <a href=""https://youtu.be/NQJ0JXgreh8"">https://youtu.be/NQJ0JXgreh8</a>",2020-11-01T13:15:25Z
Ugxb9tlywGqsIgGNsZF4AaABAg,@exampreparationonline4166,,1,6g0t3Phly2M,0,10,2020-07-23T08:07:57Z,"Adding regularization will help to prevent over-fitting in the neural network.<br><br><br>L2 regularization is most preferred as it doesn&#39;t reduces the weight to zero, it minimizes the weight. L1 is preferred when we want to compress our model.<br><br>weight decay, dropout, and early stopping are few measures to be used as regularization",2020-07-23T08:10:29Z
UgzN73YsQfvF29pmX7V4AaABAg,@brutuschina,,1,6g0t3Phly2M,1,2,2020-05-14T16:57:31Z,I would love to know the &quot;really arcane reasons&quot;.,2020-05-14T16:57:31Z
UgzN73YsQfvF29pmX7V4AaABAg.98dkwJDpG8C99lEh_pEVi9,@yuchenzhao6411,UgzN73YsQfvF29pmX7V4AaABAg,2,6g0t3Phly2M,0,1,2020-06-11T11:12:28Z,"mit18.065 lec8, hope this help",2020-06-11T11:12:28Z
UgwnZVlHUoWVkYPVnsJ4AaABAg,@sumitvaise5452,,1,6g0t3Phly2M,0,1,2020-05-13T01:51:40Z,Very insightful. Lots of concepts in 9 mins.,2020-05-13T01:51:40Z
UgyKFL44OOTMYwm69wN4AaABAg,@Harshit-cv4ie,,1,6g0t3Phly2M,0,0,2020-02-29T09:39:26Z,Robust value of lambda??,2020-02-29T09:39:26Z
UgzpsdtRxzqoXKru2GB4AaABAg,@agentanakin9889,,1,6g0t3Phly2M,4,0,2019-09-29T11:01:37Z,"If you can create a slide, why then add illegible handwriting? I stopped watching at <a href=""https://www.youtube.com/watch?v=6g0t3Phly2M&amp;t=0m45s"">0:45</a>.",2019-09-29T11:01:37Z
UgzpsdtRxzqoXKru2GB4AaABAg.9-T1yBTokL690Aqrlx5saX,@fupopanda,UgzpsdtRxzqoXKru2GB4AaABAg,2,6g0t3Phly2M,0,0,2019-10-17T06:00:57Z,LOL good luck!,2019-10-17T06:00:57Z
UgzpsdtRxzqoXKru2GB4AaABAg.9-T1yBTokL691tSYMdR7bC,@kayicomert7933,UgzpsdtRxzqoXKru2GB4AaABAg,2,6g0t3Phly2M,0,23,2019-11-28T19:36:10Z,"you just denied the opportunity of listening Deep Networks from best possible source! He is professor in Stanford and Silicon Valley companies get consultancy from him. Most importantly, he has natural talent in teaching! I hope you re-evaluate your decision.",2019-11-28T19:36:10Z
UgzpsdtRxzqoXKru2GB4AaABAg.9-T1yBTokL694tuSUvqKV0,@oleholgerson3416,UgzpsdtRxzqoXKru2GB4AaABAg,2,6g0t3Phly2M,0,8,2020-02-11T13:22:58Z,What a stupid thing to say...,2020-02-11T13:22:58Z
UgzpsdtRxzqoXKru2GB4AaABAg.9-T1yBTokL69It3Sdc2v3A,@AvinashSingh-bk8kg,UgzpsdtRxzqoXKru2GB4AaABAg,2,6g0t3Phly2M,0,2,2021-01-24T04:50:38Z,"You lost the best flavour of deeplearning after you quitted at <a href=""https://www.youtube.com/watch?v=6g0t3Phly2M&amp;t=0m45s"">0:45</a> !",2021-01-24T04:50:38Z
UgwikHbGERDxL4dSM1t4AaABAg,@RealMcDudu,,1,6g0t3Phly2M,0,4,2019-09-21T09:01:32Z,W dimensions should be switched,2019-09-21T09:01:32Z
UgwB_28bP1x4MAhM76R4AaABAg,@juanbravo5315,,1,6g0t3Phly2M,1,0,2019-08-14T16:55:02Z,"why is he calling it Frobenius norm? in this site: <a href=""http://mathworld.wolfram.com/FrobeniusNorm.html"">http://mathworld.wolfram.com/FrobeniusNorm.html</a> says that frobenius norm is taking the root squared, so isn&#39;t it matters?",2019-08-14T16:55:02Z
UgwB_28bP1x4MAhM76R4AaABAg.8ycDqM-HxsF9GGtpmROPLB,@zql7351,UgwB_28bP1x4MAhM76R4AaABAg,2,6g0t3Phly2M,0,0,2020-11-20T06:44:39Z,"Yep, I am a guy from Math. As you study deeply in both CS and math, you can find more and more this kind of ambiguity.",2020-11-20T06:44:39Z
Ugxh8c-sVeEQfIxD8tZ4AaABAg,@aliciaornelas9617,,1,6g0t3Phly2M,1,12,2019-07-21T21:14:41Z,"In minute <a href=""https://www.youtube.com/watch?v=6g0t3Phly2M&amp;t=6m20s"">6:20</a> the dimensions of weights are wrong",2019-07-21T21:14:41Z
Ugxh8c-sVeEQfIxD8tZ4AaABAg.8xetU7qWDkt96yFFkATCqL,@mohammedaldawsari4574,Ugxh8c-sVeEQfIxD8tZ4AaABAg,2,6g0t3Phly2M,0,1,2020-04-02T22:53:12Z,it depends on your impl,2020-04-02T22:53:12Z
UgzTtFMGkuS1TLgd-fR4AaABAg,@xiaodong46,,1,6g0t3Phly2M,2,24,2019-03-29T21:16:29Z,"I think the dimension of w[l] is ( n[l] , n[l-1] )",2019-03-29T21:16:29Z
UgzTtFMGkuS1TLgd-fR4AaABAg.8t4M3V2ia359GGt0al-2rM,@zql7351,UgzTtFMGkuS1TLgd-fR4AaABAg,2,6g0t3Phly2M,0,1,2020-11-20T06:37:31Z,"yep, a typo, and  the same as the upper bound of the summation",2020-11-20T06:38:17Z
UgzTtFMGkuS1TLgd-fR4AaABAg.8t4M3V2ia359QQyz6S4SpB,@abdulmukit4420,UgzTtFMGkuS1TLgd-fR4AaABAg,2,6g0t3Phly2M,0,0,2021-07-30T17:55:57Z,I agree,2021-07-30T17:55:57Z
UgwPaeGJ62nOhl2zBBN4AaABAg,@chitralalawat8106,,1,6g0t3Phly2M,1,1,2019-03-20T11:58:02Z,Sparse?,2019-03-20T11:58:02Z
UgwPaeGJ62nOhl2zBBN4AaABAg.8shB-R6roTY8v3VUw07OuM,@kumarsen88,UgwPaeGJ62nOhl2zBBN4AaABAg,2,6g0t3Phly2M,0,5,2019-05-18T06:22:24Z,"A vector is sparse if most of it&#39;s elements are zero, e.g. X = [1 0 0 0 0 1 0 0 0 0 2 0 0 0 0 ]. Whereas a dense vector is the opposite where most of the elements are non zero. e.g. X = [1 2 3 4 5 6 0 7 8 9 0 -1 -2 -3 0].<br><br>You should check out professor Gilbert Strang&#39;s Linear Algebra course and professor Ng&#39;s Machine Learning Course before going through this. :)",2019-05-18T06:22:24Z
UgzOUDImuunXmpu2j854AaABAg,@banipreetsinghraheja8529,,1,6g0t3Phly2M,0,6,2018-06-04T19:51:42Z,"Wrong Notation of W vector, and hence the sigma terms!",2018-06-04T19:51:42Z
UgyJZ_wvghSsPSBCjzZ4AaABAg,@vaibhav8941,,1,6g0t3Phly2M,3,10,2017-10-05T13:47:49Z,"W[l] would be a (n[l],n[l-1]) matrix I guess, not a (n[l],n[l-1]) mat.",2017-10-05T13:47:49Z
UgyJZ_wvghSsPSBCjzZ4AaABAg.8YL5SsOAe9Z8bK2jiRyDdK,@CapHuuQuan,UgyJZ_wvghSsPSBCjzZ4AaABAg,2,6g0t3Phly2M,0,6,2018-01-12T14:10:22Z,"Yes! I think so, It should be (n[l], n[l-1])",2018-01-12T14:10:22Z
UgyJZ_wvghSsPSBCjzZ4AaABAg.8YL5SsOAe9Z96INsmm53MI,@ebk3138,UgyJZ_wvghSsPSBCjzZ4AaABAg,2,6g0t3Phly2M,0,0,2020-03-17T07:21:14Z,"Why W[l] would be a (n[l], n[l-1]) mat? Isn&#39;t it right to be a (n[l-1], n[l]) mat as the n[l-1] means that a number of units in layer &#39;l-1&#39;. For example, the shape of W[l] is (in_features, out_features).",2020-03-17T07:22:03Z
UgyJZ_wvghSsPSBCjzZ4AaABAg.8YL5SsOAe9Z97gMUIeQd_6,@KangSW72,UgyJZ_wvghSsPSBCjzZ4AaABAg,2,6g0t3Phly2M,0,0,2020-04-20T20:41:25Z,"‚Äã@@ebk3138 Ïù¥Ï†ÑÏóê Input - Hidden - Output : 2 - 3 - 1Í∞úÏùò nodeÎì§Ïù¥ ÏûàÏóàÏ£†. Ïù¥Îïå W[1] = (3,2) W[2] = (1,3)Ïùò DimensionÏùÑ Í∞ÄÏ°åÏ£†. Í∑∏ÎûòÏÑú Î∞îÎÄåÏóàÎã§Í≥† ÏùòÍ≤¨ÏùÑ Ï£ºÏãúÎäî Í≤É Í∞ôÏïÑÏöî!",2020-04-20T20:41:25Z
UgzSpQYH5aPEpg65fMp4AaABAg,@beluga7428,,1,NyG-7nRpsW8,0,1,2023-01-19T08:29:02Z,I have a doubt if z is small then why does it have any effect on curve overfitting as we obtain decision boundary  by putting z=0 so there is no involvement of tanhz functiion  in plotting the decision boundry !!,2023-01-19T08:29:02Z
Ugxl8nRh8sRE7lYOz3Z4AaABAg,@jesuspreachings2023,,1,NyG-7nRpsW8,0,1,2022-04-06T12:00:14Z,"Relu is also linear activation function , how it doesn&#39;t reduce network into linear network?",2022-04-06T12:00:14Z
Ugxbemw-MDxe5w4msDp4AaABAg,@hackercop,,1,NyG-7nRpsW8,0,0,2021-12-01T20:32:00Z,Never thought of tanh (or sigmoid) in that perspective thanks,2021-12-01T20:32:00Z
UgwnIIGlvTxv8GKOqFN4AaABAg,@VPrashanthedb,,1,NyG-7nRpsW8,0,0,2021-09-14T18:26:21Z,Why it will be linear if w is small??,2021-09-14T18:26:21Z
Ugwnmm1ppuTPiTV6RTZ4AaABAg,@timelyrain,,1,NyG-7nRpsW8,0,0,2021-07-14T13:54:37Z,"he is genuinely excited for dropout, so I&#39;m going to click on it",2021-07-14T13:54:37Z
Ugz8McHSaDHtgzD_laN4AaABAg,@AvinashSingh-bk8kg,,1,NyG-7nRpsW8,0,0,2021-01-24T05:05:15Z,What an amazing intution üôá‚Äç‚ôÇÔ∏è,2021-01-24T05:05:15Z
Ugz55ZAffsSGJuRp4Ul4AaABAg,@ozziejin,,1,NyG-7nRpsW8,0,8,2021-01-24T03:24:51Z,"interesting perspective, never thought of using the shape of tanh to help understand the intuition of regularization",2021-01-24T03:24:51Z
UgwvhxUwBIf6GdeneK54AaABAg,@rahuldey6369,,1,NyG-7nRpsW8,0,0,2021-01-05T19:40:43Z,"as I&#39;ve already done Prof.Andrew Ngs machine learning lectures, the terms seems familiar, and the explanation he had given in the logistic regression part lambda/2m. But it would have been more helpful, if you could give us some ideas in which scenarios we prefer using L2 over L1, or we can by default try with L2 having almost the same effect. I&#39;m big fan of you professor",2021-01-05T19:40:43Z
Ugxtb6pi3uonLnChaQp4AaABAg,@sandipansarkar9211,,1,NyG-7nRpsW8,0,0,2020-12-29T16:46:08Z,very nice explanation.need to watch again,2020-12-29T16:46:08Z
UgysaUUAd4rDhgGFJax4AaABAg,@mittalparikh,,1,NyG-7nRpsW8,0,0,2020-11-01T13:16:00Z,"To understand this better first go through this mathematics of weight decay  <a href=""https://youtu.be/NQJ0JXgreh8"">https://youtu.be/NQJ0JXgreh8</a>",2020-11-01T13:16:00Z
UgxuLBkc2Wf9yBLAS3Z4AaABAg,@rp88imxoimxo27,,1,NyG-7nRpsW8,0,1,2020-10-25T08:38:25Z,"Too ez for such a genius like me, but thx for an explanation anyway, watched the video on 2x speed trying not to fall into a sleep",2020-10-25T08:38:25Z
Ugw8RFbTOhjEf915ghx4AaABAg,@krishnachauhan2850,,1,NyG-7nRpsW8,1,0,2020-07-20T11:51:18Z,How come large lembda makes w matrix zero plz guide,2020-07-20T11:51:18Z
Ugw8RFbTOhjEf915ghx4AaABAg.9BKj9Ah0BF39FqL8aZaR8K,@tamoorkhan3262,Ugw8RFbTOhjEf915ghx4AaABAg,2,NyG-7nRpsW8,0,2,2020-11-09T13:53:17Z,"The updating formula for weights in a layer is W = (1-lambda/m)W - learning_rate*(dCost/dW), so from here you can see having larger lambda will make W small. This formula is when we are regularizing.",2020-11-09T13:55:23Z
UgxTm6G76BS_1NwOquR4AaABAg,@lmadriles,,1,NyG-7nRpsW8,1,0,2020-04-20T04:39:38Z,Why high lambda isn&#39;t the same as a high learning rate?,2020-04-20T04:40:00Z
UgxTm6G76BS_1NwOquR4AaABAg.97edPtACPMq9I8mLmD94ZB,@rahuldey6369,UgxTm6G76BS_1NwOquR4AaABAg,2,NyG-7nRpsW8,0,0,2021-01-05T20:08:06Z,"Check this- <a href=""https://stats.stackexchange.com/questions/168666/boosting-why-is-the-learning-rate-called-a-regularization-parameter#:~:text=I%20don&#39;t%20get%20why,of%20Statistical%20Learning%2C%20section%2010.12.&amp;text=Regularization%20means%20%22way%20to%20avoid,too%20high%20leads%20to%20overfitting)"">https://stats.stackexchange.com/questions/168666/boosting-why-is-the-learning-rate-called-a-regularization-parameter#:~:text=I%20don&#39;t%20get%20why,of%20Statistical%20Learning%2C%20section%2010.12.&amp;text=Regularization%20means%20%22way%20to%20avoid,too%20high%20leads%20to%20overfitting)</a>.",2021-01-05T20:08:06Z
UgyzQHmjzefS8WJMs1V4AaABAg,@saanvisharma2081,,1,NyG-7nRpsW8,3,31,2019-08-08T18:36:18Z,"During high bias, weights will be very small. During high variance, weights will be high. Similarly, during regularisation....if lambda is near infinity or high, our weights will tend to go down, because the function (gradient decent) will always try to minimize the overall value. If there&#39;s less lambda, weights will increase and model will try to fit each data point.......that also creates overfitting problems. So by tuning lambda in such a way that; both bias and variance should be in a acceptable range.",2019-08-08T18:36:44Z
UgyzQHmjzefS8WJMs1V4AaABAg.8yNxeriAnf_9-cO4H6haa0,@aditisrivastava7079,UgyzQHmjzefS8WJMs1V4AaABAg,2,NyG-7nRpsW8,0,0,2019-10-03T11:27:14Z,i like your explanation,2019-10-03T11:27:14Z
UgyzQHmjzefS8WJMs1V4AaABAg.8yNxeriAnf_96-0Y9GORKe,@lekjov6170,UgyzQHmjzefS8WJMs1V4AaABAg,2,NyG-7nRpsW8,0,1,2020-03-09T18:51:44Z,"Thanks for your comment, it clicked for me now.",2020-03-09T18:51:44Z
UgyzQHmjzefS8WJMs1V4AaABAg.8yNxeriAnf_99FavQ_G9Es,@dragonixZXgames,UgyzQHmjzefS8WJMs1V4AaABAg,2,NyG-7nRpsW8,0,0,2020-05-29T19:00:23Z,"Thanks, I finally got it.",2020-05-29T19:00:23Z
UgzwYJP0jf7Hgvqqc254AaABAg,@calluma8472,,1,NyG-7nRpsW8,1,4,2019-06-13T11:35:41Z,The meaning of the word &quot;intuition&quot; is being single handedly destroyed by the misuse in this video.,2019-06-13T11:35:41Z
UgzwYJP0jf7Hgvqqc254AaABAg.8w70066Pjlp8xCvRLVyvdJ,@muhammadnaufil5237,UgzwYJP0jf7Hgvqqc254AaABAg,2,NyG-7nRpsW8,0,0,2019-07-10T15:13:48Z,lol,2019-07-10T15:13:48Z
UgwG3XNji4v5N4Kqtjl4AaABAg,@thedrei24,,1,NyG-7nRpsW8,5,8,2019-03-30T22:46:08Z,i feel like the second explanation with the tanh function is much better,2019-03-30T22:46:08Z
UgwG3XNji4v5N4Kqtjl4AaABAg.8t75728r9SY9FPiwdtDj6q,@bzqp2,UgwG3XNji4v5N4Kqtjl4AaABAg,2,NyG-7nRpsW8,0,3,2020-10-29T20:31:14Z,"But for other activations (i.e. ReLU) this explanation is totally counterintuitive. For ReLU the nonlinearity is exactly at 0, so smaller absolute value of w wouldn&#39;t really reduce the unit&#39;s use of the nonlinear range.",2020-10-29T20:31:14Z
UgwG3XNji4v5N4Kqtjl4AaABAg.8t75728r9SY9Fg3O6aMdsh,@seunggukang5571,UgwG3XNji4v5N4Kqtjl4AaABAg,2,NyG-7nRpsW8,0,0,2020-11-05T14:05:43Z,@@bzqp2 It&#39;s linear near 0 in ReLU.,2020-11-05T14:05:58Z
UgwG3XNji4v5N4Kqtjl4AaABAg.8t75728r9SY9FgLJOz72Ps,@bzqp2,UgwG3XNji4v5N4Kqtjl4AaABAg,2,NyG-7nRpsW8,0,0,2020-11-05T16:42:21Z,"@@seunggukang5571 well NEAR 0 it is linear, but exactly at 0 the 1st derivative changes, which makes it nonlinear there.",2020-11-05T16:42:21Z
UgwG3XNji4v5N4Kqtjl4AaABAg.8t75728r9SY9FgOWda3xu_,@seunggukang5571,UgwG3XNji4v5N4Kqtjl4AaABAg,2,NyG-7nRpsW8,0,0,2020-11-05T17:10:23Z,"Leaky ReLU can be an example of non-linear, but ReLU is linear in my opinion, since a domain is [0,inf) or (0,inf).",2020-11-05T17:10:23Z
UgwG3XNji4v5N4Kqtjl4AaABAg.8t75728r9SY9FgPhcIdqBQ,@bzqp2,UgwG3XNji4v5N4Kqtjl4AaABAg,2,NyG-7nRpsW8,0,0,2020-11-05T17:20:45Z,"@@seunggukang5571 ‚Äã @Seunggu Kang  Nope. Normal ReLU also is nonlinear. An activation function needs to be nonlinear (check Hinton&#39;s article on &quot;Learning representations by back-propagating errors&quot; for a more detailed explanation), and that&#39;s why we use ReLU and not a simple linear wx+b. A neural network with linear activations wouldn&#39;t learn anything no matter how deep it would be. The fact, that it has different derivatives over the domain makes it nonlinear.",2020-11-05T17:21:21Z
Ugx8rN1R4GBy032Fg0N4AaABAg,@redberries8039,,1,NyG-7nRpsW8,5,6,2018-05-29T13:14:18Z,Andrew says the tanh in the linear region will deliver linear models only ....what about RELU? that&#39;s all linear can it only deliver linear models??? RELU is popular I find that hard to believe  ...where am i confused?,2018-05-29T13:14:18Z
Ugx8rN1R4GBy032Fg0N4AaABAg.8gpiDww5cjJ8rY9AuvbFc9,@JadtheProdigy,Ugx8rN1R4GBy032Fg0N4AaABAg,2,NyG-7nRpsW8,0,1,2019-02-19T17:58:19Z,"i see what you mean, it doesnt make sense to regularize with lambda for relu, but it does if you are regularizing with dropout. great point though",2019-02-19T17:58:19Z
Ugx8rN1R4GBy032Fg0N4AaABAg.8gpiDww5cjJ8rrPduniohY,@chakibbachounda1721,Ugx8rN1R4GBy032Fg0N4AaABAg,2,NyG-7nRpsW8,0,0,2019-02-27T14:47:02Z,"<a href=""https://datascience.stackexchange.com/questions/26475/why-is-relu-used-as-an-activation-function"">https://datascience.stackexchange.com/questions/26475/why-is-relu-used-as-an-activation-function</a>",2019-02-27T14:47:02Z
Ugx8rN1R4GBy032Fg0N4AaABAg.8gpiDww5cjJ90ZkN-MPKcx,@fupopanda,Ugx8rN1R4GBy032Fg0N4AaABAg,2,NyG-7nRpsW8,0,1,2019-10-26T22:05:12Z,"ReLU has non-linearity.  It does not have a constant gradient. It&#39;s piece-wise linear, and not simply just linear.",2019-10-26T22:05:12Z
Ugx8rN1R4GBy032Fg0N4AaABAg.8gpiDww5cjJ9FPj5E4YADh,@bzqp2,Ugx8rN1R4GBy032Fg0N4AaABAg,2,NyG-7nRpsW8,0,1,2020-10-29T20:32:32Z,Relu has the nonlinearity at z=0 (which actually makes the explanation totally counterintuitive),2020-10-29T20:32:32Z
Ugx8rN1R4GBy032Fg0N4AaABAg.8gpiDww5cjJ9FPkaetDGgP,@redberries8039,Ugx8rN1R4GBy032Fg0N4AaABAg,2,NyG-7nRpsW8,0,0,2020-10-29T20:45:42Z,@@bzqp2 yes I accept this reasoning now. cheers,2020-10-29T20:45:42Z
UgwAKtAnEDgGi7seAzp4AaABAg,@redberries8039,,1,NyG-7nRpsW8,2,3,2018-05-08T09:29:41Z,"the tanh intuition makes sense to me [linearsizing and so simplifying the model] ...the first intuition, described as making the weights so small their effects disappear, does not make sense to me ...if ALL the weights are reduced by the same factor then its the same model. Isn&#39;t it? There would need to be some selectivity in the reductions it seems to me??",2018-05-08T09:29:41Z
UgwAKtAnEDgGi7seAzp4AaABAg.8fzEpNOt1Mc9-9phkSCLhJ,@RickLamers,UgwAKtAnEDgGi7seAzp4AaABAg,2,NyG-7nRpsW8,0,3,2019-09-22T00:00:13Z,The weights in the model are randomly initialized and some start close to 0 and others don&#39;t. The L2 regularization puts pressure on these weights during backpropagation from reaching high values which results in models that have fewer hidden units that significantly contribute and thus have reduced complexity in terms of number of units in the network that produce it&#39;s output.,2019-09-22T00:00:13Z
UgwAKtAnEDgGi7seAzp4AaABAg.8fzEpNOt1Mc9I8kHaLyD1p,@rahuldey6369,UgwAKtAnEDgGi7seAzp4AaABAg,2,NyG-7nRpsW8,0,0,2021-01-05T19:50:04Z,"@@RickLamers Absolutely that is how regularization works. Over-fitting occurs when you are unnecessarily giving importance to most of the weights to fit the training set well,which end up giving a model that tries to capture the whole pattern of the training data in a precise manner, but our goal isn&#39;t to build a model that precisely captures the training data pattern, but to have a more generalized model,that will perform good on test/dev which is completely unseen to the model. So in order to reduce the complexity one may try to penalize the higher weights, the weights that the model things these weights are majorly responsible to match the hypothesis,but fails when it applies it on the test/dev",2021-01-05T19:50:04Z
Ugz6BIOFhgL4NetWIIZ4AaABAg,@X_platform,,1,NyG-7nRpsW8,6,1,2017-11-17T10:42:37Z,"I am confused... if &quot;lambda&quot; is big, your &quot;dw&quot; will be big. So your &quot;w&quot; could become very negative after the update. (which in tanh is nonlinear)... won&#39;t that overfit even more?",2017-11-17T10:42:37Z
Ugz6BIOFhgL4NetWIIZ4AaABAg.8_3US2ZWgor8f4gxYNVaTt,@CapHuuQuan,Ugz6BIOFhgL4NetWIIZ4AaABAg,2,NyG-7nRpsW8,0,3,2018-04-16T01:08:15Z,"Well, I think it&#39;s because of the optimization problem. In order to minimize the cost function J, if the lambda is large, we will need to choose smaller value of W.",2018-04-16T01:08:15Z
Ugz6BIOFhgL4NetWIIZ4AaABAg.8_3US2ZWgor8onHiOra-eN,@drummatick,Ugz6BIOFhgL4NetWIIZ4AaABAg,2,NyG-7nRpsW8,0,0,2018-12-13T10:46:36Z,"You&#39;re absolutely right, There is no restriction on lambda imposed here, for an instance we can choose any negative lambda and it will obviously minimize it, for an instance choosing -infinity is best. He doesn&#39;t explains it clearly.",2018-12-13T10:46:36Z
Ugz6BIOFhgL4NetWIIZ4AaABAg.8_3US2ZWgor8onHmD3IWs8,@drummatick,Ugz6BIOFhgL4NetWIIZ4AaABAg,2,NyG-7nRpsW8,0,1,2018-12-13T10:47:07Z,"@@CapHuuQuan bro if we just take lambda=-infinity, we&#39;re done, that&#39;s the minimum of J you can get. Think about it",2018-12-13T10:47:07Z
Ugz6BIOFhgL4NetWIIZ4AaABAg.8_3US2ZWgor8pfe-92ZWLx,@CapHuuQuan,Ugz6BIOFhgL4NetWIIZ4AaABAg,2,NyG-7nRpsW8,0,1,2019-01-04T08:07:28Z,"@@drummatick Hi, as Adrew Ng explained above, if lambda is very big then the optimizer will pick up the very small value of W (W is nearly to 0). It turns out the z value will be small and the model is nearly linear model (in case of tanh activation function) ==&gt; This model is now UNDERFITTING<br><br>In contrast, if you choose lambda to be very small (in your case: -infinity) then the optimizer can just pick up any NOT small value of W. This time, the model will be complex since the value of z will be large. Of course the value of the cost function J is nearly 0 (because value of lambda is -infinity as you said), but now the risk of overfitting is super high. Your model will learn too much about the particularities of the training data, and won&#39;t be able to generalize to new data.",2019-01-04T08:07:28Z
Ugz6BIOFhgL4NetWIIZ4AaABAg.8_3US2ZWgor8tPutNQtcZ1,@satyajitgiri5060,Ugz6BIOFhgL4NetWIIZ4AaABAg,2,NyG-7nRpsW8,0,1,2019-04-07T06:13:35Z,"If w does become negative the update function w = w - alpha* (update from back-propagation + lambda (w/m)), where lambda(w/m) would be negative. Since you&#39;ll be subtracting a negative number, it becomes equivalent to adding lambda(|w|/m).",2019-04-07T06:13:35Z
Ugw81WW0o2GwvXBUitd4AaABAg,@ahmedb2559,,1,D8PJAL-MZv8,0,0,2023-01-15T11:39:41Z,Thank you !,2023-01-15T11:39:41Z
UgygUwWqiFN2C2X8TuF4AaABAg,@travel6142,,1,D8PJAL-MZv8,0,1,2021-12-19T20:28:11Z,"import numpy as np<br><br>keep_prob = 0.8<br>a3 = np.random.rand(6,5)<br>d3 = np.random.rand(6,5) &lt; keep_prob<br>new_a3 = a3*d3<br><br>print(&quot;a3: \n&quot;, a3)<br>print(&quot;d3: \n&quot;, d3)<br>print(&quot;new_a3: \n&quot;, new_a3)<br><br>inverted_new_a3 = new_a3/keep_prob<br><br>print(&quot;inverted_new_a3: \n&quot;, inverted_new_a3)<br><br>n_zeros = np.count_nonzero(new_a3==0, axis=1)<br>print(sum(n_zeros))<br><br>print(&quot;expected_value_a3: &quot;, a3.mean())<br>print(&quot;expected_value_new_a3: &quot;, new_a3.mean())<br>print(&quot;expected_value_inverted_new_a3: &quot;, inverted_new_a3.mean())",2021-12-19T20:28:11Z
UgxKgQSY62eXZYOOFQd4AaABAg,@farooqkhan1398,,1,D8PJAL-MZv8,0,0,2021-08-30T14:26:12Z,If we are to remove the nodes than why did we added those nodes at first? Why isn‚Äôt we started with a smaller network?,2021-08-30T14:26:12Z
UgwQHtGBF9K1C_BYTP14AaABAg,@anirudhsharma2003,,1,D8PJAL-MZv8,0,1,2021-08-27T05:52:27Z,??? So dropout mask d3 is calculated every iteration!? <br>Does not not make the result jump around like a monkey preventing the network from actually converging to one result!?<br><br>Why would not calculating a fixed/final d3 before training be better??,2021-08-27T05:52:27Z
Ugy1co7JVoHir5a2G2R4AaABAg,@phoboss950,,1,D8PJAL-MZv8,1,3,2021-05-07T11:20:01Z,Thanos would be proud,2021-05-07T11:20:01Z
Ugy1co7JVoHir5a2G2R4AaABAg.9N1ytcuILIZ9UbHXQXyKA5,@muskanmahajan04,Ugy1co7JVoHir5a2G2R4AaABAg,2,D8PJAL-MZv8,0,0,2021-11-11T13:24:01Z,lol,2021-11-11T13:24:01Z
UgwQs2wGpl1U21gOCqB4AaABAg,@VV-mz2yz,,1,D8PJAL-MZv8,0,0,2021-03-17T03:55:39Z,what if every element in d3 is ALL True (all is smaller than keep_prob)? I means its random so that case is possible,2021-03-17T03:55:39Z
Ugy89lu73NLaJv4Be7R4AaABAg,@toyotomihideyoshi8,,1,D8PJAL-MZv8,0,0,2021-02-16T15:20:29Z,"Thank you Andrew,, :)",2021-02-16T15:20:29Z
UgzYd1BymOy5389Z6Kt4AaABAg,@doyugen465,,1,D8PJAL-MZv8,1,0,2021-01-31T14:05:06Z,do we perform the inverse dropout calculation (a = a/ keep-prob) on the input layer neurons aswell?,2021-01-31T14:05:06Z
UgzYd1BymOy5389Z6Kt4AaABAg.9JB4TnDKj6p9JZUQVCvFtK,@kamranuser1,UgzYd1BymOy5389Z6Kt4AaABAg,2,D8PJAL-MZv8,0,1,2021-02-10T01:33:37Z,I believe he said that it is mostly done at the hidden layers.,2021-02-10T01:33:37Z
UgyXG_Ief6Os8fpf9e94AaABAg,@rahuldey6369,,1,D8PJAL-MZv8,1,0,2021-01-05T20:23:58Z,excellent explanation.Though it wasn&#39;t clear what happens during test/dev time. Does it multiply all the weights with 0.2 during test/dev for Dropout(0.2)?,2021-01-05T20:34:41Z
UgyXG_Ief6Os8fpf9e94AaABAg.9I8o9wVfnUD9JZUk_lAMpc,@kamranuser1,UgyXG_Ief6Os8fpf9e94AaABAg,2,D8PJAL-MZv8,0,2,2021-02-10T01:36:30Z,"During test time, dropout is disabled. He said that if enabled it would create noise and hence the predictions would be adversely impacted.",2021-02-10T01:36:30Z
UgwDhfzLdr0l6F1yHy54AaABAg,@sandipansarkar9211,,1,D8PJAL-MZv8,0,1,2020-12-30T14:34:48Z,great explanation .need to watch again,2020-12-30T14:34:48Z
UgwlN7fMsYcz0dJrib94AaABAg,@rp88imxoimxo27,,1,D8PJAL-MZv8,0,0,2020-10-25T09:05:41Z,"another breeze lesson, thx!",2020-10-25T09:05:41Z
Ugw1XBDBrfQNMgFuTT54AaABAg,@AndreaFantasia,,1,D8PJAL-MZv8,0,2,2020-09-18T16:33:21Z,d3=np.random.rand(*a3.shape)&lt;keep_prob     also will work fine!,2020-09-18T16:33:21Z
UgznjOh603RupBGaPit4AaABAg,@exampreparationonline4166,,1,D8PJAL-MZv8,0,3,2020-07-23T08:22:21Z,"Dropout helps us to ensure that the model is not getting biased towards a particular feature, i.e. to ensure it performs well even in the absence of that particular feature.<br>keep-prob = 0.8 means the probability of a hidden unit will be kept is 0.8, and 0.2 chances of a hidden unit will be ignored.<br><br>no dropout at test time, explicitly, because we do not want to vary the output",2020-07-23T08:22:53Z
UgzVkYRyW2svqGw48314AaABAg,@SandeepKumar-ie1ni,,1,D8PJAL-MZv8,1,9,2020-06-06T17:32:27Z,As we can see that the d3 vector is 20% sparse matrix means that 20% of the data has been set to 0/False.on multiply the a3 with d3 makes the a3 to 20% to 0 values which results the drouput machanism in the training data set but although we have to manage the a3 for the w4 iteraion equation so we want to increase the a3 by keep_prob which is in this case is 0.2 which increases a3 relatively high .may it helps you,2020-06-06T17:32:27Z
UgzVkYRyW2svqGw48314AaABAg.99_2DFboC5v9i9d2wsQ4j3,@convolutionalnn2582,UgzVkYRyW2svqGw48314AaABAg,2,D8PJAL-MZv8,0,0,2022-11-08T06:13:47Z,If L=3 how can we have Z4?,2022-11-08T06:13:47Z
UgwBkC4rUvTEkFQRd9F4AaABAg,@jhack711,,1,D8PJAL-MZv8,1,0,2019-09-26T19:07:48Z,"According to <a href=""https://www.youtube.com/watch?v=D8PJAL-MZv8&amp;t=0m40s"">0:40</a>, `1 - keep_prob` is the probability that the node will be eliminated. Andrew (I&#39;m paraphrasing a bit) says that it is equivalent to &quot;removing all the ingoing links to that node&quot;. In other words, this is equivalent to setting the whole column of d3 (<a href=""https://www.youtube.com/watch?v=D8PJAL-MZv8&amp;t=2m34s"">2:34</a>) that corresponds to the node to be eliminated to zero. By doing this, the dot product of the weights of this column to the previous layer&#39;s activation units would be 0 (which is what we want).<br>If that&#39;s the case, should we not have instead:<br>```<br>d3 = np.zeros((a3.shape[0], a3.shape[1]))<br>d3[:, np.random.rand(a3.shape[1]) &lt; keep_prob] = 1<br>```<br>where a3.shape[1] is the size of the current layer (whose nodes are dropped out) and a3.shape[0] the size of the previous layer.<br><br>If, instead, we implement it as shown in the video, that is,<br>d3 = np.random.rand(a3.shape[0], a3.shape[1]) &lt; keep_prob],<br>it is not guaranteed that the whole column corresponding to the node to be eliminated will be zero. Thoughts?",2019-09-26T23:22:09Z
UgwBkC4rUvTEkFQRd9F4AaABAg.9-MBDRLYIQW90kXS3Ysjzb,@ab452,UgwBkC4rUvTEkFQRd9F4AaABAg,2,D8PJAL-MZv8,0,0,2019-10-31T11:54:26Z,"A[3]  Has dimensions n[3] * m , where n[3] is the number of units of the third layer, and m is the number of training examples. A column of d3 will define which units of A[3] will be shut off for a given training example. When doing backprop because the activation of certain units of A[3] was 0 will make say dA1[3] be 0 as well, which will stop the the error of being propagated through the weights that connect to A1[3]. That&#39;s how dropout applies regularization, by prioritizing some weights during back prop. That prioritization will be different for different training examples.",2019-10-31T11:54:26Z
UgyDwFfGkCEd9623zbd4AaABAg,@user-ni4kq1lc6b,,1,D8PJAL-MZv8,2,0,2019-08-18T12:41:08Z,"<a href=""https://www.youtube.com/watch?v=D8PJAL-MZv8&amp;t=5m40s"">5:40</a>    what really means that divided z(4) to 0.8 because to remain the expectation of the value a(3).. someone please help me..",2019-08-18T12:41:08Z
UgyDwFfGkCEd9623zbd4AaABAg.8ym3yJkjznS905nBPw_E2F,@mikstevan,UgyDwFfGkCEd9623zbd4AaABAg,2,D8PJAL-MZv8,0,8,2019-10-15T06:52:37Z,"Increase the value of z(4) so that it is closer to what would be the output if no dropout had taken place. Basically with dropout you&#39;re killing neurons, so the sum of their outputs is smaller. It&#39;s important that z(4) is close to what would happen if all neurons were working, because during test time that&#39;s how the network will work. (At least as far as I understand)",2019-10-15T06:52:37Z
UgyDwFfGkCEd9623zbd4AaABAg.8ym3yJkjznS9JZWd0I67uE,@kamranuser1,UgyDwFfGkCEd9623zbd4AaABAg,2,D8PJAL-MZv8,0,0,2021-02-10T01:52:56Z,only a3 is divided by keep_prob. This is done to remove the impact of dropped neurons in forward and backward computations. The detail is in the math which he did not go over in the video.,2021-02-10T01:52:56Z
UgxkEnH_Yq_-xRkJQZN4AaABAg,@smilebig3884,,1,D8PJAL-MZv8,1,1,2019-08-08T15:41:00Z,"whats the point of dividing a3 by 0.8, u said it will gain back the reduced 20% loss values,  i m not getting first we shut down 20% neuron or units then we r switching them back on? this is what u mean by gaining the 20% lost values blc if u r talking about other values than 0 then yess they get increases by 20% but i dont know y we r doing this, i mean how will it effect the results in z4.",2019-08-08T15:41:00Z
UgxkEnH_Yq_-xRkJQZN4AaABAg.8yNdarlx7uL90kVqpMbZ84,@ab452,UgxkEnH_Yq_-xRkJQZN4AaABAg,2,D8PJAL-MZv8,0,4,2019-10-31T11:40:29Z,"This is how it works, the fact that he does not show the detailed implementation generates confusion. Layer by layer we perform forward prop, but we stop at every layer to apply our dropout filter, once it is applied to the previous layer we go to the next layer and compute the activations with those units turned off, we then apply the filter to the current layer and do the same steps for all hidden layers . If we did this without the scaling what would have happened ? Some of the signal would be lost completely meaning that the output would be reduced.  We have to understand that regularization is not designed to impact the forward prop, but rather back prop, and the propagation of the error through the weights. The fact that some units are deactivated will make the error propagation prioritize different weights at different training examples. If we trace it back to L2 regularization we force that regularization and prioritization of weights to happen similarly for all training examples, in dropout we mix it a bit more. Another way of looking at it is that if we didn&#39;t scale our  activation&#39;s we would be probably increasing the magnitude of error for that training example, which is not what we want, we are after the same error, but propagated differently so that some parameters get decreased, and thus we have a simpler hypothesis.",2019-10-31T11:40:29Z
UgyvjRycY_5oU45qOm14AaABAg,@uditarpit,,1,D8PJAL-MZv8,1,0,2019-05-15T14:03:24Z,"in training , node should share the effect of missing nodes that the whole idea. isn&#39;t it? i dont find divide by .8 a very appropriate way.",2019-05-15T14:03:24Z
UgyvjRycY_5oU45qOm14AaABAg.8uxargwEGF-91th5C1HsM6,@kayicomert7933,UgyvjRycY_5oU45qOm14AaABAg,2,D8PJAL-MZv8,0,1,2019-11-28T21:52:00Z,But you don&#39;t want to have covariant shift on your z terms there. Covariance makes the training slower and leads to worse accuracy. There is a video of Prof. Andrew Ng on this shifting.,2019-11-28T21:52:00Z
Ugwvpnadw20a8W5Chfl4AaABAg,@diegomoya9695,,1,D8PJAL-MZv8,0,2,2019-05-07T01:11:23Z,Why do you have to divide by 0.8 to conserve the mean? Is average,2019-05-07T01:11:23Z
Ugxzmupc7ULJrMtpTTV4AaABAg,@rekasil,,1,D8PJAL-MZv8,7,1,2019-01-06T13:16:51Z,"Please help me to understand...<br>1. Is the difference between L2 and inverted dropout that the L2 is an &quot;average&quot; of &quot;w&quot;s, so changing through iterations, while inverted dropout is always a fix number? Because both just reduce the &quot;w&quot;s.<br>2. Does inverted dropout only simulate the shut off through iterations by let&#39;s say averaging the effects of the nodes?<br>3. If so then is it possible to still have some x features which have major effects on every nodes in a layer, meaning that every nodes in a layer &quot;learn&quot; the same thing?<br>4. If so, why do not we just kill some w values for nodes randomly meaning they will not be involved in the learning process of the given node, while the other nodes in the same layer can still learn on it?",2019-01-06T13:16:51Z
Ugxzmupc7ULJrMtpTTV4AaABAg.8plLzu3IF828yNgrdsvFay,@smilebig3884,Ugxzmupc7ULJrMtpTTV4AaABAg,2,D8PJAL-MZv8,0,1,2019-08-08T16:09:30Z,"l2 regularization deals with the &quot; w &quot;  and make them small time to time in order to make ur network act like linear regression classifier, whereas dropout completely shuts down ur input nodes in the hidden layer but in order to compensate those losses u increases other input weights by 20%, this is what I have understood soo far from this.",2019-08-08T16:09:30Z
Ugxzmupc7ULJrMtpTTV4AaABAg.8plLzu3IF829GubvWHZWDR,@MrBemnet1,Ugxzmupc7ULJrMtpTTV4AaABAg,2,D8PJAL-MZv8,0,0,2020-12-06T02:17:00Z,did you understand it now,2020-12-06T02:17:00Z
Ugxzmupc7ULJrMtpTTV4AaABAg.8plLzu3IF829GwHxoi-yRe,@rekasil,Ugxzmupc7ULJrMtpTTV4AaABAg,2,D8PJAL-MZv8,0,0,2020-12-06T17:52:18Z,@@MrBemnet1 not really :),2020-12-06T17:52:18Z
Ugxzmupc7ULJrMtpTTV4AaABAg.8plLzu3IF829GwOWR78A-y,@MrBemnet1,Ugxzmupc7ULJrMtpTTV4AaABAg,2,D8PJAL-MZv8,0,0,2020-12-06T18:49:35Z,@@rekasil do you still need help? I finally understand it now.,2020-12-06T18:49:35Z
Ugxzmupc7ULJrMtpTTV4AaABAg.8plLzu3IF829GwR4z6Dbsr,@rekasil,Ugxzmupc7ULJrMtpTTV4AaABAg,2,D8PJAL-MZv8,0,0,2020-12-06T19:12:03Z,"@@MrBemnet1 That was my intention too, namely, shutting down a node. But programatically, my understanding is that the node to be dropped out is &quot;selected randomly&quot; epoch by epoch, and for &quot;simulating&quot; this action they just reducing the Ws by the dropout rate, which is basically not equal to shutting down a node. I assume there are several dropout techniques. So I would like to read more about them, some pseudo codes would be nice with pros and cons. Could you pleae help me?",2020-12-06T19:12:03Z
UgxVBkg2Jb8jYCMKMcJ4AaABAg,@Geoters,,1,D8PJAL-MZv8,1,1,2018-10-02T14:50:27Z,So when teaching Neural Network we have dropout layer(s) to prevent over-fitting. <br><br>Once we got all the weights figured out and ready to use network in production environment should we drop those layers?<br><br>They seems to only hurt our &quot;using&quot; of the network.,2018-10-02T14:50:27Z
UgxVBkg2Jb8jYCMKMcJ4AaABAg.8luKOOm9d_Y8uxa4Sd_l8x,@uditarpit,UgxVBkg2Jb8jYCMKMcJ4AaABAg,2,D8PJAL-MZv8,0,7,2019-05-15T13:56:32Z,no..drop out is only done at the time of training.,2019-05-15T13:56:32Z
UgymVNdNKWBFdq6ZOtZ4AaABAg,@shwethasubbu3385,,1,D8PJAL-MZv8,2,1,2018-07-11T17:02:13Z,"1. Why do we have to eliminate different nodes in the layers for different training examples? Like why does it have to be different?<br>2. What is the difference between test time and training time?<br>3. Instead of np.random,randn(a3.shape[0], a3.shape[1]), can we write np.random.randn(a3.shape) ?",2018-07-11T17:10:24Z
UgymVNdNKWBFdq6ZOtZ4AaABAg.8iZqUs8LmAq8jQ2p6T5ARf,@GRaajitha,UgymVNdNKWBFdq6ZOtZ4AaABAg,2,D8PJAL-MZv8,0,21,2018-08-01T18:17:42Z,"1.  Note that each node computes a specific feature for an image (assuming that the dataset being used has images). If we eliminated the same node for all images, it is equivalent to not considering that feature at all! By using random nodes we now ensure 2 things. One, the NN does not depend on one feature alone. Two, randomization improves generalization.<br><br>2. If you are considering inverted drop out then during training, you will multiply the signal by the probability 1/p, i.e (1/p)*(sigmoid(wx+b)) this helps during test time because you are not messing around with the signal.<br>     If you are considering normal drop out then you are passing pure signal during trainin time but during testing you will multiply the signal with p. I.e, p*(sigmoid(wx+b)).<br><br>3. a3.shape returns a tuple, and results in an error. Try out in a python ide maybe?<br><br>Hope that helps",2018-08-01T18:17:42Z
UgymVNdNKWBFdq6ZOtZ4AaABAg.8iZqUs8LmAq9JB5Qgf0hy8,@hamzaamjad699,UgymVNdNKWBFdq6ZOtZ4AaABAg,2,D8PJAL-MZv8,0,0,2021-01-31T14:13:25Z,d3=np.random.rand(*a3.shape)&lt;keep_prob     also will work fine!,2021-01-31T14:13:25Z
UgxR2NauGptyRmsEpYF4AaABAg,@abhramajumder2105,,1,D8PJAL-MZv8,4,7,2018-07-10T16:00:50Z,I couldn&#39;t understand the reason of multiplication of keep_prob at the end. Can any one help? thank you.,2018-07-10T16:00:50Z
UgxR2NauGptyRmsEpYF4AaABAg.8iX9fQzOb7s8o03k87Bufd,@ghadialhaj9532,UgxR2NauGptyRmsEpYF4AaABAg,2,D8PJAL-MZv8,0,19,2018-11-23T22:42:28Z,"Do you mean division? if yes then its because we have eliminated 20% of the neurons and thus 20% of the elements in the layer, so we want to compensate for that lost 20% by dividing by 0.8 to keep the same expected value of z4. Why do we want to do that? Remember that in the testing phase, we use all neurons without dropout, i.e. the full network, so we want to train the neurons to work in the full network, and give values relevant to the output in that network, rather than in the network with neurons turned off.<br><br>Hope it helps.",2018-11-23T22:42:28Z
UgxR2NauGptyRmsEpYF4AaABAg.8iX9fQzOb7s8o3gFGq-Pol,@navid2368,UgxR2NauGptyRmsEpYF4AaABAg,2,D8PJAL-MZv8,0,2,2018-11-25T08:25:22Z,@@ghadialhaj9532 Thank you,2018-11-25T08:25:22Z
UgxR2NauGptyRmsEpYF4AaABAg.8iX9fQzOb7s8uxahONRkek,@uditarpit,UgxR2NauGptyRmsEpYF4AaABAg,2,D8PJAL-MZv8,0,0,2019-05-15T14:01:59Z,"@@ghadialhaj9532 in training , node should share the effect of missing nodes that the whole idea. isn&#39;t it? i dont find it very appropriate !",2019-05-15T14:01:59Z
UgxR2NauGptyRmsEpYF4AaABAg.8iX9fQzOb7s971AbvTcIot,@dARKf3n1Xx,UgxR2NauGptyRmsEpYF4AaABAg,2,D8PJAL-MZv8,0,0,2020-04-04T11:29:39Z,@@ghadialhaj9532 thanks,2020-04-04T11:29:39Z
Ugw_XyteS-BaQKIce4R4AaABAg,@IgorAherne,,1,D8PJAL-MZv8,2,5,2017-10-31T21:32:38Z,"Thank you Andrew<br><br>Do we consider Bias to be dropped out, or we always keep it?",2017-10-31T21:32:38Z
Ugw_XyteS-BaQKIce4R4AaABAg.8ZOsK1EnS348d8p6QlsCfV,@IgorAherne,Ugw_XyteS-BaQKIce4R4AaABAg,2,D8PJAL-MZv8,0,8,2018-02-26T22:33:40Z,"the answer is we always keep it, because it&#39;s functioning as a &quot;neuron intersept&quot;, allowing to raise or lower the hiperplane so it doesn&#39;t go through zero. Its activation is always 1.0 so intuitively it makes no sense to hinder it",2018-02-26T22:34:47Z
Ugw_XyteS-BaQKIce4R4AaABAg.8ZOsK1EnS348fum3RzXIHY,@rohitsaxena6727,Ugw_XyteS-BaQKIce4R4AaABAg,2,D8PJAL-MZv8,0,9,2018-05-06T15:52:37Z,Well if you watch the previous L2 regularization video he clearly states that it is a general practice to regularize only weights matrix and not the bias vector,2018-05-06T15:52:37Z
UgzlfBMU0K7chRvqmRN4AaABAg,@ahmedb2559,,1,ARq74QuavAo,0,0,2023-01-15T11:46:08Z,Thank you !,2023-01-15T11:46:08Z
Ugw1Z4mE7j3Pc_7VeB54AaABAg,@travel6142,,1,ARq74QuavAo,2,1,2021-12-19T20:39:48Z,"Do we use another random dropout at each iteration? Suppose that we selected keep_prob=0.8 for layer 3, at each iteration, it picks another random 0.2 of units to shut off as far as I understood. Can anyone confirm me about this?",2021-12-19T20:39:48Z
Ugw1Z4mE7j3Pc_7VeB54AaABAg.9W8ubMYMcYW9XVP640RISC,@valentinfontanger4962,Ugw1Z4mE7j3Pc_7VeB54AaABAg,2,ARq74QuavAo,0,0,2022-01-22T10:49:42Z,"According to the previous video, you choose a new set of nodes after each batch",2022-01-22T10:49:42Z
Ugw1Z4mE7j3Pc_7VeB54AaABAg.9W8ubMYMcYW9cFa2RKiNpY,@alboz1327,Ugw1Z4mE7j3Pc_7VeB54AaABAg,2,ARq74QuavAo,0,0,2022-06-14T10:34:34Z,"At each iteration (batch) you pick each neuron of layer 3 and decide with prob=0.2 to shut it down. That is, at each iteration you will have 20% of your layer 3 neurons shut down, but which are shut down is random",2022-06-14T10:34:34Z
UgzJuHDgKx-OWledigF4AaABAg,@mohamedlaminebenchabane7280,,1,ARq74QuavAo,2,0,2021-10-06T14:10:44Z,why dropout if we can reduce the number of neurons?,2021-10-06T14:10:44Z
UgzJuHDgKx-OWledigF4AaABAg.9T9fFzglBo49TAsCam7SRR,@tanmayverma185,UgzJuHDgKx-OWledigF4AaABAg,2,ARq74QuavAo,0,1,2021-10-07T01:23:06Z,"The dropout happens only during the training. The test data is still predicted using the whole complete model. Also, the dropout is done randomly on a layer for each batch (that&#39;s why it is defined by probability of dropout per layer). So for each batch you will choose random nodes to be dropout and then on next batch another set of random nodes, and so on. <br>That&#39;s why it is different than reducing the number of neurons as our goal is to reduce the overfitting, not the complexity of our model. <br>Hope that helps!",2021-10-07T01:23:06Z
UgzJuHDgKx-OWledigF4AaABAg.9T9fFzglBo49caP7t7qF-M,@mohameddjilani4109,UgzJuHDgKx-OWledigF4AaABAg,2,ARq74QuavAo,0,1,2022-06-22T21:53:45Z,@@tanmayverma185 thanks a lot,2022-06-22T21:53:45Z
UgwBxtnjFFNY_mRYjkJ4AaABAg,@phumlanimbabela-thesocialc3285,,1,ARq74QuavAo,0,0,2021-08-10T19:38:18Z,Thanks.,2021-08-10T19:38:18Z
Ugyb2Ad7ilqLdMDRMDZ4AaABAg,@manuel783,,1,ARq74QuavAo,3,15,2021-01-18T22:21:47Z,"Clarification about Understanding dropout<br><br>Please note that from around <a href=""https://www.youtube.com/watch?v=ARq74QuavAo&amp;t=2m40s"">2:40</a> - <a href=""https://www.youtube.com/watch?v=ARq74QuavAo&amp;t=2m50s"">2:50</a>, the dimension of w[À°] should be 7x3 instead of 3x7, and w[¬≥] should be 3x7 instead of 7x3.<br><br>In general, the number of neurons in the previous layer gives us the number of columns of the weight matrix, and the number of neurons in the current layer gives us the number of rows in the weight matrix.",2021-01-18T22:21:47Z
Ugyb2Ad7ilqLdMDRMDZ4AaABAg.9IfUz9HXl4P9IrsANo0aVH,@supreethmv,Ugyb2Ad7ilqLdMDRMDZ4AaABAg,2,ARq74QuavAo,0,4,2021-01-23T17:44:03Z,"It basically depends on the way you multiply the weights to the data of the previous layer. So the place you&#39;ve studied might have followed the other way round.<br>Make sure the corresponding weights should be multiplied with the nodes of the previous layer.<br>This doubt occurs, coz ur basics of linear algebra should me made more firm. <br>Just watch the playlist on linear algebra by 3b1b, it&#39;s a must to know that.<br>Hope that helps bud. ‚ô•Ô∏è",2021-01-23T17:44:03Z
Ugyb2Ad7ilqLdMDRMDZ4AaABAg.9IfUz9HXl4P9SXPRUJQ7cx,@krogubueva7856,Ugyb2Ad7ilqLdMDRMDZ4AaABAg,2,ARq74QuavAo,0,3,2021-09-20T22:54:08Z,@@supreethmv The OP is confused because the opposite convention was used earlier in this course. No need to be so condescending...,2021-09-20T22:54:08Z
Ugyb2Ad7ilqLdMDRMDZ4AaABAg.9IfUz9HXl4P9j6kKa8Oeqj,@rawandbamoki9873,Ugyb2Ad7ilqLdMDRMDZ4AaABAg,2,ARq74QuavAo,0,1,2022-12-01T23:51:02Z,"From my experience, in the input layer each feature represents a column and each row represents a sample. Here in the input layer we have 3 features so the shape of the input is Nx3, where N can be any integer because it just gives us the number of samples. In the hidden layer, the weights of one neuron are in the same column and the number of neurons gives us the number of columns; we have 7 neurons with 3 weights each, hence the shape of the hidden layer is 3x7. I believe this is the convention that is mostly used.",2022-12-01T23:51:02Z
UgwIkdGhlAQHYof2TZ54AaABAg,@sandipansarkar9211,,1,ARq74QuavAo,0,3,2020-12-22T16:24:50Z,very importany lecture .need to watch again,2020-12-22T16:24:50Z
UgznvvAa1lWxgzwpX5V4AaABAg,@kswill4514,,1,ARq74QuavAo,2,1,2020-05-26T12:56:51Z,"I had a question regarding <a href=""https://www.youtube.com/watch?v=ARq74QuavAo&amp;t=3m15s"">3:15</a> since I expect assigning a low keep prop at hidden layer 1 instead of hidden layer 2. As Andy mentioned, the drop out performs shrinking of weights of input nodes which could cause overfitting, so I assumed P(keep) should be low for both hidden 1 and 2",2020-05-26T12:56:51Z
UgznvvAa1lWxgzwpX5V4AaABAg.997Dw5_UQId9CCuu_YXEeA,@chinmaymaganur7133,UgznvvAa1lWxgzwpX5V4AaABAg,2,ARq74QuavAo,0,0,2020-08-11T07:31:30Z,"hidden layer 1 receives i/p(weights)  from 3 inputs, so  weight size will be (7,3) for hd1, whereas for hdlayer2 ,it receives weights from hd1 which have 7 nodes so hd 2 weight size is(7,7)  since its a lot of parameters, p for hd2 is low compared to hd1.",2020-08-11T07:31:30Z
UgznvvAa1lWxgzwpX5V4AaABAg.997Dw5_UQId9CtV_mjteFl,@11hamma,UgznvvAa1lWxgzwpX5V4AaABAg,2,ARq74QuavAo,0,1,2020-08-28T05:48:03Z,&quot;Andy&quot;  :) :),2020-08-28T05:48:03Z
UgxdinYgA9DGvnSjQI54AaABAg,@marcellinuschrisnada7613,,1,ARq74QuavAo,2,0,2020-04-24T05:30:05Z,"Just to make sure my understanding, the downside of using dropouts is that we cannot use the loss function (or J function as previously stated in the video) as the indicator whether our model is actually converging or diverging. Because the neurons in the hidden layers are constantly changing through iterations. Therefore, we simply cannot compare since how the data is being treated differently every epoch. Is it correct?",2020-04-24T05:30:05Z
UgxdinYgA9DGvnSjQI54AaABAg.97p1Mu3yzHk97wu8TLPdK7,@winsonwijaya5592,UgxdinYgA9DGvnSjQI54AaABAg,2,ARq74QuavAo,0,1,2020-04-27T06:52:08Z,"its more likely that when computing the J, we do a forward prop through every nodes in our network when without dropout.<br>but when doing a dropout, we only do a backprop to some of the nodes in NN, which in turn that when computing the J, we will do a forward prop to only some nodes compared to when we don&#39;t use a dropout, this makes the J function less defined or not so accurate representation on how well our model cost function is(since its only calculate cost function on some nodes instead of full nodes)",2020-04-27T06:52:08Z
UgxdinYgA9DGvnSjQI54AaABAg.97p1Mu3yzHk9EdUQRVbtqr,@rahultripathi9457,UgxdinYgA9DGvnSjQI54AaABAg,2,ARq74QuavAo,0,0,2020-10-10T17:32:50Z,"Also to check if your model is performing in the right direction, we can switch off the dropout or set keepProb = 1, and see if the plot of our cost function (J) is converging or not. If yes then we are good to go for training with dropout as ON.",2020-10-10T17:32:50Z
Ugw1WnnxtlwrP1fWW1F4AaABAg,@NolanZewariligon,,1,ARq74QuavAo,1,1,2020-04-16T12:03:41Z,"<a href=""https://www.youtube.com/watch?v=ARq74QuavAo&amp;t=2m00s"">2:00</a><br>If L2 is more adaptive, what is the advantage of using dropout?<br>Is it the robustness?<br>It seems that dropout directly enforces that the network should be robust.",2020-04-16T12:03:41Z
Ugw1WnnxtlwrP1fWW1F4AaABAg.97W82lQ-qd-9CCxT93ceCY,@chinmaymaganur7133,Ugw1WnnxtlwrP1fWW1F4AaABAg,2,ARq74QuavAo,0,0,2020-08-11T07:53:50Z,"@Ran Su so weight distribution means, shape of weight matrix ???",2023-11-04T18:14:08Z
Ugyv-lLaorwrzseMWTt4AaABAg,@ABC2007YT,,1,ARq74QuavAo,0,0,2020-04-14T14:15:47Z,At what point is a dropout rate too high? 50% sounds like a lot if the training step is called frequently. I&#39;m afraid it throws out useful weights before they converge.,2020-04-14T14:15:47Z
Ugzc-kjqF_TBnE6Hert4AaABAg,@deveshnagar1732,,1,ARq74QuavAo,2,0,2020-03-31T14:58:20Z,What if instead of dropping hidden unit randomly I will trained my NN with limited units not deep,2020-03-31T14:58:20Z
Ugzc-kjqF_TBnE6Hert4AaABAg.96sFJxPm35S97Jzs37VWHZ,@joelphilip2942,Ugzc-kjqF_TBnE6Hert4AaABAg,2,ARq74QuavAo,0,8,2020-04-11T18:52:33Z,"Then there is a chance that the model will not perform well even on ur training set as the model will not able to compute the complex features due to less neurons...<br>Remember:<br>Training Error can be reduced by: Increasing the no of layers or increasing the no of neurons in a layer<br>Test Set Error can be reduced by: Using regularization strategies that ensure that the model has not overfitted on the training data, like L1 regularization,L2 regularization, Drop outs and some other techniques...<br><br><br>For more knowledge follow Andre NG&#39;s Deep Learning specialization. It consists of  5 courses and all of them are very good.......<br><br><br>Follow the link: <a href=""https://www.coursera.org/specializations/deep-learning"">https://www.coursera.org/specializations/deep-learning</a>?",2020-04-11T18:52:33Z
Ugzc-kjqF_TBnE6Hert4AaABAg.96sFJxPm35S9JIjsMQni6D,@mandarchincholkar5955,Ugzc-kjqF_TBnE6Hert4AaABAg,2,ARq74QuavAo,0,0,2021-02-03T13:30:17Z,@@joelphilip2942 thanks alot for your comment..,2021-02-03T13:30:17Z
UgyNeaGqpJUDE1KRADR4AaABAg,@coolamigo00,,1,ARq74QuavAo,6,0,2019-07-29T11:54:48Z,Do we just keep randomly changing droput neurons in every iteration once we start? How would that be useful; we need to find best combination in real world.,2019-07-29T11:54:48Z
UgyNeaGqpJUDE1KRADR4AaABAg.8xyUlNQ1mta8zfTxoZ6Vpb,@WeilongYou,UgyNeaGqpJUDE1KRADR4AaABAg,2,ARq74QuavAo,0,0,2019-09-09T19:44:58Z,I guess that means all weights are penalized?,2019-09-09T19:44:58Z
UgyNeaGqpJUDE1KRADR4AaABAg.8xyUlNQ1mta90Abnemk3cq,@ritapravadutta7939,UgyNeaGqpJUDE1KRADR4AaABAg,2,ARq74QuavAo,0,0,2019-10-17T03:49:19Z,@@WeilongYou right,2019-10-17T03:49:19Z
UgyNeaGqpJUDE1KRADR4AaABAg.8xyUlNQ1mta97K-pZOMEZL,@joelphilip2942,UgyNeaGqpJUDE1KRADR4AaABAg,2,ARq74QuavAo,0,0,2020-04-11T19:00:57Z,"Well as we are randomly selecting neurons to be deactivated in a particular iteration, you can consider that the neurons in a layer will get inputs from neurons in the previous layer, in a balanced fashion, none of them too high or too low (we scale up inputs of that layer to compensate for loss of neurons)...Hence it is not single dependent on a single feature which a particular neuron may have extracted in the previous layer.....<br>So it can work even when the some features which were present in the input data are not present in the test data...",2020-04-11T19:12:24Z
UgyNeaGqpJUDE1KRADR4AaABAg.8xyUlNQ1mta97K0w5_CFE3,@joelphilip2942,UgyNeaGqpJUDE1KRADR4AaABAg,2,ARq74QuavAo,0,1,2020-04-11T19:10:35Z,"Consider an example where you want to detect a face<br><br><br>Suppose you use a 1 layer NN, where you have the input features fed to a neuron which gives the output whether the image is a face or not..<br>Suppose we take 4 features:<br>1) eyes 2) ears 3) nose 4) mouth...<br>Now consider that all the training data consisted of images of people with specs...Then the NN would consider that all people with a face wear specs...this is a case of overfitting (somewhat extreme, i admit)....So when you balance the weights of these inputs using dropout, the inputs to the subsequent neuron from these input neurons are somewhat balanced...Hence the NN gives equal preference to eyes, ears, nose and mouth...So when it sees a person without specs, it sees that the image has other features like ears, nose and mouth...So it is a face.....<br><br><br>Hope this explains it....",2020-04-11T19:10:35Z
UgyNeaGqpJUDE1KRADR4AaABAg.8xyUlNQ1mta97LuVP6EBAh,@coolamigo00,UgyNeaGqpJUDE1KRADR4AaABAg,2,ARq74QuavAo,0,0,2020-04-12T12:44:07Z,@@joelphilip2942 Thanks! So will in the operation mode the network have all neurons or a selected combination.,2020-04-12T12:44:07Z
UgzT2qaCYK21V3e0_fR4AaABAg,@luna-kr3zc,,1,ARq74QuavAo,0,1,2019-07-08T16:51:50Z,"good voice, good explaination",2019-07-08T16:51:50Z
Ugx1FJzQAQH8PGuKW0d4AaABAg,@jpzhang8290,,1,ARq74QuavAo,3,2,2019-04-12T23:04:35Z,How can dropout be related to L2 regularization? L1 is more plausible.,2019-04-12T23:04:35Z
Ugx1FJzQAQH8PGuKW0d4AaABAg.8tdaZZ0E_Wp8zfTqrOCzkB,@WeilongYou,Ugx1FJzQAQH8PGuKW0d4AaABAg,2,ARq74QuavAo,0,0,2019-09-09T19:44:01Z,Why?,2019-09-09T19:44:01Z
Ugx1FJzQAQH8PGuKW0d4AaABAg.8tdaZZ0E_Wp92hzxmOAzH0,@o0Yozora0o,Ugx1FJzQAQH8PGuKW0d4AaABAg,2,ARq74QuavAo,0,2,2019-12-19T05:17:23Z,"I was thinking of the same thing, since L1 regularization shrinks some parameters to zero (similar effect by eliminating the nodes by using dropout). However, in this video, Andrew said that dropout spread out the weights which has the effect of shrinking the weights of all the previous units like L2 regularization.",2019-12-19T05:17:23Z
Ugx1FJzQAQH8PGuKW0d4AaABAg.8tdaZZ0E_Wp93Onwg2OOg-,@zxzhaixiang,Ugx1FJzQAQH8PGuKW0d4AaABAg,2,ARq74QuavAo,0,0,2020-01-05T05:38:58Z,Dropout can be seen as a L0 regularization (not exactly though),2020-01-05T05:38:58Z
UgzscAvd0MCJSxJs8ol4AaABAg,@MinhTran-ew3on,,1,ARq74QuavAo,4,1,2019-03-25T02:01:12Z,so why drop out work ?,2019-03-25T02:01:12Z
UgzscAvd0MCJSxJs8ol4AaABAg.8sszfSmWp_j8tYSRapQYuP,@nafisadahodwala134,UgzscAvd0MCJSxJs8ol4AaABAg,2,ARq74QuavAo,0,1,2019-04-10T13:49:24Z,Puri Ramayan ke baad pooch rahe ho ke Raam kaun hai!,2019-04-10T13:49:24Z
UgzscAvd0MCJSxJs8ol4AaABAg.8sszfSmWp_j8wCBHQmJdBn,@dragosdima8758,UgzscAvd0MCJSxJs8ol4AaABAg,2,ARq74QuavAo,0,0,2019-06-15T11:50:22Z,"He presents the intuition, if you more a more in depth analysis I recommend reading this article, <a href=""http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf?utm_content=buffer79b43&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer"">http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf?utm_content=buffer79b43&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer</a>",2019-06-15T11:50:22Z
UgzscAvd0MCJSxJs8ol4AaABAg.8sszfSmWp_j8zrxf0BrgeM,@mumcarpet109,UgzscAvd0MCJSxJs8ol4AaABAg,2,ARq74QuavAo,0,9,2019-09-14T16:04:10Z,"drop out has to work to get money, since they don&#39;t have any college degree",2019-09-14T16:04:10Z
UgzscAvd0MCJSxJs8ol4AaABAg.8sszfSmWp_j97EwfDDbvNi,@andrewtoland1933,UgzscAvd0MCJSxJs8ol4AaABAg,2,ARq74QuavAo,0,0,2020-04-09T19:48:23Z,@@mumcarpet109 drop out is most effective when applied in conjunction with tune-in and turn-on,2020-04-09T19:48:23Z
Ugw6MYjIH8qlMVvKxYF4AaABAg,@sungyunpark1366,,1,ARq74QuavAo,5,12,2019-01-30T07:10:48Z,"I think the dimension of each weight w1 should be [7][3], not [3][7]. And w3 should be [3][7]...",2019-01-30T07:10:48Z
Ugw6MYjIH8qlMVvKxYF4AaABAg.8qiVAqXAwql8rCA_HkHcyS,@davidz6828,Ugw6MYjIH8qlMVvKxYF4AaABAg,2,ARq74QuavAo,0,1,2019-02-11T05:07:14Z,"I agree. In coding and in math, the sizes are opposite to each other.",2019-02-11T05:07:14Z
Ugw6MYjIH8qlMVvKxYF4AaABAg.8qiVAqXAwql8t8NKm51vgS,@shwetashaw9978,Ugw6MYjIH8qlMVvKxYF4AaABAg,2,ARq74QuavAo,0,1,2019-03-31T10:44:32Z,"The dimension of w[l] is (n[l-1], n[l]) <br>And that of w[l].T is(n[l], n[l-1])",2019-03-31T10:44:32Z
Ugw6MYjIH8qlMVvKxYF4AaABAg.8qiVAqXAwql8w7aLvZ2JrT,@NuXxCr0,Ugw6MYjIH8qlMVvKxYF4AaABAg,2,ARq74QuavAo,0,4,2019-06-13T17:01:58Z,"@@shwetashaw9978 That is wrong. Dimension of W[l] are ( n[l], n[l-1] ). n[l] being # of neurons in current layer and n[l-1] being # of neurons in previous layer or input features.",2019-06-13T17:02:13Z
Ugw6MYjIH8qlMVvKxYF4AaABAg.8qiVAqXAwql90Ac-RdxVdi,@ritapravadutta7939,Ugw6MYjIH8qlMVvKxYF4AaABAg,2,ARq74QuavAo,0,4,2019-10-17T03:51:04Z,"It does not matter what dimension you use, you always have the option of transpose.",2019-10-17T03:51:04Z
Ugw6MYjIH8qlMVvKxYF4AaABAg.8qiVAqXAwql9FUm_cSRt5B,@BCS_AliAbbas,Ugw6MYjIH8qlMVvKxYF4AaABAg,2,ARq74QuavAo,0,0,2020-10-31T19:39:15Z,"@@shwetashaw9978 dim of w[l] is always n[l],n[l-1] andrew is mistaken here",2020-10-31T19:39:15Z
Ugz9gtqNR3J9rYTfCNp4AaABAg,@travelwithadatascientist,,1,ARq74QuavAo,0,6,2019-01-24T18:47:49Z,Thanks a lot!,2019-01-24T18:47:49Z
UgxXEkewn7v4nxn8GMd4AaABAg,@paulferro6509,,1,ARq74QuavAo,0,1,2018-02-08T16:11:18Z,Thanks!,2018-02-08T16:11:18Z
Ugx_nxi10aZDmgC8lxt4AaABAg,@martintorres5829,,1,BOCLq2gpcGU,2,0,2022-04-28T03:08:21Z,lambda is learning rate?,2022-04-28T03:08:21Z
Ugx_nxi10aZDmgC8lxt4AaABAg.9aLlc7ZI5G99enAYluxZDG,@ruscul7155,Ugx_nxi10aZDmgC8lxt4AaABAg,2,BOCLq2gpcGU,0,0,2022-08-16T13:59:16Z,it is another hyperparameter,2022-08-16T13:59:16Z
Ugx_nxi10aZDmgC8lxt4AaABAg.9aLlc7ZI5G99oVy8grUIIt,@MrAmgadHasan,Ugx_nxi10aZDmgC8lxt4AaABAg,2,BOCLq2gpcGU,0,0,2023-04-15T01:29:43Z,Not really. <br>It is the regularization hyper parameter.,2023-04-15T01:29:43Z
UgwIV83dWTmdcrl454d4AaABAg,@user-hl6yy3el8n,,1,BOCLq2gpcGU,0,11,2021-04-16T22:47:44Z,"In addition to L2 regularization and dropouts, the other common regularization methods include¬†<br>1) Data augmentation: when getting more data is expensive, we can flip image horizontally or twist image;¬†<br>2) Early stopping: plot iteration # against errors or cost function J for both training error and dev error, make iteration stop at the point where the dev error is bouncing back although the training error is still decreasing. Early stopping may backfire since it tries to solve two problems (optimization and prevent overfitting) with one method. This is the reason L2 is preferred than early stopping.",2021-04-16T22:49:20Z
Ugy7mDrSmP5MVTfHsid4AaABAg,@sandipansarkar9211,,1,BOCLq2gpcGU,0,1,2020-12-22T16:42:46Z,Nice explanation but need to watch again,2020-12-22T16:42:46Z
Ugx22NkQkjW42czuf1B4AaABAg,@shihabullah2475,,1,BOCLq2gpcGU,0,3,2020-06-11T12:51:40Z,"&quot;Notice I didn&#39;t flip it vertically because maybe we dont want a up-side down cat&quot; Haha, that was so funny. Love you Andrew &lt;3",2020-06-11T12:51:40Z
UgwbJpk7jUwSU8WpCGV4AaABAg,@EranM,,1,BOCLq2gpcGU,0,2,2018-12-09T07:58:53Z,"Andrew, What about stop training if your &#39;dev&#39; set error havn&#39;t reduce for X consecutive iterations? that&#39;s a form of early stopping which will minimize your error per hyper params set and will save time.",2018-12-09T07:58:53Z
Ugy9x2nGdPX3Yob6LLJ4AaABAg,@EranM,,1,BOCLq2gpcGU,1,3,2018-12-09T07:52:25Z,"<a href=""https://www.youtube.com/watch?v=BOCLq2gpcGU&amp;t=3m15s"">3:15</a> Picasso would be proud :&gt;",2018-12-09T07:52:25Z
Ugy9x2nGdPX3Yob6LLJ4AaABAg.8ocfbA4tvtI8vW53h8wXMz,@tejasjoshi6036,Ugy9x2nGdPX3Yob6LLJ4AaABAg,2,BOCLq2gpcGU,0,0,2019-05-29T08:49:28Z,:D,2019-05-29T08:49:28Z
UgxeYRvjQbkDQj-qL7Z4AaABAg,@tarunreddy7,,1,FDCfw-YqWTE,0,0,2023-10-30T19:48:35Z,What is the intuition behind making mean zero?,2023-10-30T19:48:35Z
Ugxn8Qo9gpiJsjKRW3x4AaABAg,@DenysNacharov,,1,FDCfw-YqWTE,1,0,2023-05-22T10:04:46Z,"For some reason I get better results from my FNN classifier without normalizing inputs. Strange, but fact",2023-05-22T10:04:46Z
Ugxn8Qo9gpiJsjKRW3x4AaABAg.9q09VMiZ7d49tXzbv6btAi,@r.k.vignesh7832,Ugxn8Qo9gpiJsjKRW3x4AaABAg,2,FDCfw-YqWTE,0,0,2023-08-18T02:58:02Z,"I‚Äôd check if you normalised the data correctly. I had a similar result the first time I tried but it turned out I was missing a step to convert all the input numbers into float32 before normalising. <br><br>However, if you‚Äôve verified that you‚Äôve normalised properly and it still continues to perform better without normalisation, it could be that some of the features you‚Äôve chosen that incidentally, have a larger range of distribution, are more important to the model‚Äôs prediction than the features with a smaller one. You might be able to further tune your model with appropriate feature engineering for that input layer‚Ä¶",2023-08-18T02:58:02Z
Ugwv_9J0XUkuByNRL_h4AaABAg,@ahmedb2559,,1,FDCfw-YqWTE,0,0,2023-01-15T11:57:29Z,Thank you !,2023-01-15T11:57:29Z
UgyeSRaL2DgU_JylYsJ4AaABAg,@JazevoAudiosurf,,1,FDCfw-YqWTE,0,0,2021-11-11T17:06:52Z,"thanks for the explanation on why to normalize, I couldn&#39;t find that anywhere else",2021-11-11T17:06:52Z
Ugwcgmrh58IqjRTDSUJ4AaABAg,@plusonetenthousand136,,1,FDCfw-YqWTE,1,0,2021-06-23T00:07:09Z,I think the formula of variance is (x - Œº)^2/(m-1). Please correct me if I am wrong.,2021-06-23T00:07:09Z
Ugwcgmrh58IqjRTDSUJ4AaABAg.9OunFUc0NXT9P0SbXudfBV,@muhammedjaabir2609,Ugwcgmrh58IqjRTDSUJ4AaABAg,2,FDCfw-YqWTE,0,0,2021-06-25T14:12:44Z,"this formula is for sample variance, but for population variance denominator is just m",2021-06-25T14:12:44Z
UgzomYz782dU_oVGOKh4AaABAg,@andersimenes1937,,1,FDCfw-YqWTE,2,0,2021-02-21T17:38:18Z,What is m here?,2021-02-21T17:38:18Z
UgzomYz782dU_oVGOKh4AaABAg.9K1XZfUl9ml9kOOGJ3qACG,@stitaprajnapanda4558,UgzomYz782dU_oVGOKh4AaABAg,2,FDCfw-YqWTE,0,0,2023-01-02T16:47:11Z,m is the sample size,2023-01-02T16:47:11Z
UgzomYz782dU_oVGOKh4AaABAg.9K1XZfUl9ml9vpJ7WAvgmk,@PippyPappyPatterson,UgzomYz782dU_oVGOKh4AaABAg,2,FDCfw-YqWTE,0,0,2023-10-13T22:46:22Z,@@stitaprajnapanda4558 `n` isn&#39;t cool enough for cha&#39;boy Ng. Neither is getting his equations or vocabulary correct either.,2023-10-13T22:46:22Z
Ugy0GAQbOMAzb-MR3Tl4AaABAg,@manuel783,,1,FDCfw-YqWTE,0,9,2021-01-18T22:29:32Z,"Clarification about Normalizing Inputs<br><br>Please note that from <a href=""https://www.youtube.com/watch?v=FDCfw-YqWTE&amp;t=0m57s"">0:57</a>, when normalizing, vector x should be divided by œÉ (and not œÉ¬≤).<br><br>So the formula for normalization is (x ‚àí Œº) / œÉ<br><br>(Subtract the mean and divide by standard deviation).<br><br>And yes, this is standardization and not normalization as stated by @Divya Ravindran",2021-01-18T22:29:32Z
UgzGBZrgelG_MiyWHnt4AaABAg,@YC-qy5lh,,1,FDCfw-YqWTE,0,0,2021-01-07T15:23:02Z,"<a href=""https://www.youtube.com/watch?v=FDCfw-YqWTE&amp;t=1m06s"">1:06</a>, I understand we need to normalise each feature to a normal distribution so that the mean is 0 and variance is 1 on each axis. If I understand it correctly, the average (miu) is a vector of length same as the number of features (not i here, the i in the video is the ith training example). But why do we add up the variance across all the features, shouldn&#39;t the variance also be a vector, since each feature has its own variance?",2021-01-07T15:28:06Z
UgxoCckRSKFUza45w9Z4AaABAg,@rahuldey6369,,1,FDCfw-YqWTE,0,1,2021-01-06T23:14:55Z,It would have been much helpful if you could give insight which one to prefer between Normalization and Standardization and why,2021-01-06T23:14:55Z
Ugy_YFw8prhcb5CmsJR4AaABAg,@sandipansarkar9211,,1,FDCfw-YqWTE,0,0,2020-12-22T16:50:53Z,good expalanations but need to watch again,2020-12-22T16:50:53Z
UgyUv9Wdp8LYymPy-kZ4AaABAg,@nikhilyewale2639,,1,FDCfw-YqWTE,1,1,2020-11-20T16:40:27Z,Optimization after normalization will give us some optimized weights corresponding to optimized I/O. How do we obtain trained weights corresponding to the original version of data from this normalized version of data ?,2020-11-20T16:40:27Z
UgyUv9Wdp8LYymPy-kZ4AaABAg.9GHy0a8VFXM9df1vvt7KFq,@Supreme_Lobster,UgyUv9Wdp8LYymPy-kZ4AaABAg,2,FDCfw-YqWTE,0,0,2022-07-19T13:38:36Z,"You dont need the weights, just unnormalize the output by doing the reverse operations (multiply by variance and add mean)",2022-07-19T13:38:36Z
UgwCy51mXyY-lqH9HDl4AaABAg,@divyaravindran007,,1,FDCfw-YqWTE,4,12,2020-10-24T00:53:56Z,"But isn&#39;t this standardization? Normalization involves methods like min max scaling. In this video, I think it is standardization of the inputs",2020-10-24T00:53:56Z
UgwCy51mXyY-lqH9HDl4AaABAg.9FAkEQvYSZ59Go-B60fBxW,@ehsanrajabi9309,UgwCy51mXyY-lqH9HDl4AaABAg,2,FDCfw-YqWTE,0,2,2020-12-03T12:34:18Z,"Yes, exactly. Standardization is a transformation in which data is scaled and the mean of data becomes zero (Œº=0) and their standard deviation becomes one (œÉ=1). Instead, in normalization, only the range of the data changes (for example change to the range [0,1]).",2020-12-03T12:34:18Z
UgwCy51mXyY-lqH9HDl4AaABAg.9FAkEQvYSZ59ONE6elTrIg,@linwingho1787,UgwCy51mXyY-lqH9HDl4AaABAg,2,FDCfw-YqWTE,0,8,2021-06-09T13:57:11Z,"yes it&#39;s standardization, but it doesn&#39;t mean it is not a normalization technique. Normalization is a general term that can refer to many differernt ways to normalize the data, and standardization is one of these ways.",2021-06-09T13:58:47Z
UgwCy51mXyY-lqH9HDl4AaABAg.9FAkEQvYSZ59df1X69_WCj,@Supreme_Lobster,UgwCy51mXyY-lqH9HDl4AaABAg,2,FDCfw-YqWTE,0,1,2022-07-19T13:35:04Z,"@@linwingho1787 thanks, this explains a lot",2022-07-19T13:35:04Z
UgwCy51mXyY-lqH9HDl4AaABAg.9FAkEQvYSZ59df4Tw9ecoQ,@linwingho1787,UgwCy51mXyY-lqH9HDl4AaABAg,2,FDCfw-YqWTE,0,1,2022-07-19T14:00:51Z,@@Supreme_Lobster welcome!,2022-07-19T14:00:51Z
UgzIIS1WMCJbogbuwSd4AaABAg,@gtsmeg3474,,1,FDCfw-YqWTE,0,1,2020-05-31T17:38:01Z,Normalizing is like scaling inputs to a given range of values no ?,2020-05-31T17:38:01Z
UgxUV5gPeZB45-5eQ1p4AaABAg,@sumitvaise5452,,1,FDCfw-YqWTE,0,0,2020-05-13T17:25:39Z,I loved this video. This gave me more insight on how can we normalize our data other than just dividing your training data of images by 255. I never tried this.  Let see how this goes.,2020-05-13T17:25:39Z
UgwuAKQc5CrOXclBw2F4AaABAg,@MrSparshtiwari,,1,FDCfw-YqWTE,0,0,2020-02-28T01:31:23Z,i have a query in subtract mean that if we are subtracting the mean everytime doesn&#39;t that interfere with our original data and shouldn&#39;t this lead to inaccurate results right ?,2020-02-28T01:31:23Z
UgwopBjVRDQxtGPmbqB4AaABAg,@amoghkulkarni3519,,1,FDCfw-YqWTE,1,0,2020-02-24T05:43:05Z,normalization can be done only when the input features are integers . we cant use it in cases like sentiment analysis right ?,2020-02-24T05:43:05Z
UgwopBjVRDQxtGPmbqB4AaABAg.95PZ9dxYjo49Pfe858PMT-,@xfire3778,UgwopBjVRDQxtGPmbqB4AaABAg,2,FDCfw-YqWTE,0,0,2021-07-11T23:30:16Z,"Just convert your values to integers. Positive sentiment is 2, neutral sentiment is 1, and negative sentiment is 0",2021-07-11T23:30:16Z
UgxTXmmAl2TvS_5MpMd4AaABAg,@giveyourmeatagoodolrub4191,,1,FDCfw-YqWTE,0,1,2020-02-16T17:02:48Z,This helped a lot! My DNN stagnated and I normalized my data not right. That was my mistake.,2020-02-16T17:02:48Z
Ugz3nGt1mGoGYh6P7wR4AaABAg,@neekuenduku,,1,FDCfw-YqWTE,0,1,2019-12-26T15:23:48Z,life saver,2019-12-26T15:23:48Z
UgxEA_u7Y1KEPay6dTR4AaABAg,@looper6394,,1,FDCfw-YqWTE,2,0,2018-08-14T17:57:08Z,Is normalization of the targets also useful?,2018-08-14T17:57:08Z
UgxEA_u7Y1KEPay6dTR4AaABAg.8jwUntzHpgd8ociUlTmnFr,@EranM,UgxEA_u7Y1KEPay6dTR4AaABAg,2,FDCfw-YqWTE,0,2,2018-12-09T08:17:37Z,hell no! why would you even consider changing them? you are trying to predict them.,2018-12-09T08:17:37Z
UgxEA_u7Y1KEPay6dTR4AaABAg.8jwUntzHpgd8pkbmWxS_bk,@jackyangara1,UgxEA_u7Y1KEPay6dTR4AaABAg,2,FDCfw-YqWTE,0,0,2019-01-06T06:24:20Z,"@@EranM if targets mean the test set, you need to normalize them.",2019-01-06T06:24:20Z
UgwEpgTOoh3PzF1p7Il4AaABAg,@looper6394,,1,FDCfw-YqWTE,5,43,2018-08-14T16:26:31Z,Two corrections: (i) use the unbiased variance estimate with m-1 in the denominator instead of m; (ii) divide x by sigma instead of sigma squared.,2018-08-14T16:26:31Z
UgwEpgTOoh3PzF1p7Il4AaABAg.8jwKR5Nzryz8t4hTTs7S7b,@xiaodong46,UgwEpgTOoh3PzF1p7Il4AaABAg,2,FDCfw-YqWTE,0,2,2019-03-30T00:32:16Z,"Yes, thank you. Divide x by œÉ will make the variance of X equal to 1.",2019-03-30T00:32:16Z
UgwEpgTOoh3PzF1p7Il4AaABAg.8jwKR5Nzryz8w41U7DUrC3,@c.w.p2295,UgwEpgTOoh3PzF1p7Il4AaABAg,2,FDCfw-YqWTE,0,5,2019-06-12T07:50:47Z,well i mean the datasets that we usually look at are super large when doing deep learning so shouldn&#39;t it not matter too much  whether we divide by m or m-1 (law of large numbers)?,2019-06-12T07:50:47Z
UgwEpgTOoh3PzF1p7Il4AaABAg.8jwKR5Nzryz94UOVfHuuvd,@user-bz7ki7dl1r,UgwEpgTOoh3PzF1p7Il4AaABAg,2,FDCfw-YqWTE,0,0,2020-02-01T06:14:47Z,I think sigma^2 and sigma make no difference.,2020-02-01T06:14:47Z
UgwEpgTOoh3PzF1p7Il4AaABAg.8jwKR5Nzryz94f1pI0yBOU,@walidayech4338,UgwEpgTOoh3PzF1p7Il4AaABAg,2,FDCfw-YqWTE,0,0,2020-02-05T18:47:30Z,thanks,2020-02-05T18:47:30Z
UgwEpgTOoh3PzF1p7Il4AaABAg.8jwKR5Nzryz98Z9T0R0JzK,@hemaswaroop7970,UgwEpgTOoh3PzF1p7Il4AaABAg,2,FDCfw-YqWTE,0,2,2020-05-12T12:45:07Z,"I believe, If we use sample (mini-batch) processing it is advisable to divide by (n-1) -. When processing the entire population (Dataset) we don&#39;t have to divide by (n-1).",2020-05-12T12:45:07Z
UgyDTs8EQqswErU544l4AaABAg,@mindalpse,,1,FDCfw-YqWTE,1,4,2017-10-22T16:04:29Z,"When normalising feature inputs, consider the distribution of the input feature.  If the feature is not normally distributed, first apply a transformation to make it a normal distribution, then scale it to have a standard deviation of 1 and a mean of 0.",2017-10-22T16:04:29Z
UgyDTs8EQqswErU544l4AaABAg.8Z16blV9Ue28yZqdmQ6J8F,@esakkiponraj.e5224,UgyDTs8EQqswErU544l4AaABAg,2,FDCfw-YqWTE,0,0,2019-08-13T09:25:52Z,"Why we should transform to normal distribution ? Advantages ? Also, how can we transform ?<br>In my case, I have 6 feature vectors, where 3 where Normally distributed and other 3 weren&#39;t ? How can i transform ?",2019-08-13T09:25:52Z
Ugyh7FvrVwKpB5O_bnV4AaABAg,@ayay9423,,1,qhXZsFVxGKo,0,1,2023-10-01T01:20:44Z,great explanation! thank you for sharing,2023-10-01T01:20:44Z
UgxvNyqjLvlomi_Sjf94AaABAg,@prajwalbharadwaj2386,,1,qhXZsFVxGKo,0,0,2023-09-12T01:00:51Z,"This covers no explanation on Vanishing Gradients, which is the case for deeper nets, where the gradients suffer to propagate back towards the starting layer of the network!!! Learning is reduced &amp; its so slow that the model barely learns at all!! Significant ideas such as Skip Connections through caching are way necessary for preventing this problem. More widely used in CNNs to avoid data loss",2023-09-12T01:00:51Z
UgzQUK3-2GMEpMs4hXt4AaABAg,@veyselaytekin8734,,1,qhXZsFVxGKo,0,0,2023-01-21T22:57:27Z,thank you so much,2023-01-21T22:57:27Z
Ugz4msfWpi3X2rlNYgZ4AaABAg,@ahmedb2559,,1,qhXZsFVxGKo,0,0,2023-01-15T12:01:50Z,Thank you !,2023-01-15T12:01:50Z
Ugyrp_uG2i7O7U79hbB4AaABAg,@vikasitbharat,,1,qhXZsFVxGKo,0,1,2023-01-14T10:34:01Z,thanks for the knowledge being delivered in such simple terms sir<br>thank you,2023-01-14T10:34:01Z
Ugyb-c2k0dsJekmyCl14AaABAg,@Waterlmelon,,1,qhXZsFVxGKo,0,0,2021-10-23T07:30:16Z,Thank you Andrew Ng as usual amazing explanation!,2021-10-23T07:30:16Z
UgztAqe5sj0mETiVKNN4AaABAg,@abdulmukit4420,,1,qhXZsFVxGKo,0,0,2021-07-30T20:04:16Z,"Hi, deepLearningAi.<br>Thank you so much for these wonderful videos. I am sure these changed a lot of lives.",2021-07-30T20:04:16Z
Ugxey0Q0AaFl3B0svXx4AaABAg,@iammakimadog,,1,qhXZsFVxGKo,2,54,2021-03-19T11:12:42Z,"Imagine you use sigmoid as activation function, which derivative is always less than 1 and greater than 0. During the backprop, you need to pass the derivative from back to front, which involves multiplying a number less than 1 for many times. If your network is deep enough, the gradient in the first few layers would become extremely small  (almost zero), and eventually those neurons will stop learning.",2021-03-19T11:12:42Z
Ugxey0Q0AaFl3B0svXx4AaABAg.9L3n6CMxjU59nFGB36KuXw,@therealsachin,Ugxey0Q0AaFl3B0svXx4AaABAg,2,qhXZsFVxGKo,0,1,2023-03-14T17:17:35Z,Thanks for pointing this out. A small correction. The derivative of sigmoid is always less than 0.25 and greater than 0. So the problem of vanishing gradient is much higher.,2023-03-14T17:17:35Z
Ugxey0Q0AaFl3B0svXx4AaABAg.9L3n6CMxjU59v5_-AJIdvN,@HarshPatel-iy5qe,Ugxey0Q0AaFl3B0svXx4AaABAg,2,qhXZsFVxGKo,0,0,2023-09-25T19:09:28Z,the learned rate will eventually become or as same as the old weight so thats how it will stop learning @@therealsachin,2023-09-25T19:09:28Z
Ugyyx4eSwOQBolCbGOR4AaABAg,@subukandaswamy4098,,1,qhXZsFVxGKo,0,4,2021-03-10T11:06:07Z,"Please wait till <a href=""https://www.youtube.com/watch?v=qhXZsFVxGKo&amp;t=4m57s"">4:57</a>....let him talk",2021-03-10T11:06:07Z
Ugw3IQp0AfVklioKVnh4AaABAg,@XX-vu5jo,,1,qhXZsFVxGKo,0,0,2021-02-10T04:49:55Z,The videos here requires you to watch each and everyone in a step-wise fashion. People arguing and asking too many irrelevant questions are people who did not watch the other videos LOL so shut up and learn! IDIOTS,2021-02-10T04:49:55Z
Ugy2PGS-bfj4LBj3UhB4AaABAg,@sandipansarkar9211,,1,qhXZsFVxGKo,0,0,2020-12-24T14:02:28Z,Great .But need towatch ot again,2020-12-24T14:02:28Z
UgyPcOoN-E9xC9f78EN4AaABAg,@tamoorkhan3262,,1,qhXZsFVxGKo,0,2,2020-11-10T12:33:48Z,"In 6min vid this is the concise and spot-on explanation. Those who were expecting some intricate complex explanations, please refer to some books, don&#39;t waste time here.",2020-11-10T12:33:48Z
UgxeFnN9yqMJiGCj0K14AaABAg,@liquid1661,,1,qhXZsFVxGKo,1,3,2020-05-20T06:48:42Z,"This is a bad explanation, it completely breaks down if you use a sigmoid activation function...",2020-05-20T06:48:42Z
UgxeFnN9yqMJiGCj0K14AaABAg.98s71PNuPAv99XNoLN8hPM,@whyisitnowhuh8691,UgxeFnN9yqMJiGCj0K14AaABAg,2,qhXZsFVxGKo,0,0,2020-06-05T16:43:25Z,yea... a lot assumptions made in this video.. like assuming all the weights are the same and the linear activation function...,2020-06-05T16:44:24Z
UgxRUkeWoEaHpBk3zEt4AaABAg,@bubblesgrappling736,,1,qhXZsFVxGKo,4,0,2020-05-15T17:00:07Z,completely disregards explaining what he means by z and l,2020-05-15T17:00:07Z
UgxRUkeWoEaHpBk3zEt4AaABAg.98gL1E8OMVK98gXXOvndE5,@sidesplitter9497,UgxRUkeWoEaHpBk3zEt4AaABAg,2,qhXZsFVxGKo,0,1,2020-05-15T18:49:22Z,he had already explained them in other videos in the course :/,2020-05-15T18:49:22Z
UgxRUkeWoEaHpBk3zEt4AaABAg.98gL1E8OMVK98irerO3a_h,@muhammadanasraza3866,UgxRUkeWoEaHpBk3zEt4AaABAg,2,qhXZsFVxGKo,0,4,2020-05-16T16:32:30Z,z is weighted sum of input features.....,2020-05-16T16:32:30Z
UgxRUkeWoEaHpBk3zEt4AaABAg.98gL1E8OMVK98jHObxhsme,@bubblesgrappling736,UgxRUkeWoEaHpBk3zEt4AaABAg,2,qhXZsFVxGKo,0,0,2020-05-16T20:26:04Z,"@@muhammadanasraza3866 ah nice, and would you happen to know what b is?",2020-05-16T20:26:04Z
UgxRUkeWoEaHpBk3zEt4AaABAg.98gL1E8OMVK98jYV_s6dKc,@muhammadanasraza3866,UgxRUkeWoEaHpBk3zEt4AaABAg,2,qhXZsFVxGKo,0,3,2020-05-16T22:55:35Z,‚Äã@@bubblesgrappling736 b is the bias(es)  :),2020-05-16T22:55:35Z
UgxdVGOE-0gfopy0tSl4AaABAg,@rizvanahmedrafsan,,1,qhXZsFVxGKo,1,3,2019-11-28T14:15:33Z,"I feel like this explanation is a bit oversimplified. Also, what happens when the weight matrices are not some multiples of identity matrix?",2019-11-28T14:15:33Z
UgxdVGOE-0gfopy0tSl4AaABAg.91ssr4EoDim947EEttUb9X,@juanx783,UgxdVGOE-0gfopy0tSl4AaABAg,2,qhXZsFVxGKo,0,0,2020-01-23T06:22:35Z,"I feel if all others hold constant like in this video, we can just eigendecompose any 2*2 matrix and easily calculate its power. But in other cases, I don&#39;t know.",2020-01-23T06:22:35Z
Ugz7GKWZdshu8FwSH0d4AaABAg,@RealMcDudu,,1,qhXZsFVxGKo,2,41,2019-09-21T14:53:11Z,"This is indeed not really about the gradient, but more about the activation. Also it assumes that W will be an Identity matrix... which is a big assumption.<br>I think for the gradient issue, you have to remember that the gradient for each layer is basically the inputs of that layer, times what ever the gradient was up to that layer. If you have a sigmoid/tanh activations, you will have that the inputs will always be a fraction. This might not be a big problem for the last layers, but as you back propagate backwards more and  more, always multiplying by a fraction, you get smaller and smaller gradients, which makes it harder and harder for the weights of those layers to learn.<br>Similarly - if your activation function can takes larger values (say ReLu) - you run the risk of your gradients becoming bigger and bigger (&quot;exploding&quot;) as you backpropagate.",2019-09-21T15:00:01Z
Ugz7GKWZdshu8FwSH0d4AaABAg.9-8r68cIQyb9CD5WSS6-pd,@karancharlee,Ugz7GKWZdshu8FwSH0d4AaABAg,2,qhXZsFVxGKo,0,0,2020-08-11T09:12:55Z,"Please explain more how a large value can mean he derivative will be large as well. if the cost is more, the derivative will be large and gradient descent on each step will make the values change accordingly,  how can the activation determine whether it will explode? does that not depend on the learning rate?",2020-08-11T09:12:55Z
Ugz7GKWZdshu8FwSH0d4AaABAg.9-8r68cIQyb9Rp8bPbFXl3,@nhactrutinh6201,Ugz7GKWZdshu8FwSH0d4AaABAg,2,qhXZsFVxGKo,0,1,2021-09-03T09:01:15Z,"Because in back prop, the derivative of weight =  derivative of error * input of that layer. Both derivative of error and input are very large, especially the input is very very large due to accumulated through many layers, and after each layer, it is increased linearly (if use relu). So derivative of weight increase much much more. Then weight is updated also much that number. Then in the next iteration, input go through network with high value weight through many layers will cause error shoot up and the same problem repeated much much much worse so it becomes overflow.",2021-09-03T09:01:15Z
Ugy6_yjyWWzlKIMTJlh4AaABAg,@David53030,,1,qhXZsFVxGKo,1,29,2018-09-23T20:05:23Z,the vanishing/exploding of activation is not the same as vanishing/exploding gradients. this is the part not well explained in this video.,2018-09-23T20:05:23Z
UgyaYlhoZ-DV9NcZ_tl4AaABAg,@user-pp1nv6le3w,,1,qhXZsFVxGKo,5,4,2018-08-09T07:18:23Z,"Mr. Professor, you speak so fast that I just can not catch up with you.  :)",2018-08-09T07:18:23Z
UgyaYlhoZ-DV9NcZ_tl4AaABAg.8jiTj5BFUDp8r4mWng_p_f,@Kevin-oo8dm,UgyaYlhoZ-DV9NcZ_tl4AaABAg,2,qhXZsFVxGKo,0,6,2019-02-08T08:13:37Z,it&#39;s great to be compact to save watching time. please go improve ur listening skill,2019-02-08T08:13:37Z
UgyaYlhoZ-DV9NcZ_tl4AaABAg.8jiTj5BFUDp8xmzEQouUM8,@hojunseo1210,UgyaYlhoZ-DV9NcZ_tl4AaABAg,2,qhXZsFVxGKo,0,18,2019-07-25T00:38:53Z,@@Kevin-oo8dm Go learn how to be polite to people.,2019-07-25T00:38:53Z
UgyaYlhoZ-DV9NcZ_tl4AaABAg.8jiTj5BFUDp8zes0TXO2Ki,@purveshjain4296,UgyaYlhoZ-DV9NcZ_tl4AaABAg,2,qhXZsFVxGKo,0,1,2019-09-09T14:04:41Z,you reduce the plackback speed manually according to your need and comfort,2019-09-09T14:04:41Z
UgyaYlhoZ-DV9NcZ_tl4AaABAg.8jiTj5BFUDp95dbyLec-2w,@k.alipardhan6957,UgyaYlhoZ-DV9NcZ_tl4AaABAg,2,qhXZsFVxGKo,0,1,2020-03-01T02:04:58Z,^ I agree. I watched at 1.5x speed,2020-03-01T02:04:58Z
UgyaYlhoZ-DV9NcZ_tl4AaABAg.8jiTj5BFUDp99XNkcLutnX,@whyisitnowhuh8691,UgyaYlhoZ-DV9NcZ_tl4AaABAg,2,qhXZsFVxGKo,0,1,2020-06-05T16:42:55Z,I think this is very a slow explanation actually ...,2020-06-05T16:42:55Z
UgxiKkSS6YNwDjqglrB4AaABAg,@siddharthsvnit,,1,qhXZsFVxGKo,0,2,2018-07-22T07:56:55Z,"this link explains it much better<br><a href=""http://neuralnetworksanddeeplearning.com/chap5.html"">http://neuralnetworksanddeeplearning.com/chap5.html</a>",2018-07-22T07:56:55Z
UgyFdGCq6-f2KCP3K2p4AaABAg,@abhijeetchauhan1349,,1,qhXZsFVxGKo,0,11,2018-06-18T18:46:50Z,TBH this explanation is very sloppy.,2018-06-18T18:46:50Z
UgwVID85A5LzK1r9czR4AaABAg,@jesperhenriksen5738,,1,qhXZsFVxGKo,3,6,2018-05-01T12:35:28Z,What would be the effect of vanishing/exploding gradients? How do you know that the problem that is occurring in your network is gradient related?,2018-05-01T12:35:28Z
UgwVID85A5LzK1r9czR4AaABAg.8fhYWzh5c7Q8fi7CrPB5I6,@grez911,UgwVID85A5LzK1r9czR4AaABAg,2,qhXZsFVxGKo,0,10,2018-05-01T17:56:01Z,"If your network is deep and it struggles to learn, i.e. has a high error on a training data even after many epochs, you can suspect this problem. To make sure you can plot a mean of gradients for each layer as in this article: <a href=""http://neuralnetworksanddeeplearning.com/chap5.html"">http://neuralnetworksanddeeplearning.com/chap5.html</a>",2018-05-01T17:56:01Z
UgwVID85A5LzK1r9czR4AaABAg.8fhYWzh5c7Q8fjcVVLERID,@jesperhenriksen5738,UgwVID85A5LzK1r9czR4AaABAg,2,qhXZsFVxGKo,0,2,2018-05-02T07:57:26Z,Thanks! :),2018-05-02T07:57:26Z
UgwVID85A5LzK1r9czR4AaABAg.8fhYWzh5c7Q8jiatQitehI,@user-pp1nv6le3w,UgwVID85A5LzK1r9czR4AaABAg,2,qhXZsFVxGKo,0,0,2018-08-09T08:29:41Z,Great explanation! Thank you.,2018-08-09T08:29:41Z
UgynSLFk_j9k0So2teV4AaABAg,@ahmedb2559,,1,s2coXdufOzE,0,0,2023-01-15T12:05:33Z,Thank you !,2023-01-15T12:05:33Z
UgwIyiJsraOHKFbS1qN4AaABAg,@user-sggbnte,,1,s2coXdufOzE,0,0,2022-10-01T16:45:00Z,ÌïúÍµ≠Ïñ¥ ÏûêÎßâ Í∞êÏÇ¨Ìï©ÎãàÎã§.. ÎèÑÏõÄÏù¥ ÎßéÏù¥ ÎêêÏäµÎãàÎã§!,2022-10-01T16:45:00Z
Ugw4LsfJW3ry1IEU9rd4AaABAg,@haneulkim4902,,1,s2coXdufOzE,0,0,2022-07-21T00:14:50Z,"@<a href=""https://www.youtube.com/watch?v=s2coXdufOzE&amp;t=2m44s"">2:44</a> using variance=2/n is better when using relu. Is there a mathematical proof? Choosing variance or hyperparameter can only be done by trial and error?",2022-07-21T00:14:50Z
UgzGNWfGjdRT2HefPb14AaABAg,@haneulkim4902,,1,s2coXdufOzE,0,0,2022-07-20T23:47:38Z,"While training deep neural network with 2 units in the final layer with sigmoid activation function for binary classification 2 weights of final layer becomes both 0 leading to same score for all inputs since it only uses bias in sigmoid, what are some reasons for this?",2022-07-20T23:47:38Z
UgypiAN5mP0ApIERzpF4AaABAg,@sanakmukherjee3929,,1,s2coXdufOzE,0,0,2022-07-14T05:32:40Z,what was the name of the paper on relu function,2022-07-14T05:32:40Z
Ugz7k2jgrznKKU7wcw54AaABAg,@usf5914,,1,s2coXdufOzE,1,2,2021-04-02T11:20:47Z,"<a href=""https://www.youtube.com/watch?v=s2coXdufOzE&amp;t=3m32s"">3:32</a><br>what is the mean of this normal distribution with especified variance ?<br>regarding to the previous lecture, it must be one?",2021-04-02T11:20:47Z
Ugz7k2jgrznKKU7wcw54AaABAg.9Lcr9_SU-YK9M6H0TRhaNS,@zardouayassir7359,Ugz7k2jgrznKKU7wcw54AaABAg,2,s2coXdufOzE,0,0,2021-04-14T06:52:40Z,"The mean is zero. If it isn&#39;t zero, the weight vector dotted with input features would produce values further than zero, which eventually increases the probability of vanishing or exploding gradients.",2021-04-14T06:52:40Z
UgxFiwOUqolK5BJXYvF4AaABAg,@sandipansarkar9211,,1,s2coXdufOzE,0,0,2020-12-24T14:09:06Z,Grood explanation .But need to watch it again,2020-12-24T14:09:06Z
UgzrVtyhVIrcGcnnIKh4AaABAg,@whyisitnowhuh8691,,1,s2coXdufOzE,0,11,2020-06-05T16:46:58Z,I am bingeing watching the whole series,2020-06-05T16:46:58Z
UgzAwrHfkRzjMNNUcg54AaABAg,@Max-lr6dk,,1,s2coXdufOzE,2,0,2020-04-22T14:55:43Z,I was looking for something better than the random initialisation on ML course on coursera. And guess on who i ran into :√†,2020-04-22T14:55:43Z
UgzAwrHfkRzjMNNUcg54AaABAg.97ktVx2Zvt097qCbD9YQyF,@anandshah9183,UgzAwrHfkRzjMNNUcg54AaABAg,2,s2coXdufOzE,0,0,2020-04-24T16:27:32Z,you should try out the deep learning course. More intuitive than the ML one,2020-04-24T16:27:32Z
UgzAwrHfkRzjMNNUcg54AaABAg.97ktVx2Zvt097qItgvqkGy,@Max-lr6dk,UgzAwrHfkRzjMNNUcg54AaABAg,2,s2coXdufOzE,0,0,2020-04-24T17:22:29Z,@@anandshah9183 I will do that thx,2020-04-24T17:22:29Z
UgxOIO7Zyw7wSsWtKYF4AaABAg,@KaanOguzhann,,1,s2coXdufOzE,0,1,2020-02-15T13:24:02Z,"Thank you for the explanation, the video deserves more likes....",2020-02-15T13:24:02Z
Ugy-nc5YqKMJZzlYY1F4AaABAg,@SoumyajitPyne,,1,s2coXdufOzE,3,8,2019-09-26T14:32:42Z,why the variance is set to 1/n?,2019-09-26T14:32:42Z
Ugy-nc5YqKMJZzlYY1F4AaABAg.9-LgjXzxPfG98c9lVmKJj9,@tomroth9964,Ugy-nc5YqKMJZzlYY1F4AaABAg,2,s2coXdufOzE,0,3,2020-05-14T02:04:45Z,"this explains it pretty well: <a href=""https://www.youtube.com/watch?v=8krd5qKVw-Q"">https://www.youtube.com/watch?v=8krd5qKVw-Q</a>",2020-05-14T02:04:45Z
Ugy-nc5YqKMJZzlYY1F4AaABAg.9-LgjXzxPfG98yjSFkDrgm,@pengsun1355,Ugy-nc5YqKMJZzlYY1F4AaABAg,2,s2coXdufOzE,0,0,2020-05-22T20:28:35Z,@@tomroth9964 thanks for that,2020-05-22T20:28:35Z
Ugy-nc5YqKMJZzlYY1F4AaABAg.9-LgjXzxPfG9KJq8JPSsM7,@gabrielwong1991,Ugy-nc5YqKMJZzlYY1F4AaABAg,2,s2coXdufOzE,0,0,2021-02-28T20:15:39Z,It is related to the order of convergence for the cost function or parameter,2021-02-28T21:05:45Z
UgyU9cjxn38Fv167AEt4AaABAg,@looper6394,,1,s2coXdufOzE,13,2,2018-08-08T16:49:55Z,"hi, how would you initialize the biases?",2018-08-08T16:49:55Z
UgyU9cjxn38Fv167AEt4AaABAg.8jgvLFVEMQV8kUytv5IpNu,@Biggzlar,UgyU9cjxn38Fv167AEt4AaABAg,2,s2coXdufOzE,0,0,2018-08-28T12:42:15Z,"The bias is always 1, that is the idea of a bias.",2018-08-28T12:42:15Z
UgyU9cjxn38Fv167AEt4AaABAg.8jgvLFVEMQV8kV7Siq5UDQ,@looper6394,UgyU9cjxn38Fv167AEt4AaABAg,2,s2coXdufOzE,0,8,2018-08-28T14:05:47Z,"@@Biggzlar the weight of the bias is always 1, the bias itself however  could be any value",2018-08-28T14:05:47Z
UgyU9cjxn38Fv167AEt4AaABAg.8jgvLFVEMQV8kVHw4HIkmh,@Biggzlar,UgyU9cjxn38Fv167AEt4AaABAg,2,s2coXdufOzE,0,0,2018-08-28T15:37:19Z,"Nope, the weight is adapted using whatever learning method you are using - the bias is always 1. By definition, it is a neuron that always outputs a signal.",2018-08-28T15:37:19Z
UgyU9cjxn38Fv167AEt4AaABAg.8jgvLFVEMQV8knEZJmgG2w,@vivdiv,UgyU9cjxn38Fv167AEt4AaABAg,2,s2coXdufOzE,0,0,2018-09-05T00:13:26Z,"yes, the bias can be of any value but I think the assumption here is that, weights are multi dimensional where as biases are singular values for each layer. So changing the biases makes less of a difference. For your solution changing the bias might yield better results, give it a try.",2018-09-05T00:13:26Z
UgyU9cjxn38Fv167AEt4AaABAg.8jgvLFVEMQV8knwwgTRnU0,@Biggzlar,UgyU9cjxn38Fv167AEt4AaABAg,2,s2coXdufOzE,0,1,2018-09-05T06:49:58Z,"Woah woah woah. No, you don&#39;t need to change the bias, because the weights that you learn for your biases will take on whatever value necessary. This is really simple: no need to adapt inputs/outputs in a neural network (that includes biases). In fact, this is wrong! We learn weights - not inputs!!!",2018-09-05T06:49:58Z
UgwIZIzUJuveWrO8Qlp4AaABAg,@WahranRai,,1,s2coXdufOzE,3,5,2018-02-22T23:05:01Z,"Sometimes it is not easy to read and understand what you wrote !!!!!!!<br>For exemple <a href=""https://www.youtube.com/watch?v=s2coXdufOzE&amp;t=4m54s"">4:54</a>  Xavier formula and below",2018-02-22T23:05:01Z
UgwIZIzUJuveWrO8Qlp4AaABAg.8cz_WTXDIci8odNgj0d819,@EranM,UgwIZIzUJuveWrO8Qlp4AaABAg,2,s2coXdufOzE,0,16,2018-12-09T14:26:23Z,Does he OWE YOU ANYTHING???????????????? He gives you free knowledge and information. You better address him with some respect fuktard.,2018-12-09T14:26:23Z
UgwIZIzUJuveWrO8Qlp4AaABAg.8cz_WTXDIci8qINBd3WPlz,@SimonK91,UgwIZIzUJuveWrO8Qlp4AaABAg,2,s2coXdufOzE,0,3,2019-01-19T18:21:30Z,@@EranM Or he could practice his deciphering skills.,2019-01-19T18:21:30Z
UgwIZIzUJuveWrO8Qlp4AaABAg.8cz_WTXDIci8y--q9huBWr,@zsh5018,UgwIZIzUJuveWrO8Qlp4AaABAg,2,s2coXdufOzE,0,1,2019-07-30T02:03:03Z,it helps to start from the beginning of the series to understand the math notations.,2019-07-30T02:03:03Z
Ugz2JZpG_sqvSujIJWF4AaABAg,@johnxina7496,,1,y1xoI7mBtOc,0,0,2023-12-16T08:48:26Z,"<a href=""https://www.youtube.com/watch?v=xY-iyQ4CB9Y"">https://www.youtube.com/watch?v=xY-iyQ4CB9Y</a>",2023-12-16T08:48:26Z
UgzSM0WLZRyvY0BKIj94AaABAg,@sandipansarkar9211,,1,y1xoI7mBtOc,0,1,2020-12-24T14:24:25Z,gret explnrtion .But need to watch again,2020-12-24T14:24:25Z
Ugx2CX2Ezp-uGrPDaCV4AaABAg,@prismaticspace4566,,1,y1xoI7mBtOc,0,0,2020-08-10T01:49:42Z,thanks for bringing back calculus,2020-08-10T01:49:42Z
UgxCLXNl6-1IRnyOFkZ4AaABAg,@yunfengwang1620,,1,y1xoI7mBtOc,0,0,2019-05-21T03:19:31Z,I was searching for the missing part of slide videos(C2M3 of Course 2 of CS230) and find this video corpus.,2019-05-21T03:19:31Z
UgyfejkkwR1n6iGGp5V4AaABAg,@kld0093,,1,y1xoI7mBtOc,1,4,2019-03-17T06:45:08Z,wtf,2019-03-17T06:45:08Z
UgyfejkkwR1n6iGGp5V4AaABAg.8sZto1Vutv79dWSfneti5-,@mohamedelyousfi2946,UgyfejkkwR1n6iGGp5V4AaABAg,2,y1xoI7mBtOc,0,0,2022-07-15T20:19:55Z,Hhhhhhh,2022-07-15T20:19:55Z
UgzcM6By5lPTlqprw0Z4AaABAg,@grez911,,1,y1xoI7mBtOc,0,19,2018-05-01T18:27:44Z,This video seems out of lessons order.,2018-05-01T18:27:44Z
UgxvzNi5dMmWEXrSxT94AaABAg,@helinafedorchuk2286,,1,y1xoI7mBtOc,0,5,2017-09-08T05:55:13Z,"Thank you so much, Andrew! It took me ages and lot of literature to learn these things about initialization, and you explained them so clearly in just 6 minutes!",2017-09-08T05:55:13Z
Ugyn65pwXT1qn8rOoU94AaABAg,@AvinashSingh-bk8kg,,1,QrzApibhohY,1,0,2021-01-24T13:38:23Z,"@<a href=""https://www.youtube.com/watch?v=QrzApibhohY&amp;t=3m56s"">3:56</a> How about finding the cosine similarity to determine the closeness of the two vectors.",2021-01-24T13:39:01Z
Ugyn65pwXT1qn8rOoU94AaABAg.9Iu-qxVFEEX9JnjDiFV-lt,@user-hx1cy3wc3m,Ugyn65pwXT1qn8rOoU94AaABAg,2,QrzApibhohY,0,0,2021-02-15T23:40:17Z,"I think there wouldn&#39;t be big difference. Because the computation of L2-norm contains inner product, and it contains the cosine value. (thought I&#39;m also new to deep learning, so it might be wrong.)",2021-02-15T23:40:17Z
Ugwep3UEBMbnp2esgiB4AaABAg,@sandipansarkar9211,,1,QrzApibhohY,0,0,2020-12-24T14:31:26Z,great explanation .But need to watch again,2020-12-24T14:31:26Z
Ugz2IDdxwXeLI1uIWJJ4AaABAg,@exampreparationonline4166,,1,QrzApibhohY,0,2,2020-07-23T08:01:25Z,gradient checking can be used to ensure that the implementation of back propagation is correct,2020-07-23T08:01:25Z
Ugz0df4fwkZbNLRSr8l4AaABAg,@fliederblumen1843,,1,QrzApibhohY,0,0,2020-07-02T18:23:31Z,"I guess it is not so correct to express in the video, as d(theta) the differential is approximately equal the difference of J() only, should not divide by 2E (no denominator)",2020-07-02T18:24:02Z
UgxX13BZa7kF9tDr7Yt4AaABAg,@yavdhesh,,1,QrzApibhohY,0,0,2020-05-28T03:45:05Z,‡§®‡§Æ‡§∏‡•ç‡§§‡•á :),2020-05-28T03:45:05Z
Ugyjyftsl8HGCipLRz94AaABAg,@danmburu4053,,1,QrzApibhohY,1,0,2019-08-12T09:20:34Z,What is the return value of J(√∏)?,2019-08-12T09:20:34Z
Ugyjyftsl8HGCipLRz94AaABAg.8yXGF1ho1N099fs72bwFsr,@ophir1080,Ugyjyftsl8HGCipLRz94AaABAg,2,QrzApibhohY,0,0,2020-06-09T09:10:09Z,"The loss. Just as you compute while training.<br>The small difference is that now you simply reshape it so you can treat each parameter equally no matter where it originally belongs (W_i, b_1, etc.)",2020-06-09T09:10:09Z
UgwoIIpHZkNTrmRmymR4AaABAg,@coolamigo00,,1,QrzApibhohY,2,0,2019-07-30T08:35:44Z,"will W1 be weight of a single neuron; number of inputs of neurons in any layer can be different than others, how will you then concatenate?",2019-07-30T10:20:00Z
UgwoIIpHZkNTrmRmymR4AaABAg.8y-hmK3z_P696hFYxvx1X8,@RaviBhatia89,UgwoIIpHZkNTrmRmymR4AaABAg,2,QrzApibhohY,0,2,2020-03-27T08:28:44Z,The concatenation is vertical stacking one after the other (Note  that Theta is a vector not a matrix),2020-03-27T08:28:44Z
UgwoIIpHZkNTrmRmymR4AaABAg.8y-hmK3z_P69NFCqVhWSYA,@volkbay,UgwoIIpHZkNTrmRmymR4AaABAg,2,QrzApibhohY,0,0,2021-05-12T14:40:47Z,"The keyword is &#39;reshaping&#39; into a vector, here.",2021-05-12T14:40:47Z
UgydsQpti2yQ24tfrcV4AaABAg,@ariyan5354,,1,QrzApibhohY,1,1,2019-02-21T11:50:06Z,What is the use of grad check,2019-02-21T11:50:06Z
UgydsQpti2yQ24tfrcV4AaABAg.8rbdclBIZiE8tWS47_IX77,@arunsiddharth852,UgydsQpti2yQ24tfrcV4AaABAg,2,QrzApibhohY,0,4,2019-04-09T19:07:43Z,Grad check is to check whether gradients you obtain from back propagation are correct or not.,2019-04-09T19:07:43Z
UgxDfro3CdEupt63xYN4AaABAg,@kavorkagames,,1,QrzApibhohY,0,6,2019-01-30T14:05:43Z,"The sole person who dislikes this often programs neural nets from scratch, not.",2019-01-30T14:05:43Z
UgzrS3p1K-1XdEBoUvx4AaABAg,@sandipansarkar9211,,1,4Ct3Yujl1dk,0,0,2020-12-24T14:37:43Z,great explanation.Need to wath again,2020-12-24T14:37:43Z
UgxZhhUejrVZlgfZqGR4AaABAg,@ritikojha3719,,1,4Ct3Yujl1dk,0,1,2020-11-02T11:38:35Z,Anyone..? how can i just check grad. check on my paper if i have to debug  the code in a very deep neural network...,2020-11-02T11:38:35Z
UgwUIfPufvwXTpju63d4AaABAg,@binxuwang4960,,1,4Ct3Yujl1dk,3,1,2020-03-31T20:43:49Z,"Actually...as tf and torch have got autograd for us, what are the cases when our backprop could be wrong?",2020-03-31T20:43:49Z
UgwUIfPufvwXTpju63d4AaABAg.96srrK5MKOf96y-5g8oyYW,@ibrahimyldrm2427,UgwUIfPufvwXTpju63d4AaABAg,2,4Ct3Yujl1dk,0,0,2020-04-02T20:32:01Z,"sir, i just have a question but not about your question. if u know the answer of my question pls inform me. So, we seperate theta as theta1,theta2,.... so on. Are the each theta(i) corresponding to any layer&#39;s w + b values? (of course as a concentaned form.)",2020-04-02T20:32:01Z
UgwUIfPufvwXTpju63d4AaABAg.96srrK5MKOf983xmDGOkM6,@timothec.8216,UgwUIfPufvwXTpju63d4AaABAg,2,4Ct3Yujl1dk,0,2,2020-04-30T09:57:50Z,I think you would use It if you implement the backpropagation yourself (creating a NN from scratch for example).,2020-04-30T09:57:50Z
UgwUIfPufvwXTpju63d4AaABAg.96srrK5MKOf983yEMVfqSk,@timothec.8216,UgwUIfPufvwXTpju63d4AaABAg,2,4Ct3Yujl1dk,0,1,2020-04-30T10:01:49Z,@@ibrahimyldrm2427 Each theta(i) corresponds to one parameter of the model (ex: W[l] or b[l]),2020-04-30T10:01:49Z
Ugz2JJ0zcyL_Wxn5lvB4AaABAg,@Jirayu.Kaewprateep,,1,4qJaSmvhxi8,0,0,2023-04-18T10:30:41Z,"üì∫üí¨ We should learn this mini-batches effects, instead of training all samples at the same time we divided the mini-0batches and see the effect from Gradient descents.<br>üß∏üí¨ That is a different thing when input has not much correlated because accuracy and loss will go up and down in the training process and as in the previous example dropout layer technique help determine the patterns in the input.<br>üß∏üí¨ The problem is how should we set the mini-batches size and the number of new inputs ( distribution rates should be the same ) this method possible to train faster when we have a high dataset input but also provides nothing and long time training for less related data.<br>üêëüí¨The accuracy rates and loss estimation values are just numbers but we can stop at the specific value we want to save and re-work. <br>üêëüí¨ One example of him doing an assignment from one course attached to this link is he changed the number of batch_size not to make it train more input samples but it is faster when they do not forget the last inputs when using less number of LSTM layer units.<br>üêëüí¨ This kind of problem you found when mapping input vocabulary.<br><br>( Nothing we found in local cartoons books Cookie run as example )<br><br>VOLA : BURG / GRUB : IBCF / FCBI<br>COKKIE : IUUQOK / KOQUUI : PBFPTP / PTPFBP <br>RUN! : XAT&#39; / &#39;TAX : ELS. / .SLE<br><br>VOLA  COKKIE  RUN!<br>===========================================================================<br>GRUB  KOQUUI  XAT&#39;<br>===========================================================================<br>IBCF  PTPFBP  ELS.<br><br>üëßüí¨ Comeback‚Äº BirdNest Hidden anywhere else.",2023-04-18T10:30:41Z
Ugy8kgfeXcai4gI7_zp4AaABAg,@rustyshackleford1964,,1,4qJaSmvhxi8,0,0,2023-02-19T22:41:02Z,Thank you thank you thank you!,2023-02-19T22:41:02Z
UgzSteLM5AcjH_yUG2J4AaABAg,@grantsmith3653,,1,4qJaSmvhxi8,0,0,2023-02-14T01:06:42Z,"I was just thinking that if you increase your mini batch size, then your error surface gets taller (assuming you&#39;re using SSE and it&#39;s a regression problem). And that means your gradients would get bigger, so your steps would all get bigger... Even though (on average) changing your batch size shouldn&#39;t change the error surface argmin. So if you increase batch size, I think you have to decrease learning rate by a proportional amount to keep your changes in weight similar",2023-02-14T01:06:42Z
UgwAOwdkyOkPBtC-PCJ4AaABAg,@ahmedb2559,,1,4qJaSmvhxi8,0,0,2023-01-18T10:24:51Z,Thank you !,2023-01-18T10:24:51Z
UgzDoQOf65A4Q2-hKcp4AaABAg,@elgs1980,,1,4qJaSmvhxi8,0,0,2022-12-31T02:50:20Z,What does processing the samples in the mini batch at the same time mean? Do we average or sum the input data before feeding them to the net?,2022-12-31T02:50:20Z
Ugzhatp7aiG7iYc48rl4AaABAg,@TheDroidMate,,1,4qJaSmvhxi8,0,6,2022-09-19T15:58:57Z,"This is by far the best explanation out there, thanks Andrew üöÄ",2022-09-19T15:58:57Z
Ugxszlph1BMHgFRiS6Z4AaABAg,@parthmadan671,,1,4qJaSmvhxi8,0,0,2022-09-16T20:19:42Z,Do we use the weights of the previous batch to initialise the next batch?,2022-09-16T20:19:42Z
Ugw5GklOcOnr68U-Jbt4AaABAg,@bilalalpaslan2,,1,4qJaSmvhxi8,0,0,2022-08-24T06:15:10Z,"Please help me? <br><br>When do the weights and the biases of model update?<br><br>End of per batch_size or end of per epoch?<br><br>I can not understand this.<br>For example,<br>Our dataset has 1600 X_train data.<br>we choose batch_size = 64 and epoch = 10, What are the weights and biases updating number 1600/64=25 or only per epoch = 10?",2022-08-24T06:15:10Z
UgwkPLAOSDRbOQU9JeV4AaABAg,@superchargedhelium956,,1,4qJaSmvhxi8,1,24,2021-06-07T22:29:19Z,This is the best way to learn.  I can compartmentalize each portion of the video into a subsection and really train myself efficiently.,2021-06-07T22:29:19Z
UgwkPLAOSDRbOQU9JeV4AaABAg.9OJ-7q1I6So9e0k5biBIQ2,@RH-mk3rp,UgwkPLAOSDRbOQU9JeV4AaABAg,2,4qJaSmvhxi8,0,2,2022-07-28T09:16:34Z,"I agree and considering how I&#39;ll often rewatch a segment of the video, it ends up being epochs = 2",2022-07-28T09:16:34Z
UgwHVoix74dTAmyodqJ4AaABAg,@s25412,,1,4qJaSmvhxi8,3,0,2021-05-22T02:38:41Z,"@<a href=""https://www.youtube.com/watch?v=4qJaSmvhxi8&amp;t=8m34s"">8:34</a> why is it being added from i=1 to l? shouldn&#39;t it be 1000?",2021-07-05T01:58:07Z
UgwHVoix74dTAmyodqJ4AaABAg.9Ncf9QQWxoC9PH1_lGaSt7,@windupbird9019,UgwHVoix74dTAmyodqJ4AaABAg,2,4qJaSmvhxi8,0,0,2021-07-02T00:43:39Z,"From my understanding, 1000 is the size of the training batch, while the l refers to the total number of layers in the nn. Since he is doing the forward and backward propagation, the gradient descent would take l steps.",2021-07-02T00:43:39Z
UgwHVoix74dTAmyodqJ4AaABAg.9Ncf9QQWxoC9POv6GsGpVF,@s25412,UgwHVoix74dTAmyodqJ4AaABAg,2,4qJaSmvhxi8,0,0,2021-07-05T02:12:15Z,"‚Äã@@windupbird9019 in another video by Ng (<a href=""https://www.youtube.com/watch?v=U-4XvK7jncg)"">https://www.youtube.com/watch?v=U-4XvK7jncg)</a> at <a href=""https://www.youtube.com/watch?v=4qJaSmvhxi8&amp;t=2m24s"">2:24</a>, he indicates that the number you divide the cost function by and the upper limit of summation symbol should be identical. So I&#39;m assuming the i=1 to l @ <a href=""https://www.youtube.com/watch?v=4qJaSmvhxi8&amp;t=8m34s"">8:34</a> is a typo... what do you think?",2021-07-05T02:13:43Z
UgwHVoix74dTAmyodqJ4AaABAg.9Ncf9QQWxoC9ReT19PEkHG,@nhactrutinh6201,UgwHVoix74dTAmyodqJ4AaABAg,2,4qJaSmvhxi8,0,0,2021-08-30T05:28:01Z,"Yes, I think it should be 1000 , the mini batch size. Typo error",2021-08-30T05:28:01Z
Ugy5oijrtVsWzotuYLV4AaABAg,@Gammalight519,,1,4qJaSmvhxi8,0,0,2021-05-10T11:48:03Z,Free education,2021-05-10T11:48:03Z
UgzTvHhSxwAl4d9c-R54AaABAg,@nikab1852,,1,4qJaSmvhxi8,0,0,2021-01-15T20:30:16Z,thank you sir!,2021-01-15T20:30:16Z
Ugwr4BuKgWn-F9JuSgd4AaABAg,@sandipansarkar9211,,1,4qJaSmvhxi8,0,0,2020-12-23T14:00:09Z,Very good rxplanation.Need to watch again,2020-12-23T14:00:09Z
UgzqCnTjIrVkAEEqjAB4AaABAg,@imanshojaei7784,,1,4qJaSmvhxi8,2,4,2020-09-12T05:11:21Z,"at <a href=""https://www.youtube.com/watch?v=4qJaSmvhxi8&amp;t=8m35s"">8:35</a> is sigma from 1 to 1000 rather than 1 to l ?",2020-09-12T05:11:21Z
UgzqCnTjIrVkAEEqjAB4AaABAg.9DV3J3QkHhL9H5gsUbtR30,@goktugguvercin8069,UgzqCnTjIrVkAEEqjAB4AaABAg,2,4qJaSmvhxi8,0,2,2020-12-10T18:51:10Z,"Yes, I guess there is a mistake there",2020-12-10T18:51:10Z
UgzqCnTjIrVkAEEqjAB4AaABAg.9DV3J3QkHhL9ee-1sjwh_z,@RH-mk3rp,UgzqCnTjIrVkAEEqjAB4AaABAg,2,4qJaSmvhxi8,0,0,2022-08-13T00:25:29Z,"I agree, it should be sum from i=1 to i=mini-batch-size, which in this case is 1000. When it was batch gradient descent for all video examples up until now, it was i=1 to i=m where m = number of training samples.",2022-08-13T00:27:46Z
UgwpX19u2iKKSJCJqgN4AaABAg,@javiercoronado4429,,1,4qJaSmvhxi8,4,42,2020-09-04T16:02:30Z,"why would someone dislike this very high level material, which Andrew made available for free for anyone?",2020-09-04T16:02:30Z
UgwpX19u2iKKSJCJqgN4AaABAg.9DBcTGWyC_39P2IsPXfHt7,@HimanshuMauryadesigners,UgwpX19u2iKKSJCJqgN4AaABAg,2,4qJaSmvhxi8,0,5,2021-06-26T07:26:08Z,envy,2021-06-26T07:26:08Z
UgwpX19u2iKKSJCJqgN4AaABAg.9DBcTGWyC_39aeawkVTDUc,@moosapatrawala1554,UgwpX19u2iKKSJCJqgN4AaABAg,2,4qJaSmvhxi8,0,1,2022-05-05T19:59:52Z,There are so many things he hasn&#39;t explained and just wrote it,2022-05-05T19:59:52Z
UgwpX19u2iKKSJCJqgN4AaABAg.9DBcTGWyC_39y9a0p0yEob,@erkinsagroglu8519,UgwpX19u2iKKSJCJqgN4AaABAg,2,4qJaSmvhxi8,0,0,2023-12-10T22:09:35Z,@@moosapatrawala1554Because this is a part of a bigger course as described on the video name,2023-12-10T22:09:35Z
UgwpX19u2iKKSJCJqgN4AaABAg.9DBcTGWyC_39yOgIixWzzq,@torgath5088,UgwpX19u2iKKSJCJqgN4AaABAg,2,4qJaSmvhxi8,0,0,2023-12-16T18:53:04Z,How to draw a kitten. Step 1: Draw a line. Step 2: Draw the rest of a kitten,2023-12-16T18:53:04Z
UgxFJiPh3vtKvk9njYx4AaABAg,@chinmaymaganur7133,,1,4qJaSmvhxi8,1,0,2020-08-12T06:23:18Z,"what is (nx,m)? ie  is nx --no of rows and m is number of features(columns) or vice versa",2020-08-12T06:23:18Z
UgxFJiPh3vtKvk9njYx4AaABAg.9CFMtv3XHCt9D2vgyBxwyP,@aayushpaudel2379,UgxFJiPh3vtKvk9njYx4AaABAg,2,4qJaSmvhxi8,0,0,2020-09-01T06:57:22Z,nx- is the number of features or input values. m- is the number of training examples.,2020-09-01T06:57:22Z
UgxiOqyiGoJ1ov-8qqN4AaABAg,@prismaticspace4566,,1,4qJaSmvhxi8,0,0,2020-08-12T03:09:13Z,baby training set...weird...,2020-08-12T03:09:13Z
Ugz3iMjYNQwkIY5K9MV4AaABAg,@tohchengchuan6840,,1,4qJaSmvhxi8,1,0,2020-07-21T10:11:34Z,"why y is (1, m) instead of (n,m) or (ny,m)?",2020-07-21T10:11:50Z
Ugz3iMjYNQwkIY5K9MV4AaABAg.9BN7XZhOlcL9D2vYXPhnwo,@aayushpaudel2379,Ugz3iMjYNQwkIY5K9MV4AaABAg,2,4qJaSmvhxi8,0,0,2020-09-01T06:56:05Z,assuming y takes a real value and not a vector value. Like in a classification problem - 0 or 1. or a regression problem. Hope it make sense! :D,2020-09-01T06:56:05Z
Ugz0qD959Vpe-XzTbDV4AaABAg,@aravindravva3833,,1,4qJaSmvhxi8,1,1,2020-06-27T01:32:57Z,"<a href=""https://www.youtube.com/watch?v=4qJaSmvhxi8&amp;t=10m52s"">10:52</a> is it 1000 gradient descent steps or 5000??",2020-06-27T01:32:57Z
Ugz0qD959Vpe-XzTbDV4AaABAg.9AOP64pivKc9AvIDMV1K-T,@pushkarwani6099,Ugz0qD959Vpe-XzTbDV4AaABAg,2,4qJaSmvhxi8,0,0,2020-07-10T05:26:57Z,"1 mini batch(1000 training sets) processes 1 gradient descent  at a time , and it is repeated 5000 times.",2020-07-10T05:26:57Z
Ugx0m1gUeICqMVV0LIV4AaABAg,@taihatranduc8613,,1,4qJaSmvhxi8,0,1,2020-06-22T21:37:22Z,you are always the best teacher,2020-06-22T21:37:22Z
Ugx_tVzmY26-r6393l94AaABAg,@yavdhesh,,1,4qJaSmvhxi8,0,6,2020-05-28T04:06:13Z,‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶ ‡§Ü‡§®‡•ç‡§¶‡•ç‡§∞‡•Å ‡§ú‡•Ä :),2020-05-28T04:06:13Z
UgxKB381oXeniSVZwYB4AaABAg,@snackbob100,,1,4qJaSmvhxi8,2,2,2020-04-21T13:44:30Z,"so all mini-batch is, is taking a vector containing the whole data set, splitting it up into k subsections, finding the average loss in each subsection, and do gradient descent on each averaged error, instead of doing gradient descent step on every single loss or each original x,y pair. So it&#39;s kind of a dimension reduction technique in a way ??",2020-04-21T13:45:28Z
UgxKB381oXeniSVZwYB4AaABAg.97iBZSmuttS9BybefVbe53,@here_4_beer,UgxKB381oXeniSVZwYB4AaABAg,2,4qJaSmvhxi8,0,1,2020-08-05T08:54:42Z,"Well, in principle you are correct. The Idea is that your mean out of 1000 samples may converge rather to the truth and also the variance (i.e. the bias of your cost) decreases with 1/sqrt(n) where n is the number of samples in a batch. Therefore your cost function evaluation is less biased and converges faster.",2020-08-05T08:54:42Z
UgxKB381oXeniSVZwYB4AaABAg.97iBZSmuttS9BybsZt1FQd,@here_4_beer,UgxKB381oXeniSVZwYB4AaABAg,2,4qJaSmvhxi8,0,1,2020-08-05T08:56:36Z,"you want to exploit the weak law of large numbers, imagine you throw a dice 10 times and you want to make predictions of its side probabilities. Your result would have been less biased if instead you would have thrown the dice 1000 times right?",2020-08-05T08:56:36Z
UgzQh2WNbDoQbUgL0Wx4AaABAg,@pivasmilos,,1,4qJaSmvhxi8,0,8,2020-04-17T14:40:34Z,Thanks for making the notation beautifully and simple.,2020-04-17T14:40:34Z
UgwmVlsOgmfCmILNmdx4AaABAg,@tutu4428,,1,4qJaSmvhxi8,0,12,2020-03-24T23:00:04Z,baby training sets,2020-03-24T23:00:04Z
UgwlX4Ooo1KS5VTLSCl4AaABAg,@tonyclvz109,,1,4qJaSmvhxi8,1,1,2019-12-03T14:01:35Z,Andrews + ENSTA = &lt;3,2019-12-03T14:01:35Z
UgwlX4Ooo1KS5VTLSCl4AaABAg.924jE4DyMLW924jH3GPuTk,@BreizhPie,UgwlX4Ooo1KS5VTLSCl4AaABAg,2,4qJaSmvhxi8,0,0,2019-12-03T14:01:59Z,"so true, I love u",2019-12-03T14:01:59Z
Ugy2Y6v8sd5nToeARYN4AaABAg,@JoseRomero-wp4ij,,1,4qJaSmvhxi8,0,1,2019-10-11T13:03:02Z,thank you so much,2019-10-11T13:03:02Z
UgzfgaTpLhPix7grB9V4AaABAg,@mishasulikashvili1215,,1,4qJaSmvhxi8,0,2,2019-07-30T22:17:20Z,Thank you sir,2019-07-30T22:17:20Z
UgyqEMkLZONUSaLMtHh4AaABAg,@user-cc8kb,,1,4qJaSmvhxi8,1,34,2018-11-21T16:19:27Z,He is so great. Andrew Ng ftw :D,2018-11-21T16:19:27Z
UgyqEMkLZONUSaLMtHh4AaABAg.8nvEK0YrFpN994zgaR9ru6,@honoriusgulmatico6073,UgyqEMkLZONUSaLMtHh4AaABAg,2,4qJaSmvhxi8,0,1,2020-05-25T16:05:10Z,So this is how this office looks like when you&#39;re NOT taking Coursera ML!,2020-05-25T16:05:10Z
Ugy-w0IudyaXUFCkRaF4AaABAg,@nirbhaykumarpandey8955,,1,4qJaSmvhxi8,1,0,2018-11-14T12:01:26Z,why is X   nx by m and not n by m ??,2018-11-14T12:01:26Z
Ugy-w0IudyaXUFCkRaF4AaABAg.8nckE8QxRKx906tI8gRHCq,@rui7268,Ugy-w0IudyaXUFCkRaF4AaABAg,2,4qJaSmvhxi8,0,0,2019-10-15T17:05:12Z,"Because nx represent input data which could be a matrix rather than a integer, e.g. if input data is a RBG image, you have (0-255)*(0-255)*3 pixels, it&#39;s not only about the number of one mini batch but also the pixels it have. Notation of nx must be better than n.",2019-10-15T17:05:12Z
UgzUVAgXPgXaz8DXKkp4AaABAg,@iAmTheSquidThing,,1,4qJaSmvhxi8,4,11,2018-04-13T23:59:28Z,"I&#39;m wondering if optimization might happen faster by first sorting the entire dataset into categories, and then ensuring that each mini-batch is a stratified sample which approximates the entire dataset.",2018-04-13T23:59:28Z
UgzUVAgXPgXaz8DXKkp4AaABAg.8f-QUzKqPDp8fNXbXxrWsv,@iAmTheSquidThing,UgzUVAgXPgXaz8DXKkp4AaABAg,2,4qJaSmvhxi8,0,9,2018-04-23T08:43:26Z,"Spirit ‚Äì Apparently someone had the idea long before me and it is effective: <a href=""https://arxiv.org/abs/1405.3080"">https://arxiv.org/abs/1405.3080</a><br><br>My understanding is that it ensures your model approximates the entire dataset at every iteration. You never have an iteration which comprises almost entirely samples from one class. Thereby wasting iterations fitting the function to an inaccurate dataset which has to be undone in later iterations.",2018-04-23T08:43:26Z
UgzUVAgXPgXaz8DXKkp4AaABAg.8f-QUzKqPDp8swNKy1_YBJ,@cdahdude51,UgzUVAgXPgXaz8DXKkp4AaABAg,2,4qJaSmvhxi8,0,2,2019-03-26T09:34:26Z,@@iAmTheSquidThing Why not just shuffle the dataset then?,2019-03-26T09:34:26Z
UgzUVAgXPgXaz8DXKkp4AaABAg.8f-QUzKqPDp8wPCte4KQgr,@amanshah9961,UgzUVAgXPgXaz8DXKkp4AaABAg,2,4qJaSmvhxi8,0,0,2019-06-20T13:14:35Z,@@iAmTheSquidThing Thanks for the reference :},2019-06-20T13:14:35Z
UgzUVAgXPgXaz8DXKkp4AaABAg.8f-QUzKqPDp9FlCvq-hfjQ,@cristian-bull,UgzUVAgXPgXaz8DXKkp4AaABAg,2,4qJaSmvhxi8,0,0,2020-11-07T14:05:18Z,"hey, that&#39;s a simple, cool idea you got there",2020-11-07T14:05:18Z
UgyF1IMR1VONLyYH9Ot4AaABAg,@bluefanta7668,,1,-_4Zi8fCZO4,1,0,2023-02-05T18:00:56Z,"In the case of mini batch GD, one epoch equals to the one the mini batch or the whole dataset?",2023-07-02T12:29:53Z
UgyF1IMR1VONLyYH9Ot4AaABAg.9ll3j9fvke19rdY21aprAM,@huaizhiwu,UgyF1IMR1VONLyYH9Ot4AaABAg,2,-_4Zi8fCZO4,0,1,2023-07-01T23:00:14Z,"One epoch means going through the whole dataset once in both batch GD and mini-batch GD. <br><br>The difference is just that there&#39;s only one gradient update per epoch in batch GD, but many updates per epoch in mini-batch GD (one update per mini-batch).",2023-07-01T23:00:14Z
UgxvEBH1aIxy8WRtqZp4AaABAg,@ahmedb2559,,1,-_4Zi8fCZO4,0,0,2023-01-18T10:33:23Z,thank you !,2023-01-18T10:33:23Z
UgxdW0fKCfuKSDORAm54AaABAg,@haneulkim4902,,1,-_4Zi8fCZO4,1,0,2022-02-09T01:44:30Z,Amazing! When using batch GD (mini-batch size = m) it converges unlike mini-batch &lt; m ?,2022-02-09T01:44:30Z
UgxdW0fKCfuKSDORAm54AaABAg.9YCm0eui5V69cr5lWcUiYx,@rafipatel5020,UgxdW0fKCfuKSDORAm54AaABAg,2,-_4Zi8fCZO4,0,0,2022-06-29T09:31:37Z,"Nope, it will converge as a regular GD. Since size=m , it is no different than a GD",2022-06-29T09:31:37Z
Ugy007_fLgA63btuYh94AaABAg,@yongjiewang9686,,1,-_4Zi8fCZO4,0,0,2021-12-09T11:16:15Z,This is called: Nice!,2021-12-09T11:16:15Z
UgxKRbJvqebadf7rD3l4AaABAg,@sandipansarkar9211,,1,-_4Zi8fCZO4,0,0,2020-12-30T14:45:30Z,great explanation.Need to watch again,2020-12-30T14:45:30Z
UgzpcxxmkYIQrh4D8V14AaABAg,@srikanth1385,,1,-_4Zi8fCZO4,1,0,2020-10-29T07:21:00Z,"In Batch GD, we pass entire dataset to the neural net and do the forward propagation, calculate the cost function, based on the cost function, we do the back propagation and we would perform the same operation for few more epochs. Can anyone help me understand with order of operation in mini batch gradient decent, and comparing it with the batch gradient decent will be high appreciated.",2020-10-29T07:21:00Z
UgzpcxxmkYIQrh4D8V14AaABAg.9FOJVl4DoxJ9Iu2UobtJLa,@AvinashSingh-bk8kg,UgzpcxxmkYIQrh4D8V14AaABAg,2,-_4Zi8fCZO4,0,4,2021-01-24T14:01:26Z,"Batch Gradient descent:<br>Suppose u have 10K records.<br>Now, all 10K records will be considered at once in the forward propogation.<br>Then we perform backward propogation on the same 10K records.<br>This takes time as we are dealing with large number of data.<br>We saw in this case gradient descent will be slow.<br>As each step towards minima will be taken once entire dataset is dealt with.<br><br>On the other hand in minibatch we split entire 10K records into small batches.<br>Suppose we split it into batches of 1k.<br>So we will have 10 such batches.<br>Now we will pick one batch of 1k records.<br>Do the forward propogation with the first batch of 1k records.<br>Again to the backward propogation on this batch and will do the gradient descent step.<br>So we saw we did not wait for the model to go through all the 10k records.Instead we do the gradient descent for every batch.<br>Now after the gradient descent on this batch, update the weight and feed the next batch and repeat.",2021-01-24T14:01:26Z
UgxTRAWoCe8t6HJxLh14AaABAg,@rahulagrawal8179,,1,-_4Zi8fCZO4,0,1,2019-12-25T12:40:52Z,but what if the test size is not a factor of 2. What wil be the sie of mini batch GD?????,2019-12-25T12:40:52Z
UgxaZNeB8KdA7iQrANJ4AaABAg,@khushnoodabbas7084,,1,-_4Zi8fCZO4,6,6,2019-06-02T14:58:30Z,"In case of multiclass classification, do we need to take care that every mini batch should have the examples of all the classes?",2019-06-02T14:58:30Z
UgxaZNeB8KdA7iQrANJ4AaABAg.8vg2Tw75Q_R8vxEimkfkoX,@naveenmirada2443,UgxaZNeB8KdA7iQrANJ4AaABAg,2,-_4Zi8fCZO4,0,1,2019-06-09T07:12:36Z,Did you get an answer?,2019-06-09T07:12:36Z
UgxaZNeB8KdA7iQrANJ4AaABAg.8vg2Tw75Q_R8vxGlO3Nmvs,@khushnoodabbas7084,UgxaZNeB8KdA7iQrANJ4AaABAg,2,-_4Zi8fCZO4,0,1,2019-06-09T07:30:26Z,Naveen Mirada no not yet..,2019-06-09T07:30:26Z
UgxaZNeB8KdA7iQrANJ4AaABAg.8vg2Tw75Q_R8y-bqhy20zE,@bharathbhimshetty8926,UgxaZNeB8KdA7iQrANJ4AaABAg,2,-_4Zi8fCZO4,0,0,2019-07-30T07:43:54Z,@@khushnoodabbas7084 I have searched a lot for multi class gradient descent regression over YouTube but in vain. All are doing videos with single independent variable..!!!,2019-07-30T07:43:54Z
UgxaZNeB8KdA7iQrANJ4AaABAg.8vg2Tw75Q_R8y1klj3rtQR,@khushnoodabbas7084,UgxaZNeB8KdA7iQrANJ4AaABAg,2,-_4Zi8fCZO4,0,0,2019-07-31T03:40:21Z,"@@bharathbhimshetty8926 . I have found the solution for this problem. you can do it in two ways 1) you can implement the same binary class classification model for multiclass classification problem using on vs all method see this lecture and related for the explanation (<a href=""https://www.youtube.com/watch?v=ZvaELFv5IpM)"">https://www.youtube.com/watch?v=ZvaELFv5IpM)</a>. 2) The second way to implement is obviously using softmax which is faster than one vs all method and standard also.  The only problem you might face when implementing softmax is calculating derivative at the final layer when doing backpropagation so after long research, I have found the solution here by this guy (wordpress@example.com) unfortunately unable to find the blog again. you can try.",2019-07-31T03:40:21Z
UgxaZNeB8KdA7iQrANJ4AaABAg.8vg2Tw75Q_R8y1kus0MAKT,@khushnoodabbas7084,UgxaZNeB8KdA7iQrANJ4AaABAg,2,-_4Zi8fCZO4,0,0,2019-07-31T03:41:35Z,@@bharathbhimshetty8926 As for as the mini-batch problem  I have implemented by considering every example in each mini batch...,2019-07-31T03:41:35Z
UgyxuFwxVAMuJGUr2MV4AaABAg,@muratcan__22,,1,-_4Zi8fCZO4,0,1,2018-12-02T21:56:16Z,nice explanation,2018-12-02T21:56:16Z
Ugyi2c8sLm8s6t3ln6N4AaABAg,@nischalsimha9995,,1,-_4Zi8fCZO4,4,0,2018-10-16T07:31:24Z,"@<a href=""https://www.youtube.com/watch?v=-_4Zi8fCZO4&amp;t=2m03s"">2:03</a> , &quot;# iterations&quot; is same as number of  epochs right?",2018-10-16T07:31:24Z
Ugyi2c8sLm8s6t3ln6N4AaABAg.8mSaGxZgjY18m_zJVhqdy0,@ManishKumar-rs8tw,Ugyi2c8sLm8s6t3ln6N4AaABAg,2,-_4Zi8fCZO4,0,3,2018-10-19T13:44:07Z,"<a href=""http://www.youtube.com/results?search_query=%23iterations"">#iterations</a> -&gt; to be done until Gradient Descent is converged. <br># epochs -&gt; One Iteration through all Mini Batches.",2018-10-20T15:00:07Z
Ugyi2c8sLm8s6t3ln6N4AaABAg.8mSaGxZgjY18ma2GlRNgP5,@nischalsimha9995,Ugyi2c8sLm8s6t3ln6N4AaABAg,2,-_4Zi8fCZO4,0,0,2018-10-19T14:18:42Z,@@ManishKumar-rs8tw But epochs in case of batch gradient descent is one pass through the whole training set right?,2018-10-19T14:18:42Z
Ugyi2c8sLm8s6t3ln6N4AaABAg.8mSaGxZgjY18mcgrKBFzCi,@ManishKumar-rs8tw,Ugyi2c8sLm8s6t3ln6N4AaABAg,2,-_4Zi8fCZO4,0,1,2018-10-20T15:00:34Z,"@Rahul Ks, Please ignore my earlier message. I edited the post.",2018-10-20T15:00:34Z
Ugyi2c8sLm8s6t3ln6N4AaABAg.8mSaGxZgjY18mcmomcUbwe,@nischalsimha9995,Ugyi2c8sLm8s6t3ln6N4AaABAg,2,-_4Zi8fCZO4,0,0,2018-10-20T15:52:39Z,@@ManishKumar-rs8tw thank you!,2018-10-20T15:52:39Z
Ugz2nVaekeBH8nNhMI14AaABAg,@banipreetsinghraheja8529,,1,-_4Zi8fCZO4,3,0,2018-06-06T20:33:20Z,"So, we can consider that in mini batch and stochastic, we keep epochs low, or else, the computational cost would be same as Batch Gradient Descent, right?",2018-06-06T20:33:20Z
Ugz2nVaekeBH8nNhMI14AaABAg.8hA5pZGMwMv8i2LNkngZK6,@4abhishekagarwal,Ugz2nVaekeBH8nNhMI14AaABAg,2,-_4Zi8fCZO4,0,0,2018-06-28T16:46:41Z,"I think it&#39;s more about the computational cost arising due to keeping a large vector (n x m) together (in your RAM) and passing it through the network iteratively. Batch gradient descent suffers from this sort of computational complexity and takes a long time per iteration. The number of gradient descent steps you take to arrive at the minima should be fewer while implementing batch gradient descent than in the stochastic/mini-batch case, however. If you don&#39;t take enough epochs in a  mini-batch/stochastic, you might not zero down on the local minima.",2018-06-28T16:49:14Z
Ugz2nVaekeBH8nNhMI14AaABAg.8hA5pZGMwMv8mSb2YYllaS,@nischalsimha9995,Ugz2nVaekeBH8nNhMI14AaABAg,2,-_4Zi8fCZO4,0,0,2018-10-16T07:38:10Z,"in mini batch gradient descent , after completing all the mini batches , do we redo the whole process again and again till we converge as we do in batch GD or is it just one time?",2018-10-16T07:38:10Z
Ugz2nVaekeBH8nNhMI14AaABAg.8hA5pZGMwMv8mnVIR63F3W,@Ditoekacahya,Ugz2nVaekeBH8nNhMI14AaABAg,2,-_4Zi8fCZO4,0,0,2018-10-24T19:42:27Z,"@@nischalsimha9995 generally yes, you need to loop through several epochs (one complete round of mini-batches¬†each) until you reach your specified cost function value",2018-10-24T19:42:27Z
UgzmyJ06EVQRCYAqRud4AaABAg,@klausdupont6335,,1,-_4Zi8fCZO4,3,24,2017-12-22T15:22:02Z,I suppose there is an error in the title: the &quot;Dexcent&quot; should be &quot;Descent&quot;.,2017-12-22T15:22:02Z
UgzmyJ06EVQRCYAqRud4AaABAg.8aU6FFQlUoE8ad5F9uyKMG,@IgorAherne,UgzmyJ06EVQRCYAqRud4AaABAg,2,-_4Zi8fCZO4,0,0,2017-12-26T12:25:41Z,:D,2017-12-26T12:25:41Z
UgzmyJ06EVQRCYAqRud4AaABAg.8aU6FFQlUoE9-ym5lhK_I8,@JoseRomero-wp4ij,UgzmyJ06EVQRCYAqRud4AaABAg,2,-_4Zi8fCZO4,0,1,2019-10-12T04:09:11Z,Wha are you? The grammar-nazi of AI?,2019-10-12T04:09:11Z
UgzmyJ06EVQRCYAqRud4AaABAg.8aU6FFQlUoE919crUXxVen,@jorjiang1,UgzmyJ06EVQRCYAqRud4AaABAg,2,-_4Zi8fCZO4,0,8,2019-11-10T15:10:44Z,@@JoseRomero-wp4ij has nothing to do with grammar.,2019-11-10T15:10:44Z
UgwRGwfI6UVWV-0tHUx4AaABAg,@antonkorolev8059,,1,lAq96T8FkTw,0,0,2023-07-22T00:38:48Z,"<a href=""https://www.youtube.com/watch?v=lAq96T8FkTw&amp;t=02m30s"">02:30</a> you are saying that if you compute this and plot it in red and then show the graph. I computed it and it doesn‚Äôt match up. <br>V1 = 4 <br>V2 = 3.6 + 4.9 = 8.4 and so on. <br>When the temperature values are around 40 deg F. <br>Then how is the red graph alights with the temperatures ?",2023-07-22T00:38:48Z
UgyvRuZjPIOzCkgzU4t4AaABAg,@navketan1965,,1,lAq96T8FkTw,0,0,2023-04-11T21:46:33Z,"For trading 15 minute forex chart what settings do you recommend for TEMA--trading being done in direction of 4 hour trend, I think for short term trading where you close trades in 2--3 days, best guide to trend direction is 4 hour chart.Trend on 4 hour chart is not going to flip on A <a href=""http://dime.by/"">dime.By</a> the time trend changes on daily chart, market has already moved in THAT DIRECTION FOR 5--10 days &amp; IT IS ALREADY TOO LATE. After all over thousands of iterations at any point chances of  market going up/down are 50/50.--What do you recommend?",2023-04-11T21:46:33Z
UgyMVklZlQ7NZ0f4dwV4AaABAg,@chenyu8553,,1,lAq96T8FkTw,0,0,2022-10-15T04:10:33Z,Nice explaination.,2022-10-15T04:10:33Z
UgwvMd7-w2rRBq88WwV4AaABAg,@a.j.noushin1071,,1,lAq96T8FkTw,1,4,2021-08-25T16:07:04Z,"It makes sense to initialize v0 to the first data point rather than zero.  From the shown graph, it is obvious that he is doing it this way but he does not mention it",2021-08-25T16:07:04Z
UgwvMd7-w2rRBq88WwV4AaABAg.9RTjBLUl0mz9fWcrlWDV6l,@prithvidhyani52,UgwvMd7-w2rRBq88WwV4AaABAg,2,lAq96T8FkTw,0,0,2022-09-03T15:00:28Z,"actually, he explains in the later videos, there is a bias correction for V_t  where you divide by 1-(beta^t). Initializing v0 to 0 or theta0 will not accurately predict the initial values.",2022-09-03T15:00:28Z
UgwJb8NNAcllqaAEkdR4AaABAg,@jhonnykokos8522,,1,lAq96T8FkTw,0,0,2021-08-08T20:49:14Z,Thank you Sir!,2021-08-08T20:49:14Z
UgyccEcOdhYNi6VEVAF4AaABAg,@DrOmarJavaid,,1,lAq96T8FkTw,0,2,2021-07-06T04:20:25Z,"There is a heading &#39;How to kill your grandmother&#39; in one of Nassim Nicholas Taleb&#39;s book (Skin in the Game, if I remember correctly)) and it talks about distortion in the real picture created by averages ... according to Taleb keeping an eye on extreme values is far far more important, particularly the outliers, then the values which come closer to a so called average ..",2021-07-06T04:28:21Z
UgzFzqOF4rna9hzoQ1d4AaABAg,@Random4Logic,,1,lAq96T8FkTw,0,0,2021-06-19T13:59:46Z,soo is this the thing people call &quot;moving average&quot; in context of neural networks to average weights over traininer iterations? If so that would mean you always average over 2 iterations? the current and the previous,2021-06-19T13:59:46Z
UgwaWo4aqT47hzGlY2N4AaABAg,@sandipansarkar9211,,1,lAq96T8FkTw,2,3,2020-12-30T14:52:40Z,great explanation.Need to watch again,2020-12-30T14:52:40Z
UgwaWo4aqT47hzGlY2N4AaABAg.9HtlU9dOMB39X2iAYvItsg,@machinelearning3518,UgwaWo4aqT47hzGlY2N4AaABAg,2,lAq96T8FkTw,0,0,2022-01-11T07:27:06Z,I&#39;m watching it again,2022-01-11T07:27:06Z
UgwaWo4aqT47hzGlY2N4AaABAg.9HtlU9dOMB39u53U-XWndO,@ermano5586,UgwaWo4aqT47hzGlY2N4AaABAg,2,lAq96T8FkTw,0,0,2023-08-31T17:53:56Z,@@machinelearning3518I am also watching again,2023-08-31T17:53:56Z
Ugzf2tEuoFjC4XbBs6t4AaABAg,@piyushsoni736,,1,lAq96T8FkTw,0,0,2020-07-21T17:09:07Z,"If emwa = n-days MA then, why do we need it??",2020-07-21T17:09:07Z
UgwqPdQrPQo3n9uzX0h4AaABAg,@mailoisback,,1,lAq96T8FkTw,0,1,2020-03-10T07:49:28Z,What is V? Is it (averaged) temperature with the same units as theta?,2020-03-10T07:49:28Z
Ugz2qCd46ZHoA3pnn-14AaABAg,@leftaroundabout,,1,lAq96T8FkTw,3,16,2020-01-26T15:07:43Z,‚ÄúExponentially weighted averages‚Äù is a quite pretentious name for the simplest <i>low pass filter</i> there is.,2020-01-26T15:07:43Z
Ugz2qCd46ZHoA3pnn-14AaABAg.94Ftij5KyZl94txD12KaRM,@oleholgerson3416,Ugz2qCd46ZHoA3pnn-14AaABAg,2,lAq96T8FkTw,0,3,2020-02-11T13:47:04Z,leftaroundabout or just much more descriptive and understandable. Tells you exactly what it does.,2020-02-11T13:47:04Z
Ugz2qCd46ZHoA3pnn-14AaABAg.94Ftij5KyZl9EYFefepRNw,@eyyo3571,Ugz2qCd46ZHoA3pnn-14AaABAg,2,lAq96T8FkTw,0,0,2020-10-08T07:28:24Z,"Im sorry, my small and feeble mind cant understand how this is similar to a low pass filter. Could you please explain.",2020-10-08T07:28:40Z
Ugz2qCd46ZHoA3pnn-14AaABAg.94Ftij5KyZl9EZHdNbYeWo,@leftaroundabout,Ugz2qCd46ZHoA3pnn-14AaABAg,2,lAq96T8FkTw,0,0,2020-10-08T17:04:57Z,"@@eyyo3571 well, any moving average is a lowpass filter: it supresses fluctuations within the window, and only lets the larger-scale trends through. However, if different portions of the window are weighted differently (or even negatively, as is the case with some other filters) it&#39;s a bit weird to call it an <i>average</i> anymore.<br>Also, the <i>exponential,</i> whilst seeming a bit of an arbitrary choice when introduced this way (why not instead e.g. a falling triangle?), actually arises completely naturally in the filter view (it&#39;s what all <i>first-order filters</i> do, those you can build by e.g. combining a resistor and a capacitor).",2020-10-08T17:05:18Z
UgzZuX8hUgn6KLCER_x4AaABAg,@goldenamaa8679,,1,lAq96T8FkTw,0,1,2019-08-20T11:34:13Z,Thank you alot,2019-08-20T11:34:13Z
Ugw5NkRhU8oKvxYh6Np4AaABAg,@JanVanhara,,1,lAq96T8FkTw,0,4,2019-02-17T16:08:27Z,"I think, the period is aproximately calculated as 2/(1-beta).",2019-02-17T16:36:24Z
Ugypjkxz2nP0R-3XFL94AaABAg,@sambitkumarbehura1620,,1,lAq96T8FkTw,4,2,2019-02-11T16:39:36Z,how is taking beta=0.9 equivalent to averaging temperature over 10 days?,2019-02-11T16:39:36Z
Ugypjkxz2nP0R-3XFL94AaABAg.8rDPoKVmhR_8t3vE4j55k7,@danlan4132,Ugypjkxz2nP0R-3XFL94AaABAg,2,lAq96T8FkTw,0,0,2019-03-29T17:13:15Z,1/(1-0.9)=10,2019-03-29T17:13:15Z
Ugypjkxz2nP0R-3XFL94AaABAg.8rDPoKVmhR_9HT1O3Ver6_,@Internetverbraucher,Ugypjkxz2nP0R-3XFL94AaABAg,2,lAq96T8FkTw,0,1,2020-12-19T20:21:39Z,"@@danlan4132 i think this is not correct. Beta=0.9 means that the average from yesterday ist weighted with 0.9, and todays Temperature reading ist weighted with 0.1. But yesterdays average already carries the average from the day before, and that carries the average from 2 days before, and so on and so on. Every day the former averages are again multiplied by 0.9, so they have less and less influence with each comming day, but they will never be weighted by 0. Even measuerements from a 100 days ago will have a slight influence on todays average, 0.9^100 to be precise. But i don&#39;t think it&#39;s correct to call this a 10 day average",2020-12-19T20:21:39Z
Ugypjkxz2nP0R-3XFL94AaABAg.8rDPoKVmhR_9OF-QKEAr3l,@redr2222,Ugypjkxz2nP0R-3XFL94AaABAg,2,lAq96T8FkTw,0,2,2021-06-06T09:14:52Z,"‚Äã@@Internetverbraucher Andrew said it approximates, not is equal to.",2021-06-06T09:14:52Z
Ugypjkxz2nP0R-3XFL94AaABAg.8rDPoKVmhR_9egeCauolFP,@RH-mk3rp,Ugypjkxz2nP0R-3XFL94AaABAg,2,lAq96T8FkTw,0,1,2022-08-14T01:12:26Z,"@@Internetverbraucher Thanks for your comment. I struggled to derive the 1 / (1 - beta) average formula so I came to think that it&#39;s not a 10 day or &quot;t&quot; day average. In the case of beta=0.9, the prevous terms include a 0.9^t, exponentially increasing the further you go back. I think for some value beta there is a cetain point where beta^t becomes so insignificant that 1 / (1 - beta) becomes the approximate threshold for the number of significant days.<br>Edit: I jumped the gun, it was explained in the next video....",2022-08-14T02:19:01Z
Ugyx9nTr3nHKNhqevbJ4AaABAg,@KASANITEJ,,1,lAq96T8FkTw,1,0,2019-01-27T03:19:53Z,says exponential.. but no exponents ü§îü§îü§î,2019-01-27T03:19:53Z
Ugyx9nTr3nHKNhqevbJ4AaABAg.8qaMMs3W1j18tR79TC4mhI,@itzikgutzcha4779,Ugyx9nTr3nHKNhqevbJ4AaABAg,2,lAq96T8FkTw,0,1,2019-04-07T17:28:45Z,"watch the next video and you&#39;ll see where the exponentials are <br><a href=""https://www.youtube.com/watch?v=lAq96T8FkTw"">https://www.youtube.com/watch?v=lAq96T8FkTw</a>",2019-04-07T17:28:45Z
UgzFsdEVra1xESsmBCZ4AaABAg,@saimadhavp,,1,lAq96T8FkTw,2,3,2018-12-28T11:05:37Z,V(t) = (beta)V(t-1) + (1-beta) * @(t) or the other way. Python Panda dataframe implements the formula mentioned by me . Which is correct? weighted_average[0] = arg[0]; weighted_average[i] = (1-beta)*weighted_average[i-1] + beta*arg[i].,2018-12-28T11:05:37Z
UgzFsdEVra1xESsmBCZ4AaABAg.8pOwomhNUCb8rSoRKsIV3T,@JanVanhara,UgzFsdEVra1xESsmBCZ4AaABAg,2,lAq96T8FkTw,0,2,2019-02-17T16:12:07Z,"alpha in pandas is the smoothing factor. Beta is weight, alpha for pandas can be calculated as: alpha = 1-beta<br>Lets try:<br>df.ewm(alpha=1-beta, adjust=False).mean()",2019-02-17T16:32:31Z
UgzFsdEVra1xESsmBCZ4AaABAg.8pOwomhNUCb8rSr1zfih7Z,@JanVanhara,UgzFsdEVra1xESsmBCZ4AaABAg,2,lAq96T8FkTw,0,1,2019-02-17T16:34:52Z,"And for period lets try:<br>period = 2/(1-beta)<br>df.ewm(span=period, adjust=False).mean()",2019-02-17T16:34:52Z
Ugz6DtBdwiHAFQlFBLZ4AaABAg,@EranM,,1,lAq96T8FkTw,1,8,2018-12-11T12:40:42Z,damn it&#39;s cold in London!,2018-12-11T12:40:42Z
Ugz6DtBdwiHAFQlFBLZ4AaABAg.8oiLBOEAVzY8qaMCmg2q5T,@KASANITEJ,Ugz6DtBdwiHAFQlFBLZ4AaABAg,2,lAq96T8FkTw,0,2,2019-01-27T03:18:30Z,4¬∞ is okay... in canada it is -20¬∞ today :(,2019-01-27T03:18:30Z
UgwaODIpEN06VqJw50p4AaABAg,@muratcan__22,,1,lAq96T8FkTw,0,1,2018-12-02T22:13:07Z,nice,2018-12-02T22:13:07Z
UgzmgqagCyXBD9Q_i2V4AaABAg,@ProfessionalTycoons,,1,lAq96T8FkTw,0,2,2018-05-23T22:33:32Z,amazing video,2018-05-23T22:33:32Z
UgyntMJ4LONXtYNsxLF4AaABAg,@danieldeychakiwsky1928,,1,lAq96T8FkTw,1,4,2018-03-26T14:47:28Z,"I noticed wikipedia (<a href=""https://en.wikipedia.org/wiki/Moving_average)"">https://en.wikipedia.org/wiki/Moving_average)</a> defines the EMA similarly except the previousEMA and what we refer to as THETA in this video are inverted. <br><br>In this video we say: todaysEMA = (Beta * previousEMA) + ((1 - Beta) * todaysTHETA)<br><br>Wikipedia says: todaysEMA = (Beta * todaysTHETA) + ((1 - Beta) * previousEMA)<br><br>If we hold Beta at say .9 then these definitions would produce different results. However, if Wikipedia set Beta to .1 but this video set Beta to .9, the result would be equivalent. <br><br>If we wanted a reactionary measure, since this is essentially a large weighted average, I&#39;d imagine that most of the time we want more weight on the new data point (todaysTHETA) and less weight on the previousEMA.",2018-03-26T15:15:13Z
UgyntMJ4LONXtYNsxLF4AaABAg.8eG50FjM7HV9drJ5RKpd54,@samdun4641,UgyntMJ4LONXtYNsxLF4AaABAg,2,lAq96T8FkTw,0,0,2022-07-24T07:59:28Z,I noticed that too. I cant find any sources that address this slight deviation in formula.,2022-07-24T07:59:28Z
Ugx7-ArvlLDaEPIu6th4AaABAg,@googul2041,,1,NxTFlzBjS-4,0,0,2023-07-01T19:42:01Z,"Naaku lekhhalu raaavuraa nainaaa, nanhhenduku veepuku tintaavuu? Yerakkaboiii hhhiiitochhhaanuu, <br>vereithara chakhhaati telivigala pillalni yeerukooo, vellu naainaa abbiiiii",2023-07-01T19:42:01Z
Ugwpw4BI0hevYIP2fYp4AaABAg,@Jirayu.Kaewprateep,,1,NxTFlzBjS-4,0,0,2023-04-26T08:52:06Z,"üì∫üí¨ Can you see the implementing part of this exponential weights average‚Åâ<br>ü•∫üí¨ There is an existing layer, inside the custom layer example Dense layer is the multiply of inputs added with previous state training weights.<br>üêëüí¨ Yes, it can be v1 = a x V0 + ( 1 - B )O1 or any formulate but implementing is you need to apply sciences for solutions such as model training, prediction, estimation, and initial layer weight. <br>üêëüí¨ You can start your model or layer with initial weight differently to focus on the calculation the instructor intends to do,  it does not require to be randomized values or their trained values. When you do not have the trained weights you can use a few sample matrixes or [  -1, -1, -1 ... ] or different value that results differently.<br>üì∫üí¨ Of course, all zeroes or negatives value seems to not have effects on the training time but the exponential average can perform training faster when selected weights in ranges of the optimizer do as small as they should.<br>üêëüí¨ Some optimizers are weighted by minimum and maximum at the same time they are responsible for finding optimum points in ranges, the application is sampled as optimizers as it does not directly affect the target but you can define the result from exponential weights by recursive function as it working recursively, gradient values but I am not saying they are estimates target global value to adjusting the learning rates directly. <br>üß∏üí¨ Some computing required Tape and Gradients which is why they do it fast but you need to define them in a working function, you can add value from input training by the training graphs to display in the final graphs or compare its input with output from Tensorboard.<br>üêëüí¨ Thank you I am finding a way to compare voltage inputs with power when required training time calculation.<br><br>üì∫üí¨ ‡∏à‡∏¥‡∏≠‡∏¢‡πà‡∏≤‡∏´‡∏¢‡∏∏‡∏î ü•∫üí¨ ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡∏±‡πâ‡∏ô ‡∏Ç‡πâ‡∏≤‡∏á‡∏ö‡πâ‡∏≤‡∏ô ‡∏û‡∏à‡∏ô‡πå‡∏à‡πâ‡∏≤‡∏á‡∏°‡∏≤‡πÑ‡∏°‡πà‡∏´‡∏¢‡∏∏‡∏î ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏Ñ‡∏≤‡∏∞‡∏£‡∏≠‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡πÄ‡∏Ñ‡πâ‡∏≤‡∏Å‡πá‡∏ü‡∏≤‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏Å‡∏≥‡πÅ‡∏û‡∏á ‡∏ú‡∏°‡∏Å‡πá‡∏ï‡∏≠‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£<br><br>üì∫üí¨ Values estimation and its value üì∫üí¨ ‡∏•‡∏≠‡∏á‡πÉ‡∏™‡πà‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏ß‡∏Å‡∏°‡∏±‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ ‡∏Ç‡πâ‡∏≤‡∏á‡∏ö‡∏¢‡πâ‡∏≤‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏´‡∏¢‡∏∏‡∏î‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏á‡∏´‡∏•‡∏∏‡∏î‡∏à‡∏≤‡∏Å‡∏ö‡∏ó‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÑ‡∏´‡∏° ‡πÅ‡∏ï‡πà‡πÄ‡∏Ñ‡πâ‡∏≤‡πÅ‡∏Ñ‡πà‡∏•‡∏≥‡∏Ñ‡∏≤‡∏ç‡∏Ñ‡∏£‡∏±‡∏ö <br>ü•∫üí¨ ‡∏ú‡∏°‡∏´‡πâ‡∏≤‡∏°‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏Ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏ü‡∏±‡∏á ‡∏ú‡∏°‡∏ü‡∏±‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏ï‡πà‡∏ß‡πà‡∏≤‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô<br>ü•∫üí¨ ‡∏Ñ‡∏¥‡∏î‡∏ß‡πà‡∏≤‡∏ú‡∏°‡∏ï‡∏±‡πâ‡∏á‡πÉ‡∏à‡∏ü‡∏±‡∏á‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏±‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏£‡∏±‡∏ö",2023-04-26T08:57:42Z
UgwZWMXSQs2FiN_zGk94AaABAg,@irannank6172,,1,NxTFlzBjS-4,0,0,2023-04-23T11:49:32Z,"Nice explanation but have one point, people use exponential weighted moving averages(EWMA) over Simple moving average(SMA) because in SMA gives same importance(weight) to (N-K)th day and Nth day in K days moving avergae as we just take average of last K elements, but in EWMA as you shown as well, Nth day has heigher weight ompared to (N-K)th day, means recently values are more important than the historical old values. it is vary important in trade buy and sell analysis as trade price trande is more dependent of recent values than the (N-K)th day value when we take moving average.",2023-04-23T11:49:32Z
UgwckjcCGS-narKNhCd4AaABAg,@ahmedb2559,,1,NxTFlzBjS-4,0,0,2023-01-18T10:37:41Z,thank you !,2023-01-18T10:37:41Z
UgyCEP7KpR-P-qnzo794AaABAg,@tudormarginean4776,,1,NxTFlzBjS-4,0,0,2022-07-21T19:18:01Z,this was quite unclear,2022-07-21T19:18:01Z
Ugw2Idssph6v306ZhM94AaABAg,@bhb5848,,1,NxTFlzBjS-4,1,1,2021-12-01T08:53:56Z,v_1 is so small since v_1 = 0.1*theta_1. Is it correct?,2021-12-01T08:53:56Z
Ugw2Idssph6v306ZhM94AaABAg.9VPIWiNoVcW9gHhgQLxTaW,@satyamgaba,Ugw2Idssph6v306ZhM94AaABAg,2,NxTFlzBjS-4,0,0,2022-09-22T16:25:24Z,yes. to resolve this issue we do bias correction(covered in next video),2022-09-22T16:28:57Z
Ugz5k2NDkMRVBhRZjaN4AaABAg,@sandipansarkar9211,,1,NxTFlzBjS-4,1,2,2020-12-30T15:02:38Z,good explntion but need to watch again,2020-12-30T15:02:38Z
Ugz5k2NDkMRVBhRZjaN4AaABAg.9Htmc8PQ-Fk9u6xOflddBs,@ermano5586,Ugz5k2NDkMRVBhRZjaN4AaABAg,2,NxTFlzBjS-4,0,0,2023-09-01T11:30:31Z,I am watching it again,2023-09-01T11:30:31Z
UgznmGFvFOpRZSP4F_V4AaABAg,@lucha6262,,1,NxTFlzBjS-4,0,3,2020-03-08T21:34:40Z,This was soooo clear! Very excited to properly start the deeplearning Coursera course,2020-03-08T21:34:40Z
UgwmJhIjRGgm48UQgJl4AaABAg,@MrZidanegenius,,1,NxTFlzBjS-4,3,1,2018-07-24T08:52:18Z,The avg can be calculated daily with just the previous days avg and total days gone by. so new avg = (prev_avg*no. of days + current value)/(no. of days+1),2018-07-24T08:52:18Z
UgwmJhIjRGgm48UQgJl4AaABAg.8j4Rl1_FBA_94UvMZsO2Z0,@user-bz7ki7dl1r,UgwmJhIjRGgm48UQgJl4AaABAg,2,NxTFlzBjS-4,0,4,2020-02-01T11:10:38Z,This method acts more like a sliding window average. Not average all samples.,2020-02-01T11:10:38Z
UgwmJhIjRGgm48UQgJl4AaABAg.8j4Rl1_FBA_9RehNdQWLFF,@nhactrutinh6201,UgwmJhIjRGgm48UQgJl4AaABAg,2,NxTFlzBjS-4,0,1,2021-08-30T07:42:09Z,"in your formula, all days weight the same",2021-08-30T07:42:09Z
UgwmJhIjRGgm48UQgJl4AaABAg.8j4Rl1_FBA_9gHhae8T-B9,@satyamgaba,UgwmJhIjRGgm48UQgJl4AaABAg,2,NxTFlzBjS-4,0,0,2022-09-22T16:24:36Z,yes it is same when your avg becomes prev_avg in next time step,2022-09-22T16:24:36Z
UgxVAe1D7U9z1EbP4ll4AaABAg,@ProfessionalTycoons,,1,NxTFlzBjS-4,0,5,2018-05-24T00:08:57Z,very clear explanation!,2018-05-24T00:08:57Z
Ugz-rpVeBLzw_PplYxh4AaABAg,@kieferaland4689,,1,lWzo8CajF5s,0,0,2023-02-04T10:43:11Z,"With all due respect Dr. Ng mispeaks at <a href=""https://www.youtube.com/watch?v=lWzo8CajF5s&amp;t=1m05s"">1:05</a>, v1 would be 0.8 in that case, which furthers the point he is making. Thank you so much for these videos.",2023-02-04T11:08:13Z
UgxInyUkXaXauEvphjt4AaABAg,@ahmedb2559,,1,lWzo8CajF5s,0,0,2023-01-18T14:05:15Z,thank you,2023-01-18T14:05:15Z
Ugz1DJFCxTf_3pFEBDV4AaABAg,@noamills1130,,1,lWzo8CajF5s,0,1,2022-02-18T21:00:08Z,"Here&#39;s where I was confused. When you want to apply the bias correction, you first calculate all of your Vt values as you would before, then you apply the correction to each item. You don&#39;t (as I originally assumed) calculate the first value V1, apply the bias correction, then use that bias-corrected value as the input for V2, and so on. Hope this helps someone else who was also confused about this.",2022-02-18T21:00:08Z
UgxYtDNWy7J4aUW9O8h4AaABAg,@feedtowin1309,,1,lWzo8CajF5s,0,0,2021-12-10T03:11:24Z,"Thank you so much for your videos, sir.",2021-12-10T03:11:24Z
UgxS9yXW7e3BzFmI3KV4AaABAg,@gz6616,,1,lWzo8CajF5s,1,15,2021-06-30T06:04:22Z,"Maybe it is worth pointing out that the bias-corrected value of v_t / (1 - beta^t) should not be used in the computation of v_{t + 1}. I tried it, and it explodes quickly to infinity.<br><br>Instead, keep a record of the v_t that is not bias-corrected, do the correction as v2_t = v_t / (1 - beta^t) and use v2_t as the output value. For v_{t+1}, still use the uncorrected v_t.",2021-06-30T06:04:22Z
UgxS9yXW7e3BzFmI3KV4AaABAg.9PCSh0pZiTW9bhI3vj9iDt,@MuhammedTan,UgxS9yXW7e3BzFmI3KV4AaABAg,2,lWzo8CajF5s,0,0,2022-05-31T17:35:20Z,Thank you for pointing that out! :),2022-05-31T17:35:20Z
Ugzo6ww6_hw9H2ByBjR4AaABAg,@sandipansarkar9211,,1,lWzo8CajF5s,1,0,2020-12-31T14:42:39Z,great explantion.Need to watch again,2020-12-31T14:42:39Z
Ugzo6ww6_hw9H2ByBjR4AaABAg.9HwK7biYStY9u6yNERyeEm,@ermano5586,Ugzo6ww6_hw9H2ByBjR4AaABAg,2,lWzo8CajF5s,0,0,2023-09-01T11:39:03Z,I am watching it again,2023-09-01T11:39:03Z
Ugyvti3UAXfy7x6_yjh4AaABAg,@jerrylin5089,,1,lWzo8CajF5s,1,1,2019-06-11T19:40:16Z,Why not initialize V1 with Theta1? Doesn&#39;t that just solve the problem?,2019-06-11T19:40:16Z
Ugyvti3UAXfy7x6_yjh4AaABAg.8w2isdWyZZu8xd_kBdJ9NT,@tongwei3527,Ugyvti3UAXfy7x6_yjh4AaABAg,2,lWzo8CajF5s,0,0,2019-07-21T09:03:00Z,then you get overfit lol,2019-07-21T09:03:00Z
UgxXu_L-yq9Y1ZsWFcB4AaABAg,@stevenz1276,,1,lWzo8CajF5s,2,1,2018-12-25T19:03:20Z,"Hi, can someone explain here why a certain day&#39; s temperature approximately equals V_t/1- beta^t ?",2018-12-25T19:03:20Z
UgxXu_L-yq9Y1ZsWFcB4AaABAg.8pI46154qCH8s4Y9fjt8my,@lihan1720,UgxXu_L-yq9Y1ZsWFcB4AaABAg,2,lWzo8CajF5s,0,0,2019-03-05T02:30:47Z,"Not &quot;a certain day&quot; but in early days, 1/(1-beta^t) corrects the bias, and in later days, the impact of this term fades away.",2019-03-05T02:30:47Z
UgxXu_L-yq9Y1ZsWFcB4AaABAg.8pI46154qCH8zxGH9IdUbZ,@MrPrince750,UgxXu_L-yq9Y1ZsWFcB4AaABAg,2,lWzo8CajF5s,0,1,2019-09-16T17:31:45Z,Make  V_t = V_t/1- beta^t when you want to correct for bias initially since 1/1-beta^t will be 1 when t is sufficiently large. So that it only jacks up the values early on.,2019-09-16T17:31:45Z
UgxwsaTNM299VB33rN14AaABAg,@ProfessionalTycoons,,1,lWzo8CajF5s,0,2,2018-05-24T00:16:22Z,very clearly explained thank you,2018-05-24T00:16:22Z
Ugx7P3bNldjdNOJdU6Z4AaABAg,@dj_metanov,,1,lWzo8CajF5s,3,12,2017-12-22T16:58:55Z,Why not initialize V0=Theta0 instead of 0 if you consider having a Day 0 with a given temperature?,2017-12-22T16:58:55Z
Ugx7P3bNldjdNOJdU6Z4AaABAg.8aUHKnuo2qq8dfnup9N1oi,@kityeung6229,Ugx7P3bNldjdNOJdU6Z4AaABAg,2,lWzo8CajF5s,0,2,2018-03-12T03:17:23Z,"I think in that case, you will still have to decide what the value of theta0 should be. Your choice of theta0 will effect the average in later calculation if bias correction is not introduced.",2018-03-12T03:17:23Z
Ugx7P3bNldjdNOJdU6Z4AaABAg.8aUHKnuo2qq8ku7ngs1ZZJ,@LL-yf9kp,Ugx7P3bNldjdNOJdU6Z4AaABAg,2,lWzo8CajF5s,0,21,2018-09-07T16:29:03Z,"If you initialize simply with v_0 = 0 (without correction), this is equivalent to assume that all the data before the first real smaple v_0 is an infinite sequence of 0.<br>Conversely, if you initialize with v_0 = theta_0, this is equivalent to assume that all the data before the first real sample v_0 is an infinite sequence of theta_0.<br>Either way, you under- respectively overestimate the influence of these infinite &quot;phantom&quot; sequences on the average.<br>To correct this, it is necessary to consider how much data of the inifinite series and how much data of the real samples went into the average. By dividing by (1-beta^T), which is much smaller than 1 for small values of T, we correct for the strong influence of the infinite-zero-sequence, otherwise leading to a strong underestimation of the average. When T gets larger (1-beta^T) approaches 1 and the correction diminishes (theoretically we are correctiong until T approaches infinity, because the influence of the infinite zero sequence holds until infinity too)",2018-09-07T16:29:03Z
Ugx7P3bNldjdNOJdU6Z4AaABAg.8aUHKnuo2qq9EeLcJ7cieW,@yidingyang8542,Ugx7P3bNldjdNOJdU6Z4AaABAg,2,lWzo8CajF5s,0,2,2020-10-11T01:35:12Z,@@LL-yf9kp very clear interpretation!,2020-10-11T01:35:12Z
UgyVQoKRZ_Gr0BI0XQp4AaABAg,@forcescode4962,,1,k8fTYJPd3_I,0,0,2023-05-01T15:51:20Z,But where did we use the bias correction formula?,2023-05-01T15:51:20Z
Ugxmy9mnLt4PQZY1OcN4AaABAg,@ahmedb2559,,1,k8fTYJPd3_I,0,0,2023-01-18T14:10:43Z,Thank you !,2023-01-18T14:10:43Z
Ugyz3IwPm54He-PhB1h4AaABAg,@eyadaiman1559,,1,k8fTYJPd3_I,1,0,2022-05-27T04:00:37Z,what causes these oscillations?,2022-05-27T04:00:37Z
Ugyz3IwPm54He-PhB1h4AaABAg.9bWXeDXBhUy9l9prvPsLT-,@alexandergraf8855,Ugyz3IwPm54He-PhB1h4AaABAg,2,k8fTYJPd3_I,0,0,2023-01-21T21:39:55Z,"Overregulation?<br><br>It works like a Servo. Too low error Signal and that thing will not follow, too much error Signal and it will jump off the table!<br><br>If you want faster learning you might wanna increase Alpha (learning rate). If the error signal (Delta) is being amplified too much in some places then the activation will be pumped up and overshoot, so for t+1 it will have to change direction and if that seems to happen all of the time...? Networks are big...maybe only some neurons start to oscillate....maybe the important ones too?<br><br>Using &quot;momentum&quot; is basically a reverb-circuit and the 1-b formula is a basic crossover mixer or &#39;blend&#39; button where one can smoothly blend between two channels.<br><br>If the old deltas are still in the node structure from previous calculation, one could simply add the old one and divide by two! That would be 50/50 mix or a &#39;beta of 0.5f&#39;. If you use that and overwrite the variable in the neuron, the variable contains 50% new and 50% old value. Next time the old old value will have become 25% and over time its constribution will fade out, just like a reverb-circuits tone.<br><br>I started overhauling my ANN routines to accelerate training, because I found out my routines are like myself: &quot;Learn something new and oh, I forgotten all the older stuff&quot;.<br><br>Today I made a training plan that never forgets and is faster üòé<br><br>1. For all Images always choose a random one! So the network has no chance of &#39;subconciously learning the ordering of data&#39; which is not wanted.<br><br>2. If an image wins (network does predict correct class), the fail[i] is being reset to 1, no backprop nessesary!<br><br>3. If an image fails (network does not predict correct class) increase the amount of fail[i] and use this as a multiplier for your learning rate!<br><br>From now on, as soon as items in your list fail, the learning rate will become a monster! Individual items in the list will only get the training they really need when they need it!<br><br>I&#39;m trying to make every outside variable become a procecuter and a loyer for the network üòé<br><br>Rate = Learning rate * consecutive failures over time * sqrt(any vector that suggests learning harder)",2023-01-21T21:39:55Z
UgxCCUZpbWIICAuY2Ul4AaABAg,@ritvikgupta7023,,1,k8fTYJPd3_I,1,1,2021-03-27T10:44:56Z,anyone else hear the high pitched sound in the background?,2021-03-27T10:44:56Z
UgxCCUZpbWIICAuY2Ul4AaABAg.9LOLHonaJvL9Mqz2phcoPE,@Billy-wo3qo,UgxCCUZpbWIICAuY2Ul4AaABAg,2,k8fTYJPd3_I,0,0,2021-05-02T19:30:31Z,Thank god. I thought tinnitus had finally caught up with me...,2021-05-02T19:30:31Z
UgyTGLCzIMhVF4vS0ed4AaABAg,@theupsider,,1,k8fTYJPd3_I,1,2,2021-01-29T19:37:49Z,the noise is killing my ears.,2021-01-29T19:37:49Z
UgyTGLCzIMhVF4vS0ed4AaABAg.9J6WxqDQBIe9J735R9EqEb,@hex808080,UgyTGLCzIMhVF4vS0ed4AaABAg,2,k8fTYJPd3_I,0,2,2021-01-30T00:36:05Z,I&#39;m so happy to be still able (almost 30 y.o.) to hear such a high pitch annoying noise.,2021-01-30T00:36:05Z
UgzgjNFne2RTDLRSkr94AaABAg,@sandipansarkar9211,,1,k8fTYJPd3_I,0,0,2020-12-21T01:02:33Z,great once again if i could go into depth,2020-12-21T01:02:33Z
Ugx9WN6NB7focQjKEkh4AaABAg,@sandipansarkar9211,,1,k8fTYJPd3_I,1,0,2020-12-20T17:14:21Z,great expalanation but takes time to understand,2020-12-20T17:14:21Z
Ugx9WN6NB7focQjKEkh4AaABAg.9HVGk7-djIU9u6zwnkcvGB,@ermano5586,Ugx9WN6NB7focQjKEkh4AaABAg,2,k8fTYJPd3_I,0,0,2023-09-01T11:52:47Z,I am watching it again,2023-09-01T11:52:47Z
Ugza_38lbq-EOnFMzJB4AaABAg,@wifi-YT,,1,k8fTYJPd3_I,0,1,2020-10-29T14:15:12Z,"Andrew‚Äôs great.  Was he right when he says at <a href=""https://www.youtube.com/watch?v=k8fTYJPd3_I&amp;t=8m55s"">8:55</a> that under BOTH versions ‚Äî with or without the (1-√ü) term ‚Äî that 0.9 is the commonly used value for √ü.  After all, in version using (1-√ü) term, the left term multiplier (0.9) is 9 times LARGER than the right term multiplier (0.1), whereas when using the alternative version without the (1-√ü) term, the left term multiplier (0.9) is actually SMALLER than the right term multiplier (1), yielding a vastly different weighted average.   Thus, it can‚Äôt be correct that under both versions, the commonly used value for √ü is the same 0.9.  Does anyone agree?  In fact, it would seem that under the latter version, √ü should be 9.0, rather than 0.9, so that the weighting is the equivalent of Andrew‚Äôs preferred former version.",2020-10-29T15:30:40Z
UgwHUxaXPmfM0em9kIx4AaABAg,@AdmMusicc,,1,k8fTYJPd3_I,1,1,2020-07-03T18:17:42Z,I directly jumped to this video for reference purposes. Can someone explain what Vdw and Vdb is?  Is V our loss function?,2020-07-03T18:17:42Z
UgwHUxaXPmfM0em9kIx4AaABAg.9AedrOG1Fx89AiisXTTbPk,@stefano4861,UgwHUxaXPmfM0em9kIx4AaABAg,2,k8fTYJPd3_I,0,2,2020-07-05T08:18:31Z,"Vdw and Vdb are the previous value they had (in the previous step)... we are computing an exponential weighted average. This will probably help <a href=""https://www.youtube.com/watch?v=lAq96T8FkTw"">https://www.youtube.com/watch?v=lAq96T8FkTw</a>",2020-07-05T08:18:31Z
UgxF6RZGB9jmNQKUmrJ4AaABAg,@kareemjeiroudi1964,,1,k8fTYJPd3_I,0,2,2020-06-07T01:12:13Z,I like this analogy of a ball and a basket. Thanks for this generous video!,2020-06-07T01:12:13Z
UgzlchOXqHIJIH7WTRR4AaABAg,@deraktdar,,1,k8fTYJPd3_I,1,5,2020-06-02T22:51:36Z,"The point about (1 - Œ≤) being excluded in some frameworks was very helpful. This type of thing is why reading methodology section of papers is totally useless - unscientific and unreproducable (only way to reproduce is to copy their exact code for a specific framework). Often exact hyper-parameters values are documented, but then details of how they are actually used in the framework is up in the air.",2020-06-02T22:51:36Z
UgzlchOXqHIJIH7WTRR4AaABAg.99QJZJtM-gU9C1S2ht6N7h,@dinoeld3800,UgzlchOXqHIJIH7WTRR4AaABAg,2,k8fTYJPd3_I,0,0,2020-08-06T20:38:57Z,I was just looking it up because I noticed Keras calculates it differently,2020-08-06T20:38:57Z
Ugz0oAQaLZ-598KjIAl4AaABAg,@abhishekbhatia651,,1,k8fTYJPd3_I,0,0,2020-05-23T09:41:45Z,"Where is the bias correction in the steps for the initial steps? Or does it not matter as we are anyway gonna make a large number of steps?<br>Edit: My bad, he explains it at <a href=""https://www.youtube.com/watch?v=k8fTYJPd3_I&amp;t=6m50s"">6:50</a>",2020-05-23T09:50:47Z
UgwjfrAoi2Nh5j95D0R4AaABAg,@komalvenkatesh4527,,1,k8fTYJPd3_I,0,1,2020-04-23T00:40:04Z,"Perfect, thank you; showing vectors in vertical direction cancelling out and horizontal vectors adding up was the key point that cleared everything up for me.",2020-04-23T00:40:04Z
UgxBNHwiy75NxtWADet4AaABAg,@komalvenkatesh4527,,1,k8fTYJPd3_I,0,10,2020-04-23T00:32:57Z,"If you are slightly lost, it&#39;s possible that you have just stumbled on the video directly without watching the previous 3 explaining exponential weighted averages. Once you see that and come back here, it will make perfect sense.",2020-04-23T00:32:57Z
Ugw1JP6SBgXqLkYB-MF4AaABAg,@sumithhh9379,,1,k8fTYJPd3_I,1,2,2020-04-22T20:34:16Z,"In Gilbert strang lecture, he only mentioned beta not 1-beta. Will the learning rate be used as 1/1-alpha if 1-beta is not used?",2020-04-22T20:36:50Z
Ugw1JP6SBgXqLkYB-MF4AaABAg.97lVF_4-_KJ9hqM-YVfeYw,@cristianbulgaru1946,Ugw1JP6SBgXqLkYB-MF4AaABAg,2,k8fTYJPd3_I,0,0,2022-10-31T09:11:13Z,"Tell me you didn&#39;t watch without telling me you didn&#39;t watch :) <a href=""https://youtu.be/k8fTYJPd3_I?t=455"">https://youtu.be/k8fTYJPd3_I?t=455</a> short answer: yes, it affects scaling of alpha",2022-10-31T09:11:13Z
Ugxywi8OqAYm2Imv-uN4AaABAg,@hiteshchoudhary9871,,1,k8fTYJPd3_I,1,5,2019-10-17T12:05:14Z,just edit your video removing the high frequency at the end of each word,2019-10-17T12:05:14Z
Ugxywi8OqAYm2Imv-uN4AaABAg.90BVYpr0wT999A4TYN03R4,@tsunghan_yu,Ugxywi8OqAYm2Imv-uN4AaABAg,2,k8fTYJPd3_I,0,1,2020-05-27T15:31:53Z,that is really annoying for sensitive ears like ours.,2020-05-27T15:31:53Z
UgylkR40P_Is8Q4BYdV4AaABAg,@debajyotisg,,1,k8fTYJPd3_I,1,1,2019-08-22T08:06:32Z,"Could someone explain this to me? For simplicity let&#39;s consider only one hidden layer. For a given mini batch (lets say t = 1), I can calculate the loss and compute the gradients &#39;dw&#39; and &#39;db&#39;. ( &#39;dw&#39; and &#39;db&#39; are vectors of size depending upon the number of nodes in the layers). When I want to calculate Vdw (which I expect is the same dimension as dw), do I average over the elements of dw? i.e. Vdw_0 = 0, Vdw_1 = beta*Vdw_0 + (1 - beta)* dw_1..... and so on?",2019-08-22T08:06:32Z
UgylkR40P_Is8Q4BYdV4AaABAg.8yvsi_X8bF09cQa2HmZfAQ,@donuts6230,UgylkR40P_Is8Q4BYdV4AaABAg,2,k8fTYJPd3_I,0,0,2022-06-18T17:06:12Z,What do you mean by average?,2022-06-18T17:06:12Z
UgzpRlFIkiMd0QkFXgV4AaABAg,@jerekabi8480,,1,k8fTYJPd3_I,2,4,2019-07-01T10:58:42Z,This is really helpful. I can now fully understand sgd with momentum by understanding the concepts of exponentially weighted average.  Thanks a lot.,2019-07-01T10:58:42Z
UgzpRlFIkiMd0QkFXgV4AaABAg.8wqI54Hwa7x9LhmP-_2osk,@usf5914,UgzpRlFIkiMd0QkFXgV4AaABAg,2,k8fTYJPd3_I,0,0,2021-04-04T09:15:23Z,where is the exponentially weighted average? that is a simple weighted average.,2021-04-04T09:15:23Z
UgzpRlFIkiMd0QkFXgV4AaABAg.8wqI54Hwa7x9Y9CBBhnTzD,@manohar_marri,UgzpRlFIkiMd0QkFXgV4AaABAg,2,k8fTYJPd3_I,0,1,2022-02-07T16:24:54Z,"@@usf5914 the weights for each of the previous values decay exponentially, which is why it‚Äôs called exponential averaging",2022-02-07T16:24:54Z
Ugx6ex_1r2lXeeIGnI54AaABAg,@michaelscheinfeild9768,,1,k8fTYJPd3_I,0,1,2019-06-20T10:24:44Z,very good explanation on the gradient with momentum the example of ball with speed and acceleration is very intuitive. thank you,2019-06-20T10:24:44Z
UgwBwrIZMSDWR-WrHiF4AaABAg,@temisegun8631,,1,k8fTYJPd3_I,0,1,2019-05-26T18:29:09Z,thank you this was helpful,2019-05-26T18:29:09Z
UgyLWL1UUXHO7Y0UtM94AaABAg,@rajupowers,,1,k8fTYJPd3_I,3,9,2019-05-10T18:31:57Z,"What is Vdw, and Vdb - @<a href=""https://www.youtube.com/watch?v=k8fTYJPd3_I&amp;t=7m15s"">7:15</a>",2019-05-10T18:31:57Z
UgyLWL1UUXHO7Y0UtM94AaABAg.8ulCcARRM3i8wOulHqS8Gb,@michaelscheinfeild9768,UgyLWL1UUXHO7Y0UtM94AaABAg,2,k8fTYJPd3_I,0,5,2019-06-20T10:27:25Z,"vdw, vdb is the weighted average of optimization parameters weights and biases see more in the blog <a href=""https://medium.com/@omkar.nallagoni/gradient-descent-with-momentum-73a8ae2f0954"">https://medium.com/@omkar.nallagoni/gradient-descent-with-momentum-73a8ae2f0954</a>",2019-06-20T10:28:25Z
UgyLWL1UUXHO7Y0UtM94AaABAg.8ulCcARRM3i95xX7or7quC,@shakesbeer00,UgyLWL1UUXHO7Y0UtM94AaABAg,2,k8fTYJPd3_I,0,1,2020-03-08T19:38:47Z,"Yeah, that is confusing and not well explained, even in the above reply. But it seems that Vdw = w_t - w_{t-1} and same for Vdb.",2020-03-08T19:38:47Z
UgyLWL1UUXHO7Y0UtM94AaABAg.8ulCcARRM3i97lw0sGof2V,@komalvenkatesh4527,UgyLWL1UUXHO7Y0UtM94AaABAg,2,k8fTYJPd3_I,0,3,2020-04-23T00:36:55Z,"You&#39;ve probably skipped the previous videos. He clearly explains that &#39;V&#39; notation is to denote the new weighted value. In this case, if dw is your current value, Vdw is your weighted average value. And dw and db are weights and biases of the neural network.",2020-04-23T00:36:55Z
UgwxZqC_VIGVWOeMiX54AaABAg,@bera8426,,1,k8fTYJPd3_I,1,0,2019-02-23T19:57:27Z,"Can anyone explain why Ng&#39;s calculations include beta and 1-beta but in other works like <a href=""https://arxiv.org/pdf/1609.04747.pdf"">https://arxiv.org/pdf/1609.04747.pdf</a> momentum is shown just using beta not 1-beta (actually they use gamma not beta for the proportion of the previous weights to carry over) ?",2019-02-23T19:57:27Z
UgwxZqC_VIGVWOeMiX54AaABAg.8rhezzLA2y29dqAo4aRg9_,@GoldLeafGaming,UgwxZqC_VIGVWOeMiX54AaABAg,2,k8fTYJPd3_I,0,0,2022-07-23T21:27:49Z,"Go to <a href=""https://www.youtube.com/watch?v=k8fTYJPd3_I&amp;t=7m35s"">7:35</a>",2022-07-23T21:27:49Z
Ugwdk8O9abT5RqhEV_54AaABAg,@fatima-ezzahrabadaoui4198,,1,k8fTYJPd3_I,1,4,2019-02-03T15:04:32Z,what are dw and db ??,2019-02-03T15:04:32Z
Ugwdk8O9abT5RqhEV_54AaABAg.8qtd_-7B6-E8tkEurCvI0F,@jonathanandrews9966,Ugwdk8O9abT5RqhEV_54AaABAg,2,k8fTYJPd3_I,0,5,2019-04-15T13:01:20Z,dw is the calculated gradients for the weights and db is the calculated gradients for the bias,2019-04-15T13:01:20Z
UgwCj_42CTVzKS2K5MF4AaABAg,@shwonder,,1,k8fTYJPd3_I,0,0,2019-01-19T15:40:32Z,"Is there need for input normalisation, when using gradient descent with momentum? My intuition says that normalisation will add very low value (if any) in this case. Is this correct?",2019-01-19T15:45:31Z
UgxsQbJVACoJ-3AF2754AaABAg,@joshuasansom_software,,1,k8fTYJPd3_I,0,9,2018-10-14T09:42:36Z,Thanks so much! Love that feeling when it all just clicks.,2018-10-14T09:42:36Z
UgyzbaFDT_ompe3nYkZ4AaABAg,@putuwisnubhaskaraputrawan846,,1,k8fTYJPd3_I,1,0,2018-10-10T02:02:12Z,ntapp gan,2018-10-10T02:02:12Z
UgyzbaFDT_ompe3nYkZ4AaABAg.8mCYpXqmPfm8mCZlbW7GHQ,@kuroa7924,UgyzbaFDT_ompe3nYkZ4AaABAg,2,k8fTYJPd3_I,0,0,2018-10-10T02:10:23Z,Fokus kuliah nu,2018-10-10T02:10:23Z
UgyNa6-j5Z0deyPnfwB4AaABAg,@thehazarika,,1,k8fTYJPd3_I,0,5,2018-01-04T17:54:17Z,I have learnt so much from you. I really want to thank you for that.I really appreciate your work. I would like to suggest you to think about few beginer learner like me and explain the concept with some analogy and provide some aid to lead the trail of thinking in a appropiate direcetion.,2018-01-04T17:54:17Z
UgyajZb1OSF0T9Vrsz94AaABAg,@klausdupont6335,,1,k8fTYJPd3_I,2,43,2017-12-22T11:56:03Z,Explaining the function of each parameter (especially the role of Œ≤ in both (Œ≤) and (1 - Œ≤)) is extremely useful for understanding the role of momentum in gradient descent. Really appreciate that!,2017-12-22T11:56:03Z
UgyajZb1OSF0T9Vrsz94AaABAg.8aTjfYuqKlH8nv3Bd17fJY,@harshberiwal4123,UgyajZb1OSF0T9Vrsz94AaABAg,2,k8fTYJPd3_I,0,1,2018-11-21T14:42:11Z,what is beta(B) here? can you please let me know?,2018-11-21T14:42:11Z
UgyajZb1OSF0T9Vrsz94AaABAg.8aTjfYuqKlH99oaK4c6pkQ,@whyisitnowhuh8691,UgyajZb1OSF0T9Vrsz94AaABAg,2,k8fTYJPd3_I,0,0,2020-06-12T18:27:49Z,agreed,2020-06-12T18:27:49Z
UgwAz96OnWeMZN07frp4AaABAg,@ahmedb2559,,1,_e-LFe_igno,0,0,2023-01-18T14:15:03Z,Thank you !,2023-01-18T14:15:03Z
UgxmUjzWfDt93Zz1SwN4AaABAg,@RH-mk3rp,,1,_e-LFe_igno,0,0,2022-08-17T02:13:05Z,I think it&#39;s safe to say that it doesn&#39;t matter whether the denominator&#39;s epsilon is inside or outside the square root?,2022-08-17T02:13:05Z
UgwR4lJs9C6Fa5EGvLZ4AaABAg,@rafipatel5020,,1,_e-LFe_igno,0,0,2022-06-29T10:22:35Z,what is the key difference between Gradient Descent with momentum and RMS prop? visualizations are same  though.\,2022-06-29T10:22:35Z
Ugx8w2CpT8443Uzz3P94AaABAg,@DANstudiosable,,1,_e-LFe_igno,1,0,2021-09-30T08:14:17Z,"Why it&#39;s called root mean squared prop? <br><a href=""https://www.youtube.com/watch?v=_e-LFe_igno&amp;t=5m35s"">5:35</a>",2021-09-30T08:14:17Z
Ugx8w2CpT8443Uzz3P94AaABAg.9Su_h2jkZJA9u71S0Z-0zH,@ermano5586,Ugx8w2CpT8443Uzz3P94AaABAg,2,_e-LFe_igno,0,0,2023-09-01T12:14:40Z,"look at  video closely, what in the formula are using?",2023-09-01T12:14:40Z
UgyLVPLdyZoYQAyzer14AaABAg,@a.j.noushin1071,,1,_e-LFe_igno,0,0,2021-08-26T01:06:33Z,"It is worth mentioning that we are no longer stepping in the direction of the steepest descent.  The sign  information in the gradient appears to be sufficient to not only find the optimum, but also (apparently) to improve convergence time (compared to steepest descent direction)",2021-08-26T01:06:33Z
UgzdYnm7QyHmZsDYtIB4AaABAg,@kumarsaurabh6256,,1,_e-LFe_igno,0,0,2021-05-24T08:20:41Z,"doubt: If square root of Sdb is less than 1, then instead of damping the oscillation in b direction, it will have opposite effect, isn&#39;t it?",2021-05-24T08:20:41Z
UgzyASC0sSJuHXqmBXV4AaABAg,@gazm2k5,,1,_e-LFe_igno,0,2,2021-02-03T18:22:08Z,"I can see how large values of Sdw slow down learning, but doesn&#39;t it also slow down learning just as much when we&#39;re not oscillating?",2021-02-03T18:22:08Z
UgzHSNtACPecKwS-cGZ4AaABAg,@sandipansarkar9211,,1,_e-LFe_igno,2,1,2020-12-21T01:08:36Z,great explanaion,2020-12-21T01:08:36Z
UgzHSNtACPecKwS-cGZ4AaABAg.9HW70fbImvM9NtG4KGaUPM,@osiris1102,UgzHSNtACPecKwS-cGZ4AaABAg,2,_e-LFe_igno,0,4,2021-05-28T13:17:53Z,But need to watch again right?,2021-05-28T13:17:53Z
UgzHSNtACPecKwS-cGZ4AaABAg.9HW70fbImvM9u71CTLLc6V,@ermano5586,UgzHSNtACPecKwS-cGZ4AaABAg,2,_e-LFe_igno,0,0,2023-09-01T12:12:32Z,@@osiris1102  I am watching it again,2023-09-01T12:12:32Z
UgzGqSPidbMP_KAKW1B4AaABAg,@mackenzieclarkson8322,,1,_e-LFe_igno,2,1,2020-10-05T10:37:46Z,"(Doubt) Intuition behind RMSprop and Momentum:<br><br>RMSprop:<br>Sdw = Œ≤.Sdw + (1-Œ≤).dw¬≤<br>Sdb = Œ≤.Sdb + (1-Œ≤).db¬≤<br>W = W - Œ±.dw/(‚àöSdw) , b = b - Œ±.db/(‚àöSdb)<br>At <a href=""https://www.youtube.com/watch?v=_e-LFe_igno&amp;t=3m00s"">3:00</a>, we see that dw is relatively small and db is large.<br>So by dividing, we are able to update W at a higher rate compared to b<br>and that way, we move quicker horizontally.<br><br>Momentum:<br>Vdw = Œ≤.Vdw + (1-Œ≤).dw<br>Vdb = Œ≤.Vdb + (1-Œ≤).db<br><br>W = W - Œ±.Vdw , b = b - Œ±.Vdb<br>If dw and db follow the same here, we update b at a higher rate that W.<br>This way, we would move more vertically and slower horizontally? <br><br>Any help would be highly appreciated, thanks.",2020-10-05T10:37:46Z
UgzGqSPidbMP_KAKW1B4AaABAg.9EQrwtuFK9U9G_5p2yzloW,@HaSongSon123,UgzGqSPidbMP_KAKW1B4AaABAg,2,_e-LFe_igno,0,0,2020-11-27T17:43:43Z,"You are right for the rmsprop algorithm but wrong for the momentum algorithm. Specifically for momentum, if db strongly oscillated in the iteration range from 1 to t, then Vdb at time t + 1 will be close to 0, (because db varies from negative to positive and vice versa, so moving average of db (Vdb) is close to 0), thus, with the update formula &quot;b = b - Œ±.Vdb&quot;, db at the time t and t+1 will be roughly equal, or b is updated with a slow rate for the future iteration.",2020-11-27T17:43:43Z
UgzGqSPidbMP_KAKW1B4AaABAg.9EQrwtuFK9U9HfJpB1htQI,@MrBemnet1,UgzGqSPidbMP_KAKW1B4AaABAg,2,_e-LFe_igno,0,0,2020-12-25T00:12:54Z,I have understood it finally . let me know if haven&#39;t figured it out yet.,2020-12-25T00:12:54Z
Ugx3iD5Ljl0qmd_MnIZ4AaABAg,@ahmedyoussef699,,1,_e-LFe_igno,1,1,2020-07-27T12:39:43Z,Is dW the derivative of the loss function respect to W ?,2020-07-27T12:39:43Z
Ugx3iD5Ljl0qmd_MnIZ4AaABAg.9BbqFqba6Pp9G04DUjuHqQ,@arnabpersonal6729,Ugx3iD5Ljl0qmd_MnIZ4AaABAg,2,_e-LFe_igno,0,1,2020-11-13T17:57:03Z,yes,2020-11-13T17:57:03Z
Ugzq8bT05zXsCpJIveR4AaABAg,@MultiBagieta,,1,_e-LFe_igno,0,5,2020-06-29T08:02:11Z,"Andrew, I think there&#39;s a problem with your audio/mic because I hear high frequency squeaks through entire video",2020-06-29T08:02:11Z
UgxicTiOPBmXlS69o9h4AaABAg,@yavdhesh,,1,_e-LFe_igno,0,1,2020-05-30T05:44:01Z,‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶ ‡§™‡•ç‡§∞‡§≠‡•Å‡§ú‡•Ä :) ‡§Æ‡•à ‡§Ü‡§™‡§ï‡§æ ‡§Ü‡§≠‡§æ‡§∞‡•Ä ‡§π‡•Å‡§Ç ‡•§,2020-05-30T05:44:01Z
UgyY7gkh68f2hV58zX94AaABAg,@dhineshkumarramasubbu1190,,1,_e-LFe_igno,0,1,2020-04-25T19:09:15Z,How do we decide which dimension to be the b(referred to in the video) in multidimensional space?,2020-04-25T19:09:15Z
Ugzaf-H8IeGDa4wkH954AaABAg,@sumithhh9379,,1,_e-LFe_igno,1,0,2020-04-23T18:06:49Z,How db is high dimensional. from my understanding it is the bias term?,2020-04-23T18:06:49Z
Ugzaf-H8IeGDa4wkH954AaABAg.97noASYzHBM97rj4NbzZTu,@luisleal4169,Ugzaf-H8IeGDa4wkH954AaABAg,2,_e-LFe_igno,0,0,2020-04-25T06:39:15Z,"Consider this is a simple example with just one bias, but  even with a small neural network ,for example one with a hidden layer, with 5 neurons you already have  a 5 dimensional space. (and that just counting the biases, but remember that both  weights and biases are trainable parameters and your space involves all of them)",2020-04-25T06:39:15Z
UgzB16DLXnj4FeKsAkJ4AaABAg,@pivasmilos,,1,_e-LFe_igno,0,0,2020-04-17T21:33:05Z,"s values seem to be estimating a moving variance?<br>And then the squaring gives us moving standard deviation.<br>So it&#39;s like negative feedback:<br>    the noisier the gradient,<br>    the bigger the std will be,<br>    which will shrink the gradient more, making it less noisy.",2020-04-17T21:33:05Z
Ugzx_cBChlYrjK07ImB4AaABAg,@mostafanakhaei2487,,1,_e-LFe_igno,0,0,2020-04-16T20:41:11Z,I watch your videos over and over. Great man,2020-04-16T20:41:11Z
UgzoWiLLljk_cGvtnqR4AaABAg,@binishjoshi1126,,1,_e-LFe_igno,0,3,2020-04-02T05:43:30Z,You know the video is going to be amazing when you see this man with his computer screen.,2020-04-02T05:43:30Z
UgwMTKylEnqwDES2o1J4AaABAg,@erdoganyildiz617,,1,_e-LFe_igno,4,3,2020-03-09T10:04:59Z,"I am totally confused about using b and w as directions of gradient descent steps. The whole explanation looks like depending on that the parameter b controls the vertical component of each gradient step whereas parameter w controls the horizontal component. But in real life, is it really the case? I belive parameter w and b both inlcudes components in each direction. What am I missing here? The whole explanation doesn&#39;t make sense to me at all.",2020-03-09T10:04:59Z
UgwMTKylEnqwDES2o1J4AaABAg.95z4G31giAr966bsApNqXg,@dhineshkumarramasubbu1190,UgwMTKylEnqwDES2o1J4AaABAg,2,_e-LFe_igno,0,0,2020-03-12T17:41:20Z,Kind of in the same situation here. I cannot translate this idea to a k dimensional case.,2020-03-12T17:41:20Z
UgwMTKylEnqwDES2o1J4AaABAg.95z4G31giAr97rjUGdOuKJ,@luisleal4169,UgwMTKylEnqwDES2o1J4AaABAg,2,_e-LFe_igno,0,1,2020-04-25T06:42:47Z,"No, you are not correct in this : &quot;I believe parameter w and b both includes components in each direction&quot;, every parameter adds a new dimension to the space , if you have 2 parameters and 1 bias that&#39;s a 3 dimensional space for example,so with 1 w and 1 b, you have a 2 dimensional space (or a plane as seen in the video) .",2020-04-25T06:42:47Z
UgwMTKylEnqwDES2o1J4AaABAg.95z4G31giAr9NtG0CzzO5A,@osiris1102,UgwMTKylEnqwDES2o1J4AaABAg,2,_e-LFe_igno,0,1,2021-05-28T13:17:19Z,@@luisleal4169 why is dw small and db large? Why not the opposite?,2021-05-28T13:17:19Z
UgwMTKylEnqwDES2o1J4AaABAg.95z4G31giAr9P2cYE_-CDb,@HimanshuMauryadesigners,UgwMTKylEnqwDES2o1J4AaABAg,2,_e-LFe_igno,0,0,2021-06-26T10:26:45Z,"@@osiris1102 see the axes (which are in horizontal plane) as the slope (from the diagram) is more steeper in the &quot;b&quot; direction , therefore dL/db ie db is large and dL/dw ie dw is small.",2021-06-26T10:26:45Z
Ugyedm5PejhiSOYqTBt4AaABAg,@kayicomert7933,,1,_e-LFe_igno,1,0,2019-12-03T17:46:12Z,Is b here the bias term in z = wx + b?,2019-12-03T17:46:12Z
Ugyedm5PejhiSOYqTBt4AaABAg.9257wGkKPKs92785I0Sb6w,@tanyalyubimaya2918,Ugyedm5PejhiSOYqTBt4AaABAg,2,_e-LFe_igno,0,0,2019-12-04T12:26:03Z,Yes,2019-12-04T12:26:03Z
Ugzo1KX-330Wg0z1DR54AaABAg,@biggucker1617,,1,_e-LFe_igno,0,1,2019-11-30T08:44:30Z,"Hello! Great video. Why isn&#39;t bias correction used in this algorithm, meanwhile it is used in ADAM, where part of RMSProp is present? Furthermore, what is a good default value for beta in RMSProp?",2019-11-30T08:44:30Z
UgwCk6yRbyq2h1X3snJ4AaABAg,@user-xn4yu5rn9q,,1,_e-LFe_igno,0,1,2019-09-15T00:26:23Z,YANG GAN,2019-09-15T00:26:23Z
UgxEHt7Xo98DQz9YGdR4AaABAg,@EndersupremE,,1,_e-LFe_igno,2,0,2019-03-28T20:28:17Z,"<a href=""https://www.youtube.com/watch?v=_e-LFe_igno&amp;t=1m27s"">1:27</a>  if its the first update then what past value would Sdw or Sdb have?",2019-03-28T20:28:17Z
UgxEHt7Xo98DQz9YGdR4AaABAg.8t1gkd77Zm58wf6rOoMw5m,@amitkharel1168,UgxEHt7Xo98DQz9YGdR4AaABAg,2,_e-LFe_igno,0,0,2019-06-27T02:48:56Z,0 may be,2019-06-27T02:48:56Z
UgxEHt7Xo98DQz9YGdR4AaABAg.8t1gkd77Zm58wmI4jCagN9,@Kylanto,UgxEHt7Xo98DQz9YGdR4AaABAg,2,_e-LFe_igno,0,0,2019-06-29T21:41:42Z,"They start at zero, but in the Adam Optimization video, he explains bias correction which fixes some issues that come with assuming the RMSDelta starts at zero",2019-06-29T21:41:42Z
UgzuGbgUnYOq4sKuRPB4AaABAg,@EranM,,1,_e-LFe_igno,0,0,2018-12-12T07:11:41Z,Great Lecture Andrew!!!,2018-12-12T07:11:41Z
UgxQboZLS4ox_HHsUh94AaABAg,@abhijeetchauhan1349,,1,_e-LFe_igno,0,1,2018-06-20T18:08:14Z,Amazing. Beautifully explained.,2018-06-20T18:08:14Z
UgxGBX3g_2HWzSagnRB4AaABAg,@ThePhoenixfromtheAsh,,1,_e-LFe_igno,0,17,2018-05-22T07:03:14Z,"I comment seldom on videos, but this is finally one video that actually explains algorithms and is not just blabbering about general ideas - so helpful. I started writing my own algorithms for gradient descent and I was desperately searching for ideas on how to speed it up. Thanks a lot.",2018-05-22T07:03:14Z
UgwT8oqKICeQBzxSrsl4AaABAg,@karishmamalkan7830,,1,_e-LFe_igno,7,7,2018-03-21T17:19:18Z,"Thanks for the explanation. I had one question:<br>What if the updates are more horizontal than vertically inclined? In that case, wouldnt we be dampening out the progress in the direction we actually want to progress faster? <br><br>Do we have reason to believe that the projection of gradients on the orthogonal axis (orthogonal to pne pointing exactly in direction of minima) are likely to be greater compared to the projection of gradients on the axis aligned towards the location of the minima?",2018-03-21T17:20:42Z
UgwT8oqKICeQBzxSrsl4AaABAg.8e3UQ1K_31I8eTLEqzjUEh,@muhammadwajahat5627,UgwT8oqKICeQBzxSrsl4AaABAg,2,_e-LFe_igno,0,0,2018-03-31T18:19:23Z,"it simply divides bigger value weights with bigger values and smaller with smaller, to equalize alpha this algo solves problem where their are bigger and smaller values of weights, you cannot use same value of alpha for both ,you have to use different values of alpha for both of them.",2018-03-31T18:20:32Z
UgwT8oqKICeQBzxSrsl4AaABAg.8e3UQ1K_31I8fkBSNnM2b6,@dpacmanh,UgwT8oqKICeQBzxSrsl4AaABAg,2,_e-LFe_igno,0,1,2018-05-02T13:11:34Z,"The horizontal/vertical inclination isn&#39;t something preset, it actually depends on the type of optimization function you choose.<br>If you were to use the stochastic gradient descent, there will be a lot of oscillations and cannot learn fast. <br>But by using the momentum/RMSProp, these oscillations are reduced, which equates to a faster learning rate.",2018-05-02T13:11:34Z
UgwT8oqKICeQBzxSrsl4AaABAg.8e3UQ1K_31I8gO59OoYcrU,@kunalsingh-vi1mv,UgwT8oqKICeQBzxSrsl4AaABAg,2,_e-LFe_igno,0,1,2018-05-18T10:25:25Z,usually there are more than two dimensions. So what it actually does is it dampens out the updates in the unwanted directions and keeps the convergence path to one of the paths to global minima of the convex function.,2018-05-18T10:25:25Z
UgwT8oqKICeQBzxSrsl4AaABAg.8e3UQ1K_31I8sr4uTlxuvc,@anirudhsharma1213,UgwT8oqKICeQBzxSrsl4AaABAg,2,_e-LFe_igno,0,0,2019-03-24T08:17:11Z,That way dW would be large hence it would automatically dampen out.,2019-03-24T08:17:11Z
UgwT8oqKICeQBzxSrsl4AaABAg.8e3UQ1K_31I9DK5K6DSv_L,@dimar4150,UgwT8oqKICeQBzxSrsl4AaABAg,2,_e-LFe_igno,0,2,2020-09-07T22:57:19Z,"I have the same question, after reading all the responses to your question, I dont think anyone has actually addressed your question",2020-09-07T22:57:40Z
Ugy2DATGQJxTi7XYNfl4AaABAg,@IgorAherne,,1,_e-LFe_igno,0,0,2017-12-26T12:30:22Z,"great explanation, thanks!",2017-12-26T12:30:22Z
UgxDA-2Io19r8Tp3OWx4AaABAg,@solidsnake013579,,1,_e-LFe_igno,1,36,2017-09-20T15:43:11Z,Hi Dr Andrew. Big fan of all your work. BTW I think you should add the keyword &quot;neural network optimization&quot; to your video title so the youtube indexer can index this keyword and show this video up on search result more. I hope more people can benefit from your videos. Thanks !,2017-09-20T15:43:11Z
UgxDA-2Io19r8Tp3OWx4AaABAg.8XjfjlLErUP9hzwaujT60c,@omaxshendy5732,UgxDA-2Io19r8Tp3OWx4AaABAg,2,_e-LFe_igno,0,0,2022-11-04T02:32:56Z,I only wrote &quot;RMSprop&quot; and this what I got :P,2022-11-04T02:32:56Z
Ugz0e90BBp4kCSmb8vl4AaABAg,@cw9249,,1,JXQT_vxqwIs,0,0,2023-04-01T12:50:54Z,It would be easier if you just typed instead of handwrite I can‚Äôt read it,2023-04-01T12:50:54Z
Ugyzd1u5JcCG-Q16Dwp4AaABAg,@piotr780,,1,JXQT_vxqwIs,0,0,2023-03-21T18:19:38Z,-1 no knowledge about why Adam works better then previous algorithms is provided,2023-03-21T18:19:38Z
UgwmJDRj7Dsyyikiagl4AaABAg,@DerAfroJack,,1,JXQT_vxqwIs,1,0,2022-09-24T13:44:28Z,"Hey there I know I am late to the party but I have a pressing question the rest of the internet has failed to answer so far.<br>I currently have to work with a model and network I didn&#39;t design and my job is to basically find out whats wrong so naturally I need to understand the LOC used.<br>There was a line I havent found any example for: optimizer = keras.optimizers.Adam(0.002, 0.5)<br>I am still studying so I am not that well versed in Keras or anything AI so far really but I wanna know if this second value refers to the beta_1 or any other value I am not noticing.<br>The documentation has me puzzled so far so I hope theres someone here who can answer this.",2022-09-24T13:45:06Z
UgwmJDRj7Dsyyikiagl4AaABAg.9gMZrSvH0fc9kYUn4D83rb,@judy1982,UgwmJDRj7Dsyyikiagl4AaABAg,2,JXQT_vxqwIs,0,0,2023-01-06T14:56:38Z,"I&#39;m late but yes it refers to beta_1. The parameters according to the documentation are learning_rate, beta_1, beta_2, epsilon etc. <br>Additionally, if you want to be sure you can run the optimizer with your values 0.002 and 0.5 and then check the value of each parameter. it shows that beta_1 is indeed 0.5",2023-01-06T14:56:38Z
UgwaZdKJK5FjlCqtV8t4AaABAg,@stipepavic843,,1,JXQT_vxqwIs,0,1,2022-04-25T18:04:08Z,this man is a Legend!!,2022-04-25T18:04:08Z
UgyyaJEggdSoAC69OJR4AaABAg,@mllo2003,,1,JXQT_vxqwIs,0,6,2022-04-15T07:38:46Z,The very best and most succinct explanation of ADAM I&#39;ve ever seen. Things become crystal clear if one watches L06 to L08 in a row.,2022-04-15T07:38:46Z
UgyYCdKzB4vNVYQikeB4AaABAg,@sashakobrusev3162,,1,JXQT_vxqwIs,0,0,2021-09-18T19:18:22Z,what is t I do not completely understand,2021-09-18T19:18:22Z
Ugwh-BXBPB9YX1TqAqx4AaABAg,@paulodybala132,,1,JXQT_vxqwIs,0,0,2021-08-22T10:35:34Z,"üòÇ <a href=""https://www.youtube.com/watch?v=JXQT_vxqwIs&amp;t=6m34s"">6:34</a>",2021-08-22T10:35:34Z
UgzsRzV47WXk1BOrqfd4AaABAg,@therealme613,,1,JXQT_vxqwIs,0,0,2021-08-16T21:22:45Z,First task of significance is for me to figure out how to spell Andrews last name then I move on to the algorithm ü§ì,2021-08-16T21:22:45Z
UgykqR9_j5w4ciHES4F4AaABAg,@GRMREAP3R97,,1,JXQT_vxqwIs,1,3,2021-07-13T11:07:37Z,Could anyone give me a list of the notations he mentions in the video or direct me towards a video that has those explained? Main issue with understanding the concept in the video is the lack of explanation of the notations used.,2021-07-13T11:07:37Z
UgykqR9_j5w4ciHES4F4AaABAg.9PjTjSwx9LR9aePoA8D8Cm,@austinhoag5130,UgykqR9_j5w4ciHES4F4AaABAg,2,JXQT_vxqwIs,0,1,2022-05-05T18:13:50Z,"Notice the C2W2L08 in the title of this video. The &quot;L08&quot; part means &quot;Lecture 8&quot; of this series. If you search for &quot;C2W2L01&quot; through &quot;C2W2L07&quot; in youtube you will find the videos leading up to this where he explains all of these terms. In particular the ones that are most helpful are: C2W2L03 (exponentially weighted averages), C2W2L05 (bias correction), C2W2L06 (momentum) and C2W2L07 (rms prop).",2022-05-05T18:13:50Z
UgxB_6K-So66bSTIgpp4AaABAg,@veganphilosopher1975,,1,JXQT_vxqwIs,0,0,2021-05-10T22:38:20Z,Ow my ears,2021-05-10T22:38:20Z
UgxC19ZEsFbMJWWbukx4AaABAg,@sahanmendis3369,,1,JXQT_vxqwIs,1,14,2021-04-28T05:44:48Z,Only understood his friend has nothing to do with Adam optimization!,2021-04-28T05:44:48Z
UgxC19ZEsFbMJWWbukx4AaABAg.9MfCNbLmKcr9egKeArKRNw,@donfeto7636,UgxC19ZEsFbMJWWbukx4AaABAg,2,JXQT_vxqwIs,0,2,2022-08-13T22:12:50Z,cuz it is based on many another algorithms you need to start from gradient decent  to know this,2022-08-13T22:12:50Z
Ugywsd5HDZ3dcuV-IHF4AaABAg,@ximingwen2542,,1,JXQT_vxqwIs,0,0,2021-04-15T18:47:34Z,what is s and v,2021-04-15T18:47:34Z
UgwswjeoBCMeW4layCZ4AaABAg,@manuel783,,1,JXQT_vxqwIs,0,56,2021-01-18T22:57:31Z,"Clarification about Adam Optimization<br><br>Please note that at <a href=""https://www.youtube.com/watch?v=JXQT_vxqwIs&amp;t=2m44s"">2:44</a>, the Sdb equation is correct.  However,  from <a href=""https://www.youtube.com/watch?v=JXQT_vxqwIs&amp;t=2m48s"">2:48</a> , the db¬≤ lost the ¬≤.<br><br>The bottom right equation should still be:<br><br>Sdb = Œ≤‚ÇÇSdb + (1 - Œ≤‚ÇÇ)db¬≤",2021-01-18T22:57:31Z
UgybOsSxJ0PbR15TsTN4AaABAg,@sandipansarkar9211,,1,JXQT_vxqwIs,1,0,2020-12-21T01:41:25Z,great explntion.Meed to watch again,2020-12-21T01:41:25Z
UgybOsSxJ0PbR15TsTN4AaABAg.9HWAm-tweN29u74AoIaV0B,@ermano5586,UgybOsSxJ0PbR15TsTN4AaABAg,2,JXQT_vxqwIs,0,0,2023-09-01T12:38:32Z,I am watching it again,2023-09-01T12:38:32Z
UgwNBh3B10gbgiD6pw54AaABAg,@hudsonvan4322,,1,JXQT_vxqwIs,0,0,2020-10-26T14:52:12Z,ÊØîÂä©ÊïôË¨õÂæóÂ•ΩÂ§™Â§ö‰∫Ü,2020-10-26T14:52:12Z
UgzxAr0cucyOHOpZOsx4AaABAg,@pipilu3055,,1,JXQT_vxqwIs,0,6,2020-07-22T08:01:04Z,This video is closely related to the video &quot;Bias Correction of Exponentially Weighted Averages&quot;. Please revisit that video if you feel this is too confusing.,2020-07-22T08:01:04Z
UgyQLNGNXeXEpLCplLJ4AaABAg,@brutuschina,,1,JXQT_vxqwIs,0,4,2020-05-17T15:24:42Z,Eve Optimization Algorithm will come soon!,2020-05-17T15:24:42Z
Ugy2x-V8DShv05lXJ494AaABAg,@prajwollamichhane4064,,1,JXQT_vxqwIs,0,9,2020-05-15T06:29:54Z,Roasting at the end ! Hahaha,2020-05-15T06:29:54Z
UgwqbulUHNaJok4GYJF4AaABAg,@ayushsahu6304,,1,JXQT_vxqwIs,0,1,2020-05-08T10:18:56Z,You are my god.,2020-05-08T10:18:56Z
UgyFaBj4JH8TbTpOImF4AaABAg,@mostafanakhaei2487,,1,JXQT_vxqwIs,0,11,2020-04-16T20:53:47Z,"any time I want to implement ML from scratch, I watch all Andrew&#39;s videos from beginning to end! I don&#39;t know how to express my appreciation to this great man.",2020-04-16T20:53:47Z
Ugy6x9_3TPQOsPEajMB4AaABAg,@omidtaghizadeh9698,,1,JXQT_vxqwIs,0,1,2020-02-21T11:25:57Z,"you really dont think that statement of the problem that ADAM solves is of relevance, when you are introducing ADAM?",2020-02-21T11:25:57Z
UgxCfTpecRmSeDqnA4R4AaABAg,@submagr,,1,JXQT_vxqwIs,0,3,2019-11-25T06:42:26Z,"You are so sweet. Thank you Sir, for these awesome videos!",2019-11-25T06:42:26Z
UgyxMDOSdIb7aFAsvJZ4AaABAg,@jerekabi8480,,1,JXQT_vxqwIs,2,13,2019-07-01T11:28:26Z,This nailed down the Adam paper. Thanks alot,2019-07-01T11:28:26Z
UgyxMDOSdIb7aFAsvJZ4AaABAg.8wqLUqvb-hi9hGruviyLOD,@ogunyolufunmilola2059,UgyxMDOSdIb7aFAsvJZ4AaABAg,2,JXQT_vxqwIs,0,1,2022-10-17T05:06:55Z,Can Adam optimization be used for classification problems?,2022-10-17T05:06:55Z
UgyxMDOSdIb7aFAsvJZ4AaABAg.8wqLUqvb-hi9is69t0pqp_,@rawandbamoki9873,UgyxMDOSdIb7aFAsvJZ4AaABAg,2,JXQT_vxqwIs,0,1,2022-11-25T22:02:42Z,@@ogunyolufunmilola2059 Yes it can,2022-11-25T22:02:42Z
UgzGRyBraxrs0Pdo0Yl4AaABAg,@jerrylin5089,,1,JXQT_vxqwIs,4,15,2019-06-11T22:06:07Z,"Why did you erase the squared at <a href=""https://www.youtube.com/watch?v=JXQT_vxqwIs&amp;t=2m46s"">2:46</a>? Shouldn&#39;t RMSprop have a squared term for the bias as well?",2019-06-11T22:06:07Z
UgzGRyBraxrs0Pdo0Yl4AaABAg.8w2zZmCGH0e90oVLCsvaof,@KrishnaAnapindi92,UgzGRyBraxrs0Pdo0Yl4AaABAg,2,JXQT_vxqwIs,0,5,2019-11-02T00:53:00Z,I think thats a typo,2019-11-02T00:53:00Z
UgzGRyBraxrs0Pdo0Yl4AaABAg.8w2zZmCGH0e98hSf4tBs73,@rohitborra2507,UgzGRyBraxrs0Pdo0Yl4AaABAg,2,JXQT_vxqwIs,0,3,2020-05-16T03:26:06Z,yes thats a mistake,2020-05-16T03:26:06Z
UgzGRyBraxrs0Pdo0Yl4AaABAg.8w2zZmCGH0e99C0rEYx_iu,@sammathew243,UgzGRyBraxrs0Pdo0Yl4AaABAg,2,JXQT_vxqwIs,0,0,2020-05-28T09:38:47Z,"The square appeared for a while, after Andrew missed it, but then vanished. It seems the video edit could not sustain the presence of 2!",2020-05-28T09:38:47Z
UgzGRyBraxrs0Pdo0Yl4AaABAg.8w2zZmCGH0e9IuF4-sa2nb,@doyugen465,UgzGRyBraxrs0Pdo0Yl4AaABAg,2,JXQT_vxqwIs,0,0,2021-01-24T15:51:22Z,"this has most definitely saved me a good few hours, possibly more than 24, of staring at my code wondering why im doing this. thank you :)",2021-01-24T15:51:22Z
Ugy10IXHbq122HSVDoh4AaABAg,@danlan4132,,1,JXQT_vxqwIs,0,7,2019-03-29T18:31:57Z,"from <a href=""https://www.youtube.com/watch?v=JXQT_vxqwIs&amp;t=0m00s"">0:00</a>-<a href=""https://www.youtube.com/watch?v=JXQT_vxqwIs&amp;t=4m36s"">4:36</a>, S_db is missing a square on db element, it should be s_db = b_2*s_db +(1-b_2)*db^2",2019-03-29T18:32:07Z
UgyOIk6KnZKeus8qZ554AaABAg,@mdashiqurrahman9369,,1,JXQT_vxqwIs,0,21,2019-03-28T18:33:39Z,there is roasting in the end,2019-03-28T18:33:39Z
UgwOQopN3Sdh9Tpv9fN4AaABAg,@krishnakrmahto97,,1,JXQT_vxqwIs,0,4,2019-02-17T16:16:52Z,God of lucid explanation &lt;3,2019-02-17T16:16:52Z
Ugy8Dxf-i8jHZ9dLJ414AaABAg,@douglaskaicong131,,1,JXQT_vxqwIs,4,54,2019-02-01T15:37:11Z,"i am confuse to the maximum level, can i buy more brain power like i buy more rams?",2019-02-01T15:37:11Z
Ugy8Dxf-i8jHZ9dLJ414AaABAg.8qoYiOMVn1A8ycRhGQYIqk,@cimmik,Ugy8Dxf-i8jHZ9dLJ414AaABAg,2,JXQT_vxqwIs,0,5,2019-08-14T18:56:07Z,"Don&#39;t worry, fellow human. Neither I have enough neurons to process that data with a decent success rate.",2019-08-14T18:56:07Z
Ugy8Dxf-i8jHZ9dLJ414AaABAg.8qoYiOMVn1A93HiQkjX70S,@mohdazam1404,Ugy8Dxf-i8jHZ9dLJ414AaABAg,2,JXQT_vxqwIs,0,8,2020-01-02T11:36:05Z,"Before this video you should be very much clear on GD, SGD and Mini Batch SGD...",2020-01-02T11:36:05Z
Ugy8Dxf-i8jHZ9dLJ414AaABAg.8qoYiOMVn1A9MfxWo8iwas,@ehsankhorasani_,Ugy8Dxf-i8jHZ9dLJ414AaABAg,2,JXQT_vxqwIs,0,0,2021-04-28T12:45:29Z,"No, just find a better video on YouTube that explain Adam",2021-04-28T12:45:29Z
Ugy8Dxf-i8jHZ9dLJ414AaABAg.8qoYiOMVn1A9gvdVjhC3us,@cking9145,Ugy8Dxf-i8jHZ9dLJ414AaABAg,2,JXQT_vxqwIs,0,0,2022-10-08T13:57:42Z,@@ehsankhorasani_ Can&#39;t find many which even explain it,2022-10-08T13:57:42Z
Ugx194fnghNdr8NHtXd4AaABAg,@EranM,,1,JXQT_vxqwIs,0,14,2018-12-12T07:19:49Z,Haha showing Adam there was hilarious :&gt;,2018-12-12T07:19:49Z
UgwW9OtgDED9vJ2-j0d4AaABAg,@aa4mad,,1,JXQT_vxqwIs,2,8,2018-12-10T18:38:49Z,please apply a low pass filter on the audio of this video,2018-12-10T18:38:49Z
UgwW9OtgDED9vJ2-j0d4AaABAg.8ogPNKxDsbX90x7AIkDHJ7,@SohamRailkar,UgwW9OtgDED9vJ2-j0d4AaABAg,2,JXQT_vxqwIs,0,1,2019-11-05T09:14:57Z,create model fo it,2019-11-05T09:14:57Z
UgwW9OtgDED9vJ2-j0d4AaABAg.8ogPNKxDsbX9EDhuPXEUo-,@MrDeyzel,UgwW9OtgDED9vJ2-j0d4AaABAg,2,JXQT_vxqwIs,0,2,2020-09-30T07:59:54Z,I&#39;ve been downloading the vids and adding a lowpass in VLC. Can&#39;t stand the hissing.,2020-09-30T07:59:54Z
UgwPAXge1ccPlrMzJzl4AaABAg,@Philson,,1,JXQT_vxqwIs,1,4,2018-08-20T14:17:46Z,SGD vs ADADELTA? If I only had those 2 choices.,2018-08-20T14:17:46Z
UgwPAXge1ccPlrMzJzl4AaABAg.8kAYTQz5aiX8prMJO6kqPv,@luanmoura7705,UgwPAXge1ccPlrMzJzl4AaABAg,2,JXQT_vxqwIs,0,0,2019-01-08T21:15:05Z,adadelta,2019-01-08T21:15:05Z
UgyPDXGX9N2n2-oog314AaABAg,@abunickabhi,,1,JXQT_vxqwIs,0,0,2018-08-10T11:45:20Z,Yay,2018-08-10T11:45:20Z
UgykYXeU9RpJEFOxS_B4AaABAg,@iNationOnline,,1,JXQT_vxqwIs,0,1,2018-07-06T20:55:34Z,is that you beatthebush?,2018-07-06T20:55:34Z
UgxK-Ao4XyEZzfc4QN54AaABAg,@ermano5586,,1,QzulmoOg2JE,0,1,2023-09-01T13:44:55Z,"Where is the guy who types that he is watching again, I thougt I will type him too that I am watching again",2023-09-01T13:44:55Z
UgyORK0VqrOGm5N73b54AaABAg,@zooltechno7065,,1,QzulmoOg2JE,0,0,2023-03-08T22:31:09Z,"hello, i am student and  i am work on my project , its name face mask detection<br>and I need help because I faceses some problems when i use adam library",2023-03-08T22:31:09Z
UgwdPzVHCOnjiLnlsN14AaABAg,@herrdebanjan2827,,1,QzulmoOg2JE,0,0,2022-06-23T10:18:47Z,0.067 and so on.,2022-06-23T10:18:47Z
Ugypmqz1NlmKHXLKZit4AaABAg,@piyalikarmakar5979,,1,QzulmoOg2JE,0,4,2021-08-27T07:36:53Z,These few important points we been always missed in lectures..Only Andrew sir can remind all these minor but most important topics..Thank you sir..,2021-08-27T07:36:53Z
UgxuuZ85X0TaF0W6FPF4AaABAg,@manuel783,,1,QzulmoOg2JE,0,9,2021-01-18T23:08:02Z,"Clarification about Learning Rate Decay<br><br>Please note that at <a href=""https://www.youtube.com/watch?v=QzulmoOg2JE&amp;t=3m35s"">3:35</a>, the values for alpha should be:<br><br>Epoch 1: alpha 0.1<br><br>Epoch 2: alpha 0.067<br><br>Epoch 3: alpha 0.05<br><br>Epoch 4: alpha 0.04<br><br>The formula for learning rate decay is:<br><br>Œ± = 1 / (1 + decayRate √ó epochNumber) Œ±‚ÇÄ",2021-01-18T23:08:02Z
Ugx4NGZre-TdAXgy_7N4AaABAg,@ramseybolton1509,,1,QzulmoOg2JE,0,1,2020-11-18T07:24:49Z,"This vid is gr8 but 3 years old, so it doesn&#39;t discuss modern LR decay methods. Check out SGDR, it discusses the concept of Warm Restarts for Learning Rate and seems to give good results like skipping local minima. May be implement it using this <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/experimental/CosineDecayRestarts"">https://www.tensorflow.org/api_docs/python/tf/keras/experimental/CosineDecayRestarts</a>",2020-11-18T07:26:39Z
UgxfdKrg9PbJmyd3EZx4AaABAg,@wifi-YT,,1,QzulmoOg2JE,0,1,2020-09-17T23:12:41Z,"Also, at <a href=""https://www.youtube.com/watch?v=QzulmoOg2JE&amp;t=3m58s"">3:58</a>, I think he meant ‚Äú0.95 TO THE POWER of epoch-num, not ‚Äútimes epoch-num.‚Äù",2020-09-17T23:13:59Z
UgykAB21wsQoEUboBOZ4AaABAg,@sandeepreddy7997,,1,QzulmoOg2JE,3,2,2020-04-20T13:16:08Z,"Correct me if Im wrong, but 1 epocch is not done on the entire data, but on a a specific batch as per discussion in Mini batch GD",2020-04-20T13:16:08Z
UgykAB21wsQoEUboBOZ4AaABAg.97fZWu0plWN98Vi23sawKM,@jawher9,UgykAB21wsQoEUboBOZ4AaABAg,2,QzulmoOg2JE,0,12,2020-05-11T04:39:03Z,1 epoch = 1 pass on entire data<br>1 iteration = 1 pass on 1 batch,2020-05-11T04:39:03Z
UgykAB21wsQoEUboBOZ4AaABAg.97fZWu0plWN9FhZoTP2i_G,@default2826,UgykAB21wsQoEUboBOZ4AaABAg,2,QzulmoOg2JE,0,0,2020-11-06T04:08:18Z,"Wrong, 1 epoch is the entire data, 1 iteration /step is a specific batch/mini batch, multiple iterations /steps are done until the entire dataset is gone through and that&#39;s when one epoch is complete",2020-11-06T04:08:18Z
UgykAB21wsQoEUboBOZ4AaABAg.97fZWu0plWN9LqpQtGL4Gh,@leosmi1,UgykAB21wsQoEUboBOZ4AaABAg,2,QzulmoOg2JE,0,0,2021-04-07T21:35:02Z,"1 epoch is 1 or more batches, it depends the size of your RAM memory.",2021-04-07T21:35:02Z
UgzBHqlPRs5A5PeXlgJ4AaABAg,@RaviBhatia89,,1,QzulmoOg2JE,2,11,2020-03-27T13:37:11Z,"For those using the Playlist, the lecture 10 is missing, it is here: <br><br><a href=""https://www.youtube.com/watch?v=fODpu1-lNTw"">https://www.youtube.com/watch?v=fODpu1-lNTw</a>",2020-03-27T13:37:11Z
UgzBHqlPRs5A5PeXlgJ4AaABAg.96hnr51omVJ9JrYrIs391P,@jjh3587,UgzBHqlPRs5A5PeXlgJ4AaABAg,2,QzulmoOg2JE,0,3,2021-02-17T11:17:56Z,"its C2W3L10, not C2W2L10",2021-02-17T11:17:56Z
UgzBHqlPRs5A5PeXlgJ4AaABAg.96hnr51omVJ9u7BYD8XK1-,@ermano5586,UgzBHqlPRs5A5PeXlgJ4AaABAg,2,QzulmoOg2JE,0,0,2023-09-01T13:42:53Z,@@jjh3587 It was a joke,2023-09-01T13:42:53Z
Ugw_Cp7hIQJD3iffqkt4AaABAg,@uniquetobin4real,,1,QzulmoOg2JE,1,1,2020-03-17T12:48:37Z,Wtf is alpho 0.... I love your videos but u ain&#39;t a teacher....u can only explain to nerds and experts,2020-03-17T12:48:37Z
Ugw_Cp7hIQJD3iffqkt4AaABAg.96IyLZNj4in96emGq1zVap,@H4nek,Ugw_Cp7hIQJD3iffqkt4AaABAg,2,QzulmoOg2JE,0,0,2020-03-26T09:25:38Z,"Alpha_0 is the initial learning rate - the one that is supplied by the user. The algorithm starts with it and then performs the decay, effectively lowering it.",2020-03-26T09:25:38Z
Ugz2g0mQAjhkp7W0C2N4AaABAg,@onionike4198,,1,QzulmoOg2JE,0,1,2019-09-25T01:40:12Z,"Wow, I never even considered this! Thanks!",2019-09-25T01:40:12Z
Ugz1ujq4tRpILWGZwet4AaABAg,@asterdan712,,1,QzulmoOg2JE,0,74,2019-03-27T08:28:20Z,On an intuitive level this is exactly how you would play golf. Hit hard at the start of the game and as you come nearer to the hole reduce the power of your shot to reach the hole or minima in case of gradient descent,2019-03-27T08:28:20Z
UgwGZLLmIYE6TcjDOLh4AaABAg,@CygnusX211,,1,QzulmoOg2JE,4,124,2018-02-18T16:07:22Z,"The decay rates in the table at around 3.41 should be 0.1, 0.067, 0.05 etc. Off by a decimal",2018-02-18T16:07:22Z
UgwGZLLmIYE6TcjDOLh4AaABAg.8coXXycNFyd8rFasgCO7je,@flamingpheonix5231,UgwGZLLmIYE6TcjDOLh4AaABAg,2,QzulmoOg2JE,0,5,2019-02-12T13:03:32Z,yah lol I thought I was dumb or something,2019-02-12T13:03:32Z
UgwGZLLmIYE6TcjDOLh4AaABAg.8coXXycNFyd99SZKCx_WAA,@nzsvus,UgwGZLLmIYE6TcjDOLh4AaABAg,2,QzulmoOg2JE,0,0,2020-06-03T19:47:49Z,"@@flamingpheonix5231 Yeah, me too, I had to use a calculator, to understand what is going on üòÖ",2020-06-03T19:47:49Z
UgwGZLLmIYE6TcjDOLh4AaABAg.8coXXycNFyd9Y-1be-ujQF,@vaibhavkhobragade9773,UgwGZLLmIYE6TcjDOLh4AaABAg,2,QzulmoOg2JE,0,1,2022-02-03T17:40:07Z,"Yep, I didn&#39;t do any calculation but my intutition tell me how learning rate is increasing. It should be decreasing learning rate right. ;)",2022-02-03T17:42:03Z
UgwGZLLmIYE6TcjDOLh4AaABAg.8coXXycNFyd9gZHMSXzqXb,@user-eb8gx7ny7k,UgwGZLLmIYE6TcjDOLh4AaABAg,2,QzulmoOg2JE,0,0,2022-09-29T12:12:56Z,thanks alot „Öé„Öé,2022-09-29T12:12:56Z
UgzMMb-O63JL-IocjhN4AaABAg,@jorendorff,,1,AXDByU3D1hA,0,1,2023-03-24T13:11:03Z,"At the end of the previous video, C2W2L09, Ng says the next video will be about local optima, but the next video in the playlist is this one. The missing video is &quot;The Problem of Local Optima (C2W3L10)&quot; -- it looks like it was just misnumbered and put into week 3 instead of week 2. <a href=""https://www.youtube.com/watch?v=fODpu1-lNTw"">https://www.youtube.com/watch?v=fODpu1-lNTw</a>",2023-03-24T13:11:03Z
UgycC0mlDk6gY-hD6Gt4AaABAg,@anirudhsharma2003,,1,AXDByU3D1hA,0,0,2021-09-05T05:28:27Z,"Can we not keep everything constant initially, try 10 values for hyperparameter 1, get the best and then move on to next hyperparameter?",2021-09-05T05:28:27Z
UgwStgC0of9wT73vmqF4AaABAg,@anirudhsharma2003,,1,AXDByU3D1hA,0,0,2021-09-05T05:27:31Z,"Can we like rotate the grid by say some angle*? then every point will have a different alpha, and what&#39;s more, they will be evenly* spread??<br><br>Specifically rotation by a multiple of atan(1/number of points)",2021-09-05T05:27:31Z
Ugwq82XA4DAg9KtsHtJ4AaABAg,@ensabinha,,1,AXDByU3D1hA,0,0,2021-03-16T17:24:25Z,Or you can use a metaheuristic such as differential evolution to optimize the hyperparameters,2021-03-16T17:24:25Z
Ugz-osIDq1XtCRNOdSR4AaABAg,@sandipansarkar9211,,1,AXDByU3D1hA,0,1,2020-12-11T20:03:07Z,this is little bit tough topic for beginners.Till the previus video in the series is OK,2020-12-11T20:03:07Z
UgzSKWYEKK7BFs1yN454AaABAg,@yavdhesh,,1,AXDByU3D1hA,0,2,2020-05-31T00:47:01Z,"‡§™‡•ç‡§∞‡§£‡§æ‡§Æ ‡§Ü‡§£‡•ç‡§°‡•ç‡§∞‡•Å ‡§ú‡•Ä, ‡§Ü‡§™‡§ï‡§æ ‡§¨‡§π‡•Å‡§§ ‡§¨‡§π‡•Å‡§§ ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶‡•§",2020-05-31T00:47:01Z
Ugxr4GASoT1C6b5LSFJ4AaABAg,@akrsrivastava,,1,AXDByU3D1hA,0,3,2019-12-31T06:06:50Z,Deep Learning Models can take days to train. How can we search across the hyperparameter space more efficiently? Randomly picking up hyperparameters is difficult because you cant ascertain which hyper parameter amongst the one you changed actually benefitted the model.,2019-12-31T06:06:50Z
UgwdNEzgRfVOxZDb1-x4AaABAg,@freerockneverdrop1236,,1,AXDByU3D1hA,0,1,2019-10-23T21:24:27Z,"First, thank you very much for the awesome videos. One question, ADAM adjusts the learning rate dynamically. Why do we still need to tune it instead of just setting a reasonable value? Say 0.001",2019-10-23T21:24:27Z
Ugy1Bpjn5UVEwDlZ8QJ4AaABAg,@WilsonMar1,,1,AXDByU3D1hA,0,0,2018-08-27T20:31:55Z,Tuning hyperperameters is addressed by Amazon&#39;s SageMaker. Is that any good?,2018-08-27T20:31:55Z
UgwE4_NdCaZ-dG7iy254AaABAg,@hermonjay4744,,1,AXDByU3D1hA,2,0,2017-11-09T04:11:55Z,Where is C2W3L02 course?,2017-11-09T04:11:55Z
UgwE4_NdCaZ-dG7iy254AaABAg.8ZjBNZ1bzbG8_B8CGQPiRE,@X_platform,UgwE4_NdCaZ-dG7iy254AaABAg,2,AXDByU3D1hA,0,0,2017-11-20T10:02:08Z,There seems to have two 03s. One of them is probably 02.,2017-11-20T10:02:08Z
UgwE4_NdCaZ-dG7iy254AaABAg.8ZjBNZ1bzbG8_BQQXLagee,@hermonjay4744,UgwE4_NdCaZ-dG7iy254AaABAg,2,AXDByU3D1hA,0,1,2017-11-20T12:41:22Z,I see.. let&#39;s stick with the playlist,2017-11-20T12:41:22Z
UgwLmZ04KPifmqbuIc94AaABAg,@ChizkiyahuOhayon,,1,cSoK_6Rkbfg,0,1,2023-10-31T03:48:56Z,"That is the Benford&#39;s law in math. The distance between numbers should be evaluated by division, not subtraction.",2023-10-31T03:49:07Z
UgzOtG7otAPW_3uW5vJ4AaABAg,@speed-stick,,1,cSoK_6Rkbfg,1,0,2022-02-28T14:36:44Z,"Can somebody explain why sampling from <b>[0,1)</b> gives a value in <b>[0.1,1)</b> 90% of the time? <b>np.random.uniform(0,1)</b> says:<br><i>any value within the given interval is equally likely to be drawn</i>",2022-02-28T14:37:10Z
UgzOtG7otAPW_3uW5vJ4AaABAg.9Z-4VI4hUWH9Z534l8C6Z0,@hasnainmamdani4534,UgzOtG7otAPW_3uW5vJ4AaABAg,2,cSoK_6Rkbfg,0,2,2022-03-02T22:19:49Z,"Because [0.1, 1.0) makes up 90% of the range [0.0, 1.0).",2022-03-02T22:19:49Z
UgzDnHTlz9XylZH1dE94AaABAg,@burak4799,,1,cSoK_6Rkbfg,0,0,2021-06-05T00:32:09Z,"Oh, If I only had known this before spending hours doing grid search :/",2021-06-05T00:32:09Z
UgxLp13GzdNxgopKIxN4AaABAg,@gabrielwong1991,,1,cSoK_6Rkbfg,0,0,2021-03-04T16:20:14Z,Can you sample from uniform distribution between log(0.0001) to log(1) and for those random values we use exponent to unwind the log to get the value?,2021-03-04T16:20:14Z
UgysKXK_jb1RwFyDnhJ4AaABAg,@sandipansarkar9211,,1,cSoK_6Rkbfg,1,1,2020-12-21T01:24:02Z,great explanatiom,2020-12-21T01:24:02Z
UgysKXK_jb1RwFyDnhJ4AaABAg.9HW8mbrCaLy9u7QfdqOB8d,@ermano5586,UgysKXK_jb1RwFyDnhJ4AaABAg,2,cSoK_6Rkbfg,0,2,2023-09-01T15:55:07Z,need to watch again,2023-09-01T15:55:07Z
UgxYVplPJyx2NKfyMmx4AaABAg,@user-md3ze5dx3l,,1,cSoK_6Rkbfg,0,0,2020-02-12T20:11:01Z,"where can i find material(document) of this course,..",2020-02-12T20:11:01Z
UgyNYeC5ctHzFpfHd0J4AaABAg,@haha-ds2ep,,1,cSoK_6Rkbfg,1,11,2018-02-12T03:15:40Z,Should this be C2W3L02?,2018-02-12T03:15:59Z
UgyNYeC5ctHzFpfHd0J4AaABAg.8cYhSgYK_yK8kPnRVQqhHy,@himanshuchauhan1554,UgyNYeC5ctHzFpfHd0J4AaABAg,2,cSoK_6Rkbfg,0,1,2018-08-26T12:25:55Z,Yes,2018-08-26T12:25:55Z
Ugzn6hrViMm_ng8XITZ4AaABAg,@Jirayu.Kaewprateep,,1,wKkcBPp3F1Y,0,0,2023-05-10T07:35:27Z,üì∫üí¨ Learning model curves and how to develop work models.<br>ü•∫üí¨ I am interesting and still watch you release VDO.,2023-05-10T07:35:27Z
UgyrXdgEaytFFwMdKAt4AaABAg,@olha_,,1,wKkcBPp3F1Y,0,0,2022-10-07T21:48:48Z,"That is called K and r reproductive strategy, respectively.",2022-10-07T21:48:48Z
Ugw524PZsPxV5By9ubV4AaABAg,@tahminehzakizadeh,,1,wKkcBPp3F1Y,0,0,2022-08-23T09:14:53Z,"If you are interested in Hyperparameter Optimization, please check my Channel. I have videos about this topic",2022-08-23T09:14:53Z
UgzI1XdnyyoLneDAPsd4AaABAg,@haneulkim4902,,1,wKkcBPp3F1Y,1,4,2022-02-09T00:47:09Z,"I thought he was showing way to tune hyperparameters using pandas module...lol you got me <a href=""http://mr.ng/"">Mr.Ng</a>.",2022-02-09T00:47:09Z
UgzI1XdnyyoLneDAPsd4AaABAg.9YCfSbqz4jN9_tb89ksZQf,@AbhinavSingh-oq7dk,UgzI1XdnyyoLneDAPsd4AaABAg,2,wKkcBPp3F1Y,0,1,2022-04-16T19:18:46Z,and got tensed wondering what is this CAVIAR now !?,2022-04-16T19:18:46Z
Ugzz8HbHVkMu-kdvL3t4AaABAg,@sandipansarkar9211,,1,wKkcBPp3F1Y,1,1,2020-12-21T01:32:14Z,need to watch it again,2020-12-21T01:32:14Z
Ugzz8HbHVkMu-kdvL3t4AaABAg.9HW9ik0uluz9u7SC3bjgZ0,@ermano5586,Ugzz8HbHVkMu-kdvL3t4AaABAg,2,wKkcBPp3F1Y,0,1,2023-09-01T16:08:25Z,I am watching it again,2023-09-01T16:08:25Z
Ugwj6AA8re531el15d54AaABAg,@ehsankiani542,,1,wKkcBPp3F1Y,0,5,2020-08-24T23:42:35Z,Too general description.,2020-08-24T23:42:35Z
UgxdG1LRaJpJ2DV3A0V4AaABAg,@MrQwerty2524,,1,wKkcBPp3F1Y,1,2,2020-06-30T14:59:23Z,"If only i understand how the kaggle score works... My kaggle score goes up (0.44 -&gt; 0.47) but my mse, validation loss and val_accuracy go down...",2020-06-30T14:59:23Z
UgxdG1LRaJpJ2DV3A0V4AaABAg.9AXZmAKrJM69wa8gAjOBsl,@shrayesraman5192,UgxdG1LRaJpJ2DV3A0V4AaABAg,2,wKkcBPp3F1Y,0,0,2023-11-01T21:57:54Z,Loss and MSE should go down lmao,2023-11-01T21:57:54Z
Ugx8-I452IEs5Zh8NxB4AaABAg,@johndoe-lx3zh,,1,wKkcBPp3F1Y,0,1,2020-04-02T16:52:45Z,very helpful thank you!,2020-04-02T16:52:45Z
UgwmeoBMIGyIvLtDWMh4AaABAg,@MrCynosure4sure,,1,wKkcBPp3F1Y,4,68,2017-10-10T07:45:10Z,I thought it would be python pandas :D,2017-10-10T07:45:10Z
UgwmeoBMIGyIvLtDWMh4AaABAg.8YXJw80yY4N8m4Blt04HPi,@inosuke44,UgwmeoBMIGyIvLtDWMh4AaABAg,2,wKkcBPp3F1Y,0,0,2018-10-06T20:06:47Z,I also thought soo,2018-10-06T20:06:47Z
UgwmeoBMIGyIvLtDWMh4AaABAg.8YXJw80yY4N93kNtsZpUZQ,@brzrst802,UgwmeoBMIGyIvLtDWMh4AaABAg,2,wKkcBPp3F1Y,0,0,2020-01-14T00:05:11Z,same!,2020-01-14T00:05:11Z
UgwmeoBMIGyIvLtDWMh4AaABAg.8YXJw80yY4N98CS_C2rzOu,@awsm1680,UgwmeoBMIGyIvLtDWMh4AaABAg,2,wKkcBPp3F1Y,0,6,2020-05-03T17:09:36Z,thought there&#39;s a caviar library in python lol,2020-05-03T17:09:36Z
UgwmeoBMIGyIvLtDWMh4AaABAg.8YXJw80yY4N9NXGK4HRJuU,@goksuceylan8844,UgwmeoBMIGyIvLtDWMh4AaABAg,2,wKkcBPp3F1Y,0,0,2021-05-19T14:57:30Z,@@awsm1680 bruh same,2021-05-19T14:57:30Z
UgznmQHzaek1SZbU19B4AaABAg,@Jirayu.Kaewprateep,,1,tNIpEZLv_eg,0,0,2023-04-20T15:13:07Z,üì∫üí¨ We can use Z cap I instead of Z I <br>üß∏üí¨ Does it mean that we do not find all the value from all nodes because probability start from the same the update value is in linear with beta and gamma parameter‚Åâ,2023-04-20T15:13:07Z
UgzzWrn-Zryrcx9Cuhh4AaABAg,@AbhinavSingh-oq7dk,,1,tNIpEZLv_eg,1,1,2022-04-17T14:46:07Z,"<a href=""https://www.youtube.com/watch?v=tNIpEZLv_eg&amp;t=7m28s"">7:28</a> , it is said we might want larger variance for z, but why? Wouldn&#39;t that lead to slow learning problem / vanishing gradient in case of sigmoid?",2022-04-17T14:46:07Z
UgzzWrn-Zryrcx9Cuhh4AaABAg.9_vgj4R2Pjc9wmpKyZ7zlT,@Komisar95,UgzzWrn-Zryrcx9Cuhh4AaABAg,2,tNIpEZLv_eg,0,0,2023-11-06T20:10:14Z,"If you imagine the variance which is small, you will produce inputs near zero, where sigmoid behaves as a linear function. This would make the whole layer a useless linear transformation.",2023-11-06T20:10:14Z
Ugzckos2D0IlgMLof9p4AaABAg,@machinelearning3518,,1,tNIpEZLv_eg,0,0,2022-01-11T11:04:33Z,it should be x=x/sigma not sigma^2 ??,2022-01-11T11:04:33Z
UgxelXlz8aF_xKSREhV4AaABAg,@abdulmukit4420,,1,tNIpEZLv_eg,0,1,2021-08-07T17:15:51Z,Beautiful explanation. This makes so much more sense now.,2021-08-07T17:15:51Z
UgyyHNnskEPqJfGjjZ54AaABAg,@alakbarvalizada5425,,1,tNIpEZLv_eg,0,3,2021-03-28T13:07:09Z,"For input normalization x divided by variance. Instead of variance should it be standard deviation? I mean not sigma^2 but sqrt(sigma^2) at <a href=""https://www.youtube.com/watch?v=tNIpEZLv_eg&amp;t=0m58s"">0:58</a> time of video.",2021-03-28T13:13:31Z
Ugz3zBpSVuBAaiAVh094AaABAg,@sandipansarkar9211,,1,tNIpEZLv_eg,1,2,2020-12-19T15:12:19Z,great explanation.Need to make notes,2020-12-19T15:12:19Z
Ugz3zBpSVuBAaiAVh094AaABAg.9HSTzTt5j6b9u8va5jB0jP,@ermano5586,Ugz3zBpSVuBAaiAVh094AaABAg,2,tNIpEZLv_eg,0,0,2023-09-02T05:53:13Z,I&#39;m making notes,2023-09-02T05:53:13Z
UgzG54JXEWRwGv0ral14AaABAg,@jandresjn,,1,tNIpEZLv_eg,0,0,2020-12-04T22:04:01Z,"Excelent presentation, terrible letter :v",2020-12-04T22:04:01Z
UgztjqXWcGoiuVpyzqt4AaABAg,@clivefernandes5435,,1,tNIpEZLv_eg,0,0,2020-08-16T19:00:29Z,So gamma and beta are learning the true variance and mean  of the dataset rite ?,2020-08-16T19:00:29Z
UgyRxZn-n2oe4Ha3gcV4AaABAg,@depizixuri58,,1,tNIpEZLv_eg,0,0,2020-06-28T20:20:22Z,What if the layer is not fully connected? How is the batch normalization done?,2020-06-28T20:20:22Z
UgzlwW6W0HYi2PEax454AaABAg,@KapilSharma-co8xq,,1,tNIpEZLv_eg,1,1,2020-06-18T12:02:47Z,Should it not be<br>Sigma^2=(1/m) summation (zi^2-u^2),2020-06-18T12:03:28Z
UgzlwW6W0HYi2PEax454AaABAg.9A2M1HpsVQf9CsJJKiV6eT,@apurvsingh2575,UgzlwW6W0HYi2PEax454AaABAg,2,tNIpEZLv_eg,0,0,2020-08-27T18:41:34Z,"Since he has already subtracted the value of mean from X, i.e, X = X - mu, the new mean becomes 0, so, variance = X^2/N",2020-08-27T18:41:34Z
UgzmxQITIDUnSSN8izh4AaABAg,@yuchenzhao6411,,1,tNIpEZLv_eg,0,0,2020-06-13T14:42:58Z,"How to initialize gamma and beta? (gamma=1, beta=0)?",2020-06-13T15:11:52Z
Ugyq5GG3aXKVSZWEFaN4AaABAg,@keqiaoli4617,,1,tNIpEZLv_eg,2,0,2020-02-28T17:11:07Z,Thanks for the video. I have a dumb question about what do you mean by the hidden unit value? or what does z refer to? It confused me a lot.,2020-02-28T17:11:07Z
Ugyq5GG3aXKVSZWEFaN4AaABAg.95a54OrS7_Y961q3-DZUGF,@alikhansmt,Ugyq5GG3aXKVSZWEFaN4AaABAg,2,tNIpEZLv_eg,0,3,2020-03-10T21:09:05Z,Hidden unit value refers to the output vector of multiplication of previous layer activation and the weights before applying non linearity to it. <br>z = WX+b <br>here z = hidden unit values i.e preactivation values of some hidden layer<br>W = Weight matrix of that layer (the weight values are what are learnt by the network) <br>X= Input to that layer. -&gt; These are the values that are normalized.<br>b= bias.,2020-03-10T21:09:05Z
Ugyq5GG3aXKVSZWEFaN4AaABAg.95a54OrS7_Y99WsGKEdIyq,@The_Lord_Yeshua,Ugyq5GG3aXKVSZWEFaN4AaABAg,2,tNIpEZLv_eg,0,0,2020-06-05T11:59:01Z,z VALUE comes form normal distribution statistical tables....hidden unit are variables in the hidden layers,2020-06-05T11:59:01Z
UgyxZxvPb5hKB-de6sR4AaABAg,@vikankshnath8068,,1,tNIpEZLv_eg,0,0,2020-01-27T14:17:12Z,Amazing thanks,2020-01-27T14:17:12Z
Ugz7BcukTvoD_Nq7Byh4AaABAg,@gorgolyt,,1,tNIpEZLv_eg,3,2,2019-07-20T16:51:31Z,"I found it a bit unclear what the axis of normalisation was (I believe each individual activation is normalised using the mean and standard deviation of that activation over the batch?), and how many learnable parameters there are -- is there a gamme and beta for each activation? It&#39;s not clear whether the zs, gammas, betas, etc. are scalars of single activations or vectors of the whole layer.",2019-07-20T16:51:31Z
Ugz7BcukTvoD_Nq7Byh4AaABAg.8xbqZizzN8G91tH2-HTc1U,@kayicomert7933,Ugz7BcukTvoD_Nq7Byh4AaABAg,2,tNIpEZLv_eg,0,1,2019-11-28T17:55:38Z,"As I understood, Z is the vector of whole output of one layer. You find the variance and the mean over this vector, too. Probably, you have found your answer while ago nevertheless I wanted to answer.",2019-11-28T17:55:38Z
Ugz7BcukTvoD_Nq7Byh4AaABAg.8xbqZizzN8G93qmFmT5CyE,@beizhou2488,Ugz7BcukTvoD_Nq7Byh4AaABAg,2,tNIpEZLv_eg,0,2,2020-01-16T11:42:12Z,"They are the vectors of the whole layer. For each z, four parameters are attached to it. Two learnable parameters, which are gamma and beta, and two unlearnable parameters, which are the mean and deviation. All the calculations are element-wise but the representations are all vectors.  Hopefully, my answer dissipates your doubts. If it is not clear for you, leave your question here.",2020-01-16T11:42:12Z
Ugz7BcukTvoD_Nq7Byh4AaABAg.8xbqZizzN8G9I1OO1do2v6,@vamsikrishnabhadragiri402,Ugz7BcukTvoD_Nq7Byh4AaABAg,2,tNIpEZLv_eg,0,0,2021-01-02T23:15:17Z,@@beizhou2488 Could you please explain why don&#39;t we want to make the mean and standard deviation come from the same distribution all the time. I mean why did we add beta and gamma to the normalized equation.,2021-01-02T23:15:17Z
Ugw1qqRGHFspskNvmzB4AaABAg,@adityavaikunt5498,,1,tNIpEZLv_eg,1,1,2019-06-06T09:16:13Z,"if we set gamma and beta to get a different mean and variance each time for a different layer, what is the purpose of batch normalization? or is the effect of batch normalization restricted to each layer individually?",2019-06-06T09:16:13Z
Ugw1qqRGHFspskNvmzB4AaABAg.8vpjUXFNxTd99CsXjZtP9w,@walidmaly3,Ugw1qqRGHFspskNvmzB4AaABAg,2,tNIpEZLv_eg,0,0,2020-05-28T17:36:35Z,They are trainable so you do not set them,2020-05-28T17:36:35Z
UgyxQWKpLVFOg_Nqftd4AaABAg,@TheBjjninja,,1,tNIpEZLv_eg,0,2,2019-04-28T17:15:31Z,I thought the purpose of batch normalization is a regularization technique for neural networks with the objective of reducing overfitting.   Perhaps it both increases performance also and addresses overfitting?,2019-04-28T17:15:31Z
UgxP-fV2he1DCEVgP1d4AaABAg,@sudhakar3115,,1,tNIpEZLv_eg,0,2,2019-03-03T07:19:38Z,"Thanks for uploading the concise, core idea centric along with implementational explanation of core elements needed to build an efficient neural network.",2019-03-03T07:19:38Z
UgxByQbUcjze_qztSQZ4AaABAg,@jamesearle6932,,1,tNIpEZLv_eg,1,1,2019-02-18T18:55:39Z,"What is z? <a href=""https://www.youtube.com/watch?v=tNIpEZLv_eg&amp;t=2m30s"">2:30</a>",2019-02-18T18:55:39Z
UgxByQbUcjze_qztSQZ4AaABAg.8rVfwxAPtOS8rYII-CHpOl,@MaXXiVeEP,UgxByQbUcjze_qztSQZ4AaABAg,2,tNIpEZLv_eg,0,8,2019-02-19T19:17:55Z,It is the value of the neuron before applying the activation function. So a = h(z) for some activation function h. z itself is the dot product of the weights w with the inputs to the neuron.,2019-02-19T19:17:55Z
UgwndZBJ-wfSHgG_uRx4AaABAg,@banipreetsinghraheja8529,,1,tNIpEZLv_eg,0,1,2018-06-07T13:52:32Z,"&quot;The effect of gamma and beta is to set the mean to whatever you want it to be&quot;, you forgot to mention variance.  Should&#39;ve been that the effect of gamma and beta is to set the mean and variance to whatever you want it to be.",2018-06-07T13:52:32Z
Ugyep8pbpKGrYKbe1rd4AaABAg,@IgorAherne,,1,tNIpEZLv_eg,1,82,2017-12-29T00:51:49Z,"Professor is very sneaky and uses the TV series approach. Every time I am saying &quot;well, one more video and that&#39;s it&quot;, but in the end we have &quot;John kills Bob&quot; and a big &quot;to be continued sign&quot;. So here I am, sitting for 2 hours straight, watching about another important technique that happens to exist, mentioned at the end of each video :D Thanks!",2017-12-29T00:51:49Z
Ugyep8pbpKGrYKbe1rd4AaABAg.8aj_Dht34KK8gjlglYDg-l,@md.rijoanrabbi99,Ugyep8pbpKGrYKbe1rd4AaABAg,2,tNIpEZLv_eg,0,1,2018-05-27T05:49:08Z,ha ha. i like your comment......how many ways he has!!,2018-05-27T05:49:08Z
Ugz_AZTqanoVzO3t-4d4AaABAg,@abhishekrao2120,,1,tNIpEZLv_eg,6,15,2017-10-16T03:45:29Z,What is lowercase m here? Is it number of hidden units in layer l or the number of samples in mini batch?,2017-10-16T03:45:29Z
Ugz_AZTqanoVzO3t-4d4AaABAg.8YlLGrdo9gV8ZfSFiiiRmH,@realTCG2,Ugz_AZTqanoVzO3t-4d4AaABAg,2,tNIpEZLv_eg,0,5,2017-11-07T17:22:26Z,It is the batch size,2017-11-07T17:22:26Z
Ugz_AZTqanoVzO3t-4d4AaABAg.8YlLGrdo9gV8_45P2436YC,@kyungtaelim4412,Ugz_AZTqanoVzO3t-4d4AaABAg,2,tNIpEZLv_eg,0,5,2017-11-17T16:22:59Z,"Normally, It is the number of training data = batch size here.",2017-11-17T16:22:59Z
Ugz_AZTqanoVzO3t-4d4AaABAg.8YlLGrdo9gV8_5_E4WpQgw,@abhishekrao2120,Ugz_AZTqanoVzO3t-4d4AaABAg,2,tNIpEZLv_eg,0,1,2017-11-18T06:11:36Z,Thank you,2017-11-18T06:11:36Z
Ugz_AZTqanoVzO3t-4d4AaABAg.8YlLGrdo9gV8_kYIRF2Zu8,@eason_longleilei,Ugz_AZTqanoVzO3t-4d4AaABAg,2,tNIpEZLv_eg,0,1,2017-12-04T13:22:50Z,it&#39;s the samples numbers,2017-12-04T13:22:50Z
Ugz_AZTqanoVzO3t-4d4AaABAg.8YlLGrdo9gV8kSoHRYKMeq,@claudiocimarelli3900,Ugz_AZTqanoVzO3t-4d4AaABAg,2,tNIpEZLv_eg,0,7,2018-08-27T16:31:00Z,"it is so confusing how he explains this detail because he surely means that (i) is the ith neuron of n in layer [l]. Clearly (and is a rare case ) he made some sort of mistake, and in fact, in a subsequent video, he talks about (i) as an example in a batch and not as a neuron.",2018-08-27T16:31:00Z
Ugxp_TIp0JCT7n6xX9t4AaABAg,@Jirayu.Kaewprateep,,1,em6dfRxYkYU,0,0,2023-04-22T10:06:08Z,"üì∫üí¨ By considering only B-beta applying batch normalize layer into the networks, values change with specific ratios to preserve the relationship. üì∫üí¨ Try to make it explained.<br>üß∏üí¨ ( 1 ) Do you mean that B-beta and A-gamma have a linear relationship each time a new value update‚Åâ<br>üë§üí¨ Yes, it has we can see from the graphical node ratios update.<br>üêëüí¨ ( 2 ) When it has a linear relationship means you can estimate the effects of the input on the output. Can we add the Dropout layer after BatchNormalize and the Dense layer‚Åâ<br>üë§üí¨ Yes, does it provide a better effect when exponential input with decimal‚Åâ<br>üêêüí¨ ( 3 ) In some cases the value input is much different ( not a picture image or decimal number ) however, mean and variances are not direct effects by the input. <br>üêêüí¨Can we calculate the effect only on the significant nodes? ‚Åâ<br>üë§üí¨ Yes, that is TF2 option graph mode‚Åâ",2023-04-22T10:06:08Z
UgxkMQlgOyZ1kHEYROl4AaABAg,@RH-mk3rp,,1,em6dfRxYkYU,0,0,2023-01-02T07:25:15Z,"Ah, if only Andrew would show the partial derivative derivations for loss gradients w.r.t. gamma, beta, and inputs. No problem though since the paper already shows that. For me I&#39;d like to see those steps and the dimensions of the gradients.",2023-01-02T07:25:15Z
UgyjY7HE2TdtlYEYGG54AaABAg,@ruscul7155,,1,em6dfRxYkYU,0,0,2022-07-02T01:42:48Z,"Sir. Do you have to do ‚Äúbatch normalization‚Äù to the output layer? In your diagram you didnt put that red line but you put beta[l], gamma[l] and w[l] implying output layer has normalization too. But i just want to clarify",2022-07-02T01:42:48Z
UgyBoAjamp-CSAdQUQZ4AaABAg,@gz6947,,1,em6dfRxYkYU,1,0,2021-03-09T03:25:22Z,Didnt explain what a &quot;batch&quot; contains. Is it a batch of neurons or a batch of training examples?,2021-03-09T03:25:22Z
UgyBoAjamp-CSAdQUQZ4AaABAg.9KeCfXkWqab9NvuhrzwqFC,@osiris1102,UgyBoAjamp-CSAdQUQZ4AaABAg,2,em6dfRxYkYU,0,0,2021-05-29T14:00:10Z,Batch of training examples. Watch his previous videos.,2021-05-29T14:00:10Z
UgxT4FjePlr8BruQm4t4AaABAg,@ummeammarah70,,1,em6dfRxYkYU,0,0,2021-03-07T07:33:40Z,How can we compute derivative of beta and gamma?,2021-03-07T07:33:40Z
Ugx3bThH2hUBKk836pZ4AaABAg,@sandipansarkar9211,,1,em6dfRxYkYU,1,1,2020-12-19T15:25:09Z,Great explaantion.Need to make notes,2020-12-19T15:25:09Z
Ugx3bThH2hUBKk836pZ4AaABAg.9HSVSTDSGfB9u99rTPu1Ra,@ermano5586,Ugx3bThH2hUBKk836pZ4AaABAg,2,em6dfRxYkYU,0,0,2023-09-02T08:06:39Z,I am making notes,2023-09-02T08:06:39Z
UgxNdLOf_ip9oHMBRoh4AaABAg,@MrBreadfan17,,1,em6dfRxYkYU,0,1,2020-08-23T03:17:10Z,"I love his  explanations but i hope these videos get a remake with clearer symbols and formulas , that would make it much easier",2020-08-23T03:17:10Z
UgzfWcZFb4mkoEaCkIx4AaABAg,@depizixuri58,,1,em6dfRxYkYU,1,0,2020-06-28T22:12:16Z,"This makes nonsense.<br>If the Z are averaged to zero, then when they are summed before the activation, they sum to zero.<br>Z_i=(z_i - average(z_n)) /stdev(z_n)<br>.<br>Sum(Z_n)=0<br>So Sum(Z_n)*gamma+beta = beta<br>.<br>This eliminates the effects of the weights. The output is always beta, no matter what the weights are.",2020-06-28T22:12:55Z
UgzfWcZFb4mkoEaCkIx4AaABAg.9ATBj0K_POE9AXjdHQf6dn,@chufankong639,UgzfWcZFb4mkoEaCkIx4AaABAg,2,em6dfRxYkYU,0,0,2020-06-30T16:34:17Z,Gamma and beta are supposed to be applied to each individual z not the sum. Any particular reason you wanna sum z up?,2020-06-30T16:34:17Z
UgznOr9xhEUUA3tuiWd4AaABAg,@uniquetobin4real,,1,em6dfRxYkYU,0,0,2020-05-26T10:23:09Z,Is he referring to the layer or neurons,2020-05-26T10:23:09Z
UgzBYffYOwzWGIDeLgt4AaABAg,@yingyuxia6972,,1,em6dfRxYkYU,0,20,2020-03-13T15:59:23Z,"Thanks for making this free for all to learn, progressing AI forward!",2020-03-13T15:59:23Z
UgwhmZbguPM7r4bSWc94AaABAg,@ankurnath695,,1,em6dfRxYkYU,0,0,2020-02-09T21:53:20Z,Thank you!,2020-02-09T21:53:20Z
UgzkugolbefLFuS5POd4AaABAg,@skytree278,,1,em6dfRxYkYU,0,0,2019-08-22T05:00:33Z,Thank you!,2019-08-22T05:00:33Z
UgyPbAwEosXVo5mtsNR4AaABAg,@thereclaimer3634,,1,em6dfRxYkYU,0,5,2019-07-29T10:28:38Z,Would it not be better to apply Batch Normalization after the activation when using ReLU since ReLU would just be zero for a certain part of the activations anyway (depending on the shift parameter)?,2019-07-29T10:28:38Z
UgzIxC7R70TWtf6xBSt4AaABAg,@AgrataShukla,,1,em6dfRxYkYU,0,7,2019-05-23T07:45:59Z,"This is the most easiest explanation.I can easily understanding,Thanks Ng sir",2019-05-23T07:45:59Z
UgzeZAg9J2jONkfCd3R4AaABAg,@SoumilShah,,1,em6dfRxYkYU,1,0,2019-03-09T23:43:37Z,what should be initial value of beta and gamma thanks wonderful lecture please if you can tell me beta and gamma initialized to,2019-03-09T23:43:37Z
UgzeZAg9J2jONkfCd3R4AaABAg.8sH7-ixIIdI8vMf5qzNS0G,@k.seangtan6070,UgzeZAg9J2jONkfCd3R4AaABAg,2,em6dfRxYkYU,0,0,2019-05-25T17:00:40Z,The source code in tensorflow mention that zero for beta and 1 for gamma,2019-05-25T17:00:40Z
UgznaFxieiY45flalJd4AaABAg,@bluemarsss,,1,em6dfRxYkYU,1,1,2018-11-27T01:38:03Z,Why do we compute new means and variances for each batch? Why not combine what we learn about the mean and variances of each batch in order to best estimate the &quot;true&quot; mean and variance for the activations?,2018-11-27T01:38:03Z
UgznaFxieiY45flalJd4AaABAg.8o86DhgZzzT97alVGGWIM9,@pivasmilos,UgznaFxieiY45flalJd4AaABAg,2,em6dfRxYkYU,0,0,2020-04-18T16:33:18Z,"&quot;Batch norm is similar to dropout in the sense that it multiplies each hidden unit by a random value at each step of training. In this case, the random value is the standard deviation of all the hidden units in the minibatch. Because different examples are randomly chosen for inclusion in the minibatch at each step, the standard deviation randomly fluctuates.<br><br>Batch norm also subtracts a random value (the mean of the minibatch) from each hidden unit at each step.<br><br>Both of these sources of noise mean that every layer has to learn to be robust to a lot of variation in its input, just like with dropout.&quot;<br><a href=""https://www.quora.com/Is-there-a-theory-for-why-batch-normalization-has-a-regularizing-effect/answer/Ian-Goodfellow"">https://www.quora.com/Is-there-a-theory-for-why-batch-normalization-has-a-regularizing-effect/answer/Ian-Goodfellow</a>",2020-04-18T16:33:18Z
UgyKxNp_MoZuGHz778B4AaABAg,@veggiecroquettes1638,,1,em6dfRxYkYU,1,0,2018-11-08T05:09:53Z,"Then how do you initialize the coefficient of Z_norm,  &#39;Gamma&#39;, and bias term, &#39;Beta&#39;?<br>Is it okay to pick those up from the Normal distribution?",2018-11-08T05:09:53Z
UgyKxNp_MoZuGHz778B4AaABAg.8nNZMZ-KANJ8upjaC_pnrW,@kennys1881,UgyKxNp_MoZuGHz778B4AaABAg,2,em6dfRxYkYU,0,3,2019-05-12T12:45:44Z,original paper recommends; gamma =&gt; ones &amp; beta =&gt; zeros.,2019-05-12T12:45:44Z
Ugwdre81DRe8egXRddJ4AaABAg,@sau002,,1,em6dfRxYkYU,0,7,2018-07-10T11:11:53Z,A very difficult subject. Very well explained.,2018-07-10T11:11:53Z
UgyZNrvVbvb8JsW3eiZ4AaABAg,@banipreetsinghraheja8529,,1,em6dfRxYkYU,3,2,2018-06-07T14:52:57Z,"I did not understand why are you updating beta term with gradient descent? Does this have to do anything with the prediction of a trained NN? And if yes, then what are initial values that we give to beta?",2018-06-07T14:52:57Z
UgyZNrvVbvb8JsW3eiZ4AaABAg.8hC3fHxO0US8je6mMEjE_1,@sebastianrodriguezcolina634,UgyZNrvVbvb8JsW3eiZ4AaABAg,2,em6dfRxYkYU,0,3,2018-08-07T14:40:53Z,"make sure you watch the previous video, I bet it will be more clear",2018-08-07T14:40:53Z
UgyZNrvVbvb8JsW3eiZ4AaABAg.8hC3fHxO0US8kwP8vY9OlQ,@LL-yf9kp,UgyZNrvVbvb8JsW3eiZ4AaABAg,2,em6dfRxYkYU,0,0,2018-09-08T13:39:06Z,beta and gamma are learned on their side by the neural network (alternatively they could be choosen to be fixed) and are simply treated like the weights when it comes to updating by an iterative method (such as gradient descent).,2018-09-08T13:39:06Z
UgyZNrvVbvb8JsW3eiZ4AaABAg.8hC3fHxO0US8vMfCDVvq1A,@k.seangtan6070,UgyZNrvVbvb8JsW3eiZ4AaABAg,2,em6dfRxYkYU,0,0,2019-05-25T17:01:33Z,beta can be thought as bias in Neural Network actually,2019-05-25T17:01:33Z
UgzcJ6faxPQXerdUViV4AaABAg,@dexlee7277,,1,em6dfRxYkYU,0,5,2018-01-18T07:21:01Z,ËÆ≤ÁöÑÂ•ΩÔºÅ,2018-01-18T07:21:01Z
UgxFS1M_VX1X3BDYrjt4AaABAg,@gugaime,,1,nUUqwaxLnWs,0,0,2023-06-16T14:56:48Z,Amazing explanation,2023-06-16T14:56:48Z
Ugzy1eF3ID8fpK0Cf9t4AaABAg,@quishzhu,,1,nUUqwaxLnWs,0,0,2022-09-08T17:48:06Z,Ë∞¢Ë∞¢,2022-09-08T17:48:06Z
UgxBaR6u1U-UeK9LQN54AaABAg,@karanmilindacharya5325,,1,nUUqwaxLnWs,0,4,2022-02-22T02:18:34Z,This is gold. These videos should be archived in &quot;AI museums&quot;. Normalises such dense concepts easily.(No pun intended),2022-02-22T02:18:34Z
UgyRf5sV5SKMQZr2OzJ4AaABAg,@wajidhassanmoosa362,,1,nUUqwaxLnWs,0,0,2021-12-11T03:50:46Z,Beautifully Explained,2021-12-11T03:50:46Z
Ugyw_aMNtteqHiDF9OR4AaABAg,@siarez,,1,nUUqwaxLnWs,1,6,2021-12-09T19:12:15Z,The &quot;covariant shift&quot; explanation has been falsified as an explanation for why BatchNorm works. If you are interested check out the paper &quot;How does batch normalization help optimization?&quot;,2021-12-09T19:12:15Z
Ugyw_aMNtteqHiDF9OR4AaABAg.9Vk-dQ9F3tu9kPI3nCZpsG,@dimitrisspiridonidis3284,Ugyw_aMNtteqHiDF9OR4AaABAg,2,nUUqwaxLnWs,0,0,2023-01-03T01:12:17Z,God bless you,2023-01-03T01:12:17Z
UgwXpUEsCdGVRT1k1m14AaABAg,@oliviergraffeuille9795,,1,nUUqwaxLnWs,0,1,2021-12-07T01:43:10Z,"According to <a href=""https://www.youtube.com/watch?v=DtEq44FTPM4"">https://www.youtube.com/watch?v=DtEq44FTPM4</a> , the covariate shift explanation (which was proposed by the original batch norm paper) has since been debunked by more recent papers. I don&#39;t know much about this though, if someone else would like to elaborate.",2021-12-07T01:43:33Z
UgxlZ6eedsudpeGL68t4AaABAg,@mariusmic6573,,1,nUUqwaxLnWs,0,0,2021-11-17T14:59:16Z,What is &#39;z&#39; in this video?,2021-11-17T14:59:16Z
Ugyfkg12I5ifA3iAIKR4AaABAg,@qorbanimaq,,1,nUUqwaxLnWs,0,0,2021-09-06T10:08:50Z,This video is just pure gold!,2021-09-06T10:08:50Z
Ugzpc28Cl1aohw8c-It4AaABAg,@randomforrest9251,,1,nUUqwaxLnWs,0,2,2021-06-11T09:44:26Z,This guy makes it look so easy... one has to love him,2021-06-11T09:44:26Z
UgxV16uHkPyR78lA-nJ4AaABAg,@s25412,,1,nUUqwaxLnWs,2,0,2021-05-31T03:29:29Z,"<a href=""https://www.youtube.com/watch?v=nUUqwaxLnWs&amp;t=7m55s"">7:55</a> why don&#39;t we use the mean and variance of the entire trg set instead of just those of a mini-batch? Wouldn&#39;t this reduce noise further (similar to using larger mini-batch size)? Unless we want those noise to seek out regularizing effect?",2021-05-31T03:39:38Z
UgxV16uHkPyR78lA-nJ4AaABAg.9Nzw7Ou4a8z9QwknELr-8y,@lupsik1,UgxV16uHkPyR78lA-nJ4AaABAg,2,nUUqwaxLnWs,0,2,2021-08-12T11:26:56Z,"Larger batch sizes are detrimental, like Yann Lecun once said<br> &quot;training with large minibatches is bad for your health.<br>More importantly, it&#39;s bad for your test error.<br>Friends dont let friends use minibatches larger than 32.&quot;<br><br>as far as i understand it, with bigger batches you get stuck in narrower local optima while the noisier sets helps you generalize better and get pushed out of those local optima.<br><br>Theres still lots of argument about this tho in some cases with very noisy data like predicting stock prices.",2021-08-12T11:27:49Z
UgxV16uHkPyR78lA-nJ4AaABAg.9Nzw7Ou4a8z9QxAu1cV3eq,@s25412,UgxV16uHkPyR78lA-nJ4AaABAg,2,nUUqwaxLnWs,0,0,2021-08-12T15:23:48Z,@@lupsik1 great response!,2021-08-12T15:23:48Z
UgwCbOyd2-txKJze5Y94AaABAg,@azizabdraimov180,,1,nUUqwaxLnWs,0,1,2021-04-12T11:10:58Z,"The original paper where the batch normalization technique was introduced (by Sergey Ioffe, Christian Szegedy) says that removing dropout speeds up training, without increasing overfitting and there also recommendations not to use drop out together with batch normalization since it adds noise to stats calculations (mean and variance)...so should we really use DO with BN?",2021-04-12T11:10:58Z
UgyoqHniRmivXIHH01t4AaABAg,@XX-vu5jo,,1,nUUqwaxLnWs,0,0,2021-03-23T12:51:34Z,Keras people needs to watch this video!,2021-03-23T12:51:34Z
UgwfwHPlgpo9Fg137Bx4AaABAg,@sandipansarkar9211,,1,nUUqwaxLnWs,1,1,2020-12-19T14:59:56Z,great xplnatoion,2020-12-19T14:59:56Z
UgwfwHPlgpo9Fg137Bx4AaABAg.9HSSZjCelKU9u9gnw5qoYj,@ermano5586,UgwfwHPlgpo9Fg137Bx4AaABAg,2,nUUqwaxLnWs,0,0,2023-09-02T13:03:16Z,I am watching it again,2023-09-02T13:03:16Z
UgzmMb0rmpOuC5nGWUh4AaABAg,@tayyabahayat6898,,1,nUUqwaxLnWs,0,0,2020-08-21T14:37:14Z,"Best video on RseNet Architecture. Click on the link and learn ResNet in easiest wording.<br><a href=""https://www.youtube.com/watch?v=fvrIqFCUWV4&amp;t=44s"">https://www.youtube.com/watch?v=fvrIqFCUWV4&amp;t=44s</a>",2020-08-21T14:37:14Z
Ugw1EKODrmdv9pXGDOZ4AaABAg,@amartyahatua,,1,nUUqwaxLnWs,0,1,2020-08-14T00:00:27Z,Best explanation of batch norm,2020-08-14T00:00:27Z
Ugxk4CdZKtq2RrXhMXZ4AaABAg,@yuchenzhao6411,,1,nUUqwaxLnWs,0,1,2020-06-14T05:20:18Z,"Since gamma and beta are parameters will be updated, how can mean and variance remain unchanged?",2020-06-14T05:20:18Z
Ugw7q6HLbDQzXyYKArZ4AaABAg,@youknowhoiamhehe,,1,nUUqwaxLnWs,0,0,2020-05-13T21:32:34Z,Is he the GOD?,2020-05-13T21:32:34Z
Ugx_2cOa92gINtcQX4h4AaABAg,@arvindsuresh86,,1,nUUqwaxLnWs,0,1,2020-05-01T05:55:57Z,"Wow, great explanation! Thanks!",2020-05-01T05:55:57Z
UgxQ5S9fuvlw7DIyKjt4AaABAg,@muntoonxt,,1,nUUqwaxLnWs,1,14,2020-03-21T11:13:03Z,"Is this video still accurate? This paper claims that BatchNorm does <i>not</i> reduce Internal Covariate Shift: <a href=""https://arxiv.org/abs/1805.11604"">https://arxiv.org/abs/1805.11604</a>",2020-03-21T11:14:12Z
UgxQ5S9fuvlw7DIyKjt4AaABAg.96T5a6q1LC39AXPQExvdQm,@ooodragon94,UgxQ5S9fuvlw7DIyKjt4AaABAg,2,nUUqwaxLnWs,0,0,2020-06-30T13:28:52Z,"no, at least the time this video was taken, ICS was what the BN authors invoked for the reason of better training",2020-06-30T13:28:52Z
Ugxx1DKZhvRJC3QEdAl4AaABAg,@pemfiri,,1,nUUqwaxLnWs,2,1,2020-02-01T08:53:44Z,don&#39;t the activation function such as sigmoid in each node already normalize the outputs from  neurons for the most part ?,2020-02-01T08:53:44Z
Ugxx1DKZhvRJC3QEdAl4AaABAg.94Ufgnz_v2y9KxRkj0v-XB,@bharathtejchinimilli320,Ugxx1DKZhvRJC3QEdAl4AaABAg,2,nUUqwaxLnWs,0,0,2021-03-16T14:42:42Z,but the outputs are not zero centered,2021-03-16T14:42:42Z
Ugxx1DKZhvRJC3QEdAl4AaABAg.94Ufgnz_v2y9KxRzwu6FW-,@bharathtejchinimilli320,Ugxx1DKZhvRJC3QEdAl4AaABAg,2,nUUqwaxLnWs,0,0,2021-03-16T14:44:47Z,"generally, sigmoids are not used because of saturation and not been zero centre outputs. instead, ReLU are used",2021-03-16T14:44:47Z
UgzrIsd5xC3ZOH295Op4AaABAg,@lakshaithani268,,1,nUUqwaxLnWs,0,0,2019-10-22T18:56:22Z,Great explanation,2019-10-22T18:56:22Z
UgxIfFB2Ytf0UqMA6QJ4AaABAg,@maplex2656,,1,nUUqwaxLnWs,0,13,2019-10-19T08:38:21Z,"When the previous layer is covered, all things are clear. Brilliant explanation. Batch normalization works similarly the way input standardization works.",2019-10-19T08:38:21Z
UgwfssRTmxWRi3408l14AaABAg,@nikhilrana8800,,1,nUUqwaxLnWs,0,0,2019-10-09T16:51:05Z,I am not able to grab the batch norm working. Pls help me...,2019-10-09T16:51:05Z
UgxJXIPOxCbe1TaYE5Z4AaABAg,@tianyuez,,1,nUUqwaxLnWs,0,2,2019-09-25T06:58:14Z,Andrew Yang is really good at math,2019-09-25T06:58:14Z
UgxAzVtRu9FDWvW-9gJ4AaABAg,@skytree278,,1,nUUqwaxLnWs,0,0,2019-08-22T03:55:23Z,Thank you!,2019-08-22T03:55:23Z
UgwRebnIsf1AhUO8pU14AaABAg,@digitalghosts4599,,1,nUUqwaxLnWs,0,25,2019-07-29T18:30:32Z,"Wow this is the best explanation I&#39;ve seen so far! I really like Andrew Ng, he has an amazing talent for explaining even the most complicated things in a simple way and when he has to use mathematics to explain some concepts he does it in such a brilliant way that they become even simpler to understand and not more complicated as with some tutors",2019-07-29T18:30:32Z
Ugxv61vel0YBplQTjfZ4AaABAg,@sudharsaneaswaran2516,,1,nUUqwaxLnWs,2,0,2019-06-25T12:38:59Z,what does coloured image got to do with the location of data point in graph?,2019-06-25T12:38:59Z
Ugxv61vel0YBplQTjfZ4AaABAg.8wb0nF5vz4d8wfpJpEs893,@amitkharel1168,Ugxv61vel0YBplQTjfZ4AaABAg,2,nUUqwaxLnWs,0,0,2019-06-27T09:26:10Z,pixel values,2019-06-27T09:26:10Z
Ugxv61vel0YBplQTjfZ4AaABAg.8wb0nF5vz4d8yz1FJD_2Ja,@dianadrives4519,Ugxv61vel0YBplQTjfZ4AaABAg,2,nUUqwaxLnWs,0,0,2019-08-23T13:27:30Z,"That is just another way to show the difference in distribution of training and testing data. So in images the distribution difference is shown by one set having black cats another having non-black cats. While in the graph, the distribution difference is shown by the differences in position of the positive and negative data points. In short, these are two different examples hightlighting a single issue i.e covariance shift.",2019-08-23T13:27:30Z
UgwVLDbjOZyk2rxeTs54AaABAg,@anynamecanbeuse,,1,nUUqwaxLnWs,2,1,2019-05-11T10:13:28Z,"I&#39;m confused. Is that normalizing all neurons within each layer, or normalizing all activations computed from a mini-batch of one neuron ?",2019-05-11T10:13:28Z
UgwVLDbjOZyk2rxeTs54AaABAg.8umtN8UfweN8x_1yH_nkQK,@yueying9083,UgwVLDbjOZyk2rxeTs54AaABAg,2,nUUqwaxLnWs,0,0,2019-07-19T14:42:08Z,Á¨¨‰∫åÁßç,2019-07-19T14:42:08Z
UgwVLDbjOZyk2rxeTs54AaABAg.8umtN8UfweN90RAawC8JI1,@JohnFunnyMIH,UgwVLDbjOZyk2rxeTs54AaABAg,2,nUUqwaxLnWs,0,2,2019-10-23T14:10:00Z,"To be precise, it&#39;s neither both, though closer to the second. When training your network, you normalize all Z[l] - scalars corresponding to each neuron of l-th layer. Z[l] = W[l] * A[l-1]. Where W[l] is current layer weights matrix, and A[l-1] is previous layer activations.¬†<br>So, you normalize numbers which are not yet activations of current layer, but calculated from weights of current layer and previous layer activations.",2019-10-23T14:12:17Z
UgyLznv-SeqBHbl94XR4AaABAg,@AlexanderWhillas,,1,nUUqwaxLnWs,0,4,2019-05-08T03:01:40Z,"Covariabt shift is the <i>wrong</i> explanation for why BatchNorm works. &quot;Instead ... a more fundamental impact of BatchNorm on the training process [is] it makes the optimization landscape significantly smoother&quot; see <a href=""http://papers.nips.cc/paper/7515-how-does-batch-normalization-help-optimization"">http://papers.nips.cc/paper/7515-how-does-batch-normalization-help-optimization</a>",2019-05-08T03:01:59Z
UgyB_1wQeyN_w5TfJP94AaABAg,@leeminize,,1,nUUqwaxLnWs,0,0,2019-01-21T13:49:06Z,"Plz refer to <a href=""https://arxiv.org/abs/1805.11604"">https://arxiv.org/abs/1805.11604</a>",2019-01-21T13:49:06Z
UgxrAJyDONEMs6PSr-x4AaABAg,@EranM,,1,nUUqwaxLnWs,0,0,2018-12-27T08:18:00Z,Ingenious!,2018-12-27T08:18:00Z
UgwXq2Mm5hREr6jiXBJ4AaABAg,@best_Vinyl_CollectorinShenZhen,,1,nUUqwaxLnWs,1,0,2018-11-20T22:31:04Z,"If the mini-batch size is only 1, is BN still working?",2018-11-20T22:31:04Z
UgwXq2Mm5hREr6jiXBJ4AaABAg.8ntK2z2djd78rAhTflktUY,@karthik-ex4dm,UgwXq2Mm5hREr6jiXBJ4AaABAg,2,nUUqwaxLnWs,0,1,2019-02-10T15:24:56Z,minibatch with the size of 1 is not a mini batch. Its using each point in the data seperately. you cannot batch norm with size=1,2019-02-10T15:24:56Z
UgxDRyIBEm8sR49uK1V4AaABAg,@holgip6126,,1,nUUqwaxLnWs,0,11,2018-11-05T22:32:55Z,like this guy - has calm voice / patience,2018-11-05T22:32:55Z
UgwtNvcYLhJnUI_9zRR4AaABAg,@bgenchel1,,1,nUUqwaxLnWs,2,16,2018-07-27T07:47:21Z,"&quot;don&#39;t use it for regularization&quot; - just use it all the time for general good practice, or are there times when I shouldn&#39;t use it?",2018-07-27T07:47:21Z
UgwtNvcYLhJnUI_9zRR4AaABAg.8jC2hx_7Hus9DAdNelI4ey,@first-thoughtgiver-of-will2456,UgwtNvcYLhJnUI_9zRR4AaABAg,2,nUUqwaxLnWs,0,0,2020-09-04T06:51:14Z,"I think problems may arise if you don&#39;t have all of your training data ready and are looking to perform some transfer learning (training on new data) in the future since this is very domain dependent, as hinted at by the minibatch size-regularization effect but also and more importantly by the batch norm hyperparameters. I would always try to implement this. It seems ironic that it generalizes well but is constrained by the prescribed covariance from the training data.",2020-09-04T07:01:15Z
UgwtNvcYLhJnUI_9zRR4AaABAg.8jC2hx_7Hus9Q7nWsbXL0n,@wtf1570,UgwtNvcYLhJnUI_9zRR4AaABAg,2,nUUqwaxLnWs,0,0,2021-07-23T07:10:16Z,"In some regression problems, it hurts the absolute value which might be critical.",2021-07-23T07:10:16Z
UgzLwVo1Ule7YEJNMsZ4AaABAg,@aamir122a,,1,nUUqwaxLnWs,0,30,2018-06-23T01:59:37Z,"Great work, you have the natural talent to make difficult topics easily learnable",2018-06-23T01:59:37Z
UgyA4JRPXTxzicJ6V8p4AaABAg,@banipreetsinghraheja8529,,1,nUUqwaxLnWs,5,5,2018-06-12T10:44:21Z,"You said that Batch Norm limits the change in values of the 3rd layer ( or more generally, any deeper layer) due to parameters of earlier layers, however, when you are performing Gradient Descent, the values of the new parameters ( parameters due to Batch Norm gamma and beta ), are also being learnt, and are changing with the help of learning rate and henceforth, the mean and variance of earlier layers are changing and are not limited to 0 and 1 respectively ( or more generally whatever you set it to ), so, I am not able to intuite this fixing of mean and variance of the parameters of earlier layer to prevent covariate shift. Can anyone help me out with this?",2018-06-12T10:44:21Z
UgxyQXWehqUDLfsAVsp4AaABAg,@SuperMaker.M,,1,5qefnAek8OA,0,0,2023-09-10T10:22:22Z,you&#39;re the best!,2023-09-10T10:22:22Z
Ugxdf_3iYH1Qr6npxO14AaABAg,@aiymzhanbaitureyeva5296,,1,5qefnAek8OA,0,2,2022-05-13T08:53:47Z,"If I understand correctly, we can optionally take and run all the training data through the last network and get the desired mean mu and sigma squared for each layer, but this will take time. <br>That is why in practice it is easier to take new values ‚Äã‚Äãof mu and sigma squared on each t (on each mini-batch) and step by step add to the exponentially weighted average formula and finally get even a rough but acceptable average of mu and sigma squared. Apparently, in practice, this result is no worse than if we took the average mu and sigma squared over the entire training set.<br>Also, gamma and beta are trained on all batches (the entire training set). That&#39;s why we can achieve a slight regularization effect.<br>I wrote these moments that were not entirely clear to me initially and required some time to figure it out. I hope this comment will speed up the process for someone if you are as confused at the beginning as I am. Good luck!",2022-05-14T12:04:07Z
Ugz0tSZUDbP4xNtE2A54AaABAg,@OmarHisham1,,1,5qefnAek8OA,1,2,2022-04-11T23:20:32Z,Challenge: Do 5 push-ups every time  Prof. Andrew says &quot;mini-batch&quot; or &quot;exponentially-weighted average&quot;,2022-04-11T23:20:32Z
Ugz0tSZUDbP4xNtE2A54AaABAg.9_h9pTNKHAy9u9h_5SIoLr,@ermano5586,Ugz0tSZUDbP4xNtE2A54AaABAg,2,5qefnAek8OA,0,0,2023-09-02T13:09:59Z,Challenge accepted,2023-09-02T13:09:59Z
Ugx-Rx-S4VBzSnIXLud4AaABAg,@48956l,,1,5qefnAek8OA,0,1,2021-09-09T13:47:56Z,I love your videos but your audio mastering is hurting my ears. There is a very strange and uncomfortable high pitched noise in your videos....,2021-09-09T13:47:56Z
UgyhSMDFFp8XlAk1RI94AaABAg,@venkateshwarlusonnathi4137,,1,5qefnAek8OA,0,2,2021-04-11T05:28:59Z,Very nice explanation. One question though. Why do we need to take exponential verage of Mu and sigmas squares? The batches are generally randomly formed. There for there is no sequential element to the series. Is it not sufficient to take a simple mean of the two as batch size is constant.,2021-04-11T05:28:59Z
Ugxk42wzsNs_tu6hgjF4AaABAg,@yonggangxu9871,,1,5qefnAek8OA,0,1,2021-01-26T20:41:18Z,"Great lecture! One suggestion/question... As \gamma \in R^m, is it better to replace \gamma with gamma^{(i)} in the last equation at <a href=""https://www.youtube.com/watch?v=5qefnAek8OA&amp;t=0m40s"">0:40</a>? Same for \beta. With the current notation, it looks as if the exact same affine transformation were applied to all components.",2021-01-26T20:41:18Z
Ugz7lKKJW1Og5wPMTAd4AaABAg,@sandipansarkar9211,,1,5qefnAek8OA,1,0,2020-12-19T16:26:31Z,Gret explanation.Need to mke notes,2020-12-19T16:26:31Z
Ugz7lKKJW1Og5wPMTAd4AaABAg.9HSbTv4QSx_9u9hg2FGb0T,@ermano5586,Ugz7lKKJW1Og5wPMTAd4AaABAg,2,5qefnAek8OA,0,0,2023-09-02T13:10:56Z,I am making notes,2023-09-02T13:10:56Z
UgzWwNaq71M1oNcZUwV4AaABAg,@SuilujChannel,,1,5qefnAek8OA,0,0,2020-12-03T10:09:13Z,why is this exponentially weighted average not used in the training phase too? in the training we only use data of the current mini-batch to calculate the mean and variance for that batch. whouldn&#39;t it be clever to use the exponentially weighted average for that too?,2020-12-03T10:11:53Z
Ugw6krbMANMyjpnQ43N4AaABAg,@vnpikachu4627,,1,5qefnAek8OA,1,0,2020-09-04T12:48:18Z,"Each mini-batch will have different values of beta, gama, so how do we set the values of beta, gama at test time?",2020-09-04T12:48:18Z
Ugw6krbMANMyjpnQ43N4AaABAg.9DBHEtweyty9J-yLDcVvy9,@Mrityujha,Ugw6krbMANMyjpnQ43N4AaABAg,2,5qefnAek8OA,0,0,2021-01-27T06:31:07Z,"Beta, gamma are learned/trained during the training itself. They remain as it is while inference time.",2021-01-27T06:31:07Z
UgzgA5LfdlXCNF4Kz_94AaABAg,@user-jc4qs9xh9n,,1,5qefnAek8OA,0,7,2020-05-05T05:43:25Z,He&#39;s a god.,2020-05-05T05:43:25Z
UgxFfzFKjpNJfZ5dbg14AaABAg,@curiousSloth92,,1,5qefnAek8OA,4,2,2020-04-01T17:43:18Z,Why an EXPONENTIAL moving average? Does that mean that more recently calculated means and variance are more important?,2020-04-01T17:43:18Z
UgxFfzFKjpNJfZ5dbg14AaABAg.96v7-3aoBxF97au5DKn1-x,@pivasmilos,UgxFfzFKjpNJfZ5dbg14AaABAg,2,5qefnAek8OA,0,0,2020-04-18T17:48:24Z,"It makes sense. The network might have completely changed since the first epoch, so the means and variances from that time don&#39;t matter at all compared to the more recent ones.<br>I&#39;m sure there are papers filled with estimation theory that give better explanations.",2020-04-18T17:48:24Z
UgxFfzFKjpNJfZ5dbg14AaABAg.96v7-3aoBxF97bjlWDH4TC,@curiousSloth92,UgxFfzFKjpNJfZ5dbg14AaABAg,2,5qefnAek8OA,0,0,2020-04-19T01:37:25Z,"Milo≈° Piva≈° ok,thank you",2020-04-19T01:37:25Z
UgxFfzFKjpNJfZ5dbg14AaABAg.96v7-3aoBxF97ffqk5OD_Z,@yashas9974,UgxFfzFKjpNJfZ5dbg14AaABAg,2,5qefnAek8OA,0,0,2020-04-20T14:20:09Z,@@pivasmilos but the mean and variances of a mini-batch do not change unless you are randomizing the dataset after every epoch. I feel like using an exponential weighted average gives better accuracy for the mini-batches that appeared later in the last epoch.,2020-04-20T14:20:09Z
UgxFfzFKjpNJfZ5dbg14AaABAg.96v7-3aoBxF97qer0VBrUq,@pivasmilos,UgxFfzFKjpNJfZ5dbg14AaABAg,2,5qefnAek8OA,0,2,2020-04-24T20:43:06Z,"@@yashas9974 <br>For the same input, the activations change with every gradient descent step.<br><br>If they change, how could their moments not change?",2020-04-24T20:43:06Z
UgyDYN15LNRGFj2FAy94AaABAg,@koeficientas,,1,5qefnAek8OA,0,0,2019-02-03T17:37:25Z,"OK, at test time we use mean and variance that was estimated as mean(mean) and mean(variance). What with gamma and beta. They are separately trained for each mini batch or we track and update single gamma and beta for each batch norm layer?",2019-02-03T17:38:28Z
Ugyy2q5tyti2dzcCC_B4AaABAg,@u9722206,,1,5qefnAek8OA,1,12,2018-11-29T00:58:36Z,"To answer some questions below : Gamma and beta is optimized given the input to batch norm layer is normalized during training. That&#39;s why we can&#39;t skip normalization during test time. Gamma and beta are estimates of shift and scaling over the whole training set, therefore we need to normalize input to batch norm layer assuming each mini-batch has the same mean and variance as the whole training set distribution. In reality, mini-batch has strong sampling bias especially if the sampling size is small relative to the training data.",2018-11-29T00:59:15Z
Ugyy2q5tyti2dzcCC_B4AaABAg.8oDBIY-hw1q9u-0-rBy70Z,@penpomvx9228,Ugyy2q5tyti2dzcCC_B4AaABAg,2,5qefnAek8OA,0,0,2023-08-29T09:28:09Z,Can we take the using of Gamma and beta as a way to compensate for the noises from the normalization?,2023-08-29T09:28:09Z
UgyzNRTXupbsGV4xN_94AaABAg,@t8m8r,,1,5qefnAek8OA,1,1,2018-08-31T23:23:52Z,"Why not use gamma and beta since they are the learned sigma and mu? Or, just skip the whole normalization thing during test time?",2018-08-31T23:23:52Z
UgyzNRTXupbsGV4xN_94AaABAg.8kcqhi_TIOA8n1uYiE3VQo,@bipulkalita5780,UgyzNRTXupbsGV4xN_94AaABAg,2,5qefnAek8OA,0,1,2018-10-30T19:20:29Z,"normalization steps are also neurons, skipping them means skipping their layer which will break the networks.",2018-10-30T19:20:29Z
UgypgHNDdP29sOzgvQx4AaABAg,@heejuneAhn,,1,5qefnAek8OA,3,0,2018-08-10T13:58:56Z,"Can you clearly explain why we have to multiply and add &quot;gamma&quot; and &quot;beta&quot; again, when we already accomplished the normalization.    In another word, I cannot see the reason &quot;Identify  transform&quot; which has mathematically nothing.",2018-08-10T13:58:56Z
UgypgHNDdP29sOzgvQx4AaABAg.8jllMilt6uD8kGYhNnXHN2,@parnianshahkar7797,UgypgHNDdP29sOzgvQx4AaABAg,2,5qefnAek8OA,0,1,2018-08-22T22:15:15Z,"in the previous video prof. mentioned that we need to change the variance some times in order to increase or decrease nonlinearity. Similarly, we may need to shift Z sometimes. So this formula(the one which contains beta and gamma) is very general.",2018-08-22T22:15:15Z
UgypgHNDdP29sOzgvQx4AaABAg.8jllMilt6uD8kX65w7YSO-,@ch40t1c1989,UgypgHNDdP29sOzgvQx4AaABAg,2,5qefnAek8OA,0,6,2018-08-29T08:32:25Z,"With the first normalization step you normalize all your z-values to 0 mean and variance 1. Well, what if you don&#39;t want all your z-values (i.e. the values that are subsequently fed into your chosen activation function (e.g. sigmoid, tanh, ReLu)) to be primarily between -1 and 1? For example, most z-values between -1 and 1 would result in only exploiting the mostly linear region of the sigmoid activation function (that is exactly the example Andrew mentioned in the previous video). So, the best choice is to let the network learn the most suitable distribution of z by letting it learn beta and gamma.",2018-08-29T08:33:32Z
UgypgHNDdP29sOzgvQx4AaABAg.8jllMilt6uD97ffz_kc-9u,@yashas9974,UgypgHNDdP29sOzgvQx4AaABAg,2,5qefnAek8OA,0,1,2020-04-20T14:21:21Z,Or even simpler: have gamma and beta so that the network can undo the normalization if that was the right thing to do.<br><br>Or even more simpler: so that the representational power of the network is not changed (because you can undo the normalization).,2020-04-20T14:21:21Z
UgzyCYc5z3ZWKh7wCYZ4AaABAg,@WillYuJenHuang,,1,5qefnAek8OA,1,2,2018-07-13T01:19:35Z,"Sorry, I may miss what Prof. Andrew Ng said. But what is the advantage to using the moving average mean and variance than its own mean and variance from each batch?",2018-07-13T01:19:35Z
UgzyCYc5z3ZWKh7wCYZ4AaABAg.8icJCafJTfq8p4dBw7xkNj,@itzmesujit,UgzyCYc5z3ZWKh7wCYZ4AaABAg,2,5qefnAek8OA,0,3,2018-12-20T13:49:20Z,"I think what he meant was, since you pass one input at a time during test and don&#39;t have any batch to take average or variance over, you could keep a running  mean and variance during the training and use that for each test input when you begin testing",2018-12-20T13:49:20Z
UgwOj0-mXvh7xbFqg7B4AaABAg,@alfcnz,,1,5qefnAek8OA,2,12,2018-06-28T19:33:59Z,The resolution is very very low. What&#39;s happened?,2018-06-28T19:33:59Z
UgwOj0-mXvh7xbFqg7B4AaABAg.8i2dX5LL0a89NCiFtUo7TB,@jimmiemunyi,UgwOj0-mXvh7xbFqg7B4AaABAg,2,5qefnAek8OA,0,0,2021-05-11T15:26:17Z,I love your videos Alfredo!,2021-05-11T15:26:17Z
UgwOj0-mXvh7xbFqg7B4AaABAg.8i2dX5LL0a89NClhftVNb0,@alfcnz,UgwOj0-mXvh7xbFqg7B4AaABAg,2,5qefnAek8OA,0,0,2021-05-11T15:56:26Z,@@jimmiemunyi thank you ü•∞ü•∞ü•∞,2021-05-11T15:56:26Z
Ugxi1JnyfV9DOByM9wR4AaABAg,@donm7906,,1,5qefnAek8OA,1,1,2018-05-12T20:41:39Z,"I think we should only consider this method when we have single test data at a time.<br><br>If you can divide test set into mini-batches, then don&#39;t worry about this.",2018-05-12T20:41:39Z
Ugxi1JnyfV9DOByM9wR4AaABAg.8g9juaCL1BW8kX6Z1ezHIt,@ch40t1c1989,Ugxi1JnyfV9DOByM9wR4AaABAg,2,5qefnAek8OA,0,0,2018-08-29T08:36:24Z,"True, but often you can use larger batch sizes when you do inference than when you do training since you don&#39;t need to store all the parameters for backprob in GPU memory. I assume If you have differently sized mini-batches for training and testing you should also do it as is proposed in this video...",2018-08-29T08:37:09Z
UgwFSWHMQWuBp4q9V0h4AaABAg,@alexanderfedintsev9570,,1,5qefnAek8OA,1,2,2018-02-28T15:46:35Z,Shouldn&#39;t you use unbiased variance estimate?,2018-02-28T15:46:35Z
UgwFSWHMQWuBp4q9V0h4AaABAg.8dDF6YH93Gt8jfxEAnMEG7,@wangtony3543,UgwFSWHMQWuBp4q9V0h4AaABAg,2,5qefnAek8OA,0,0,2018-08-08T07:47:11Z,also wanna ask this. I think it rely on the number of mini batch,2018-08-08T07:47:11Z
Ugz2qR1j2YkF28O0-2d4AaABAg,@daqi7346,,1,5qefnAek8OA,0,9,2018-01-03T16:55:53Z,"Exactly what I was looking for, which was not very clear in the paper.",2018-01-03T16:55:53Z
UgynF7S0qpRxN92bUmR4AaABAg,@HZLTV,,1,LLux1SW--oM,0,4,2023-06-18T21:08:11Z,"I don&#39;t think I&#39;ll ever understand the maths behind this properly, but the fact that I even understood it <b>sort of</b> just proves how good he is at teaching... the visual example given helped a tonne",2023-06-18T21:08:11Z
UgwJrgSchHmWYELDzhN4AaABAg,@AdarshMahabubnagar,,1,LLux1SW--oM,0,0,2022-02-16T02:42:55Z,"Is it possible to show the softmax activation function graphically? If so, please provide",2022-02-16T02:42:55Z
Ugw6ZepF-vV-8VBgsBR4AaABAg,@ziku8910,,1,LLux1SW--oM,0,0,2021-10-08T03:40:31Z,"That was very helpful, thank you!",2021-10-08T03:40:31Z
UgxtsDIQugKCHvm_ZIx4AaABAg,@leagueofotters2774,,1,LLux1SW--oM,0,0,2021-09-23T00:28:46Z,Soft and soothing....kind of like the Bob Ross of machine learning.,2021-09-23T00:28:46Z
UgwJ0LhPW7zaLtNExsp4AaABAg,@fjficm,,1,LLux1SW--oM,0,0,2021-08-23T00:46:36Z,"with &quot;t&quot; when you say normailsed, the probabilities would be different, wouldnt it? You would have to use 1 / sqr (t.t) in front of the 4x1 matrix and convert it into a unit matrix. Then use the dot products of the element to work out the probablities of each which will still work out to 1. Or is this wrong",2021-08-23T00:46:36Z
UgxrZ67fZA1XrZfj1Sx4AaABAg,@usf5914,,1,LLux1SW--oM,0,0,2021-04-21T00:58:34Z,"<a href=""https://www.youtube.com/watch?v=LLux1SW--oM&amp;t=4m03s"">4:03</a> (4, 1) or (1, 4)?",2021-04-21T00:58:34Z
Ugw8PG0qqF9uExJ_jGx4AaABAg,@manuel783,,1,LLux1SW--oM,0,1,2021-01-18T23:14:18Z,"Clarifications about Softmax Regression<br><br>Please note that at <a href=""https://www.youtube.com/watch?v=LLux1SW--oM&amp;t=4m30s"">4:30</a>, the text for the softmax formulas mixes subscripts &quot;j&quot; and &quot;i&quot;, when the subscript should just be the same (just &quot;i&quot;) throughout the formula.",2021-01-18T23:14:18Z
Ugye5eUMGEsdOkBBWVB4AaABAg,@sandipansarkar9211,,1,LLux1SW--oM,0,0,2021-01-01T17:02:10Z,Greqt exoplamantion.Ned to wtch again,2021-01-01T17:02:10Z
Ugx7hYV3wupwTFUf8gl4AaABAg,@wifi-YT,,1,LLux1SW--oM,0,0,2020-12-08T09:04:53Z,"At <a href=""https://www.youtube.com/watch?v=LLux1SW--oM&amp;t=9m32s"">9:32</a> forward, what‚Äôs the reason the decision boundaries are all linear, when the softmax function is NOT itself a linear function?  The softmax function uses, after all, an e to the z function in its numerator, which function is certainly not linear!           So, similarly, why is it that Andrew says at <a href=""https://www.youtube.com/watch?v=LLux1SW--oM&amp;t=11m16s"">11:16</a> that only when you add hidden layers do you end up with non-linear decision boundaries?",2020-12-08T09:12:40Z
Ugy_dQqHzAfhiQA8bF54AaABAg,@84xyzabc,,1,LLux1SW--oM,0,4,2020-09-30T10:04:42Z,"I think, in the denominator, its t_j at <a href=""https://www.youtube.com/watch?v=LLux1SW--oM&amp;t=4m58s"">4:58</a>",2020-09-30T10:04:42Z
UgwYLni50lW2ku-JPvJ4AaABAg,@gavin8535,,1,LLux1SW--oM,1,0,2020-08-13T09:27:01Z,"What is W^L at <a href=""https://www.youtube.com/watch?v=LLux1SW--oM&amp;t=3m56s"">3:56</a> ?",2020-08-13T09:27:01Z
UgwYLni50lW2ku-JPvJ4AaABAg.9CIGiMbQdF99DA8tCtmV2x,@aayushpaudel2379,UgwYLni50lW2ku-JPvJ4AaABAg,2,LLux1SW--oM,0,0,2020-09-04T02:16:03Z,"Weight matrix for layer L , i.e the last layer.",2020-09-04T02:16:03Z
Ugw3nT8x9K5OwoB9nb54AaABAg,@mariabardas2568,,1,LLux1SW--oM,0,0,2020-03-02T14:44:45Z,Great lesson !!!! Very useful.,2020-03-02T14:44:45Z
UgxC7R-Kkhs5wIPfcPN4AaABAg,@camilaonofri2624,,1,LLux1SW--oM,0,1,2020-02-28T16:46:53Z,"If you use the sigmoid fx for a multiclass problem you have to make a decision boundary for each class against the others (1-vs-all algo), and then you get independent probabilities. How were the decision boundaries for the examples <a href=""https://www.youtube.com/watch?v=LLux1SW--oM&amp;t=10m33s"">10:33</a> calculated considering you had no hidden layers? (how were the line equations found?)",2020-02-28T16:48:22Z
UgxcY00aF3tuF-wnVBd4AaABAg,@scl144,,1,LLux1SW--oM,0,8,2019-12-03T12:57:28Z,Î≤àÏó≠Ìï¥Ï£ºÏã† Î∂Ñ ÎàÑÍµ¨Ïã†ÏßÄ Î™∞ÎùºÏÑú ÎèôÏÑúÎÇ®Î∂ÅÏúºÎ°ú Ï†àÌñàÏäµÎãàÎã§. ÎÑàÎ¨¥ Í∞êÏÇ¨Ìï©ÎãàÎã§.. ÎçïÎ∂ÑÏóê ÌõåÎ•≠Ìïú Í∞ïÏùò Î≥¥Í≥† Í∞ëÎãàÎã§,2019-12-03T12:57:28Z
Ugz0giphps1GfFBujph4AaABAg,@benw4361,,1,LLux1SW--oM,1,1,2019-11-16T23:04:41Z,"It seems like the largest number is still selected as the predicted solution i.e. 5, so I&#39;m confused by what the purpose is of softmax when you could select the largest value instead? Wouldn&#39;t that effectively translate to the class with the largest probability anyway?",2019-11-16T23:04:41Z
Ugz0giphps1GfFBujph4AaABAg.91Pvs1C5yAc9JXM11ok91D,@michael3698bear,Ugz0giphps1GfFBujph4AaABAg,2,LLux1SW--oM,0,2,2021-02-09T05:41:45Z,"Late reply but for anyone wonder. Yes you are correct, for prediction purposes it makes no difference (though still maybe you would like to see the &quot;probabilities&quot; generated), but you are correct that just the the max will be chosen as the &quot;predicted solution&quot;. This however is not true for training. When training you need to be able to measure &quot;how wrong&quot; you were. This is where the softmax function comes in to give probabilities, which you can calculate loss from, and also calculate a derivative to update the weights.",2021-02-09T05:41:45Z
UgybWamdE7TN_qvJGM94AaABAg,@boratsagdiev6486,,1,LLux1SW--oM,2,4,2019-07-11T06:49:57Z,"It should be tj not ti at <a href=""https://www.youtube.com/watch?v=LLux1SW--oM&amp;t=4m33s"">4:33</a> right?",2019-07-11T06:49:57Z
UgybWamdE7TN_qvJGM94AaABAg.8xEaZrEv6-m9AS4A7d7bH5,@mathiasgustum858,UgybWamdE7TN_qvJGM94AaABAg,2,LLux1SW--oM,0,0,2020-06-28T11:46:57Z,yes :),2020-06-28T11:46:57Z
UgybWamdE7TN_qvJGM94AaABAg.8xEaZrEv6-m9CX2g9rOfMY,@lucylu2530,UgybWamdE7TN_qvJGM94AaABAg,2,LLux1SW--oM,0,0,2020-08-19T03:12:59Z,I believe that under the sigma function it should be i=4,2020-08-19T03:12:59Z
UgyV7g-Bhy_-82Pzrn94AaABAg,@siddharthsvnit,,1,LLux1SW--oM,0,0,2019-02-18T03:11:13Z,"This one is more detailed and also matrix based implementation<br><a href=""https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/"">https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/</a>",2019-02-18T03:11:13Z
UgySkJQB55mamWIOtkJ4AaABAg,@fatimahmath4819,,1,LLux1SW--oM,0,0,2019-02-03T19:03:09Z,‚öò‚öò‚öò‚öò‚öò,2019-02-03T19:03:09Z
UgzFXsK9uj5vg7gzAD94AaABAg,@marcostavarez2702,,1,LLux1SW--oM,1,0,2018-12-09T00:41:01Z,could someone please explain the roles of the &#39;blocks-of-color&#39; and the &#39;colored-in-circles&#39; represent ?,2018-12-09T00:41:01Z
UgzFXsK9uj5vg7gzAD94AaABAg.8obuERyfctl8rNdESLK8yg,@IrfanAhmad-od2sn,UgzFXsK9uj5vg7gzAD94AaABAg,2,LLux1SW--oM,0,0,2019-02-15T15:58:02Z,"colored-in-circles are actual training data/values.After training model on training data,model predicted all decision <a href=""http://boundaries.so/"">boundaries.so</a> color of blocks are blocks predicted by model.",2019-02-15T15:58:24Z
Ugw4L5A5znVeOjrwxpN4AaABAg,@yilmazbingol6953,,1,LLux1SW--oM,1,2,2018-10-03T00:47:50Z,"i think at time 4.30,sum indices should be j=0 to j=3. if i m wrong, <br>pls correct me.",2018-10-03T00:47:50Z
Ugw4L5A5znVeOjrwxpN4AaABAg.8lvOkouuXeT8niLSH8HqDs,@mathias8137,Ugw4L5A5znVeOjrwxpN4AaABAg,2,LLux1SW--oM,0,0,2018-11-16T16:11:37Z,"This makes definitely more sense to me. The same applies for the sum written in <a href=""https://www.youtube.com/watch?v=LLux1SW--oM&amp;t=5m00s"">5:00</a>",2018-11-16T16:11:37Z
UgxH85mho5162NghOIp4AaABAg,@mortezaabdipour5584,,1,LLux1SW--oM,0,2,2018-07-13T01:09:44Z,"Thank you, M.r Andrew, for always sharing your knowledge",2018-07-13T01:09:44Z
UgxRPVHHIO4ISWpT-eR4AaABAg,@Jwaltonp,,1,LLux1SW--oM,0,2,2018-06-06T01:22:02Z,"Fantastic, I love how easy it was to understand the material that was presented. If you have a donation page, please let me know!",2018-06-06T01:22:02Z
UgzuOG95-dAKl7xR--l4AaABAg,@grez911,,1,LLux1SW--oM,1,0,2018-05-09T05:15:21Z,How do you calculate so quickly? I don&#39;t see a calculator on your table.,2018-05-09T05:15:21Z
UgzuOG95-dAKl7xR--l4AaABAg.8g0MWZ2ML7K9-L88m7gpCi,@chancychan7175,UgzuOG95-dAKl7xR--l4AaABAg,2,LLux1SW--oM,0,0,2019-09-26T09:21:42Z,"Actually I cal it for <a href=""http://mr.ng/"">MR.NG</a> hh",2019-09-26T09:21:42Z
UgzRKLsLB2ECCM8LEnN4AaABAg,@stefandimeski8569,,1,LLux1SW--oM,3,5,2018-04-17T12:15:31Z,"How were the decision boundaries for the examples <a href=""https://www.youtube.com/watch?v=LLux1SW--oM&amp;t=10m33s"">10:33</a> calculated? (how were the line equations found?)",2018-04-17T12:15:31Z
UgzRKLsLB2ECCM8LEnN4AaABAg.8f8T6aI6qCW8g0OXLLXpA8,@grez911,UgzRKLsLB2ECCM8LEnN4AaABAg,2,LLux1SW--oM,0,2,2018-05-09T05:32:56Z,"Make a grid, let&#39;s say 100 by 100 points, and in each point calculate the activation. It&#39;s actually how he do this in programming exercises.",2018-05-09T05:32:56Z
UgzRKLsLB2ECCM8LEnN4AaABAg.8f8T6aI6qCW8g3uDNJFvBZ,@stefandimeski8569,UgzRKLsLB2ECCM8LEnN4AaABAg,2,LLux1SW--oM,0,0,2018-05-10T14:16:17Z,Thanks man! Then I suppose it&#39;s impossible to get a closed-form equation for the decision boundary?<br><br>Can you please provide link to the video where he uses the method you described here?,2018-05-10T14:16:17Z
UgzRKLsLB2ECCM8LEnN4AaABAg.8f8T6aI6qCW95a1x_6AIFy,@camilaonofri2624,UgzRKLsLB2ECCM8LEnN4AaABAg,2,LLux1SW--oM,0,0,2020-02-28T16:43:50Z,please let me know if you got it,2020-02-28T16:43:50Z
Ugwoz_hAUBZRZ81aw3J4AaABAg,@mariusz2313,,1,LLux1SW--oM,4,100,2018-02-12T20:50:09Z,"&quot;If you can&#39;t explain it simply, you don&#39;t understand it well enough. &quot;<br>Albert Einstein<br><br>You definitely know the topic perfectly well! Thanks!",2018-02-12T20:50:09Z
Ugwoz_hAUBZRZ81aw3J4AaABAg.8c_a7tueFVQ8eevhMPA1EN,@chanwookim6504,Ugwoz_hAUBZRZ81aw3J4AaABAg,2,LLux1SW--oM,0,1,2018-04-05T15:37:37Z,so true,2018-04-05T15:37:37Z
Ugwoz_hAUBZRZ81aw3J4AaABAg.8c_a7tueFVQ8iWA_3k8mk1,@roboticsresources9680,Ugwoz_hAUBZRZ81aw3J4AaABAg,2,LLux1SW--oM,0,1,2018-07-10T06:49:28Z,"Actually , it was Richard Feynman who said it",2018-07-10T06:49:28Z
Ugwoz_hAUBZRZ81aw3J4AaABAg.8c_a7tueFVQ8jbugym5keD,@bornslippy9109,Ugwoz_hAUBZRZ81aw3J4AaABAg,2,LLux1SW--oM,0,1,2018-08-06T18:08:04Z,"no einstein said it, feynman applied it perfectly",2018-08-06T18:08:04Z
Ugwoz_hAUBZRZ81aw3J4AaABAg.8c_a7tueFVQ9C3ApQPghFf,@est9949,Ugwoz_hAUBZRZ81aw3J4AaABAg,2,LLux1SW--oM,0,1,2020-08-07T12:46:56Z,This is a common logical fallacy: A implies B is not equivalent to B implies A.,2020-08-07T12:46:56Z
Ugw4djcZhCFlot2SAht4AaABAg,@wolfisraging,,1,LLux1SW--oM,0,0,2018-01-07T07:27:25Z,U r best,2018-01-07T07:27:25Z
Ugx8a89Xpv7oUp4NfRZ4AaABAg,@cryhav0k2112,,1,LLux1SW--oM,4,1,2017-12-24T22:17:42Z,Where do the numbers in the Z vector come from?,2017-12-24T22:17:50Z
Ugx8a89Xpv7oUp4NfRZ4AaABAg.8a_-PM-03jH8ac1ud0S_Q2,@kunhongyu5053,Ugx8a89Xpv7oUp4NfRZ4AaABAg,2,LLux1SW--oM,0,1,2017-12-26T02:37:18Z,just assumption,2017-12-26T02:37:18Z
Ugx8a89Xpv7oUp4NfRZ4AaABAg.8a_-PM-03jH8ac21OHm61V,@cryhav0k2112,Ugx8a89Xpv7oUp4NfRZ4AaABAg,2,LLux1SW--oM,0,0,2017-12-26T02:38:21Z,"Kunhong YU sure, but i mean intuitively, what do they represent?",2017-12-26T02:38:21Z
Ugx8a89Xpv7oUp4NfRZ4AaABAg.8a_-PM-03jH8ac47G9N9Hm,@kunhongyu5053,Ugx8a89Xpv7oUp4NfRZ4AaABAg,2,LLux1SW--oM,0,0,2017-12-26T02:56:38Z,"Similar to simple Logistic Regression, Softmax just adds more output units rather than one. For logistic regression, output unit is just a 1 dimensional vector computing input X&#39;s linear &quot;score&quot;, if it&#39;s larger than zero, then its label is 1 and vice versa. Softmax is like training multiple binary classifiers simultaneously, for a sample, each element in Z is also a &quot;score&quot;, largest score denotes  that sample may have corresponding label.",2017-12-26T02:56:38Z
Ugx8a89Xpv7oUp4NfRZ4AaABAg.8a_-PM-03jH8aosQiBhxD0,@DouglasDuhaime,Ugx8a89Xpv7oUp4NfRZ4AaABAg,2,LLux1SW--oM,0,1,2017-12-31T02:15:49Z,"@derrikbosse, the Z vector identified here has 3 arguments: W{L}, A{L-1}, and B{L}. W{L} is the vector of weights within the last layer of the network. A{L-1} is the vector of outputs from the penultimate layer of the network. B{L} is the bias vector from the last layer of the network. If none of this makes any sense, check out Professor Ng&#39;s earlier discussion of logistic regression, which is the simplest kind of neural network. That helped me make sense of this presentation: <a href=""https://www.youtube.com/watch?v=hjrYrynGWGA&amp;index=8&amp;list=PLkDaE6sCZn6Ec-XTbcX1uRg2_u4xOEky0"">https://www.youtube.com/watch?v=hjrYrynGWGA&amp;index=8&amp;list=PLkDaE6sCZn6Ec-XTbcX1uRg2_u4xOEky0</a>",2017-12-31T02:15:49Z
Ugw7seNEPaFmawRquRB4AaABAg,@Jabrils,,1,LLux1SW--oM,1,70,2017-10-21T11:11:22Z,"thank you master andrew, this was super to the point.",2017-10-21T11:11:22Z
Ugw7seNEPaFmawRquRB4AaABAg.8Yz0H25qrm08juBKvKEDF-,@roniquinonez9715,Ugw7seNEPaFmawRquRB4AaABAg,2,LLux1SW--oM,0,8,2018-08-13T20:28:32Z,Spotted a wild Jabril in his natural environment! <br><b>Attempts to say Hello</b>,2018-08-13T20:28:32Z
Ugw7qnplsC-AQY8ZRll4AaABAg,@Jack-dx7qb,,1,LLux1SW--oM,0,1,2017-10-05T15:44:52Z,So clear!,2017-10-05T15:44:52Z
UgybHcI2_TMjNnA8Gkd4AaABAg,@Jirayu.Kaewprateep,,1,ueO_Ph0Pyqk,0,0,2023-04-27T05:43:56Z,"üì∫üë§üí¨ Yui you do not have to explain much in detail they are watching because of me and they understand the concepts.<br>ü•∫üí¨ Yes, I know beginning I noted it down for myself but as you see they keep trying to yell at me I do not make a bad word but reply and inform you they are doing but with my attention and I confirm that I am listening with my attention 100% I tell them to stop but they are not that is why I tell all that I am listening with full potential please stop that is all.<br>ü•∫üí¨ Your lessons are value for attention learning.<br><br>üì∫üë§üí¨ Backward propagation and the summation of derivative / üì∫üë§üí¨ We do this way along add some sentence or question somebody specific to think about it that loss focus and continue ü•∫üí¨ Yes and outside they are not stopping but do not worry this lesson is not too hard or I read it before watching this VDO. üèçüí¨‚Äº üí¨‚Äºüí¨‚Äºüí¨‚Äºüí¨‚Äº<br>üì∫üë§üí¨ That is it SoftMax regressions algorithms  <br>ü•∫üí¨ It is one of the Backward propagation algorithms, it is the same terms when the primary is very large and the exponential is small until you consider it is a small value update.<br>ü•∫üí¨ It is different than the SoftMax layer we use often, I think you update the backward propagation methods. Is it provide better results ‚Åâ<br>ü•∫üí¨ Last time the regression you explain about update weight as weight = A x I + ( 1 - B ) where it is a linear relationship but you need to explain about softmax update or some questions on StackOverflow asking about it. It is possible and it is the input matrices if you look at loss estimation functions but I think you make this VDO must to have some contents that innovations.<br><br>üêëüí¨ It effects by creating small values from input matrices by dividing them from the estimates target value, now the weights update does not only increase or decrease value parameters from the training function but its relationship remains as the SoftMax layer does.<br>üêêüí¨ Do you mean even networks have likely and unlikely ‚Åâ<br>üëßüí¨ Yes of course and how about the dropout may be he aim to prunes the dropout from the leafs nodes by priority.",2023-04-27T06:10:29Z
Ugxxkwdcn3jacpt5USZ4AaABAg,@gabrielwong1991,,1,ueO_Ph0Pyqk,0,0,2021-03-07T00:19:53Z,What happens if your output layer is continuous like house price? Do you set a boundary and bin them into each unit?,2021-03-07T00:19:53Z
UgxuyIkJx5JCIb59EBl4AaABAg,@sandipansarkar9211,,1,ueO_Ph0Pyqk,1,0,2021-01-01T17:12:36Z,nic explanation.Ned to watch again,2021-01-01T17:12:36Z
UgxuyIkJx5JCIb59EBl4AaABAg.9HzA4oeuC4W9u9jhBLLVI1,@ermano5586,UgxuyIkJx5JCIb59EBl4AaABAg,2,ueO_Ph0Pyqk,0,0,2023-09-02T13:28:34Z,I am watching it again,2023-09-02T13:28:34Z
UgzvfhXZcvQ56ZuFyWp4AaABAg,@billykotsos4642,,1,ueO_Ph0Pyqk,0,0,2020-06-18T17:39:27Z,Yes. This is soooo good !!!!,2020-06-18T17:39:27Z
UgxxwirZpNw-CtbSP_B4AaABAg,@cyrilgarcia2485,,1,ueO_Ph0Pyqk,1,1,2020-04-29T02:48:07Z,So this type of loss function is called cross entropy,2020-04-29T02:48:07Z
UgxxwirZpNw-CtbSP_B4AaABAg.980bnzWCUmu9DAD7cdH97u,@aayushpaudel2379,UgxxwirZpNw-CtbSP_B4AaABAg,2,ueO_Ph0Pyqk,0,0,2020-09-04T02:53:07Z,Multi-Class Cross Entropy !,2020-09-04T02:53:07Z
UgxoSDzbbfagx4UfOHJ4AaABAg,@teampluu4195,,1,ueO_Ph0Pyqk,0,0,2019-07-03T13:30:18Z,Awesome video! Thank you very much!,2019-07-03T13:30:18Z
Ugx047Nm19Jq-qurs5V4AaABAg,@miguelpetrarca5540,,1,ueO_Ph0Pyqk,1,0,2019-04-04T23:10:19Z,is this the same cost function we would use if we chose an activation layer with a sigmoid cost function?,2019-04-04T23:10:19Z
Ugx047Nm19Jq-qurs5V4AaABAg.8tK-rW1ShhC9DADBd7k2kT,@aayushpaudel2379,Ugx047Nm19Jq-qurs5V4AaABAg,2,ueO_Ph0Pyqk,0,0,2020-09-04T02:53:40Z,"for Sigmoid activation, better use binary cross entropy loss",2020-09-04T02:53:40Z
UgxNUWCXKT-yq7UJLF54AaABAg,@chriswyatt66,,1,ueO_Ph0Pyqk,0,1,2019-01-25T15:16:22Z,"Thankyou Andrew. This was very helpful.  The bit I missed on the last two videos was how to convert 2D input(x,y) to 4Classes on the input side. Is that done by hidden layers?",2019-01-25T15:16:22Z
UgyIUQ1XVq51_q78wrd4AaABAg,@youtubeadventurer1881,,1,ueO_Ph0Pyqk,2,1,2019-01-18T20:46:02Z,"Yay, I managed to derive it myself. I&#39;m certainly not an expert in calculus though!",2019-01-18T20:46:02Z
UgyIUQ1XVq51_q78wrd4AaABAg.8qG2wGDWp2X8vRS4FmbHO4,@taiyaki6982,UgyIUQ1XVq51_q78wrd4AaABAg,2,ueO_Ph0Pyqk,0,1,2019-05-27T13:34:19Z,"Are you talking about d(zL) = y_hat - y? For some reason when I try to do it I always get y_hat*y - y, not y_hat - y",2019-05-27T13:34:19Z
UgyIUQ1XVq51_q78wrd4AaABAg.8qG2wGDWp2X94i1Sl5_o4i,@compilationsmania451,UgyIUQ1XVq51_q78wrd4AaABAg,2,ueO_Ph0Pyqk,0,0,2020-02-06T22:42:01Z,@@taiyaki6982 did you find what you&#39;re mistake is? Because that&#39;s what I&#39;m getting.,2020-02-06T22:42:01Z
UgyBCPpO_4jevKmVId14AaABAg,@kyungtaelim4412,,1,ueO_Ph0Pyqk,0,2,2017-11-15T18:24:37Z,"C2W3L10 is missing, those who want to study of C2W3L10 (about Deep Learning Framework) please refer to <a href=""https://youtu.be/AK6r-llqogg"">https://youtu.be/AK6r-llqogg</a><br><br>P.S., I really appreciate for the lecture :)",2017-11-15T18:24:37Z
UgzWYIkW3Y2pVWdVAyR4AaABAg,@IgorAherne,,1,ueO_Ph0Pyqk,0,16,2017-10-24T00:07:27Z,"Thank you very much Andrew! <br>At first, I was struggling to understand previous videos (backprop, sgd), but now I find your explanations actually one of the best &amp; carefully given with love to the students<br><br><a href=""https://www.youtube.com/watch?v=ueO_Ph0Pyqk&amp;t=5m00s"">5:00</a> was very helpful - my jaw dropped!",2017-10-24T00:27:46Z
UgxO-toKeaDOjAREpbh4AaABAg,@checkpeck,,1,ueO_Ph0Pyqk,4,0,2017-10-13T17:01:17Z,all these could have been very easily communicated rather than complexing it with all the jargons,2017-10-13T17:01:17Z
UgxO-toKeaDOjAREpbh4AaABAg.8Yf1xw7DJ1M8fmYtBwueGp,@dpacmanh,UgxO-toKeaDOjAREpbh4AaABAg,2,ueO_Ph0Pyqk,0,2,2018-05-03T11:14:50Z,Thats exactly what a person who didnt follow the series would feel :),2018-05-03T11:14:50Z
UgxO-toKeaDOjAREpbh4AaABAg.8Yf1xw7DJ1M8fuFj0yO0M0,@LunnarisLP,UgxO-toKeaDOjAREpbh4AaABAg,2,ueO_Ph0Pyqk,0,2,2018-05-06T11:01:20Z,It was really easily communicated lol..,2018-05-06T11:01:20Z
UgxO-toKeaDOjAREpbh4AaABAg.8Yf1xw7DJ1M8hOeINrOqu1,@banipreetsinghraheja8529,UgxO-toKeaDOjAREpbh4AaABAg,2,ueO_Ph0Pyqk,0,2,2018-06-12T12:12:36Z,"Uhmm, he doesn&#39;t give a crash course on a particular topic, not like Siraj Raval. You ought to go through all of his videos to get what he is saying. You might be feeling as a person who couldn&#39;t catch up with earlier episodes, and now isn&#39;t able to understand the plot of a series.",2018-06-12T12:12:36Z
UgxO-toKeaDOjAREpbh4AaABAg.8Yf1xw7DJ1M9C6eC32uoL4,@rubinluitel158,UgxO-toKeaDOjAREpbh4AaABAg,2,ueO_Ph0Pyqk,0,1,2020-08-08T21:10:02Z,you have to go through the previous videos to understand this...,2020-08-08T21:10:02Z
Ugy6jM5DQIHkCFqES9d4AaABAg,@miftahbedru543,,1,ueO_Ph0Pyqk,0,2,2017-10-05T12:48:49Z,"As always, awesome illustration! Big sauce of your videos are the intuition  to simplify the maths",2017-10-05T12:51:35Z
UgxWmTMCZ2XsizyhnAt4AaABAg,@kil210bom4,,1,fODpu1-lNTw,0,0,2023-09-11T17:09:34Z,i steady this problem before. <br>but now i facing this problem in reality project. <br>it&#39;s difficult problem. but i will beat him üí™,2023-09-11T17:09:34Z
UgxEKnuq1hcsAax4SG54AaABAg,@KompakterOperator,,1,fODpu1-lNTw,0,0,2023-03-20T17:06:44Z,"<a href=""https://www.youtube.com/watch?v=fODpu1-lNTw&amp;t=2m36s"">2:36</a> epic dinosaur rider",2023-03-20T17:06:44Z
Ugwra--CeomSA-FGTg14AaABAg,@danmo7072,,1,fODpu1-lNTw,0,0,2022-03-25T11:15:59Z,the dude on horse is facing backwards.though,2022-03-25T11:15:59Z
UgzgtFgIquPPQRlJqR14AaABAg,@ubermensch5472,,1,fODpu1-lNTw,0,7,2022-02-12T01:56:08Z,I can&#39;t get over that horse drawing! There is something about it being used in this situation - a deep learning course - that makes it so cute and funny.,2022-02-12T01:56:08Z
Ugy74m0VdVdFubJFDG14AaABAg,@wifi-YT,,1,fODpu1-lNTw,5,0,2022-02-04T02:49:53Z,"At <a href=""https://www.youtube.com/watch?v=fODpu1-lNTw&amp;t=4m24s"">4:24</a>, Andrew says algorithms like momentum and RMS prop can lessen problem of plateaus slowing down learning. Isn‚Äôt it really only RMS prop (or the RMS prop component of Adam), not momentum, that helps solve the plateau problem?  Momentum only solves problem of gradient swinging back and forth (overshooting) between positive and negative, which is not a plateau situation.<br>   On further reflection, maybe momentum can help a bit with plateau problem, as well, in some situations. Where one is not overshooting, but moving very slowly down plateau with declining gradients, momentum‚Äôs averaging current small gradient with prior larger gradients yields faster move down plateau.  So momentum helps a bit, though not nearly as much as RMS prop, which specifically boosts effective learning rate where the gradients are small.  <br>    Am I getting this right?",2022-02-04T03:07:19Z
Ugy74m0VdVdFubJFDG14AaABAg.9Y00XD1MzXm9fjduwcY_gm,@growthmpsfunnels3358,Ugy74m0VdVdFubJFDG14AaABAg,2,fODpu1-lNTw,0,1,2022-09-09T01:39:00Z,It is a comment that takes the conversation forward for sure for the newbies..,2022-09-09T01:39:00Z
Ugy74m0VdVdFubJFDG14AaABAg.9Y00XD1MzXm9fjkLI3ifsw,@growthmpsfunnels3358,Ugy74m0VdVdFubJFDG14AaABAg,2,fODpu1-lNTw,0,0,2022-09-09T02:35:10Z,"@@wifi-YT honestly, I just started my AI research. I am not in a position to answer yet. Would you like to know about my philosophy for the future of AI. I would like to know more about what you do",2022-09-09T02:35:10Z
Ugy74m0VdVdFubJFDG14AaABAg.9Y00XD1MzXm9fjuwLBVSNq,@growthmpsfunnels3358,Ugy74m0VdVdFubJFDG14AaABAg,2,fODpu1-lNTw,0,0,2022-09-09T04:07:44Z,@@wifi-YT makes two of us. Although I  learning it slowly more than an amateur would.. which field or profession do you belong to..I am from finance and marketing background,2022-09-09T04:07:44Z
Ugy74m0VdVdFubJFDG14AaABAg.9Y00XD1MzXm9fkML8Eb1rZ,@growthmpsfunnels3358,Ugy74m0VdVdFubJFDG14AaABAg,2,fODpu1-lNTw,0,0,2022-09-09T08:15:56Z,@@wifi-YT ok..but a conversation is tough without some reference point..:),2022-09-09T08:15:56Z
Ugy74m0VdVdFubJFDG14AaABAg.9Y00XD1MzXm9hk-1yD9rAO,@wifi-YT,Ugy74m0VdVdFubJFDG14AaABAg,2,fODpu1-lNTw,0,0,2022-10-28T21:55:08Z,"@ez sorry, I only know about the Coursera Deep Learning specialization.  There‚Äôs also on YouTube videos taught by ‚ÄúMandy‚Äù. <a href=""https://www.youtube.com/watch?v=qFJeN9V1ZsI"">https://youtu.be/qFJeN9V1ZsI</a>",2023-11-04T16:03:14Z
UgyvLg5wmb6CNy2vyTN4AaABAg,@taeheeko2793,,1,fODpu1-lNTw,0,1,2022-01-27T07:40:17Z,Thanks for very intuitive lesson! Now I understand why analysis on saddle points becomes interesting more than that of convergence.,2022-01-27T07:40:17Z
UgyFjrJ8Y1XcKLPTAjV4AaABAg,@deletedaccount2580,,1,fODpu1-lNTw,0,2,2021-03-23T11:38:24Z,is drawing is horse or dragon ?One of the great professor Andrew Ng,2021-03-23T11:38:24Z
UgzY6yeAklotjuCWapZ4AaABAg,@sandipansarkar9211,,1,fODpu1-lNTw,1,0,2021-01-01T17:18:02Z,nice explanation .need to watch again,2021-01-01T17:18:02Z
UgzY6yeAklotjuCWapZ4AaABAg.9HzAhcwAI339u7J2hE4Byf,@ermano5586,UgzY6yeAklotjuCWapZ4AaABAg,2,fODpu1-lNTw,0,0,2023-09-01T14:48:29Z,I am watching it again,2023-09-01T14:48:29Z
Ugxziq0j-KdXsY0WnFV4AaABAg,@kristenm6,,1,fODpu1-lNTw,1,1,2020-12-27T15:20:46Z,"At <a href=""https://www.youtube.com/watch?v=fODpu1-lNTw&amp;t=1m46s"">1:46</a>, why is the chance of the 20,000 plotted weights curving downward 2^-20000?",2020-12-27T15:20:46Z
Ugxziq0j-KdXsY0WnFV4AaABAg.9Hm5JJflpHi9ITNkWjc55q,@blubblubber9460,Ugxziq0j-KdXsY0WnFV4AaABAg,2,fODpu1-lNTw,0,6,2021-01-13T20:08:29Z,"for each of the 20000 directions, it can either be downward or upward (with probability 1/2 or 2^-1 respectively). Chance that it is downward for all 20000 directions (when it&#39;s really a local minima and not a saddle point) is then 2^-20000, that&#39;s basic probability calculation. It&#39;s like tossing a coin 20000 times and getting 20000 times head, which is of course extremely unlikely.",2021-01-13T20:10:44Z
UgyJ00hga2iKj0czJeR4AaABAg,@ishraqkhan8222,,1,fODpu1-lNTw,0,32,2020-02-11T16:23:31Z,"Oh my God, he actually drew the horse",2020-02-11T16:23:31Z
UgzOWdpW8ctH9yf0cyV4AaABAg,@fruitbaskets7984,,1,fODpu1-lNTw,0,0,2019-11-07T20:23:57Z,"Woah, very nice to know!",2019-11-07T20:23:57Z
UgziMbq3_qLfXXthMkl4AaABAg,@gorgolyt,,1,fODpu1-lNTw,0,21,2019-07-20T20:31:59Z,What&#39;s happening at the back end of that horse? üòÇ My neural network classifies that with high probability as a dinosaur.,2019-07-20T20:31:59Z
Ugwborylq7G5t9rhVfZ4AaABAg,@MrHics,,1,fODpu1-lNTw,0,81,2019-01-21T04:12:50Z,"I just came here for the dragon drawing. Now I know it&#39;s a horse-saddle, and now I want to learn AI",2019-01-21T04:12:50Z
Ugym_vPHduVdKF4kg0B4AaABAg,@tbru92,,1,fODpu1-lNTw,0,26,2018-01-26T09:14:32Z,lovely drawing :) <br>thanks for your awesome courses!! :),2018-01-26T09:14:32Z
UgyJFv7YPDwS_rGhihh4AaABAg,@swfsql,,1,S9ElPZupUsE,0,0,2023-09-02T17:56:29Z,"Thanks for the courses!<br>In case anyone is wondering, this course indeed only has 3 weeks.",2023-09-02T17:56:29Z
Ugx_a-wSufc35XJga_14AaABAg,@smarrilo98,,1,S9ElPZupUsE,2,37,2020-06-29T18:09:59Z,"for anyone who watches this, tensorflow has changed and you should learn tensorflow2 or higher depending on when you see this comment :D",2020-06-29T18:09:59Z
Ugx_a-wSufc35XJga_14AaABAg.9AVKnJF54qs9kKfVNulq4s,@BlakeAlexanderGames,Ugx_a-wSufc35XJga_14AaABAg,2,S9ElPZupUsE,0,2,2023-01-01T06:09:34Z,or should i just learn pytorch?,2023-01-01T06:09:34Z
Ugx_a-wSufc35XJga_14AaABAg.9AVKnJF54qs9u9m-ySuLrs,@ermano5586,Ugx_a-wSufc35XJga_14AaABAg,2,S9ElPZupUsE,0,0,2023-09-02T13:48:44Z,Phokin Hel,2023-09-02T13:48:44Z
UgyOgS9xwUBl9kXJsNB4AaABAg,@sklify1232,,1,S9ElPZupUsE,2,9,2019-12-10T20:10:10Z,"Seem to have deprecated, current TF doesn&#39;t like this code and throws a bunch of errors and stuff. Use this code to force it to work &quot;<br>import tensorflow.compat.v1 as tf<br>tf.disable_v2_behavior()<br>&quot;<br>instead of &quot; import tensorflow as tf&quot;",2019-12-10T20:10:10Z
UgyOgS9xwUBl9kXJsNB4AaABAg.92NPynTl2Et937SkU0TQgZ,@astropiu4753,UgyOgS9xwUBl9kXJsNB4AaABAg,2,S9ElPZupUsE,0,1,2019-12-29T11:57:58Z,thanks man,2019-12-29T11:57:58Z
UgyOgS9xwUBl9kXJsNB4AaABAg.92NPynTl2Et9439BMH2Lyc,@NirmalKumar-sc5tk,UgyOgS9xwUBl9kXJsNB4AaABAg,2,S9ElPZupUsE,0,1,2020-01-21T16:21:26Z,Probably you are using TensorFlow 2.0 which is much different from TF 1.x for many operations.,2020-01-21T16:21:26Z
UgymvPdt1O1HGTZQvMV4AaABAg,@shahbazquraishy143,,1,S9ElPZupUsE,1,2,2019-10-16T15:43:37Z,But sir you didn&#39;t tell the way to find the optimum number of nodes and layers for a NN.<br>And it ended.,2019-10-16T15:43:37Z
UgymvPdt1O1HGTZQvMV4AaABAg.909JkUw6HNA99KW2SM6Jte,@kenskyschulz1979,UgymvPdt1O1HGTZQvMV4AaABAg,2,S9ElPZupUsE,0,0,2020-05-31T16:45:16Z,NAS,2020-05-31T16:45:16Z
UgxcjWiPNdCTRkNK7t14AaABAg,@ogsconnect1312,,1,S9ElPZupUsE,0,0,2019-09-10T14:12:07Z,Thanks,2019-09-10T14:12:07Z
Ugz-icpsxawEsjhZDuR4AaABAg,@kld0093,,1,S9ElPZupUsE,0,4,2019-03-17T10:19:35Z,This is gold,2019-03-17T10:19:35Z
Ugy4MdvY0Lmd72BhZqR4AaABAg,@willpearson,,1,S9ElPZupUsE,0,8,2018-03-29T09:48:48Z,"Best tutorial I&#39;ve found, great for developing an understanding of TF.",2018-03-29T09:48:48Z
UgyOQF8qvQajLdZq3LZ4AaABAg,@tallwaters9708,,1,S9ElPZupUsE,0,4,2018-01-13T09:02:04Z,Great video man! Helps a lot,2018-01-13T09:02:04Z
UgxwE_dX3lOW9eUgnBl4AaABAg,@kyungtaelim4412,,1,S9ElPZupUsE,0,3,2017-11-15T18:23:50Z,"C2W3L10 is missing, those who want to study of C2W3L10 (about Deep Learning Framework) please refer to <a href=""https://youtu.be/AK6r-llqogg"">https://youtu.be/AK6r-llqogg</a><br><br>P.S., I really appreciate for the lecture :)",2017-11-15T18:23:50Z
UgwpKWo9gzh3qPpaY1F4AaABAg,@user-he4rv6zx5m,,1,CS4cs9xVecg,0,0,2023-11-15T00:01:02Z,please do a series video of  Graph Neural Networks!,2023-11-15T00:01:02Z
UgyccPDomBvs9pZEPQx4AaABAg,@iqranazir9551,,1,CS4cs9xVecg,0,0,2023-08-18T04:45:56Z,Thank you so much for sharing valuable videos,2023-08-18T04:45:56Z
UgwT_pWD8af3L9MJECZ4AaABAg,@iliveforthevibez6216,,1,CS4cs9xVecg,0,0,2023-01-29T12:17:36Z,Is this the video material that is also on the Course Deep Learning Specialization?,2023-01-29T12:17:36Z
Ugwc5YTo7HSKs0coPgt4AaABAg,@tasnimrahman7261,,1,CS4cs9xVecg,0,2,2022-08-02T12:23:52Z,Thank you so much. I have been following a lot of your courses for a while now and they are amazing. Thank you for providing us this knowledge without any strings attached. I am and will always be grateful.,2022-08-02T12:23:52Z
Ugw4o8NpOKQOOCAQdZt4AaABAg,@sarthak7839,,1,CS4cs9xVecg,1,0,2022-07-26T07:47:08Z,is this whole course on youtube only or do we have to purchase it on coursera?,2022-07-26T07:47:08Z
Ugw4o8NpOKQOOCAQdZt4AaABAg.9dwRGqBv7EC9qQOXFytz7q,@jambajuice07,Ugw4o8NpOKQOOCAQdZt4AaABAg,2,CS4cs9xVecg,0,1,2023-06-01T14:36:21Z,"exactly same as in coursera , coursera just have some extra labs and quizes . which wont make a huge difference",2023-06-01T14:36:21Z
UgzcXkNhSxxafmI_eqh4AaABAg,@stipepavic843,,1,CS4cs9xVecg,0,0,2022-01-20T18:44:10Z,respect!!!,2022-01-20T18:44:10Z
UgyeuFjvWmafq6cwfe54AaABAg,@Replacedhumans,,1,CS4cs9xVecg,0,0,2022-01-16T23:21:29Z,Learning from Mr. Andrew Ng is MINING OF THE GOLD !,2022-01-16T23:21:29Z
Ugx0RKBMRJJRnS6MV654AaABAg,@AMan-fb6dq,,1,CS4cs9xVecg,0,1,2021-08-07T10:31:03Z,volume is very low in these videos. I want my money back.,2021-08-07T10:31:03Z
Ugy_hxnzwIFcsfK8x0l4AaABAg,@KuroDHarsh,,1,CS4cs9xVecg,0,1,2021-07-07T14:52:39Z,Welcome to the best course,2021-07-07T14:52:39Z
UgzzxhLCprzNNjC6-xN4AaABAg,@billclintondube5235,,1,CS4cs9xVecg,0,0,2021-05-20T13:16:30Z,all the way from zimbabwe students send their gratitude to you mr Ng,2021-05-20T13:16:30Z
Ugyy99WcRqhIRTshCHt4AaABAg,@machinistnick2859,,1,CS4cs9xVecg,0,0,2021-01-16T13:11:10Z,Thanks,2021-01-16T13:11:10Z
UgxJNJx1W9ONQb77W7p4AaABAg,@yihuilu478,,1,CS4cs9xVecg,0,0,2020-10-30T12:16:20Z,"We are so appreciated that you have shared these videos, is there anyone could help to share the reading and testing materials ?",2020-10-30T12:16:20Z
UgwbsQZuy3ioeeX7Khd4AaABAg,@ManishSharma-tp3eb,,1,CS4cs9xVecg,0,0,2020-10-23T14:39:35Z,Thanks,2020-10-23T14:39:35Z
Ugz8t8PdSQ69wccJY-B4AaABAg,@user-qd9oz6te6u,,1,CS4cs9xVecg,0,1,2020-06-05T09:09:06Z,Thank you for the great lecture. Can I get lecture notes?,2020-06-05T09:09:06Z
UgxVi_6Dgkuki9kUYv94AaABAg,@iwtwb8,,1,CS4cs9xVecg,0,2,2020-05-21T19:17:47Z,Highest like to dislike I&#39;ve ever seen.,2020-05-21T19:17:47Z
UgzSImXHZKngTE1KOyh4AaABAg,@miguelangelingenieria,,1,CS4cs9xVecg,0,0,2020-04-24T21:32:32Z,Thank you for sharing :D,2020-04-24T21:32:32Z
UgxghUJd8HDQKfUOS3F4AaABAg,@VIVEKMISHRA-sw1mu,,1,CS4cs9xVecg,0,0,2020-04-07T12:25:27Z,"All of You Please Try this series: <a href=""https://www.youtube.com/watch?v=aPfkYu_qiF4&amp;list=PL3pGy4HtqwD2kwldm81pszxZDJANK3uGV"">https://www.youtube.com/watch?v=aPfkYu_qiF4&amp;list=PL3pGy4HtqwD2kwldm81pszxZDJANK3uGV</a>",2020-04-07T12:25:27Z
Ugxet6V8t-qDNLNsWIp4AaABAg,@louerleseigneur4532,,1,CS4cs9xVecg,0,0,2020-03-06T03:25:49Z,merci,2020-03-06T03:25:49Z
UgwF_BXIJvw9cLghvDJ4AaABAg,@fareenkhan2753,,1,CS4cs9xVecg,0,1,2019-11-20T08:16:45Z,Guess what? Cats.,2019-11-20T08:16:45Z
Ugynqqb15LpXDzb_7vl4AaABAg,@joepearson6111,,1,CS4cs9xVecg,3,1,2019-10-25T19:58:43Z,WIll these help someone who really wants to learn this field but isn&#39;t 100% sure on their mathematical skills but is somewhat sure on their programmatic skills?,2019-10-25T19:58:43Z
Ugynqqb15LpXDzb_7vl4AaABAg.90Wx5m0LcYv97d5e26ov0f,@kchaitanyakumar8747,Ugynqqb15LpXDzb_7vl4AaABAg,2,CS4cs9xVecg,0,0,2020-04-19T14:16:37Z,"Yes, it does. basic linear algebra, calculus, statistics, and probability is enough",2020-04-19T14:16:37Z
Ugynqqb15LpXDzb_7vl4AaABAg.90Wx5m0LcYv97vRGK8C2q5,@ibropwns,Ugynqqb15LpXDzb_7vl4AaABAg,2,CS4cs9xVecg,0,1,2020-04-26T17:11:49Z,"they will, and the good thing about it is that once you get hang of it you&#39;ll get the desire to learn the underlying math in order to get a deeper understanding",2020-04-26T17:11:49Z
Ugynqqb15LpXDzb_7vl4AaABAg.90Wx5m0LcYv9C8vC5DC2Hh,@malikzubair4766,Ugynqqb15LpXDzb_7vl4AaABAg,2,CS4cs9xVecg,0,0,2020-08-09T18:17:04Z,"@@ibropwns Brother i am new to this Course, but i have somewhat average skills of math, calculus and statistics, is it possible for me to learn this course? and what about Programming? do we have to program the mathematical models of these videos by our self or the tutor will teach us too?",2020-08-09T18:17:04Z
UgyOQoTy02A7u-1Jblh4AaABAg,@DeepLearninginHindi,,1,CS4cs9xVecg,1,8,2019-09-16T11:24:31Z,Thanks Andrew for making all these videos publicly available. They have helped me a lot in learning as well as teaching my own courses on deep learning.,2019-09-16T11:24:31Z
UgyOQoTy02A7u-1Jblh4AaABAg.8zwbFT2fMWM979-9KuzJJP,@VIVEKMISHRA-sw1mu,UgyOQoTy02A7u-1Jblh4AaABAg,2,CS4cs9xVecg,0,0,2020-04-07T12:23:24Z,"@Bumblesnuff buffallobath  Try this series: <a href=""https://www.youtube.com/watch?v=aPfkYu_qiF4&amp;list=PL3pGy4HtqwD2kwldm81pszxZDJANK3uGV"">https://www.youtube.com/watch?v=aPfkYu_qiF4&amp;list=PL3pGy4HtqwD2kwldm81pszxZDJANK3uGV</a>",2023-11-16T11:12:48Z
UgxYYU-N5OFnT9MlzfR4AaABAg,@HarshitSharma-lu3uf,,1,CS4cs9xVecg,0,9,2019-05-11T02:05:50Z,"Thank you for all these videos....just wanna ask sumthng.....are these the same as the videos on Coursera,if yes,  is it missing some videos...coz is missing three videos then,right?",2019-05-11T02:05:50Z
UgwYmeOFtQoJAmR1QyB4AaABAg,@arijdkwbddd,,1,CS4cs9xVecg,0,11,2019-04-27T11:23:43Z,I love his accents . So easy to understand for non-native English speaking  people.,2019-04-27T11:24:04Z
Ugz_tOCmNWQGsE29bvt4AaABAg,@siddhinathkharade156,,1,CS4cs9xVecg,1,4,2019-02-25T08:26:30Z,Thank you for sharing this valuable education for all of us!!!!,2019-02-25T08:26:30Z
Ugz_tOCmNWQGsE29bvt4AaABAg.8rl_Vy9LUzo98LK8pVJClv,@siddhinathkharade156,Ugz_tOCmNWQGsE29bvt4AaABAg,2,CS4cs9xVecg,0,0,2020-05-07T03:49:07Z,"@Bumblesnuff buffallobath No, Can you please help me in it.",2023-11-15T12:54:19Z
UgzAjqJeSL1XgLhVybl4AaABAg,@waynefilkins8394,,1,CS4cs9xVecg,1,0,2019-02-07T04:55:55Z,are these the same as on coursera?  why are they free here?,2019-02-07T04:55:55Z
UgzAjqJeSL1XgLhVybl4AaABAg.8r1r5uIEulo8rxGVSOWXfm,@MultiKhush,UgzAjqJeSL1XgLhVybl4AaABAg,2,CS4cs9xVecg,0,2,2019-03-01T21:22:32Z,There are no assignment or certificate here. Assignments helps alot.,2019-03-01T21:22:32Z
Ugwy5MZAseiSsVCI3dh4AaABAg,@michaelohaya3660,,1,CS4cs9xVecg,3,34,2019-01-08T12:55:23Z,why is coursera registration not limitless. Going through the course to refresh memory should be encouraged,2019-01-08T12:55:23Z
Ugwy5MZAseiSsVCI3dh4AaABAg.8pqT7K_6lqF979--gTGdCl,@VIVEKMISHRA-sw1mu,Ugwy5MZAseiSsVCI3dh4AaABAg,2,CS4cs9xVecg,0,0,2020-04-07T12:22:05Z,"Try this <a href=""https://www.youtube.com/watch?v=aPfkYu_qiF4&amp;list=PL3pGy4HtqwD2kwldm81pszxZDJANK3uGV"">https://www.youtube.com/watch?v=aPfkYu_qiF4&amp;list=PL3pGy4HtqwD2kwldm81pszxZDJANK3uGV</a>",2020-04-07T12:22:05Z
Ugwy5MZAseiSsVCI3dh4AaABAg.8pqT7K_6lqF97dFYlxWrv1,@nomad1104,Ugwy5MZAseiSsVCI3dh4AaABAg,2,CS4cs9xVecg,0,2,2020-04-19T15:43:09Z,You can get the Course as audit.,2020-04-19T15:43:09Z
Ugwy5MZAseiSsVCI3dh4AaABAg.8pqT7K_6lqF9GERS4rT2fh,@westwest2917,Ugwy5MZAseiSsVCI3dh4AaABAg,2,CS4cs9xVecg,0,1,2020-11-19T07:49:23Z,@@VIVEKMISHRA-sw1mu No thanks lol,2020-11-19T07:49:23Z
UgyfL1Icnt4EsB1peJJ4AaABAg,@backgroundnoiselistener3599,,1,CS4cs9xVecg,1,31,2018-12-26T18:49:48Z,Thank you for sharing this valuable education for all of us. We sincerely thank you,2018-12-26T18:49:48Z
UgyfL1Icnt4EsB1peJJ4AaABAg.8pKcLqu6Q879RS3_jdci-G,@kshitijshekhar1144,UgyfL1Icnt4EsB1peJJ4AaABAg,2,CS4cs9xVecg,0,1,2021-08-25T00:35:33Z,"you can become anything you want in computer science, just by using what&#39;s on the internet",2021-08-25T00:35:33Z
UgzS015JbSP5Zus-6f14AaABAg,@adityapaithon6499,,1,CS4cs9xVecg,0,1,2018-11-24T20:03:11Z,Awesome <br>Checkout my Channel for cool python projects and programming tutorials,2018-11-24T20:03:11Z
UgwHVec2Bw4dsNK797t4AaABAg,@bojanavukov3830,,1,CS4cs9xVecg,0,0,2018-10-10T19:50:35Z,"you may find very nice lecture notes: <a href=""http://datahacker.rs/001-introduction-to-deep-learning/"">http://datahacker.rs/001-introduction-to-deep-learning/</a>",2018-10-10T19:50:35Z
Ugy1hQP7kZBBxN49znR4AaABAg,@user-vk6ee8xv9m,,1,CS4cs9xVecg,3,3,2018-09-12T08:52:24Z,"‰∏™‰∫∫Â≠¶‰π†Á¨îËÆ∞Ôºå‰∏ÄËµ∑Â≠¶‰π†ÔºÅ<a href=""http://fangzh.top/categories/AI/Deep-Learning/"">http://fangzh.top/categories/AI/Deep-Learning/</a>",2018-09-12T08:52:24Z
Ugy1hQP7kZBBxN49znR4AaABAg.8l5BWUoOLq78pEc_0r9w4d,@wangheng3183,Ugy1hQP7kZBBxN49znR4AaABAg,2,CS4cs9xVecg,0,1,2018-12-24T10:56:17Z,very good!,2018-12-24T10:56:17Z
Ugy1hQP7kZBBxN49znR4AaABAg.8l5BWUoOLq78vJ9aXhWDfW,@user-bq2qt4mt4p,Ugy1hQP7kZBBxN49znR4AaABAg,2,CS4cs9xVecg,0,0,2019-05-24T08:18:55Z,‰Ω†Â•ΩÔºåYouTube‰∏äÈù¢ÁúãÂà∞‰∏≠ÊñáÂ•Ω‰∫≤Âàá„ÄÇ,2019-05-24T08:18:55Z
Ugy1hQP7kZBBxN49znR4AaABAg.8l5BWUoOLq7979-JsL_uTk,@VIVEKMISHRA-sw1mu,Ugy1hQP7kZBBxN49znR4AaABAg,2,CS4cs9xVecg,0,0,2020-04-07T12:24:51Z,"@@wangheng3183 Try this series: <a href=""https://www.youtube.com/watch?v=aPfkYu_qiF4&amp;list=PL3pGy4HtqwD2kwldm81pszxZDJANK3uGV"">https://www.youtube.com/watch?v=aPfkYu_qiF4&amp;list=PL3pGy4HtqwD2kwldm81pszxZDJANK3uGV</a>",2020-04-07T12:24:51Z
UgzQ_ZGxksY0JLPjbAt4AaABAg,@taibisaad9002,,1,CS4cs9xVecg,0,0,2018-08-11T05:45:20Z,‚ô•,2018-08-11T05:45:20Z
UgzyNWEs5ZK1Qzti3XV4AaABAg,@andimardinsyah8869,,1,CS4cs9xVecg,0,67,2018-08-06T12:07:09Z,&quot;Don&#39;t worry about it&quot;,2018-08-06T12:07:09Z
UgyRgGXocDzNY1HyRu14AaABAg,@degenerategambler69,,1,CS4cs9xVecg,0,9,2018-07-05T19:54:38Z,"ƒ∞√ßimden ge√ß,iliklerime kadar Classification yap.",2018-07-05T19:54:38Z
UgzXjE9nFuRhBA9GMyB4AaABAg,@jakorzeczemaszyna3770,,1,CS4cs9xVecg,1,21,2018-06-20T14:02:10Z,Thanks you for great opportunity to learn. Those type of videos keep me thinking that it is worth to spend more time watching YouTube :),2018-06-20T14:02:10Z
UgzXjE9nFuRhBA9GMyB4AaABAg.8hiSBjE0htq979-2UwlzmG,@VIVEKMISHRA-sw1mu,UgzXjE9nFuRhBA9GMyB4AaABAg,2,CS4cs9xVecg,0,0,2020-04-07T12:22:28Z,"Try this <a href=""https://www.youtube.com/watch?v=aPfkYu_qiF4&amp;list=PL3pGy4HtqwD2kwldm81pszxZDJANK3uGV"">https://www.youtube.com/watch?v=aPfkYu_qiF4&amp;list=PL3pGy4HtqwD2kwldm81pszxZDJANK3uGV</a>",2020-04-07T12:22:28Z
Ugwo9X8XNQGWiLXOidd4AaABAg,@liukang6856,,1,CS4cs9xVecg,0,5,2018-04-30T10:16:50Z,Merci beaucoup ..,2018-04-30T10:16:50Z
Ugxy_Yd6At0wUL3SfO14AaABAg,@Mohamed_Alsanosy_,,1,n1l-9lIMW7E,0,0,2022-04-21T08:02:21Z,"i have a question : what the difference between neural network concept and &quot;If Else&quot; in programming , i hope someone understand what i mean",2022-04-21T08:02:21Z
UgyNwPnw-phvEU5ffht4AaABAg,@thepresistence5935,,1,n1l-9lIMW7E,0,0,2021-09-23T03:04:42Z,Brilliant Explanation Thankyou so much for giving it free,2021-09-23T03:04:42Z
UgygI_5b49gaajZlB4V4AaABAg,@machinistnick2859,,1,n1l-9lIMW7E,0,0,2021-01-16T14:37:42Z,Thanks sir,2021-01-16T14:37:42Z
UgzsraRqvkIvt2_P00V4AaABAg,@aaronaaronaaron5922,,1,n1l-9lIMW7E,0,0,2021-01-11T22:51:13Z,nice and aclear üòÆ Thanks !!! üòÅ,2021-01-11T22:51:13Z
UgxQTY8yBLbqbi8iXjp4AaABAg,@zimingxu9517,,1,n1l-9lIMW7E,0,0,2020-12-19T06:07:05Z,Thank you!,2020-12-19T06:07:05Z
UgzCfAZzPprecbwn3W54AaABAg,@sandipansarkar9211,,1,n1l-9lIMW7E,0,0,2020-12-18T14:32:36Z,Great explanation for beginners,2020-12-18T14:32:36Z
UgwI--byW7vK1_QLWSh4AaABAg,@yuxuanji2054,,1,n1l-9lIMW7E,0,1,2020-09-15T03:32:47Z,remarkable explanation,2020-09-15T03:32:47Z
UgyfVIcPvxYlsE6D4jV4AaABAg,@aakashdewangan7313,,1,n1l-9lIMW7E,0,1,2020-05-18T12:39:08Z,Don&#39;t like it,2020-05-18T12:39:08Z
Ugz662OCfmQsVINcKGd4AaABAg,@retelligence_wading,,1,n1l-9lIMW7E,0,1,2020-03-20T01:48:58Z,Ìï≠Í≥µÎåÄ 1Îπ†,2020-03-20T01:48:58Z
Ugz0s53Lka9aaEN5R5N4AaABAg,@louerleseigneur4532,,1,n1l-9lIMW7E,0,1,2020-03-06T22:47:25Z,merci,2020-03-06T22:47:25Z
UgyH9m8CDdLLvQv0iKh4AaABAg,@sumitkumar-vn4xk,,1,n1l-9lIMW7E,1,0,2020-01-15T14:18:31Z,Suggest me real world projects for Deep Learning. Thanks!!!!!,2020-01-15T14:18:31Z
UgyH9m8CDdLLvQv0iKh4AaABAg.93oULmXeEzR94_idSEuwdp,@vikranthkanumuru8900,UgyH9m8CDdLLvQv0iKh4AaABAg,2,n1l-9lIMW7E,0,0,2020-02-03T17:14:55Z,Dead serious. Solve a problem you are facing. That&#39;s how I learned the fastest. Then watch the videos to fill in the gaps,2020-02-03T17:14:55Z
UgyG8QjjBM6FbI-_zlx4AaABAg,@legacies9041,,1,n1l-9lIMW7E,0,12,2019-12-13T04:29:50Z,Idk if The Prof. Believes in God but God bless you in this life and whatever comes next!!,2019-12-13T04:29:50Z
UgwzxAkVRtUh-1Uv3yd4AaABAg,@lorenzoleongutierrez7927,,1,n1l-9lIMW7E,1,5,2019-10-06T20:07:48Z,"Simply brilliant , thanks Andrew !",2019-10-06T20:07:48Z
UgwzxAkVRtUh-1Uv3yd4AaABAg.9-l21cw0-7k90VxmO_vD1B,@unqualaraib1474,UgwzxAkVRtUh-1Uv3yd4AaABAg,2,n1l-9lIMW7E,0,1,2019-10-25T10:45:26Z,hey can you suggest me a current thesis topic relating to CNN,2019-10-25T10:45:26Z
Ugw7MlbmDUR7GllxALd4AaABAg,@yuhui2936,,1,n1l-9lIMW7E,0,1,2019-09-22T15:34:26Z,The graph showed in this lecture is more similar to probability graph than neural network.,2019-09-22T15:34:26Z
UgxccR7P2aR3sQCvQat4AaABAg,@DeezoAce,,1,n1l-9lIMW7E,2,4,2019-05-20T18:08:12Z,why is the quality soo low :o,2019-05-20T18:08:12Z
UgxccR7P2aR3sQCvQat4AaABAg.8v9ur4Dpg3094XRQLMsPyQ,@battleragecoc9411,UgxccR7P2aR3sQCvQat4AaABAg,2,n1l-9lIMW7E,0,0,2020-02-02T10:37:59Z,"<a href=""https://www.coursera.org/learn/machine-learning"">https://www.coursera.org/learn/machine-learning</a> you can get the full course here. He just stole stanford&#39;s course and posted it here.",2020-02-02T10:37:59Z
UgxccR7P2aR3sQCvQat4AaABAg.8v9ur4Dpg309TAjMaBakim,@lifelonglearning9387,UgxccR7P2aR3sQCvQat4AaABAg,2,n1l-9lIMW7E,0,0,2021-10-07T00:05:49Z,@@battleragecoc9411 No he didn&#39;t. The instructor is the owner of the channel and  also the founder of Coursera and also a Prof in Stanford.,2021-10-07T00:05:49Z
UgzFgfgyE3q659zwj-94AaABAg,@bilawal,,1,n1l-9lIMW7E,2,16,2019-01-09T07:50:18Z,Your channel is a tremendous resource. Keep up the great work! Just one small gripe - please try to go <b>at least</b> 1080p resolution in your videos for quality sake :)  Watching a 360p video about deep learning really doesn&#39;t feel right lol. Maybe even train a net to upscale your existing video to 4K ;),2019-01-09T07:50:18Z
UgzFgfgyE3q659zwj-94AaABAg.8psV-mjTfKa8wZNsgHKlog,@anshulyadav3899,UgzFgfgyE3q659zwj-94AaABAg,2,n1l-9lIMW7E,0,1,2019-06-24T12:02:58Z,That&#39;s called super-resolution. Can be achieved using GANs,2019-06-24T12:02:58Z
UgzFgfgyE3q659zwj-94AaABAg.8psV-mjTfKa9BCjpLyNkcI,@FsimulatorX,UgzFgfgyE3q659zwj-94AaABAg,2,n1l-9lIMW7E,0,2,2020-07-17T09:23:16Z,@@anshulyadav3899 What are you doing in a &#39;hello-world&#39; deep learning video if you already know about GANs üòÇ,2020-07-17T09:23:16Z
UgzKwwT1vCeagvhxo5J4AaABAg,@ramazancesur6143,,1,n1l-9lIMW7E,1,4,2018-10-22T15:56:20Z,thaks a lot for this course which is amazing for learning lecture...,2018-10-22T15:56:20Z
UgzKwwT1vCeagvhxo5J4AaABAg.8mhwpRQ2ixJ94XRJ2QUvt_,@battleragecoc9411,UgzKwwT1vCeagvhxo5J4AaABAg,2,n1l-9lIMW7E,0,0,2020-02-02T10:36:59Z,"Dude this is not hos course. It is the number one AI course ever made. <a href=""https://www.coursera.org/learn/machine-learning"">https://www.coursera.org/learn/machine-learning</a>  it&#39;s free check it out.",2020-02-02T10:36:59Z
Ugwwnhluj-aP8_mVJEd4AaABAg,@bahar4813,,1,n1l-9lIMW7E,0,5,2018-08-02T10:21:57Z,Thank you,2018-08-02T10:21:57Z
UgzBDN57zlWd9We7LK14AaABAg,@degenerategambler69,,1,n1l-9lIMW7E,2,3,2018-07-05T20:06:26Z,"Millet kƒ±raathaneleri kapatƒ±lsƒ±n, NVIDIA destekli Deep Learning workshoplarƒ± a√ßƒ±lsƒ±n!",2018-07-05T20:07:12Z
UgzBDN57zlWd9We7LK14AaABAg.8iKinobZ8yL8iWItiAogEl,@onurkara6435,UgzBDN57zlWd9We7LK14AaABAg,2,n1l-9lIMW7E,0,1,2018-07-10T08:02:11Z,what do u expect from our government :)),2018-07-10T08:02:11Z
UgzBDN57zlWd9We7LK14AaABAg.8iKinobZ8yL8zVTXDqqaeT,@saba7371,UgzBDN57zlWd9We7LK14AaABAg,2,n1l-9lIMW7E,0,0,2019-09-05T13:09:34Z,ne √ßok t√ºrk varmƒ±≈ü bu adamƒ± takip eden :D helal bize...,2019-09-05T13:09:34Z
Ugwb3KsCoPYVw9BacL54AaABAg,@vanshikagarg5683,,1,BYGpKPY9pO0,0,1,2023-06-20T16:49:21Z,Ï¢ãÏïÑÏöî. Í∞êÏÇ¨Ìï¥Ïöî<br>üëåüëå,2023-06-20T16:49:21Z
UgwB_jFqIiAtPlMGxzt4AaABAg,@gshaibi,,1,BYGpKPY9pO0,0,0,2021-06-04T12:41:46Z,Thank you,2021-06-04T12:41:46Z
UgwCHPEKeVyjVtcf8kd4AaABAg,@akshayakumars2814,,1,BYGpKPY9pO0,0,0,2021-01-28T12:07:06Z,ÈùûÂ∏∏Â•ΩÁöÑË¨õÂ∫ß,2021-01-28T12:07:06Z
UgzTZvo7yLZgsoifXUV4AaABAg,@machinistnick2859,,1,BYGpKPY9pO0,0,1,2021-01-16T14:38:06Z,Thanks sir,2021-01-16T14:38:06Z
UgxiWDr1a1xxMYdSgJh4AaABAg,@retelligence_wading,,1,BYGpKPY9pO0,0,1,2020-03-20T01:49:24Z,Ìï≠Í≥µÎåÄ 1Îπ†,2020-03-20T01:49:24Z
UgwXqoVl3aE-jaKX9Cx4AaABAg,@louerleseigneur4532,,1,BYGpKPY9pO0,0,1,2020-03-06T22:58:39Z,merci,2020-03-06T22:58:39Z
UgwFukoQiYIBqokaJrV4AaABAg,@drummerboi4eva,,1,BYGpKPY9pO0,0,3,2020-01-02T11:42:20Z,Great explaination!,2020-01-02T11:42:20Z
UgwH142dHYfo5F54kk94AaABAg,@jonathanlorence8939,,1,BYGpKPY9pO0,0,20,2019-06-12T06:24:19Z,"Thanks for make this material free,,, fir",2019-06-12T06:24:19Z
UgyCqcWw_IyAcV67ccV4AaABAg,@JK-ky5of,,1,BYGpKPY9pO0,1,4,2019-03-08T20:11:36Z,Is it possible to have the slides of all the course?,2019-03-08T20:11:36Z
UgyCqcWw_IyAcV67ccV4AaABAg.8sE9wxsPblm8sZdBj79vvp,@MohammedMadkhana,UgyCqcWw_IyAcV67ccV4AaABAg,2,BYGpKPY9pO0,0,2,2019-03-17T04:19:57Z,"You can get them from the website <a href=""http://coursera.org/"">coursera.org</a> after enrolling",2019-03-17T04:19:57Z
Ugxd4f9IkV5_EunjLKF4AaABAg,@saanvisharma2081,,1,BYGpKPY9pO0,2,2,2018-12-23T08:06:08Z,I wonder whether it is possible to build a neural networks without feeding data??? I mean unsupervised learning!!,2018-12-23T08:07:31Z
Ugxd4f9IkV5_EunjLKF4AaABAg.8pBkIqdI5Qj8ppLO5U-nl_,@Maverick3681,Ugxd4f9IkV5_EunjLKF4AaABAg,2,BYGpKPY9pO0,0,6,2019-01-08T02:28:31Z,Unsupervised learning doesn&#39;t occur without data. It just works without the labels (i.e. Y in this case). And yes Neural networks are also used for Unsupervised Learning,2019-01-08T02:28:31Z
Ugxd4f9IkV5_EunjLKF4AaABAg.8pBkIqdI5Qj9CTPHehM63x,@saanvisharma2081,Ugxd4f9IkV5_EunjLKF4AaABAg,2,BYGpKPY9pO0,0,5,2020-08-17T17:13:31Z,Now I&#39;m laughing at my own ignorance!!! How dumb I was thinking that unsupervised learning can be achieved without data!!! Yeah 2019 was a productive year though,2020-08-17T17:13:31Z
UgzLd0qYIMoc6ql18D54AaABAg,@user-qg6yl7gl8c,,1,xflCLdJh0n0,0,0,2023-11-16T06:48:20Z,"Where is the test, quizes??",2023-11-16T06:48:20Z
UgxaIC2X-pvFrA3yk2R4AaABAg,@user-oh2zg9nx9e,,1,xflCLdJh0n0,0,0,2023-11-15T07:43:02Z,"the content is good, but the video quality is pretty bad",2023-11-15T07:43:02Z
UgznB09BdMXZYu8p0Kl4AaABAg,@anirbansaha1996,,1,xflCLdJh0n0,0,1,2021-02-11T10:51:00Z,"If you don&#39;t understand what it means, don&#39;t worry about it. Finally @<a href=""https://www.youtube.com/watch?v=xflCLdJh0n0&amp;t=6m26s"">6:26</a>. Okay, now I am seeing Andrew Ng finally.",2021-02-11T10:51:00Z
UgzEYDsjEkxLYPdY-nN4AaABAg,@sandipansarkar9211,,1,xflCLdJh0n0,0,0,2021-01-28T18:03:08Z,nice explanation,2021-01-28T18:03:08Z
UgwJgxiW0Nai93UgOGZ4AaABAg,@machinistnick2859,,1,xflCLdJh0n0,0,0,2021-01-16T14:44:09Z,Thanks sir ji,2021-01-16T14:44:09Z
UgzXiQ0CVxramB3u-HJ4AaABAg,@kazenokize2,,1,xflCLdJh0n0,0,0,2021-01-06T02:53:23Z,thank you for this incredible series from a humble brazilian,2021-01-06T02:53:23Z
UgzWaFnVSMSwBRLSjlp4AaABAg,@behnamprime5257,,1,xflCLdJh0n0,0,0,2020-04-26T19:39:00Z,"at Minute 1, the effect of the amount of data on different machine learning algorithms compared to deep learning is explained. I can not find a reference for this. Does anyone know the reference?",2020-04-26T19:39:00Z
Ugy1as2FzkWAyJeWu3p4AaABAg,@retelligence_wading,,1,xflCLdJh0n0,0,0,2020-03-20T01:49:33Z,Ìï≠Í≥µÎåÄ 1Îπ†,2020-03-20T01:49:33Z
UgxKuY2dVxgIFCjOOox4AaABAg,@normalchannel4747,,1,xflCLdJh0n0,0,15,2019-10-08T10:59:55Z,Thank you dear Andrew Ng I truly love your courses :),2019-10-08T10:59:55Z
Ugyeh-EdNAy1i6dOVX94AaABAg,@AmitKumar-hm4gx,,1,xflCLdJh0n0,1,1,2019-06-06T16:01:40Z,"At <a href=""https://www.youtube.com/watch?v=xflCLdJh0n0&amp;t=07m04s"">07:04</a> Andrew states that though the slope for ReLu function is also 0 on the left, it seems that this function works better than Sigmoid. I would like to know if slopes for both the function are 0 on the left, what is the reasoning for ReLu to be better?",2019-06-06T16:01:40Z
Ugyeh-EdNAy1i6dOVX94AaABAg.8vqSt87ZsoG8yIeRxQV0B6,@MrCmon113,Ugyeh-EdNAy1i6dOVX94AaABAg,2,xflCLdJh0n0,0,2,2019-08-06T17:12:10Z,"Learning is faster, because the gradient is equal to the output for positive weights and weights being effectively turned off leads to a sparse model. Still there is problems with ReLU, but in practice they seem to work best.",2019-08-06T17:12:10Z
UgzZ2ppU9HwbAZAvoDh4AaABAg,@lemyul,,1,xflCLdJh0n0,0,0,2019-06-04T02:11:30Z,thanks dee,2019-06-04T02:11:30Z
UgwxN0Or7vnHBJsCDK94AaABAg,@dheerajkura5193,,1,xflCLdJh0n0,1,0,2019-03-11T07:44:59Z,In the video the explanation is more inclined towards deep learning... Andrew mentioned that when the data is more deep learning is applied but didn&#39;t talk about the varsity of the data... Is that mean when the size of the data Increased varacity of the data will also increase..??,2019-03-11T07:44:59Z
UgwxN0Or7vnHBJsCDK94AaABAg.8sKYtBtsD8J8teduECIiXl,@dheerajkura5193,UgwxN0Or7vnHBJsCDK94AaABAg,2,xflCLdJh0n0,0,0,2019-04-13T08:53:00Z,"ting machineintellect more dimensions in the data.. For say to predict the image there are lot of dimensions.. Machine has to understand the pixel color coding which ranges from 0-255, at this situation deep learning is useful.. When it comes to predicting the binary classification problem like predicting the loan probability  usually around  20-25 parameters(its not limited) are considered which decides the applicant financial credibility  .. And the classification prediction is either customer will replay loan/not<br><br>So simply to say... When the data is scaled we can&#39;t directly apply  deep learning that leads to overfitting problem... Before applying algorithms proper analysis of data needs to be done... <br><br>Since Andrew is talking about deep learning and the examples he mentioned like speech recognition / image recognition.. Machine learning models wont give better predictions for speech/image recognition or text sequence predictions <br><br>Hope this explanation suits the question",2019-04-13T08:53:00Z
UgzyPQJzHpVuXzhHza94AaABAg,@kshitijdeansam8093,,1,xflCLdJh0n0,3,1,2018-02-18T22:23:09Z,for text classification what is the standard amount of data is good for deeplearning,2018-02-18T22:23:09Z
UgzyPQJzHpVuXzhHza94AaABAg.8cpCYJvWMJu8dwb_iwy6Hf,@Horopter,UgzyPQJzHpVuXzhHza94AaABAg,2,xflCLdJh0n0,0,0,2018-03-18T15:56:44Z,About 250 chunks of 200 documents per chunk. Be cautious. It will take days to train the data.,2018-03-18T15:56:44Z
UgzyPQJzHpVuXzhHza94AaABAg.8cpCYJvWMJu8oa4RpA_n_P,@saanvisharma2081,UgzyPQJzHpVuXzhHza94AaABAg,2,xflCLdJh0n0,0,1,2018-12-08T07:40:28Z,@@Horopter exactly. And we do need high end processors to perform text classification.,2018-12-08T07:40:28Z
UgzyPQJzHpVuXzhHza94AaABAg.8cpCYJvWMJu8zrrVnFsnqr,@rickjamesbtch9417,UgzyPQJzHpVuXzhHza94AaABAg,2,xflCLdJh0n0,0,0,2019-09-14T15:10:21Z,Depends on:<br><br>-How powerful is your system<br>-Size of text<br>-Desired accuracy<br><br>One rule that fits all does not exist :) it would be gr8 if it did!,2019-09-14T15:10:21Z
UgxP9d8GrdTtCc6u-K14AaABAg,@sagarikahazra5241,,1,ysnIDax71yY,0,0,2023-11-29T12:02:21Z,Where is the questions?,2023-11-29T12:02:21Z
Ugx_qXl-uSKX7ejGdUl4AaABAg,@user-qg6yl7gl8c,,1,ysnIDax71yY,0,0,2023-11-16T06:51:47Z,where is the quiz and tests?,2023-11-16T06:51:47Z
UgwFR-l0Gp993aUiOz14AaABAg,@machinistnick2859,,1,ysnIDax71yY,0,0,2021-01-16T14:57:14Z,Thanks sir,2021-01-16T14:57:14Z
UgxCVnG6WeLU_ZI-7x14AaABAg,@kazenokize2,,1,ysnIDax71yY,0,1,2021-01-06T02:58:52Z,thank you so much! I really cant thank you enough!!!!,2021-01-06T02:58:52Z
Ugw5WWWlqcXdv_NwRep4AaABAg,@louerleseigneur4532,,1,ysnIDax71yY,0,0,2020-03-07T09:53:23Z,merci,2020-03-07T09:53:23Z
UgxHWapuh014YlCglx14AaABAg,@saanvisharma2081,,1,ysnIDax71yY,0,29,2018-12-23T16:46:26Z,"Now I&#39;m fan of this person!!! <br>He&#39;s clear, confident, simple to explain NN",2018-12-23T16:46:26Z
Ugw7fRgTV4CzVd7xy2t4AaABAg,@ahmedmohamedosama9569,,1,ysnIDax71yY,1,0,2018-08-16T20:27:42Z,Does anyone could put a link for the 10 MCQ Questions ?,2018-08-16T20:28:17Z
Ugw7fRgTV4CzVd7xy2t4AaABAg.8k0ucR2pSpO8scXyF9A95K,@karthikkrishnan9476,Ugw7fRgTV4CzVd7xy2t4AaABAg,2,ysnIDax71yY,0,0,2019-03-18T16:42:30Z,Ahmed Mohamed Osali,2019-03-18T16:42:30Z
UgzL9MXoD-32fY-MdlF4AaABAg,@ahmadshaarawy6556,,1,ysnIDax71yY,1,3,2017-12-17T15:35:30Z,"Excuse me, where can I find the 10 mcq questions?",2017-12-17T15:35:30Z
UgzL9MXoD-32fY-MdlF4AaABAg.8aHFoS73D6g9fo5qA3BxoR,@manavjain9648,UgzL9MXoD-32fY-MdlF4AaABAg,2,ysnIDax71yY,0,0,2022-09-10T19:08:43Z,On Coursera,2022-09-10T19:08:43Z
UgzxKp_oSx3YdapCpLZ4AaABAg,@jean-loicdejaeger5729,,1,ysnIDax71yY,4,1,2017-12-08T05:19:49Z,Does this course focus on building deep neural network from scratch?<br>Or will it rely on libraries like Tensorflow or Kera ?,2017-12-08T05:19:49Z
UgzxKp_oSx3YdapCpLZ4AaABAg.8_tzC9Va8z98eda1l7FiyN,@BocaoLegal,UgzxKp_oSx3YdapCpLZ4AaABAg,2,ysnIDax71yY,0,0,2018-04-05T03:09:03Z,That is the one question that i would like to be answered.,2018-04-05T03:09:03Z
UgzxKp_oSx3YdapCpLZ4AaABAg.8_tzC9Va8z98j9GzUV4m5V,@EranM,UgzxKp_oSx3YdapCpLZ4AaABAg,2,ysnIDax71yY,0,0,2018-07-26T05:54:22Z,I&#39;m quite sure you need to implement them yourself.,2018-07-26T05:54:22Z
UgzxKp_oSx3YdapCpLZ4AaABAg.8_tzC9Va8z98pCfdh9tjj0,@saanvisharma2081,UgzxKp_oSx3YdapCpLZ4AaABAg,2,ysnIDax71yY,0,0,2018-12-23T16:44:40Z,This course is entirely theoretical and you&#39;ve to go through webpages for examples. Correct me if I&#39;m wrong!!,2018-12-23T16:44:40Z
UgzxKp_oSx3YdapCpLZ4AaABAg.8_tzC9Va8z98wHO5nNU4Kc,@saurabhvishwakarma4937,UgzxKp_oSx3YdapCpLZ4AaABAg,2,ysnIDax71yY,0,0,2019-06-17T12:18:34Z,@@saanvisharma2081  andrew have a paid course in coursera  where you will find  it,2019-06-17T12:18:34Z
UgzRLUQ6BavvMHE5ljZ4AaABAg,@user-qg6yl7gl8c,,1,7AZjh2VXD6E,0,0,2023-11-16T06:50:52Z,where is the quiz?,2023-11-16T06:50:52Z
UgzMOO0xZVqJRDpnTBN4AaABAg,@machinistnick2859,,1,7AZjh2VXD6E,0,1,2021-01-16T14:59:42Z,Thanks sir,2021-01-16T14:59:42Z
Ugyb75xTPik5OeYnQDR4AaABAg,@louerleseigneur4532,,1,7AZjh2VXD6E,0,3,2020-03-07T09:55:32Z,merci,2020-03-07T09:55:32Z
UgxFdnuC5Zm1nQydgrp4AaABAg,@rohini9120,,1,eqEc66RFY0I,0,0,2022-08-12T12:23:46Z,Sir why can&#39;t we use RGB as three different features in the cat example?,2022-08-12T12:23:46Z
UgyWnbqcyOl7iHtlwz54AaABAg,@eatbreathedatascience9593,,1,eqEc66RFY0I,2,0,2022-02-03T02:26:37Z,Where could I download the Notation Guide ?  Thanks.,2022-02-03T02:26:37Z
UgyWnbqcyOl7iHtlwz54AaABAg.9XyP3qw_Gjq9Z06FVWlxgp,@niniolaadegboyega9964,UgyWnbqcyOl7iHtlwz54AaABAg,2,eqEc66RFY0I,0,1,2022-03-01T00:11:17Z,"Here are a few useful links: <a href=""https://nthu-datalab.github.io/ml/slides/Notation.pdf"">https://nthu-datalab.github.io/ml/slides/Notation.pdf</a> and <a href=""http://www.math.lsa.umich.edu/~kesmith/295handout1-2010.pdf"">http://www.math.lsa.umich.edu/~kesmith/295handout1-2010.pdf</a>",2022-03-01T00:11:17Z
UgyWnbqcyOl7iHtlwz54AaABAg.9XyP3qw_Gjq9Z0AQJSGrew,@eatbreathedatascience9593,UgyWnbqcyOl7iHtlwz54AaABAg,2,eqEc66RFY0I,0,0,2022-03-01T00:47:43Z,@@niniolaadegboyega9964 Thanks very much.,2022-03-01T00:47:43Z
Ugxi0J_pT-fEoIYJ8oV4AaABAg,@rayeneaminaboukabouya4782,,1,eqEc66RFY0I,0,0,2021-12-01T17:25:01Z,thank you so much &lt;3,2021-12-01T17:25:01Z
Ugy7j2s_NnJfqEsp6ph4AaABAg,@toyotomihideyoshi8,,1,eqEc66RFY0I,0,0,2021-02-13T08:38:13Z,"it is a good video,, :)",2021-02-13T08:38:13Z
UgzCNB1w-BxSYUVin7l4AaABAg,@machinistnick2859,,1,eqEc66RFY0I,0,0,2021-01-16T15:00:43Z,Thanks sir,2021-01-16T15:00:43Z
UgzCaMJs-L5XPL3CpUR4AaABAg,@DineshBabu-gn8cm,,1,eqEc66RFY0I,1,0,2020-12-31T08:35:02Z,what if we have different pixel for each input instead of 64x64. then how can we represent the shape of x . because each feature will be having different n(x) ? please anyone explain me.,2020-12-31T08:35:02Z
UgzCaMJs-L5XPL3CpUR4AaABAg.9Hvf364-VHU9PW7DiB_LPk,@rohail260,UgzCaMJs-L5XPL3CpUR4AaABAg,2,eqEc66RFY0I,0,2,2021-07-07T21:21:32Z,"no we have to make all the input sizes same. Conventionally, when dealing with images of different sizes in CNN, we resize the images to the size of the smallest images with the help of any image manipulation library (OpenCV, PIL etc) or some times, pad the images of unequal size to desired size",2021-07-07T21:21:32Z
Ugyd4rwfIJCuge5uMpt4AaABAg,@sandipansarkar9211,,1,eqEc66RFY0I,1,1,2020-12-13T18:31:38Z,Very good.Makes nots .very inp,2020-12-13T18:31:38Z
Ugyd4rwfIJCuge5uMpt4AaABAg.9HDO0zHqWEA9Ww9TxtDZfb,@machinelearning3518,Ugyd4rwfIJCuge5uMpt4AaABAg,2,eqEc66RFY0I,0,0,2022-01-08T09:00:29Z,yep,2022-01-08T09:00:29Z
Ugw4mbSBOv9ZjZ0xZbh4AaABAg,@holajuventud3282,,1,eqEc66RFY0I,3,5,2020-09-16T19:30:00Z,This is odd. This video only has 32 comments?,2020-09-16T19:30:00Z
Ugw4mbSBOv9ZjZ0xZbh4AaABAg.9Dftk_9EASz9My19CXGLq4,@rahulkapoor7305,Ugw4mbSBOv9ZjZ0xZbh4AaABAg,2,eqEc66RFY0I,0,1,2021-05-05T13:12:17Z,People are taking it at coursera.,2021-05-05T13:12:17Z
Ugw4mbSBOv9ZjZ0xZbh4AaABAg.9Dftk_9EASz9Ww9W6tXO4u,@machinelearning3518,Ugw4mbSBOv9ZjZ0xZbh4AaABAg,2,eqEc66RFY0I,0,1,2022-01-08T09:00:47Z,then?,2022-01-08T09:00:47Z
Ugw4mbSBOv9ZjZ0xZbh4AaABAg.9Dftk_9EASz9X9cz2kpSjh,@paulbaharet1324,Ugw4mbSBOv9ZjZ0xZbh4AaABAg,2,eqEc66RFY0I,0,1,2022-01-13T23:56:23Z,@@machinelearning3518 uncommon,2022-01-13T23:56:23Z
UgyNPzVjs71Wu7wYbcZ4AaABAg,@sabyasachidey7621,,1,eqEc66RFY0I,1,4,2020-09-14T21:41:29Z,What does Y represents?,2020-09-14T21:41:29Z
UgyNPzVjs71Wu7wYbcZ4AaABAg.9DazCiqE6Zr9DftzJwSfaH,@holajuventud3282,UgyNPzVjs71Wu7wYbcZ4AaABAg,2,eqEc66RFY0I,0,3,2020-09-16T19:32:01Z,"y is convention used for labels, what you are trying to predict. In this case cat or non-cat",2020-09-16T19:32:01Z
Ugyj7HD8ZtQJjUdmqDh4AaABAg,@yogeshwarangovindarajan8817,,1,eqEc66RFY0I,1,1,2020-04-18T10:57:07Z,"what is nx means in input? for example if am having 7 training samples and 5 input columns means then what is nx, m?",2020-04-18T10:57:07Z
Ugyj7HD8ZtQJjUdmqDh4AaABAg.97aA0tVqnng97wUj2WB-u1,@WAanik,Ugyj7HD8ZtQJjUdmqDh4AaABAg,2,eqEc66RFY0I,0,6,2020-04-27T03:01:20Z,"So let us assume your image is of resolution 256*256. Irrespective of what number of samples you&#39;re feeding as training set, your nx will always be 256*256*3.<br>Nx here is the feature vector. This means each image can be broken down as 256 rows and 256 columns, and each pixel (one cell, formed from one row and one column) is composed of 3 metrics of colours. <br><br>So, to answer your question, nx is a parameter of the images you&#39;re providing, whereas m is a parameter of how many samples you&#39;re providing.",2020-04-27T03:01:20Z
Ugx8H8HRfCWpIzK2bMN4AaABAg,@user-jd2uh6hj8z,,1,eqEc66RFY0I,0,1,2020-01-05T06:43:30Z,thank you,2020-01-05T06:43:30Z
UgyI5cPDSUlzGeVs89R4AaABAg,@GhostkillerPlaysMC,,1,eqEc66RFY0I,0,13,2019-12-08T22:07:54Z,Thank you for simplifying the math I haven&#39;t learned. Great video,2019-12-08T22:08:19Z
UgzR9adn8UcWxCDw4CZ4AaABAg,@guyindisguise,,1,eqEc66RFY0I,1,6,2019-12-01T20:35:35Z,"Towards the end (roughly at around <a href=""https://www.youtube.com/watch?v=eqEc66RFY0I&amp;t=7m20s"">7:20</a>) he says Y will be a 1 by m -dimensional matrix, which is fine, but he writes down Y element R^1xm<br><br><br>At the top of the slide however we see y element {0, 1} since we are dealing with binary classification. Shouldn&#39;t that be reflected in Y (the vector of dependent variables). I think mathematicians call this the vector space (correct me if I&#39;m wrong) and since we&#39;re dealing with binary classification (only zero and one) it shouldn&#39;t include the R which stands for all real numbers, right?",2019-12-01T20:35:35Z
UgzR9adn8UcWxCDw4CZ4AaABAg.920Hj6iDVCz9sjSTmFFZMF,@e.galois4940,UgzR9adn8UcWxCDw4CZ4AaABAg,2,eqEc66RFY0I,0,1,2023-07-29T02:38:25Z,"Yes, ur right",2023-07-29T02:38:25Z
Ugx3xmZLy_ubEe8TkpB4AaABAg,@arcanernz,,1,eqEc66RFY0I,2,8,2019-11-13T17:54:30Z,"I feel like the cat picture should be replaced with hotdog so it would be hotdog, not hotdog.",2019-11-13T17:54:56Z
Ugx3xmZLy_ubEe8TkpB4AaABAg.91HdzV9v0KJ931BxbC-lxW,@vinayreddy8683,Ugx3xmZLy_ubEe8TkpB4AaABAg,2,eqEc66RFY0I,0,2,2019-12-27T01:35:46Z,You got the reference from silicon valley yea!!!!!,2019-12-27T01:35:46Z
Ugx3xmZLy_ubEe8TkpB4AaABAg.91HdzV9v0KJ9BFyj6f2wuq,@ktai9953,Ugx3xmZLy_ubEe8TkpB4AaABAg,2,eqEc66RFY0I,0,0,2020-07-18T15:31:13Z,jing yang!!!,2020-07-18T15:31:13Z
Ugx4pwUsU2UxtKkw7CV4AaABAg,@chitralalawat8106,,1,eqEc66RFY0I,2,2,2019-03-15T18:16:41Z,"Here,the speaker s calling rows as columns &amp; vice versa that I understand..!! The shape of X vector is rows * col that&#39;s okay... In y there are m rows &amp; single column so the shape should be (m,1)... Why here it is written as y.shape =(1,m)????",2019-03-15T18:16:41Z
Ugx4pwUsU2UxtKkw7CV4AaABAg.8sVzMOb4A8G8slUNJiTKI_,@basuam,Ugx4pwUsU2UxtKkw7CV4AaABAg,2,eqEc66RFY0I,0,1,2019-03-22T04:04:16Z,"Because each sample is a column and y refers to the label of each sample. Because we have m samples (columns), y needs to relate to the label of each sample. Hence y.shape = (1,m)",2019-03-22T04:04:16Z
Ugx4pwUsU2UxtKkw7CV4AaABAg.8sVzMOb4A8G8smCE2_Xb91,@chitralalawat8106,Ugx4pwUsU2UxtKkw7CV4AaABAg,2,eqEc66RFY0I,0,0,2019-03-22T10:44:58Z,Tks. I got it..!!,2019-03-22T10:44:58Z
UgyGQ3dY0szGQGRR_dp4AaABAg,@dennisdevink5667,,1,eqEc66RFY0I,6,3,2019-02-26T09:07:47Z,The n after R is standing for the dimensions... but  what does the x after the n means?,2019-02-26T09:07:47Z
UgyGQ3dY0szGQGRR_dp4AaABAg.8roE1KBfcWy8sFHqO-CkV_,@abir95571,UgyGQ3dY0szGQGRR_dp4AaABAg,2,eqEc66RFY0I,0,0,2019-03-09T06:39:50Z,"x is the feature feature vector , it&#39;s just a nomenclature . Nx refers to Dimension(N) of any vector(x) . So R^Nx means vector of real numbers whose length is same as that of feature vector (Which in our case is the total pixels)",2019-03-09T06:42:36Z
UgyGQ3dY0szGQGRR_dp4AaABAg.8roE1KBfcWy8sVyo815B94,@chitralalawat8106,UgyGQ3dY0szGQGRR_dp4AaABAg,2,eqEc66RFY0I,0,0,2019-03-15T18:11:52Z,@@abir95571 dimension means order of a matrix/vector.. right??<br>Why the dimension here is only in the form of a single no.???,2019-03-15T18:11:52Z
UgyGQ3dY0szGQGRR_dp4AaABAg.8roE1KBfcWy8sW3ju637Re,@chitralalawat8106,UgyGQ3dY0szGQGRR_dp4AaABAg,2,eqEc66RFY0I,0,0,2019-03-15T19:03:43Z,Hey! Looks like you&#39;re seriously understanding what the speaker is saying.. Could you please help me with this... I want you to join my group so that we all can study further ..!!,2019-03-15T19:03:43Z
UgyGQ3dY0szGQGRR_dp4AaABAg.8roE1KBfcWy8sk65Ts-TZH,@CodeWithKal,UgyGQ3dY0szGQGRR_dp4AaABAg,2,eqEc66RFY0I,0,0,2019-03-21T15:12:53Z,R is the dimension space and n subscript(x) represents the number of features. Whatever the number of features available to us is our number of dimension.,2019-03-21T15:12:53Z
UgyGQ3dY0szGQGRR_dp4AaABAg.8roE1KBfcWy8sk6pT6n6B2,@CodeWithKal,UgyGQ3dY0szGQGRR_dp4AaABAg,2,eqEc66RFY0I,0,0,2019-03-21T15:19:18Z,in easy word n subscript x is the dimension of input feature vector...as in case of image example we were having 11288 number of features or dimensions,2019-03-21T15:19:18Z
UgwIAbrUQgBaUG0mpmJ4AaABAg,@mariumhayat8663,,1,eqEc66RFY0I,3,0,2018-12-23T10:06:25Z,"what if I input a black and white image( a drawing figure),would that also use the 3 colors(r,g,b)?",2018-12-23T10:06:25Z
UgwIAbrUQgBaUG0mpmJ4AaABAg.8pBy3pB71Ze8si-UjV6_1j,@suranjanotti,UgwIAbrUQgBaUG0mpmJ4AaABAg,2,eqEc66RFY0I,0,0,2019-03-20T19:36:41Z,What is the image format?,2019-03-20T19:36:41Z
UgwIAbrUQgBaUG0mpmJ4AaABAg.8pBy3pB71Ze8tb0IVtV-P8,@marconardelli5538,UgwIAbrUQgBaUG0mpmJ4AaABAg,2,eqEc66RFY0I,0,4,2019-04-11T23:00:28Z,No grayscale images have only 1 channel,2019-04-11T23:00:28Z
UgwIAbrUQgBaUG0mpmJ4AaABAg.8pBy3pB71Ze8yUR04_42F1,@vigneshaiyer838,UgwIAbrUQgBaUG0mpmJ4AaABAg,2,eqEc66RFY0I,0,1,2019-08-11T06:56:55Z,As the black and white would have just one matrix instead of three the rows of X would be just 64*64 instead of 64*64*3.,2019-08-11T06:56:55Z
UgyuuzepYNwEN-bDROJ4AaABAg,@amaytrivedi3482,,1,eqEc66RFY0I,6,2,2018-07-20T02:16:58Z,"Why did we use 64*64*3 , what about the last matrix of 64*64(Blue)?",2018-07-20T02:16:58Z
UgyuuzepYNwEN-bDROJ4AaABAg.8iuRL-W73Vg8iwZEELhFRL,@sultanedip,UgyuuzepYNwEN-bDROJ4AaABAg,2,eqEc66RFY0I,0,1,2018-07-20T22:04:26Z,"3 represents 3 colors, red, green, blue. he just wrote some red and green color codes as example as I understand",2018-07-20T22:04:26Z
UgyuuzepYNwEN-bDROJ4AaABAg.8iuRL-W73Vg8pGUfaf2bLv,@saanvisharma2081,UgyuuzepYNwEN-bDROJ4AaABAg,2,eqEc66RFY0I,0,0,2018-12-25T04:17:02Z,@@kamalsidhu5888 that&#39;s the right explanation...:-),2018-12-25T04:17:02Z
UgyuuzepYNwEN-bDROJ4AaABAg.8iuRL-W73Vg8pgu-gH1kNa,@random4573,UgyuuzepYNwEN-bDROJ4AaABAg,2,eqEc66RFY0I,0,2,2019-01-04T19:46:35Z,( 64√ó64 ) x 3 matrices,2019-01-04T19:47:00Z
UgyuuzepYNwEN-bDROJ4AaABAg.8iuRL-W73Vg8sW3m5MLi_d,@chitralalawat8106,UgyuuzepYNwEN-bDROJ4AaABAg,2,eqEc66RFY0I,0,2,2019-03-15T19:04:01Z,Hey! Looks like you&#39;re seriously understanding what the speaker is saying.. Could you please help me with this... I want you to join my group so that we all can study further ..!!,2019-03-15T19:04:01Z
UgyuuzepYNwEN-bDROJ4AaABAg.8iuRL-W73Vg8utIcm9adtA,@user-rt8dy4zb4h,UgyuuzepYNwEN-bDROJ4AaABAg,2,eqEc66RFY0I,0,0,2019-05-13T21:58:22Z,@@chitralalawat8106 . . . Group ?,2019-05-13T21:58:22Z
Ugw589KVwIGTcn4a2BR4AaABAg,@StarContract,,1,eqEc66RFY0I,1,14,2018-02-21T15:15:44Z,"Be blessed sir, such a cool concept",2018-02-21T15:15:44Z
Ugw589KVwIGTcn4a2BR4AaABAg.8cwA0R1e7Sf8dwdVW12mQS,@Horopter,Ugw589KVwIGTcn4a2BR4AaABAg,2,eqEc66RFY0I,0,0,2018-03-18T16:13:30Z,Did you find any accompanying code?,2018-03-18T16:13:30Z
Ugz7mBqFERX3dJpnmLN4AaABAg,@negiankur_,,1,hjrYrynGWGA,0,1,2023-01-25T14:39:02Z,had to re watch it 10 times to understand it,2023-01-25T14:39:02Z
Ugz9Yk1ZfFBfAe70qM54AaABAg,@ibrahemnasser2744,,1,hjrYrynGWGA,0,0,2022-08-16T03:22:29Z,Why he is multiplying by weight transpose?,2022-08-16T03:22:29Z
UgzMhlDKcTvEhTw7tUl4AaABAg,@machinistnick2859,,1,hjrYrynGWGA,0,0,2021-01-16T15:05:10Z,Thanks sir,2021-01-16T15:05:10Z
Ugyk9-m1SSRGJqqAqaB4AaABAg,@sandipansarkar9211,,1,hjrYrynGWGA,1,3,2020-12-13T18:39:21Z,Very important .Please make notes,2020-12-13T18:39:21Z
Ugyk9-m1SSRGJqqAqaB4AaABAg.9HDOu_v1oeb9ScFrLmhkO1,@thepresistence5935,Ugyk9-m1SSRGJqqAqaB4AaABAg,2,hjrYrynGWGA,0,0,2021-09-23T05:25:51Z,ok,2021-09-23T05:25:51Z
UgyhU2HmXlrWidN4COV4AaABAg,@codewebsduh2667,,1,hjrYrynGWGA,0,3,2020-10-25T08:44:31Z,"Jesus , going from a physics background to AI is so easy.",2020-10-25T08:44:31Z
UgylhXmXqj5Md-bOO1t4AaABAg,@papayaspice1155,,1,hjrYrynGWGA,2,36,2020-07-10T19:15:52Z,"to anyone finding it difficult, here&#39;s my understanding of it:<br><br>in the equation, y^ = sigmoid(wT ‚Ä¢ x + b)<br><br>x represents a matrix of weights of nx dimension. example,<br>x = [<br>x0,<br>x1,<br>...,<br>xn]<br><br>w represents a matrix of weights, which also has the same dimensions as x, i.e. nx. example,<br>w = [<br>w0,<br>w1,<br>...,<br>wn]<br><br>wT represents the transpose of w. a transpose operation on a matrix means swapping the columns with rows, and rows with columns. so, wT would look like,<br><br>wT = [w0, w1, ..., wn]<br><br>the reason we take the transpose of w and multiply it with x is because whenever two arrays, one of order (1, x) and another of order (x, 1) are multiplied together, the output is a single number (matrix with order 1x1) instead of another matrix.<br><br>b, here, represents the bias.<br><br>p.s.: correct me if im wrong, please!",2020-07-10T19:15:52Z
UgylhXmXqj5Md-bOO1t4AaABAg.9Awm4W7En1i9ScFkG_rTFf,@thepresistence5935,UgylhXmXqj5Md-bOO1t4AaABAg,2,hjrYrynGWGA,0,0,2021-09-23T05:24:53Z,"Thankyou so much for crystal and clear explanation, I got some difficulty to understand this, Now I am clear. Thanks",2021-09-23T05:24:53Z
UgylhXmXqj5Md-bOO1t4AaABAg.9Awm4W7En1i9em2cby3Lw0,@ibrahemnasser2744,UgylhXmXqj5Md-bOO1t4AaABAg,2,hjrYrynGWGA,0,4,2022-08-16T03:30:47Z,"Multiplying x which is lets say a 3*1 matrix <br>[x1,<br>x2,<br>x3]<br>By the weight vector which is also 3*1<br>[w1,<br>w2,<br>w3]<br><br>Is not valid. So he transposed W to be 1*3 but now the result is 3*3 matrix!!!<br><br>What is that??<br><br>We just need to dot product each x with the corresponding weight to get the final y hat.",2022-08-16T03:30:47Z
UgwYnntJIO9yHcBVX7N4AaABAg,@stevenkim6869,,1,hjrYrynGWGA,0,0,2020-07-02T16:19:20Z,"if you need help understanding the basics, check out StatQuest, with Josh Starmer.  so many difficult concepts explained beautifully.",2020-07-02T16:19:20Z
UgwlNpVn7KGk2gG0iP54AaABAg,@TheEducationWorldUS,,1,hjrYrynGWGA,0,0,2020-04-15T06:50:51Z,Great video,2020-04-15T06:50:51Z
UgyaroREWo9ND_bNngh4AaABAg,@JesseNerio,,1,hjrYrynGWGA,0,1,2020-02-16T19:41:11Z,Why is the sigmoid curve so commonly used for predicting probabilities in logistic regression? Can&#39;t I just use a standard wx+b and cut it at the domain? I could just use that value and round it up to the labels?,2020-02-16T19:41:11Z
UgwwXqvESe84qu_P_lF4AaABAg,@suhaneshivam82,,1,hjrYrynGWGA,0,0,2019-11-21T13:38:21Z,Why don&#39;t we the sign of expression w.x+b to determine whether images is of cat or not.Infact if w.x+b&gt;0 then sigmoid function would pridict is as cat with probability greater than 0.5 and if w.x+b&lt;0 it will predict it as cat with probability less than 0.5 so why don&#39;t we use directly the value of w.x+b instead of applying sigmoidal function.,2019-11-21T13:38:21Z
Ugzav_rxidHRyoRKP-54AaABAg,@BrianSmith-cw7mr,,1,hjrYrynGWGA,3,1,2019-10-13T23:40:23Z,anyone know how or why the transpose of w is used instead of just w ?,2019-10-13T23:40:23Z
Ugzav_rxidHRyoRKP-54AaABAg.902RvlHmlRS90_zt3TYDyC,@cvnikita1,Ugzav_rxidHRyoRKP-54AaABAg,2,hjrYrynGWGA,0,2,2019-10-27T09:40:01Z,"w is a vector with n-x dimensions. by using the transpose we can do &#39;dot product&#39; and obtain a scalar value wtx, which as is shown is used with +b to derive z. Do look up dot product rules and it will be clearer. <br><br>We could also use the transpose of x instead, then we keep w as is. (But all the training data was laid out with x vectors so we&#39;d have to change /adapt all of the training vectors. )",2019-10-27T09:40:01Z
Ugzav_rxidHRyoRKP-54AaABAg.902RvlHmlRS90bm6xmH4Ta,@BrianSmith-cw7mr,Ugzav_rxidHRyoRKP-54AaABAg,2,hjrYrynGWGA,0,0,2019-10-28T02:18:12Z,"@@cvnikita1 Thank you for the answer!  Although currently I do not possess a full intuitive understaning, I&#39;d humbly propose a concise explanation of why a transpose exists at the start is because transpose calculates the minimum error, specifically the minimum least squares.  Interested readers can check out this link for a first-principles understanding: <a href=""http://mlwiki.org/index.php/OLS_Regression"">http://mlwiki.org/index.php/OLS_Regression</a>",2019-10-28T02:18:12Z
Ugzav_rxidHRyoRKP-54AaABAg.902RvlHmlRS96Rx5eW7jDQ,@cvnikita1,Ugzav_rxidHRyoRKP-54AaABAg,2,hjrYrynGWGA,0,0,2020-03-21T00:30:52Z,"@@mohamedabdelhakeem9923 b is bias. It is a constant. So while w is a variable that tells us the gradient of the line, b tells us something about the y intercept.",2020-03-21T00:30:52Z
Ugzyd4nlKoZEA_4DTzt4AaABAg,@coolamigo00,,1,hjrYrynGWGA,2,1,2019-07-28T14:13:25Z,"As per my understanding developed, sigmoid applied to linear regression makes it logistic. Q1 am I right? Q2 what if a different Activation function was used? I mean, would it still be called logistic regression.",2019-07-28T14:13:25Z
Ugzyd4nlKoZEA_4DTzt4AaABAg.8xw9pp_x3S28zzs-ICCApk,@rickjamesbtch9417,Ugzyd4nlKoZEA_4DTzt4AaABAg,2,hjrYrynGWGA,0,1,2019-09-17T17:48:34Z,"I don&#39;t think it makes sense to use any other function, as sigmoid function fluctuates between 1 and 0 which makes it best option for the problem. You technically can use anything you want but the result won&#39;t make any sense. Think about it in this way: Why would you try to hammer a nail with a ruler instead of hammer? Doesn&#39;t mean ruler is useless, it simply means it is not fit for the purpose, as hammer is the appropriate tool in this case.¬†<br>Think about probability, probability (in this specific case) is between 0% and 100%, which is same as 0 and 1. For example, 10% probably = 0.10, 20% = 0.20, 50% = 0.5 and 100% = 1. That&#39;s why you use sigmoid function. Correct me if I&#39;m wrong.",2019-09-17T17:58:14Z
Ugzyd4nlKoZEA_4DTzt4AaABAg.8xw9pp_x3S298hH05dSsw6,@Rofl890,Ugzyd4nlKoZEA_4DTzt4AaABAg,2,hjrYrynGWGA,0,1,2020-05-16T01:44:15Z,"@@rickjamesbtch9417 I don&#39;t think that&#39;s right, I don&#39;t know about coolamigo&#39;s question about if they breaks the terminology or not, but you can use different activation methods for such problems and still get &quot;right&quot; answers; some will just arrive at the answer quicker. Try it for yourself, try the different activations on a regression problem and you&#39;ll see it really only affects the speed: <a href=""http://playground.tensorflow.org/"">http://playground.tensorflow.org/</a>",2020-05-16T01:44:15Z
Ugy0hJjwGLpBcAUZWZh4AaABAg,@thedrei24,,1,hjrYrynGWGA,1,1,2019-03-22T22:34:48Z,"hey, thanks for the content, ver helpful. I wanna add one thing, could you please add more musicality in your voice? I find it very hard to focus because the tonality is the same regardless of the emphasis :)",2019-03-22T22:34:48Z
Ugy0hJjwGLpBcAUZWZh4AaABAg.8snTT-hZGpa9ScFqEPa7Pl,@thepresistence5935,Ugy0hJjwGLpBcAUZWZh4AaABAg,2,hjrYrynGWGA,0,0,2021-09-23T05:25:42Z,I got already sleep,2021-09-23T05:25:42Z
Ugyx9OCrMnXbp8MG3y14AaABAg,@sownikturaga800,,1,hjrYrynGWGA,1,1,2019-01-07T17:09:01Z,why order of w matrix is nx X 1 and y^ = wT . X + b why not order be 1 X nx and y^ = w . X + b. I think both are same. Then why cant we use the 2nd notation. Please clarify my doubt.,2019-01-07T17:09:01Z
Ugyx9OCrMnXbp8MG3y14AaABAg.8poLM7EZsym8tAgVweVuGW,@samuelnittala3791,Ugyx9OCrMnXbp8MG3y14AaABAg,2,hjrYrynGWGA,0,0,2019-04-01T08:19:18Z,Order of w and X must be same,2019-04-01T08:19:18Z
UgxD6y2XHjSNdN8d-QF4AaABAg,@sownikturaga800,,1,hjrYrynGWGA,1,3,2019-01-07T16:56:47Z,what are the initial values of w and b... ??,2019-01-07T16:56:47Z
UgxD6y2XHjSNdN8d-QF4AaABAg.8poJxcBBVpa90a1O9dlOge,@nikitasinhal489,UgxD6y2XHjSNdN8d-QF4AaABAg,2,hjrYrynGWGA,0,0,2019-10-27T10:01:53Z,"any values to start with, or use zero for convenience. his gradient descent lecture explains more.",2019-10-27T10:01:53Z
Ugyt1hYPgnn7Xtboect4AaABAg,@saanvisharma2081,,1,hjrYrynGWGA,2,4,2018-12-19T17:23:39Z,I found this video/lesson is more easier than previous one!!!,2018-12-19T17:23:39Z
Ugyt1hYPgnn7Xtboect4AaABAg.8p2RvlmWHUs8ugmstTjyQa,@saanvisharma2081,Ugyt1hYPgnn7Xtboect4AaABAg,2,hjrYrynGWGA,0,1,2019-05-09T01:21:20Z,Back here to revise,2019-05-09T01:21:20Z
Ugyt1hYPgnn7Xtboect4AaABAg.8p2RvlmWHUs9ScFn4uzrGj,@thepresistence5935,Ugyt1hYPgnn7Xtboect4AaABAg,2,hjrYrynGWGA,0,0,2021-09-23T05:25:16Z,@@saanvisharma2081 I don&#39;t understand,2021-09-23T05:25:16Z
UgzfALA7v0Ze-xAxggJ4AaABAg,@ashu2205,,1,hjrYrynGWGA,3,2,2018-12-11T08:58:00Z,"<a href=""http://goo.gl/fswf"">goo.gl/fswf</a>",2018-12-11T08:58:00Z
UgzfALA7v0Ze-xAxggJ4AaABAg.8ohwhCMLz-f8ok3zsP-RuW,@ashu2205,UgzfALA7v0Ze-xAxggJ4AaABAg,2,hjrYrynGWGA,0,0,2018-12-12T04:48:56Z,testing youtube api,2018-12-12T04:48:56Z
UgzfALA7v0Ze-xAxggJ4AaABAg.8ohwhCMLz-f8p2SPj8BHak,@ashu2205,UgzfALA7v0Ze-xAxggJ4AaABAg,2,hjrYrynGWGA,0,0,2018-12-19T17:27:53Z,@@saanvisharma2081 thanks for what?,2018-12-19T17:27:53Z
UgzfALA7v0Ze-xAxggJ4AaABAg.8ohwhCMLz-f9ADNVKne42H,@smmaersama8497,UgzfALA7v0Ze-xAxggJ4AaABAg,2,hjrYrynGWGA,0,0,2020-06-22T18:47:16Z,what is that,2020-06-22T18:47:16Z
UgzwQTMZX5WqWF69tp94AaABAg,@karatjin6417,,1,hjrYrynGWGA,0,17,2018-09-02T03:09:25Z,"hmm, this is getting difficult...",2018-09-02T03:09:25Z
UgwRNfiwc51EUSnEslh4AaABAg,@degenerategambler69,,1,hjrYrynGWGA,0,11,2018-07-10T18:13:52Z,"i have messed up , my logistic regression became autistic regression",2018-07-10T18:21:10Z
UgxC-9s9lpbS36rJdhl4AaABAg,@LHM1226,,1,hjrYrynGWGA,1,1,2018-06-27T16:06:52Z,Is that equal to w¬∑x.,2018-06-27T16:06:52Z
UgxC-9s9lpbS36rJdhl4AaABAg.8i-h1BkdKz_8kMxiPWth3u,@trouserpython3857,UgxC-9s9lpbS36rJdhl4AaABAg,2,hjrYrynGWGA,0,4,2018-08-25T09:58:01Z,Bro...,2018-08-25T09:58:01Z
Ugx0ghU2hrTS1oYsYrF4AaABAg,@suharsh96,,1,hjrYrynGWGA,1,1,2018-04-07T21:54:44Z,not hotdog,2018-04-07T21:54:44Z
Ugx0ghU2hrTS1oYsYrF4AaABAg.8ekkSAVRHIN8iYtSL6UqZZ,@sametyildizeli,Ugx0ghU2hrTS1oYsYrF4AaABAg,2,hjrYrynGWGA,0,0,2018-07-11T08:08:50Z,Erlich is a liar,2018-07-11T08:08:50Z
UgxOKRE1-RxvUS2GrOF4AaABAg,@mukunthag8760,,1,SHEPb1JHw5o,0,2,2022-01-01T12:20:16Z,He is an extremely good teacher!,2022-01-01T12:20:16Z
UgysbBIFKbFNUwH02vd4AaABAg,@1052boon,,1,SHEPb1JHw5o,0,0,2021-07-27T09:50:36Z,ÏÑ§Î™Ö Í∞êÏÇ¨Ìï©ÎãàÎã§:),2021-07-27T09:50:36Z
Ugxaem0N94Jiq7R6vll4AaABAg,@sharmakartikeya,,1,SHEPb1JHw5o,0,3,2021-07-12T11:31:00Z,"At <a href=""https://www.youtube.com/watch?v=SHEPb1JHw5o&amp;t=4m15s"">4:15</a>, sir mistakenly says that we need to have -log(y_hat) as big as possible. It is the opposite. After all -log(y_hat) is itself the cost function for some y_hat and y = 1.<br>So for - log(y_hat) to be as small as possible (for y = 1) we would want log(y_hat) to be as large as possible. For this we would want y_hat to be as large as possible (Remember the graph of log x, it is a monotonically increasing curve). Remember that y_hat is nothing but the probability (our model produces) of y=1 for some weights and bias, so y_hat can never be greater than 1. So we want our y_hat to be as close to 1 as possible.",2021-07-12T11:31:00Z
UgzMDLB0fG5Wmrn0-254AaABAg,@iammakimadog,,1,SHEPb1JHw5o,2,1,2021-03-18T14:54:16Z,"<a href=""https://www.youtube.com/watch?v=SHEPb1JHw5o&amp;t=2m27s"">2:27</a> technically you can still use MSE because MSE is convex",2021-03-18T14:54:44Z
UgzMDLB0fG5Wmrn0-254AaABAg.9L1bf3Rv2Hh9dhfhaLKR8f,@andretelfer3678,UgzMDLB0fG5Wmrn0-254AaABAg,2,SHEPb1JHw5o,0,0,2022-07-20T14:13:23Z,I am struggling to understand this too... I hope this comes up in a later video,2022-07-20T14:13:23Z
UgzMDLB0fG5Wmrn0-254AaABAg.9L1bf3Rv2Hh9sjWcohiEn6,@e.galois4940,UgzMDLB0fG5Wmrn0-254AaABAg,2,SHEPb1JHw5o,0,0,2023-07-29T03:14:45Z,"Nah, squared error is not convex for sigmoid function bro",2023-07-29T03:14:45Z
Ugzrr_GSb1QHAM7sahp4AaABAg,@louerleseigneur4532,,1,SHEPb1JHw5o,0,0,2021-01-18T15:18:40Z,Thanks god<br>Thanks sir,2021-01-18T15:18:55Z
Ugxg3HBEMui7_UUkTT14AaABAg,@meirgoldenberg5638,,1,SHEPb1JHw5o,0,0,2021-01-13T21:11:27Z,"At <a href=""https://www.youtube.com/watch?v=SHEPb1JHw5o&amp;t=7m54s"">7:54</a>, Andrew says that the next video would show that logistic regression can be viewed as a small neural net. However, the next video does not seem to fulfill this promise.",2021-01-13T21:11:27Z
Ugy66ak8an40D04_ivR4AaABAg,@sandipansarkar9211,,1,SHEPb1JHw5o,0,0,2020-12-13T18:49:40Z,need to make notes,2020-12-13T18:49:40Z
UgxGdmIoBaN89DGQiWt4AaABAg,@ahasanhabibsajeeb1979,,1,SHEPb1JHw5o,0,0,2020-10-21T03:45:46Z,Why don‚Äôt i understand you?,2020-10-21T03:45:46Z
UgyoEPQFAvwyAh6ZHSJ4AaABAg,@syahirdev3193,,1,SHEPb1JHw5o,0,0,2020-10-02T11:01:00Z,my brain hurts...,2020-10-02T11:01:00Z
UgwQ6R5fV45vKuuGYCR4AaABAg,@zs9510,,1,SHEPb1JHw5o,0,0,2020-09-22T01:53:23Z,Explained very well.,2020-09-22T01:53:23Z
Ugw7bEUVsjFkzpfyzCd4AaABAg,@hunter330,,1,SHEPb1JHw5o,2,46,2020-06-28T13:54:49Z,"At <a href=""https://www.youtube.com/watch?v=SHEPb1JHw5o&amp;t=4m15s"">4:15</a>, Andrew should say that we want -ylog(y_hat) &quot;as small as possible&quot; instead of &quot;as big as possible&quot;. Source: His notes on Coursera.",2020-06-28T13:54:49Z
Ugw7bEUVsjFkzpfyzCd4AaABAg.9ASInVaDaZI9JuH85DoIsC,@khaledadrani3184,Ugw7bEUVsjFkzpfyzCd4AaABAg,2,SHEPb1JHw5o,0,0,2021-02-18T12:40:48Z,+1,2021-02-18T12:40:48Z
Ugw7bEUVsjFkzpfyzCd4AaABAg.9ASInVaDaZI9xglfF5h2ec,@mahsa5527,Ugw7bEUVsjFkzpfyzCd4AaABAg,2,SHEPb1JHw5o,0,0,2023-11-29T08:14:08Z,"No, we have a minus before log(y~) and this should be the max if we want to make the value of the loss function minimum.",2023-11-29T08:14:08Z
UgyQRI31037XzazxoUF4AaABAg,@Morpho32,,1,SHEPb1JHw5o,1,5,2020-06-19T15:24:18Z,"At <a href=""https://www.youtube.com/watch?v=SHEPb1JHw5o&amp;t=4m20s"">4:20</a>, he says &quot;we want -log(y hat) to be as big as possible&quot;. That&#39;s not true, we want to be as small as possible since it&#39;s the loss function and that&#39;s why we want y_hat to be as big as possible so that actually -log(y_hat) is as small as possible.",2020-06-19T15:24:18Z
UgyQRI31037XzazxoUF4AaABAg.9A5Ht3VkZTT9OJFs0mIGi6,@morancium,UgyQRI31037XzazxoUF4AaABAg,2,SHEPb1JHw5o,0,0,2021-06-08T00:55:34Z,i think you messed up with negative sign,2021-06-08T00:55:34Z
UgxSs7A3BFHzpkitkV54AaABAg,@skypickle29,,1,SHEPb1JHw5o,1,0,2020-03-08T23:48:28Z,"@:22 we use Wtranspose. Why transpose? The first sample is a column vector. How is W defined? Isn&#39;t it a column vector as well in which case you only need to multiply x*W , not W transpose.?",2020-03-08T23:48:28Z
UgxSs7A3BFHzpkitkV54AaABAg.95xyhb8V3u49Awo1-O8N1W,@papayaspice1155,UgxSs7A3BFHzpkitkV54AaABAg,2,SHEPb1JHw5o,0,0,2020-07-10T19:32:52Z,explained in a comment on the previous video,2020-07-10T19:32:52Z
Ugzmim8UJx2NlWMdU6B4AaABAg,@prafulbs7216,,1,SHEPb1JHw5o,1,0,2020-02-22T14:25:46Z,could someone explain dimension of weight matrix?,2020-02-22T14:25:46Z
Ugzmim8UJx2NlWMdU6B4AaABAg.95LLO89rtbg9Awnzbaaamj,@papayaspice1155,Ugzmim8UJx2NlWMdU6B4AaABAg,2,SHEPb1JHw5o,0,0,2020-07-10T19:32:32Z,explained in a comment on fhet video before this one,2020-07-10T19:32:32Z
UgyJapG-IL9pQE0q4ed4AaABAg,@prafulbs7216,,1,SHEPb1JHw5o,1,4,2020-02-14T16:24:44Z,what is difference Y^(y hat) and y ?,2020-02-14T16:24:44Z
UgyJapG-IL9pQE0q4ed4AaABAg.950xdQ6k_Yj958WAuvj23M,@nikilkumarr,UgyJapG-IL9pQE0q4ed4AaABAg,2,SHEPb1JHw5o,0,14,2020-02-17T14:49:57Z,"y hat is the predicted value (as calculated from the logistic regression model) while y is the actual value (or value of the label). Pretty much, the error is the difference between what the model predicts and the actual value :)",2020-02-17T14:49:57Z
UgweMrnlOr92nExUFVJ4AaABAg,@rameshmaddali6208,,1,SHEPb1JHw5o,0,2,2019-04-16T13:43:30Z,Best video on loss and cost function explanation,2019-04-16T13:43:30Z
UgyAiIq5fdO5Lv7MclV4AaABAg,@ashwinilalawat604,,1,SHEPb1JHw5o,1,0,2019-03-15T18:49:08Z,Yes,2019-03-15T18:49:08Z
UgyAiIq5fdO5Lv7MclV4AaABAg.8sW242ArtVO8sW2WmXDCCr,@ashwinilalawat604,UgyAiIq5fdO5Lv7MclV4AaABAg,2,SHEPb1JHw5o,0,0,2019-03-15T18:53:03Z,No,2019-03-15T18:53:03Z
Ugwqw0ouYYSkKq573Kt4AaABAg,@susnatodhar7197,,1,SHEPb1JHw5o,2,0,2019-01-09T15:38:14Z,can someone tell me what is &#39;e&#39;?,2019-01-09T15:38:14Z
Ugwqw0ouYYSkKq573Kt4AaABAg.8ptKZ1LkYaw8qAIxbu0asw,@caducoelho2221,Ugwqw0ouYYSkKq573Kt4AaABAg,2,SHEPb1JHw5o,0,1,2019-01-16T15:10:35Z,e is the Euler&#39;s number.,2019-01-16T15:10:35Z
Ugwqw0ouYYSkKq573Kt4AaABAg.8ptKZ1LkYaw8qAJ0JDn2Bj,@caducoelho2221,Ugwqw0ouYYSkKq573Kt4AaABAg,2,SHEPb1JHw5o,0,1,2019-01-16T15:11:05Z,"<a href=""https://www.mathsisfun.com/numbers/e-eulers-number.html"">https://www.mathsisfun.com/numbers/e-eulers-number.html</a>",2019-01-16T15:11:05Z
UgwVUeRTX8lI4i_sbmR4AaABAg,@ramazancesur6143,,1,SHEPb1JHw5o,1,1,2018-10-28T10:16:39Z,this course is very great which beginner level for all  in neural network course,2018-10-28T10:16:39Z
UgwVUeRTX8lI4i_sbmR4AaABAg.8mwmiqDEqUA8sW3RUrLp2y,@chitralalawat8106,UgwVUeRTX8lI4i_sbmR4AaABAg,2,SHEPb1JHw5o,0,0,2019-03-15T19:01:04Z,Hey! Looks like you&#39;re seriously understanding what the speaker is saying.. Could you please help me with this... I want you to join my group so that we all can study further ..!!,2019-03-15T19:01:04Z
Ugx_qnyX27zNrjfGdV54AaABAg,@StarContract,,1,SHEPb1JHw5o,5,7,2018-02-21T15:33:57Z,A neural network is trying to figure out how neural networks work at the moment.,2018-02-21T15:33:57Z
Ugx_qnyX27zNrjfGdV54AaABAg.8cwC5qcYTkM8r85IexsFIt,@doubtunites168,Ugx_qnyX27zNrjfGdV54AaABAg,2,SHEPb1JHw5o,0,0,2019-02-09T15:04:10Z,how is your loss function so far?,2019-02-09T15:04:10Z
Ugx_qnyX27zNrjfGdV54AaABAg.8cwC5qcYTkM8sW3abjd-RQ,@chitralalawat8106,Ugx_qnyX27zNrjfGdV54AaABAg,2,SHEPb1JHw5o,0,0,2019-03-15T19:02:27Z,Hey! Looks like you&#39;re seriously understanding what the speaker is saying.. Could you please help me with this... I want you to join my group so that we all can study further ..!!,2019-03-15T19:02:27Z
Ugx_qnyX27zNrjfGdV54AaABAg.8cwC5qcYTkM8ws6lrxZEzi,@abhinavkommula4588,Ugx_qnyX27zNrjfGdV54AaABAg,2,SHEPb1JHw5o,0,2,2019-07-02T03:58:18Z,@@chitralalawat8106 stop trolling please,2019-07-02T03:58:18Z
Ugx_qnyX27zNrjfGdV54AaABAg.8cwC5qcYTkM8ws9rNl2evR,@chitralalawat8106,Ugx_qnyX27zNrjfGdV54AaABAg,2,SHEPb1JHw5o,0,0,2019-07-02T04:25:16Z,@@abhinavkommula4588 you mind ur own business,2019-07-02T04:25:16Z
Ugx_qnyX27zNrjfGdV54AaABAg.8cwC5qcYTkM8wsAoJrTMF8,@abhinavkommula4588,Ugx_qnyX27zNrjfGdV54AaABAg,2,SHEPb1JHw5o,0,2,2019-07-02T04:33:36Z,‚Äã@@chitralalawat8106 oKay bUdDY mInd tHe tOxIciTy yEaH?,2019-07-02T04:33:36Z
UgzYRVVDnjSWo4kJwKF4AaABAg,@rahulkumar-xl9pt,,1,SHEPb1JHw5o,6,1,2018-01-26T11:39:20Z,Why does the log function need to be large when y is both 0 or 1?,2018-01-26T11:39:20Z
UgzYRVVDnjSWo4kJwKF4AaABAg.8bsp_m3Tu2T8e-jRM9_7eJ,@kangzheng1390,UgzYRVVDnjSWo4kJwKF4AaABAg,2,SHEPb1JHw5o,0,0,2018-03-20T06:22:20Z,rahul kumar they are two different cases.,2018-03-20T06:22:20Z
UgzYRVVDnjSWo4kJwKF4AaABAg.8bsp_m3Tu2T8fXADWFj2HD,@sebastianrodriguezcolina634,UgzYRVVDnjSWo4kJwKF4AaABAg,2,SHEPb1JHw5o,0,2,2018-04-27T02:31:26Z,what you want is that your cost function is large when your prediction is far from the true value,2018-04-27T02:31:26Z
UgzYRVVDnjSWo4kJwKF4AaABAg.8bsp_m3Tu2T8sW3Y6OBK-Y,@chitralalawat8106,UgzYRVVDnjSWo4kJwKF4AaABAg,2,SHEPb1JHw5o,0,0,2019-03-15T19:01:58Z,Hey! Looks like you&#39;re seriously understanding what the speaker is saying.. Could you please help me with this... I want you to join my group so that we all can study further ..!!,2019-03-15T19:01:58Z
UgzYRVVDnjSWo4kJwKF4AaABAg.8bsp_m3Tu2T9--C2_tDHbN,@justin119933,UgzYRVVDnjSWo4kJwKF4AaABAg,2,SHEPb1JHw5o,0,1,2019-09-17T20:52:31Z,"so as to keep the loss function as small as possible on both scenarios. (check the writing in green on the video at  <a href=""https://www.youtube.com/watch?v=SHEPb1JHw5o&amp;t=5m42s"">5:42</a>)",2019-09-17T21:04:52Z
UgzYRVVDnjSWo4kJwKF4AaABAg.8bsp_m3Tu2T9-PWzSnrUaa,@zhilinglin4648,UgzYRVVDnjSWo4kJwKF4AaABAg,2,SHEPb1JHw5o,0,0,2019-09-28T02:15:43Z,"Hi I also have the same question and finally sort it out after reading this post. <a href=""https://towardsdatascience.com/optimization-loss-function-under-the-hood-part-ii-d20a239cde11"">https://towardsdatascience.com/optimization-loss-function-under-the-hood-part-ii-d20a239cde11</a>",2019-09-28T02:15:43Z
UgwgkVKKlKSrmVceu3Z4AaABAg,@uqyge,,1,SHEPb1JHw5o,1,5,2017-09-09T08:28:40Z,great intro course,2017-09-09T08:28:40Z
UgwgkVKKlKSrmVceu3Z4AaABAg.8XH_GadjRYn8sW3_0c7rZ2,@chitralalawat8106,UgwgkVKKlKSrmVceu3Z4AaABAg,2,SHEPb1JHw5o,0,0,2019-03-15T19:02:14Z,Hey! Looks like you&#39;re seriously understanding what the speaker is saying.. Could you please help me with this... I want you to join my group so that we all can study further ..!!,2019-03-15T19:02:14Z
Ugz9aqPAyeKfGotlnJN4AaABAg,@codingwithsam4992,,1,uJryes5Vk1o,0,0,2023-09-10T16:19:54Z,It&#39;s so amazing that what humans are thinking danger to them is nothing but a minimization problem of calculus üòÜ,2023-09-10T16:19:54Z
UgyNYthAihbc5oF8Tg94AaABAg,@user-bd8jb7ln5g,,1,uJryes5Vk1o,0,0,2023-08-12T22:43:33Z,"I&#39;ve not seen calculus/linear algebra/etc in 25 years, but your explanations are easily digestible",2023-08-12T22:43:33Z
UgzyPMdnzPxaVBo41xp4AaABAg,@classicalfandom8219,,1,uJryes5Vk1o,0,0,2023-04-06T14:28:05Z,"I think if you guys don&#39;t know about calculus, you should take a khan academy course and look some 3Blue1Brown videos for better understanding of what Andrew is trying to make us understand in  Gradient Descent and why we want to go to that valley bottom in the graph",2023-04-06T14:28:05Z
Ugy-jBW1sy_OGZKycMx4AaABAg,@mr.shroom4280,,1,uJryes5Vk1o,0,0,2023-03-05T07:05:21Z,"I have a question, when we are doing gradient descent on a higher level of complexity, so there is like more than 4 weights and biases, is gradient descent going to have to be applied to all of them individually? How is the derivative of the function with respect to some variable going to be calculated dynamically?, I know that there is around this, there must be, I just don&#39;t know what it is. Because all the tutorials im seeing on uni or bivariate gradient descent.",2023-03-05T07:05:21Z
Ugyu51VtMXrg2-H5M-R4AaABAg,@RAJIBLOCHANDAS,,1,uJryes5Vk1o,1,0,2022-06-10T06:13:09Z,"I tried to provide detailed discussion on Gradient Descent Algorithm.   Link:      <a href=""https://youtu.be/TbEpx8j6Vgo"">https://youtu.be/TbEpx8j6Vgo</a>",2022-06-10T06:13:09Z
Ugyu51VtMXrg2-H5M-R4AaABAg.9c4oxAOCYG19c4pD_jgFY0,@RAJIBLOCHANDAS,Ugyu51VtMXrg2-H5M-R4AaABAg,2,uJryes5Vk1o,0,0,2022-06-10T06:15:31Z,Your lectures are really useful. Thanks for uploading your lectures on YouTube.,2022-06-10T06:15:31Z
Ugxf_t211KXMzGq8I-t4AaABAg,@arthurkalb1817,,1,uJryes5Vk1o,0,2,2022-04-23T01:51:18Z,"Use of the Del, instead of d, indicates that some variables are held constant. There is a huge difference. It&#39;s not insignificant.",2022-04-23T01:51:18Z
UgxYvAFis-DT6JkYmVp4AaABAg,@thepresistence5935,,1,uJryes5Vk1o,1,3,2021-09-23T06:14:06Z,"If you don&#39;t understand here&#39;s my understanding<br><br>Gradient Descent:  Consider you&#39;re standing on top of the mountain, you want to come down to the ground( Global minima ). <br>You will take small, small steps to reach the Global minima. Not think like this( if I take a large step I will reach soon. If you took a large step you will step down and you will die).<br>Same here our Initial Loss function value is too high our ultimate aim is to bring down the loss function value to the Global minima (smallest value). For that, we will initialize some values with the gradient descent formula to bring down the value to small(not use the random weight initialization). <br><br>Thanks! <br>correct me if I am wrong.",2021-09-23T06:14:06Z
UgxYvAFis-DT6JkYmVp4AaABAg.9ScLNgWOOp29ZJCo5Fl93t,@abcxyz9723,UgxYvAFis-DT6JkYmVp4AaABAg,2,uJryes5Vk1o,0,2,2022-03-08T10:14:09Z,"The small steps are required because the global optimum is unknown. By stepping down small steps into the direction of biggest descent you approach the global optimum iteratively. If you took one large step into the direction of biggest descent at the beginning, you will likely end at some point that is not the optimum. The directions of biggest descent can change iteratively for each step you take.",2022-03-08T10:14:09Z
Ugw42bDWtujqOfYh2at4AaABAg,@youssefelamrani7905,,1,uJryes5Vk1o,1,0,2021-08-12T11:32:55Z,"when do we stop with gradient descent, is it when dJ/dw = 0?",2021-08-12T11:32:55Z
Ugw42bDWtujqOfYh2at4AaABAg.9QwlTxVZfjg9WF_zb9JfvC,@moein671,Ugw42bDWtujqOfYh2at4AaABAg,2,uJryes5Vk1o,0,0,2021-12-22T10:54:17Z,as we go further and further the derivative converges to zero and when it multiplies to learning rate it becomes almost zero,2021-12-22T10:54:17Z
UgzaX_QH8pAiIqKMWp54AaABAg,@ayushjangid,,1,uJryes5Vk1o,0,1,2021-07-28T09:26:37Z,isn&#39;t this gradient descent algorithm in one dimension like the newton&#39;s method to find roots,2021-07-28T09:26:37Z
Ugz24a9N0CzCqbLo0XR4AaABAg,@charlos1388,,1,uJryes5Vk1o,0,0,2021-07-16T11:09:09Z,"fancy d refers to partial derivatives or derivatives, while normal d refers to differential, that occurs to be the same when we&#39;re working in R.<br> The theta notation in previous video simplifies the gradient notation here, compacting both iterations for w and b, that are really one parameter in n+1 dimensions. I mean, if you&#39;re updating both parameters one after the other, why not update the parameter (w,b)? Is it maybe that the step lenght for w and b is not the same? Excuse me if this question is clarified later in the course.",2021-07-16T11:09:09Z
Ugyqh6O1hvu8Opmgd7h4AaABAg,@morancium,,1,uJryes5Vk1o,0,1,2021-06-08T02:21:30Z,"<a href=""https://www.youtube.com/watch?v=uJryes5Vk1o&amp;t=8m35s"">8:35</a> he got me there XD",2021-06-08T02:21:30Z
Ugx16pRMuZ41w1C7wiJ4AaABAg,@bpaudel2239,,1,uJryes5Vk1o,0,4,2021-05-20T18:01:00Z,The steepest route downhill might only be applicable if the optimisation is convex,2021-05-20T18:01:00Z
UgxbPTm5NIgXhDsYn2R4AaABAg,@manuel783,,1,uJryes5Vk1o,0,0,2021-01-18T19:14:42Z,"Clarification about Gradient Descent Video<br><br>Please note that in the video at the second slide, there is a missing parenthesis.  <br><br>The negative sign should apply to the entire cost function (both terms in the summation).<br><br>Also Andrew mentions: &quot;To make this easier to draw, I&#39;m going to ignore b for now, just to make this a one-dimensional plot instead of a high-dimensional plot.&quot;. This plot is actually two-dimensional, it shows the loss J(w) for values of w.",2021-01-18T19:15:16Z
Ugx2X75Ungp1RxEx7TN4AaABAg,@louerleseigneur4532,,1,uJryes5Vk1o,0,0,2021-01-18T16:08:04Z,Thanks sir,2021-01-18T16:08:04Z
UgzDic_rQtHbwlp-srN4AaABAg,@viswajeetkumar7977,,1,uJryes5Vk1o,0,2,2020-12-24T18:52:19Z,ARRAY BC ye kya BAWASIR hai be<br>NEURAL NETWORK padhay ai thay lauray MATHS<br>kyo padha rhay ho,2020-12-24T18:52:19Z
UgzYp5n7yQpU0RA53mB4AaABAg,@sandipansarkar9211,,1,uJryes5Vk1o,0,0,2020-12-15T18:32:45Z,great explanation,2020-12-15T18:32:45Z
UgzU10lSZJ9a6q9Dd4d4AaABAg,@williamgenetelli7334,,1,uJryes5Vk1o,0,1,2020-12-10T19:22:46Z,I would like to say thank you. I&#39;ve been looking for this for weeks and i now fully understand neurone network. This is helping me out so much for a University Project. So thank you !,2020-12-10T19:22:46Z
UgzjSsd88dE8KJ51FGB4AaABAg,@aayushpaudel2379,,1,uJryes5Vk1o,0,1,2020-08-23T09:31:11Z,"Now that I have gone through this lecture, I will worry about nothing in the days to come. ;)",2020-08-23T09:31:11Z
Ugwk5vg018OZdtnw3qF4AaABAg,@Lauschangreifer,,1,uJryes5Vk1o,2,1,2020-05-06T19:09:55Z,"I think, the symbol it&#39;s a cyrillic d for partial derivatives",2020-05-06T19:09:55Z
Ugwk5vg018OZdtnw3qF4AaABAg.98KOj0LXHCK9HjLUtsTwuP,@konstantinpluzhnikov4862,Ugwk5vg018OZdtnw3qF4AaABAg,2,uJryes5Vk1o,0,0,2020-12-26T13:44:26Z,Maybe it is a greek symbol. But it is also seldom used in Russian (cyrillic) language as lowercase d.,2020-12-26T13:44:26Z
Ugwk5vg018OZdtnw3qF4AaABAg.98KOj0LXHCK9HltMz2kOhr,@Lauschangreifer,Ugwk5vg018OZdtnw3qF4AaABAg,2,uJryes5Vk1o,0,0,2020-12-27T13:27:40Z,"@@konstantinpluzhnikov4862,  it is used as regular cyrillic small italic d, in many today&#39;s fonts so far I see, such as  Times, Arial etc. And I learned this in school, some decades ago ;-)",2020-12-27T13:27:40Z
Ugxel-zijMalUpQKB_h4AaABAg,@ibrahimyldrm2427,,1,uJryes5Vk1o,1,1,2019-10-11T22:13:53Z,"i have a question about cost function. at the first place, i really understood what we do by implementing gradient descent on cost function but then i am cƒ±nfused.let&#39;s say there is a some question like cost function. does it have always unique w,b value ?  in this case i don not have to use gradient descent? i know what is function and can find global minimum always",2019-10-11T22:13:53Z
Ugxel-zijMalUpQKB_h4AaABAg.9-y8RUjOQht92NNrQRwpr-,@rahulnirajsingh901,Ugxel-zijMalUpQKB_h4AaABAg,2,uJryes5Vk1o,0,5,2019-12-10T19:51:41Z,"yes it does have w,b unique values. you will get different cost function value  and aim is to minimize it, so that the error reduced to zero. i.e it reaches the global minimum.",2019-12-10T19:53:45Z
UgxaAwxwKW5Tn43oDyR4AaABAg,@nijhumreza9878,,1,uJryes5Vk1o,1,36,2019-09-05T07:13:43Z,it turns out that  you don&#39;t have to worry about anything,2019-09-05T07:13:43Z
UgxaAwxwKW5Tn43oDyR4AaABAg.8zUpntqM8v597tvn-wO1zg,@danielteixeira6497,UgxaAwxwKW5Tn43oDyR4AaABAg,2,uJryes5Vk1o,0,5,2020-04-26T03:08:49Z,"Andrew reached nirvana through coding, some next level stuff",2020-04-26T03:08:49Z
Ugw1Q2gCm20yZryT22B4AaABAg,@lemyul,,1,uJryes5Vk1o,0,0,2019-06-04T10:55:32Z,height,2019-06-04T10:55:32Z
Ugz8SjDyFNzmhfU7vA14AaABAg,@chitralalawat8106,,1,uJryes5Vk1o,2,0,2019-03-17T14:32:25Z,"Can&#39;t it be w+Alpha*dJ(w,b)/dw",2019-03-17T14:32:25Z
Ugz8SjDyFNzmhfU7vA14AaABAg.8s_jH_I0rxu9F2TLRJyQ7u,@srikanth1385,Ugz8SjDyFNzmhfU7vA14AaABAg,2,uJryes5Vk1o,0,0,2020-10-20T19:43:40Z,It is possible when the slope is negative,2020-10-20T19:43:40Z
Ugz8SjDyFNzmhfU7vA14AaABAg.8s_jH_I0rxu9FErmb3D3n9,@codewebsduh2667,Ugz8SjDyFNzmhfU7vA14AaABAg,2,uJryes5Vk1o,0,0,2020-10-25T15:16:52Z,"Because a derivative will determine the direction of the gradient as well. ie if the gradient&#39;s direction is increasing the gradient is positive , if it&#39;s decreasing our gradient is negative. Hence the negative sign , in front of the derivative, will simply reverse the direction we want to go each time.",2020-10-25T15:16:52Z
UgxjdkO_1jNRF-Dm4ml4AaABAg,@saanvisharma2081,,1,uJryes5Vk1o,5,1,2018-12-25T14:09:07Z,"What&#39;s the difference between loss function and cost function, in previous lecture he started with loss function and ended up cost function.",2018-12-25T14:09:07Z
UgxjdkO_1jNRF-Dm4ml4AaABAg.8pHYRCDLX7s8piYVGY7INL,@Video-Notes,UgxjdkO_1jNRF-Dm4ml4AaABAg,2,uJryes5Vk1o,0,7,2019-01-05T11:08:24Z,well  i think cost function basically is the mean of all the loss functions in your training set,2019-01-05T11:08:24Z
UgxjdkO_1jNRF-Dm4ml4AaABAg.8pHYRCDLX7s8qggolA_irq,@twinaibots5549,UgxjdkO_1jNRF-Dm4ml4AaABAg,2,uJryes5Vk1o,0,14,2019-01-29T14:22:46Z,"Basically, the loss function is used for a single training example but cost function is used for the entire training set.",2019-01-29T14:22:46Z
UgxjdkO_1jNRF-Dm4ml4AaABAg.8pHYRCDLX7s8t1YRXHgMSm,@fazilokuyanus3396,UgxjdkO_1jNRF-Dm4ml4AaABAg,2,uJryes5Vk1o,0,2,2019-03-28T19:06:53Z,"He has explained  at the previos vidoe; to better unterstand , i can suggest you to look at it",2019-03-28T19:06:53Z
UgxjdkO_1jNRF-Dm4ml4AaABAg.8pHYRCDLX7s8wDSSjeiDH5,@MrRenanwill,UgxjdkO_1jNRF-Dm4ml4AaABAg,2,uJryes5Vk1o,0,2,2019-06-15T23:39:42Z,"Cost function is sometimes called empirical risk, this name comes because of some other concept that arises in Machine Learling called expected risk which generalizes the idea of cost function of &quot;all possible training sets&quot;. Because of it I prefer call it empirical risk. =) Minimizing the cost function of &quot;all possible training sets&quot;, i.e., the minimize the expected risk is what we aim achieve, but this is often impraticable.",2019-06-15T23:56:46Z
UgxjdkO_1jNRF-Dm4ml4AaABAg.8pHYRCDLX7s9AApqDFgPGE,@shubhamchandra9258,UgxjdkO_1jNRF-Dm4ml4AaABAg,2,uJryes5Vk1o,0,0,2020-06-21T19:05:57Z,cost is the mean loss in the data set.,2020-06-21T19:05:57Z
UgzglxtUgodeXlwSdkB4AaABAg,@arghavankayvani1059,,1,uJryes5Vk1o,0,5,2018-08-18T18:53:56Z,one of the best! thank you for the great lecture..,2018-08-18T18:53:56Z
Ugzunnd7vRyhtx2yfU14AaABAg,@sarfarazmemon2429,,1,uJryes5Vk1o,1,63,2018-02-11T06:17:54Z,"If you don&#39;t know, don&#39;t worry about it :-)",2018-02-11T06:17:54Z
Ugzunnd7vRyhtx2yfU14AaABAg.8cWSWSeCGfD9ScJCDYF981,@thepresistence5935,Ugzunnd7vRyhtx2yfU14AaABAg,2,uJryes5Vk1o,0,1,2021-09-23T05:55:03Z,I melted,2021-09-23T05:55:03Z
UgzspbdRnD5ofPeX1N14AaABAg,@dengpan8086,,1,uJryes5Vk1o,1,2,2017-10-30T17:12:35Z,Ë∞¢Ë∞¢,2017-10-30T17:12:35Z
UgzspbdRnD5ofPeX1N14AaABAg.8ZLpl_OkQT98r85edXh_ZG,@doubtunites168,UgzspbdRnD5ofPeX1N14AaABAg,2,uJryes5Vk1o,0,0,2019-02-09T15:07:18Z,‰∏ç‚ÄãÂÆ¢Ê∞î,2019-02-09T15:07:18Z
UgxQG25xco4GQnPJBzJ4AaABAg,@justinkim7202,,1,GzphoJOVEcE,0,0,2023-10-19T22:06:24Z,I&#39;m already familiar with the concept but I found this explanation exceptional,2023-10-19T22:06:36Z
Ugy9ln7_LYGcqH_7ZyR4AaABAg,@maxgriffiths6968,,1,GzphoJOVEcE,0,0,2022-01-28T19:03:03Z,What a great guy,2022-01-28T19:03:03Z
UgzguGKekOkFVKF7jL94AaABAg,@thepresistence5935,,1,GzphoJOVEcE,0,0,2021-09-24T04:39:56Z,"What an explanation, Feeling good for got free this gold one",2021-09-24T04:39:56Z
UgyqLdVDnlmefN69o3N4AaABAg,@khushboovyas5932,,1,GzphoJOVEcE,0,3,2020-07-02T11:19:22Z,Thank you sir .. after completing Machine Learning playlist that inspired me to do deep learning playlist.. u explain every single concept of math behind it. . Truly u r best Professor..,2020-07-02T11:19:22Z
Ugw4T6Q_23QLmJX3JQ54AaABAg,@TheArrycool,,1,GzphoJOVEcE,0,7,2018-12-20T17:32:08Z,You&#39;re lectures are the best and you are so humble.,2018-12-20T17:32:08Z
Ugz4IV_Btp7n7RjrrI54AaABAg,@EranM,,1,GzphoJOVEcE,4,22,2018-11-07T09:06:32Z,"<a href=""https://www.youtube.com/watch?v=GzphoJOVEcE&amp;t=5m35s"">5:35</a> - Listen to Andrew says ohohohohohohohohohooh a lot of times! :&gt;",2018-11-07T09:06:32Z
Ugz4IV_Btp7n7RjrrI54AaABAg.8nLPe1Amda58p52J7hm44b,@TheArrycool,Ugz4IV_Btp7n7RjrrI54AaABAg,2,GzphoJOVEcE,0,0,2018-12-20T17:37:30Z,I heard at 1.5x.,2018-12-20T17:37:30Z
Ugz4IV_Btp7n7RjrrI54AaABAg.8nLPe1Amda58pDo4MNVt7s,@pengcheng7799,Ugz4IV_Btp7n7RjrrI54AaABAg,2,GzphoJOVEcE,0,1,2018-12-24T03:17:35Z,Lmao xD,2018-12-24T03:17:35Z
Ugz4IV_Btp7n7RjrrI54AaABAg.8nLPe1Amda58pH_iXkSDcs,@saanvisharma2081,Ugz4IV_Btp7n7RjrrI54AaABAg,2,GzphoJOVEcE,0,0,2018-12-25T14:29:06Z,@@TheArrycool you must be talented then ;-),2018-12-25T14:29:06Z
Ugz4IV_Btp7n7RjrrI54AaABAg.8nLPe1Amda597QsDkIyUs4,@mobinalhassan,Ugz4IV_Btp7n7RjrrI54AaABAg,2,GzphoJOVEcE,0,0,2020-04-14T11:00:26Z,@@TheArrycool  Yaaaaaa,2020-04-14T11:00:26Z
Ugw-06adl-m3E2we0LN4AaABAg,@kvin007,,1,GzphoJOVEcE,0,4,2018-10-20T19:29:22Z,These videos make me wanna buy all courses by Andrew Ng. He&#39;s such a good professor!,2018-10-20T19:29:22Z
Ugztt9jW-BbBzMddwlN4AaABAg,@sandipansarkar9211,,1,5H7M5Vd3-pk,0,0,2021-01-15T15:42:16Z,nice explanation,2021-01-15T15:42:16Z
Ugx02hrJU0YQgCnKYNR4AaABAg,@nasiksami2351,,1,5H7M5Vd3-pk,0,1,2020-11-10T03:22:48Z,Now after so many years I&#39;m able to get what all those actually meant!,2020-11-10T03:22:48Z
UgzM-DpXsofL0Jv35u94AaABAg,@Pierluigi-ns4ms,,1,5H7M5Vd3-pk,0,1,2020-07-25T16:15:46Z,"I think, you could tell how you find the derivative of a basic function in only 10 seconds. However, of course you will need to look for information for more advanced functions.<br>¬†<br>****Example for the people who do not know how to do: Our function is 6x3, and we want to find the derivative:<br>¬†<br>1) Look at x3. Take 3 and bring it to the beginning of it ------&gt; We got 3.6.x3<br>2) For the same x3, reduce 3 by 1 (we always reduce by 1) ------&gt; We got 3.6.x2 ------&gt; 18x2<br>¬†<br>However, thanks for this amazing lesson series. I learned a lot",2020-07-25T16:15:46Z
UgxZalGzZJvyc1vjVqF4AaABAg,@mobinalhassan,,1,5H7M5Vd3-pk,0,0,2020-04-14T11:06:45Z,d/da (a^n=n*a^n-1),2020-04-14T11:06:45Z
UgxU7CsrAU3T1_7P5DV4AaABAg,@TheEducationWorldUS,,1,5H7M5Vd3-pk,0,1,2020-04-10T17:14:55Z,really awesome,2020-04-10T17:14:55Z
Ugy-wiFNd2XfBeImOvh4AaABAg,@jackwang5588,,1,5H7M5Vd3-pk,0,0,2020-02-19T20:52:08Z,Â§™ÈÖ∑‰∫Ü,2020-02-19T20:52:08Z
Ugwo8s3HVEoirDY4y6d4AaABAg,@MondayMotivations,,1,5H7M5Vd3-pk,0,4,2020-01-02T05:51:14Z,"Derivative is scary, slope is what i was looking for. :)",2020-01-02T05:51:14Z
Ugw40wkpLbY9Yk32wLx4AaABAg,@salmanshaukat1951,,1,5H7M5Vd3-pk,1,17,2018-05-23T15:24:29Z,"for the first time, I was able to understand what derivative actually is!",2018-05-23T15:24:29Z
Ugw40wkpLbY9Yk32wLx4AaABAg.8gaVM6nyA__96_UYSZxB4q,@shreejanshrestha1931,Ugw40wkpLbY9Yk32wLx4AaABAg,2,5H7M5Vd3-pk,0,0,2020-03-24T08:05:49Z,Same  here haha. was familiar with derivative and its working mechanism but his examples made more clearer to visualize derivative,2020-03-24T08:05:49Z
UgxnafJ0d6wL4nwtUKB4AaABAg,@ganeshms4624,,1,5H7M5Vd3-pk,0,1,2018-03-02T15:07:02Z,"@<a href=""http://deeplearning.ai/"">Deeplearning.ai</a> The title is wrong and is misleading. Please correct it to &quot;More Derivative Examples (C1W2L06)&quot;",2018-03-02T15:07:02Z
UgzQRgOIG5Gm_0jB_Up4AaABAg,@deusexistelonge,,1,5H7M5Vd3-pk,0,1,2017-12-08T17:41:15Z,Wrong title,2017-12-08T17:41:15Z
UgxTJQ1EqyeK3v30zDR4AaABAg,@jasonye2850,,1,5H7M5Vd3-pk,1,4,2017-11-16T13:19:10Z,"This video should be C1W2L06 @<a href=""http://deeplearning.ai/"">Deeplearning.ai</a>",2017-11-16T13:19:10Z
UgxTJQ1EqyeK3v30zDR4AaABAg.8_1BZo-23Zz9-w85ZCn9eq,@user-pr6qg1pr8g,UgxTJQ1EqyeK3v30zDR4AaABAg,2,5H7M5Vd3-pk,0,0,2019-10-11T03:32:25Z,"I think the same. @<a href=""http://deeplearning.ai/"">Deeplearning.ai</a>",2019-10-11T03:32:25Z
UgwoZDxKgqJ9QFjMNDt4AaABAg,@amalprakash5632,,1,hCP1vGoCdYU,0,0,2021-05-25T13:27:00Z,Where can I get all the ppts?,2021-05-25T13:27:00Z
UgwR2INeWv3x92zbgjx4AaABAg,@codewebsduh2667,,1,hCP1vGoCdYU,0,1,2020-10-25T15:20:55Z,Wow i&#39;m on a roll,2020-10-25T15:20:55Z
Ugxlh9BnhRju9c4Igmx4AaABAg,@yakshitjain3048,,1,hCP1vGoCdYU,0,7,2019-01-05T08:18:10Z,I wish if u were my professor  in my college. Your explanation are amazing,2019-01-05T08:18:10Z
UgzO3ozmxS85tzKk56Z4AaABAg,@zztazta,,1,hCP1vGoCdYU,0,16,2018-12-22T16:21:33Z,"I wish to make a comment. Throughout elementary school, high school, college I hate math with a passion and avoided my college physics class until I can no longer avoid them before graduation. But here I am binge-watching these video lectures!!",2018-12-22T16:21:33Z
UgzE-8PTLAoE50RxCqB4AaABAg,@gaussian3750,,1,hCP1vGoCdYU,0,2,2018-08-25T08:34:12Z,good lecture!,2018-08-25T08:34:12Z
UgxgrfKN-Q_U99FBOZd4AaABAg,@justinkim7202,,1,nJyUyKN-XBQ,0,0,2023-10-19T23:25:13Z,Just phenomenal.. I&#39;ve seen so much of the other contents on this topic but this is the one!,2023-10-20T00:13:20Z
UgwEcLfjT3J-r5FXes54AaABAg,@Mehdirose,,1,nJyUyKN-XBQ,0,1,2022-04-06T14:04:39Z,clear explanation. have been confused with derivatives for more than 10 years,2022-04-06T14:04:39Z
UgzfYR7FvHjPMvEfpZ14AaABAg,@dijkstra4678,,1,nJyUyKN-XBQ,0,0,2022-03-18T17:37:39Z,Amazing,2022-03-18T17:37:39Z
UgwzpZ8PzyHqh2Whudp4AaABAg,@santhoshjosephc1,,1,nJyUyKN-XBQ,1,0,2021-06-15T04:38:41Z,"I am getting db = 6 and dc = 9. Actually db = 3 * c and dc = 3 * b. If you apply chain rule, isn&#39;t what you will get?",2021-06-15T04:38:41Z
UgwzpZ8PzyHqh2Whudp4AaABAg.9OafyIAMumo9SepG063myY,@thepresistence5935,UgwzpZ8PzyHqh2Whudp4AaABAg,2,nJyUyKN-XBQ,0,1,2021-09-24T05:22:25Z,"Don&#39;t go deep dive, just understand the concepts we don&#39;t apply chain rule in real world industries it&#39;s tough it takes a year to do that. understand the concepts is better don&#39;t confuse your mind",2021-09-24T05:22:25Z
UgxrhiCk2-EXzjJCCJN4AaABAg,@abhijitvikash,,1,nJyUyKN-XBQ,0,4,2020-08-28T09:25:20Z,I love you Andrew Ng !!  I may never be able to meet you in person but you are my Guru!! Thank you Tanks you !!,2020-08-28T09:25:20Z
UgxLhHQ3XiLi3D2r_j94AaABAg,@bishanduttbhatt9694,,1,nJyUyKN-XBQ,1,0,2020-06-25T15:21:23Z,"Everything was so beautiful, but I am confused about that chain rule, can someone help me there ?.",2020-06-25T15:21:23Z
UgxLhHQ3XiLi3D2r_j94AaABAg.9AKjK0gxatB9A_f1MrBfNq,@devenbothra5472,UgxLhHQ3XiLi3D2r_j94AaABAg,2,nJyUyKN-XBQ,0,2,2020-07-01T19:51:44Z,"check this video for the explanation <a href=""https://www.khanacademy.org/math/ap-calculus-ab/ab-differentiation-2-new/ab-3-1a/v/chain-rule-introduction"">https://www.khanacademy.org/math/ap-calculus-ab/ab-differentiation-2-new/ab-3-1a/v/chain-rule-introduction</a>.",2020-07-01T19:51:44Z
UgxuePJruZTTVBmpRzV4AaABAg,@hanbaochengeon744,,1,nJyUyKN-XBQ,0,7,2020-05-06T19:16:34Z,"Thanks Andrew, this intuition really helps me understand backprop much better",2020-05-06T19:16:34Z
Ugzwrt0PnERlZ_D3f_R4AaABAg,@klam77,,1,nJyUyKN-XBQ,1,1,2019-12-20T01:25:34Z,"Isn&#39;t it true that libraries like Tensorflow, compute derivatives ANALYTICALLY directly from knowledge of the algrebraic operations in the graph, and NOT numerically as shown in the video?",2019-12-20T01:25:34Z
Ugzwrt0PnERlZ_D3f_R4AaABAg.92k9Dmi_EZG9GsB0macmjF,@navsquid32,Ugzwrt0PnERlZ_D3f_R4AaABAg,2,nJyUyKN-XBQ,0,7,2020-12-05T03:34:43Z,"Automatic differentiation is neither symbolic/analytic differentiation, nor is it numerical differentiation. Autodiff is the chain rule applied to computational graphs, which describe a computation in terms of operational primitives. For example, if my function is f(x, y) = xy + x^2, I can describe this as a computational graph. If r1 = x*y, r2 = x*x, and r3 = r1 + r2, then the derivatives of these operations are all primitive derivatives. I know that dr1/dx = y, dr2/dx = 2x, dr3/dr1 = 1 and dr3/dr2 = 1. So, if I wanted to know df/dx, then using the chain rule I would need to compute dr3/dr1*dr1/dx + dr3/dr2*dr2/dx, which is equal to 1*y + 1*2x. Now you have the derivatives in terms of values that you will get on the forward pass. <br><br>The only thing that needs to be programmed is the derivative rule for a primitive operation (addition, multiplication, division, exponentiation, logs, trig functions). That way, at each node in the computational graph, the derivative can be described in terms of the inputs to the node, which will be part of the larger chain rule.",2020-12-05T03:34:43Z
Ugz894ROWQJaUa4o90p4AaABAg,@xyu224,,1,nJyUyKN-XBQ,9,10,2018-12-06T23:53:50Z,why the default language is Korean?! so annoying!,2018-12-06T23:53:50Z
Ugz894ROWQJaUa4o90p4AaABAg.8oXfFC-TQRp8vks6OX8q9g,@lemyul,Ugz894ROWQJaUa4o90p4AaABAg,2,nJyUyKN-XBQ,0,15,2019-06-04T11:55:22Z,learn Korean,2019-06-04T11:55:22Z
Ugz894ROWQJaUa4o90p4AaABAg.8oXfFC-TQRp8y5UDGRrIzS,@sangwoohan1177,Ugz894ROWQJaUa4o90p4AaABAg,2,nJyUyKN-XBQ,0,5,2019-08-01T14:23:55Z,I&#39;m korean and I find it annoying too haha. I can&#39;t read my native language as well as english.,2019-08-01T14:23:55Z
Ugz894ROWQJaUa4o90p4AaABAg.8oXfFC-TQRp8ye9QQns96I,@alisarmadi9383,Ugz894ROWQJaUa4o90p4AaABAg,2,nJyUyKN-XBQ,0,0,2019-08-15T10:54:53Z,Use the auto-generated English subtitle,2019-08-15T10:54:53Z
Ugz894ROWQJaUa4o90p4AaABAg.8oXfFC-TQRp8zcr7lnHgtH,@yiqingwang8655,Ugz894ROWQJaUa4o90p4AaABAg,2,nJyUyKN-XBQ,0,0,2019-09-08T19:18:28Z,"@@sangwoohan1177hhhhh. Me too! I am Chinese, and I find it&#39;s easier to read and listen to lectures in English.",2019-09-08T19:18:28Z
Ugz894ROWQJaUa4o90p4AaABAg.8oXfFC-TQRp9087Ornb1Pv,@343906919,Ugz894ROWQJaUa4o90p4AaABAg,2,nJyUyKN-XBQ,0,0,2019-10-16T04:36:26Z,@@yiqingwang8655 Me too. :),2019-10-16T04:36:26Z
UgzkyfEncbdk6lutd2J4AaABAg,@vikramyadav-fe4vj,,1,z_xiwjEdAC4,1,0,2023-01-28T12:14:17Z,Try to explain in correct order üôÜüíÅ,2023-01-28T12:14:17Z
UgzkyfEncbdk6lutd2J4AaABAg.9lQqhFCs9eZ9lRD8g3zi_J,@vikramyadav-fe4vj,UgzkyfEncbdk6lutd2J4AaABAg,2,z_xiwjEdAC4,0,0,2023-01-28T15:39:09Z,Finally after watching repeatedly for few times it took 3/4 th of day to fully understand üôÜ‚ù§Ô∏è,2023-01-28T15:39:09Z
UgyiTry0giHwRQy8UpZ4AaABAg,@charlos1388,,1,z_xiwjEdAC4,0,0,2021-07-16T11:50:33Z,whats the matter with the logarithms? it is okay,2021-07-16T11:50:33Z
Ugyw9obZj-e6WVqxlWN4AaABAg,@swaralipibose9731,,1,z_xiwjEdAC4,4,1,2021-02-27T11:31:52Z,"I dont understand that how dw1=x1*dz  , does this have to do something with the chain rule and would this work if z was non linear",2021-02-27T11:36:31Z
Ugyw9obZj-e6WVqxlWN4AaABAg.9KGKP24d5nH9L4WVmt01SQ,@gozdec.1376,Ugyw9obZj-e6WVqxlWN4AaABAg,2,z_xiwjEdAC4,0,2,2021-03-19T17:58:09Z,"yes, it is chain rule. dz actually means dL/da times da/dz. He would have chosen a better name to represent dL/dz",2021-03-19T17:58:09Z
Ugyw9obZj-e6WVqxlWN4AaABAg.9KGKP24d5nH9LHIr5sm511,@evaar440,Ugyw9obZj-e6WVqxlWN4AaABAg,2,z_xiwjEdAC4,0,6,2021-03-24T17:08:59Z,I was also confused but I figured it out .. it is because he represents the partial derivative expression with a single variable:<br>dL/dw1 = dL/dz * dz/dw1<br>               = <b>dz</b>  *   x1,2021-03-24T17:08:59Z
Ugyw9obZj-e6WVqxlWN4AaABAg.9KGKP24d5nH9LJnMij-0bp,@swaralipibose9731,Ugyw9obZj-e6WVqxlWN4AaABAg,2,z_xiwjEdAC4,0,0,2021-03-25T16:22:48Z,@@gozdec.1376 thank you I also figured it out after doing the derivations of a small neural network in pen and paper,2021-03-25T16:22:48Z
Ugyw9obZj-e6WVqxlWN4AaABAg.9KGKP24d5nH9PeJhOXcgIE,@stoka43,Ugyw9obZj-e6WVqxlWN4AaABAg,2,z_xiwjEdAC4,0,0,2021-07-11T11:03:45Z,"Just pay attention to the notation dz = dL/dz, apply chain rule and you&#39;re gonna resolve it.",2021-07-11T11:03:45Z
UgwieQNkC4Cw3Q0S9Pp4AaABAg,@manishpoudel1063,,1,z_xiwjEdAC4,5,1,2021-01-16T10:52:08Z,isn&#39;t derivate of log(a) = 1/(a * ln(10))  ?  Why did ln(10) disappear if we were to calculate the dL/da,2021-01-16T10:52:50Z
UgwieQNkC4Cw3Q0S9Pp4AaABAg.9I_6THWb8y89JDc03EYYwN,@meetbhalia7502,UgwieQNkC4Cw3Q0S9Pp4AaABAg,2,z_xiwjEdAC4,0,0,2021-02-01T13:45:21Z,I guess he took it as a constant that is maybe included when calculating the learning rate. Not sure though,2021-02-01T13:45:21Z
UgwieQNkC4Cw3Q0S9Pp4AaABAg.9I_6THWb8y89KCr1SUPkzJ,@sercangul4119,UgwieQNkC4Cw3Q0S9Pp4AaABAg,2,z_xiwjEdAC4,0,0,2021-02-26T03:08:46Z,In(10) is 1,2021-02-26T03:08:46Z
UgwieQNkC4Cw3Q0S9Pp4AaABAg.9I_6THWb8y89KD2iBoXwsp,@meetbhalia7502,UgwieQNkC4Cw3Q0S9Pp4AaABAg,2,z_xiwjEdAC4,0,0,2021-02-26T04:59:36Z,@@sercangul4119 ln10 is not 1. Log10 is 1,2021-02-26T04:59:36Z
UgwieQNkC4Cw3Q0S9Pp4AaABAg.9I_6THWb8y89KMc6euQouN,@edilgin622,UgwieQNkC4Cw3Q0S9Pp4AaABAg,2,z_xiwjEdAC4,0,1,2021-03-01T22:10:49Z,i tried to understand ln10 thing for ten minutes and then came here from coursera to find answers lol,2021-03-01T22:10:49Z
UgwieQNkC4Cw3Q0S9Pp4AaABAg.9I_6THWb8y89MpEoLxkhTX,@abbasafridi4732,UgwieQNkC4Cw3Q0S9Pp4AaABAg,2,z_xiwjEdAC4,0,0,2021-05-02T03:18:28Z,@@sercangul4119 not ln(10) but log(10) is 1,2021-05-02T03:18:28Z
UgzugZKhhlIx71-Dj8h4AaABAg,@codewebsduh2667,,1,z_xiwjEdAC4,2,3,2020-10-25T16:08:00Z,Interesting how you ignore the 1/ln(10) infront of dL/da perhaps it&#39;s because it&#39;s incorporated into the learning rate?<br><br>Also there is a mistake:<br>dL/da = -y/a + (1-y)/(1-a),2020-10-25T16:08:00Z
UgzugZKhhlIx71-Dj8h4AaABAg.9FExdA9UqHk9an0V5ve8Mo,@EricD_192,UgzugZKhhlIx71-Dj8h4AaABAg,2,z_xiwjEdAC4,0,0,2022-05-09T02:25:48Z,There is not such mistake.,2022-05-09T02:25:48Z
UgzugZKhhlIx71-Dj8h4AaABAg.9FExdA9UqHk9oCYniEjHHC,@classicalfandom8219,UgzugZKhhlIx71-Dj8h4AaABAg,2,z_xiwjEdAC4,0,0,2023-04-07T12:33:57Z,I think I saw the same derivation in Andrew&#39;s explanation. you should see it again,2023-04-07T12:33:57Z
Ugz2LxJwGzP7KD7tiUN4AaABAg,@wifi-YT,,1,z_xiwjEdAC4,0,16,2020-09-22T11:22:18Z,"While Andrew is usually a great explainer, and a great teacher, this explanation, beginning at <a href=""https://www.youtube.com/watch?v=z_xiwjEdAC4&amp;t=2m27s"">2:27</a> to the end, was genuinely very confusing.  And I‚Äôm one who did (and still does) understand the concepts before viewing this video.  He should have lined up his formulas one step to the right of where he did (i.e., da formula should be placed under L(a,y), and dz formula under a=sigma(z)).  And by <a href=""https://www.youtube.com/watch?v=z_xiwjEdAC4&amp;t=5m44s"">5:44</a>, he should have first spelled out dz/dw1, dz/dw2, and dz/db and placed them under z=w1x1 + w2x2 + b, before jumping to the final dL/dw1, dL/dw2, and dL/db formulas.  That way one could more clearly see the chain rule in effect.    So if you were confused, don‚Äôt be discouraged.   It was extremely confusing.     That said, Andrew is usually an awesome explainer.  He is a great guy, and a good teacher overall.",2020-09-22T11:26:35Z
UgxZKsJTCwi-nP-O8kV4AaABAg,@sandipadhikari644,,1,z_xiwjEdAC4,0,0,2020-07-16T12:50:53Z,Salute u sir,2020-07-16T12:50:53Z
Ugz3I-YQBv3J727Z6aJ4AaABAg,@skypickle29,,1,z_xiwjEdAC4,0,1,2020-03-09T01:52:24Z,"Also, you used a as the hyper parameter of the learning rate in the previous video. That a is clearly unrelated to this alpha. VERY CONFUSING",2020-03-09T01:52:24Z
UgxCD_Z5-MjYSCndvTx4AaABAg,@skypickle29,,1,z_xiwjEdAC4,0,0,2020-03-09T01:48:00Z,"I am confused between the a  and the alpha. LOSS was previously defined as a function of y and yhat. So when you differentiate LOSS with respect to a, are you really saying to just differentiate loss with respect to yhat?",2020-03-09T01:48:00Z
Ugz92xgXAVuqv4K7MDN4AaABAg,@pranjulitondia8745,,1,z_xiwjEdAC4,1,0,2020-01-15T17:17:39Z,i&#39;m not getting what this &quot;b&quot; means here ?,2020-01-15T17:17:39Z
Ugz92xgXAVuqv4K7MDN4AaABAg.93onqlKZS-k9425kTLl7KM,@joelvieira7954,Ugz92xgXAVuqv4K7MDN4AaABAg,2,z_xiwjEdAC4,0,0,2020-01-21T06:32:11Z,it represents the bias,2020-01-21T06:32:11Z
UgyU_y8ulKoyXkDuGuB4AaABAg,@shekararukala9242,,1,z_xiwjEdAC4,1,1,2019-11-04T05:56:05Z,I&#39;m confused with x1 and x2. There should be only one x right? one input given to two nodes w1 and w1.  can someone clarify my doubt?<br><br>Thanks in advance!,2019-11-04T05:56:05Z
UgyU_y8ulKoyXkDuGuB4AaABAg.90uBbqooZHs92WgwuVKnoQ,@arjunkulshrestha5339,UgyU_y8ulKoyXkDuGuB4AaABAg,2,z_xiwjEdAC4,0,5,2019-12-14T10:40:21Z,"There is only one input, but it has two &#39;features&#39;, for example, size of a house and quality of schools around it are the two features of a singular input (one house) which will determine its, say, price.",2019-12-14T10:40:21Z
UgxaujWBaDqNlKpMQot4AaABAg,@ibrahimyldrm2427,,1,z_xiwjEdAC4,0,42,2019-10-11T18:00:57Z,"if u don&#39;t know, don&#39;t worry about it",2019-10-11T18:00:57Z
UgxDmD3UgWQn0Qncmeh4AaABAg,@HKPhotographyVlogs,,1,z_xiwjEdAC4,1,0,2019-06-20T14:20:41Z,"Just a Degree more Clarification : lolz<br>dL/da = &quot;da&quot; = d/da [ L(a,y) ]= d/da [-y log a + (1-y) log (1-a)]<br>= -y d/da (log a) + (1-y ) d/da (1-a)<br>= -y * 1/a  +  1-y  *  1-a  = -y/a +1-y/1-a<br>.<br>dL/dz = &quot;dz&quot;  = dL/da * da/dz  (chain rule)<br>since dL/da =   -y/a +1-y/1-a, and derivative of sigmoid is a(a-1) which is  da/dz<br>so,  &quot;dz&quot;  = dL/da * da/dz = [-y/a +1-y/1-a ] * [a(a-1)]  =  a-y<br>.<br>dL/dw1 = &quot;dw1&quot; = dL/dz * dz/dw1<br>since dL/dz is represented as &quot;dz&quot;, where dz/dw1 = d/dw1 [x1w1 +x2w2 +b]<br>x1d/dw1 (w1) + 0  + 0  =  x1<br>Hence, dL/dw1 = &quot;dw1&quot;  =  dL/dz * dz/dw1 =  &quot;dz&quot; x1<br>( &quot;*&quot; is used for Multiplication&quot; )",2019-06-20T14:20:41Z
UgxDmD3UgWQn0Qncmeh4AaABAg.8wPKSnLOCjy9sPDP3ett_i,@ybkaa8062,UgxDmD3UgWQn0Qncmeh4AaABAg,2,z_xiwjEdAC4,0,0,2023-07-20T20:42:39Z,how can d/da (log a) be equal to 1/a ?? Isn&#39;t it supposed to be 1 / (ln 10 * a) ?,2023-07-20T20:42:39Z
UgzEiLxyy-kakOmpWXZ4AaABAg,@sateeshkumar1145,,1,z_xiwjEdAC4,2,1,2019-05-17T01:22:27Z,"Correction: At <a href=""https://www.youtube.com/watch?v=z_xiwjEdAC4&amp;t=03m05s"">03:05</a>, the derivative of L should have a negative sign with each term",2019-05-17T01:22:27Z
UgzEiLxyy-kakOmpWXZ4AaABAg.8v0ON7-y7GC8w4zxzePYta,@VISHHVAKSRINIVASBCE,UgzEiLxyy-kakOmpWXZ4AaABAg,2,z_xiwjEdAC4,0,7,2019-06-12T16:48:02Z,"No, taking the derivative of (1-y)log(1-a) with respect to a yields another negative one due to (1-a) where a has a negative sign to it (refer chain rule). Hence the result is correct.",2019-06-12T16:48:02Z
UgzEiLxyy-kakOmpWXZ4AaABAg.8v0ON7-y7GC92P-6FXtAY0,@LeenaGurgPhysics,UgzEiLxyy-kakOmpWXZ4AaABAg,2,z_xiwjEdAC4,0,0,2019-12-11T10:53:52Z,"It is correct because there is another negative sign outside L ( at <a href=""https://www.youtube.com/watch?v=z_xiwjEdAC4&amp;t=1m30s"">1:30</a>)",2019-12-11T10:53:52Z
UgxEfy3ozy4UZv-NZdV4AaABAg,@FezanRafique,,1,z_xiwjEdAC4,0,3,2019-04-11T02:44:24Z,great explanation from a great teacher!,2019-04-11T02:44:24Z
UgyZjs5CxVDncm7SbyN4AaABAg,@zerotheextreme,,1,z_xiwjEdAC4,0,6,2018-12-26T10:51:31Z,y = expected_output; a = calculated_output,2018-12-26T10:51:31Z
UgwRgw0mFsLCpZGNQhB4AaABAg,@BharadwajRbwaj95,,1,z_xiwjEdAC4,6,7,2018-07-19T20:31:30Z,da/dz = a(1-a) .... How ? What&#39;s the equation of &#39;a&#39; before partial derivation ? Please Help !,2018-07-19T20:31:30Z
UgwRgw0mFsLCpZGNQhB4AaABAg.8itoneBKV-X8j17BVRoNvH,@ZhangKanda,UgwRgw0mFsLCpZGNQhB4AaABAg,2,z_xiwjEdAC4,0,2,2018-07-23T01:54:50Z,Derivative of a Sigmoid Function,2018-07-23T01:54:50Z
UgwRgw0mFsLCpZGNQhB4AaABAg.8itoneBKV-X8kAe-tQhkMC,@Kamal_M_Abed_ElRazek,UgwRgw0mFsLCpZGNQhB4AaABAg,2,z_xiwjEdAC4,0,35,2018-08-20T15:14:54Z,a = sigma(z) = 1/(1+e^-z) <br>da/dz = e^-z/(1+e^-z)^2 = (e^-z) * (1/1+e^-z)^2 <br>e^-z can be written as (1/a)-1<br>(1/1+e^-z)^2 as (a)^2<br>a^2 * ((1/a)-1) =a(1-a),2018-08-20T15:14:54Z
UgwRgw0mFsLCpZGNQhB4AaABAg.8itoneBKV-X8kqrcYhMR6z,@bojanzlatkovic1086,UgwRgw0mFsLCpZGNQhB4AaABAg,2,z_xiwjEdAC4,0,6,2018-09-06T10:01:15Z,"<a href=""https://math.stackexchange.com/questions/78575/derivative-of-sigmoid-function-sigma-x-frac11e-x"">https://math.stackexchange.com/questions/78575/derivative-of-sigmoid-function-sigma-x-frac11e-x</a>",2018-09-06T10:01:15Z
UgwRgw0mFsLCpZGNQhB4AaABAg.8itoneBKV-X8m5bFUN8sMU,@nischalsimha9995,UgwRgw0mFsLCpZGNQhB4AaABAg,2,z_xiwjEdAC4,0,2,2018-10-07T09:17:24Z,"thanks , appreciate it!",2018-10-07T09:17:24Z
UgwRgw0mFsLCpZGNQhB4AaABAg.8itoneBKV-X8nBBEO08_8x,@prayushdawda7807,UgwRgw0mFsLCpZGNQhB4AaABAg,2,z_xiwjEdAC4,0,2,2018-11-03T09:48:10Z,@@Kamal_M_Abed_ElRazek thanks!,2018-11-03T09:48:10Z
UgxW_UmUzhLlI8l82eN4AaABAg,@edwinvarghese,,1,z_xiwjEdAC4,3,1,2018-05-11T09:59:44Z,how is w1 = x1*dz ? Can anyone help?,2018-05-11T09:59:44Z
UgxW_UmUzhLlI8l82eN4AaABAg.8g60e6grQER8gTm9RPCp0K,@anishmadan610,UgxW_UmUzhLlI8l82eN4AaABAg,2,z_xiwjEdAC4,0,2,2018-05-20T15:26:06Z,"It is dw1 and not w1. So if &quot;dz&quot; = dL/dz, then &quot;dw1&quot;=dL/dw1 = (dL/dz)*(dz/dw1), where dz/dw1 = x1",2018-05-20T15:26:06Z
UgxW_UmUzhLlI8l82eN4AaABAg.8g60e6grQER8khT7z7efK-,@saiharish4482,UgxW_UmUzhLlI8l82eN4AaABAg,2,z_xiwjEdAC4,0,4,2018-09-02T18:25:19Z,z = w1x1 + w2x2+b<br>Dz/Dw1 = x1 ( where here Dz means partial derivative of z)<br>Dz = x1*Dw1<br>1/Dz = 1/(x1.Dw1)<br>DL/Dz = DL/(x1.Dw1)<br>dz = (1/x1)*dw1 (since DL/Dz = dz)<br>dw1 = x1*dz,2018-09-02T18:25:19Z
UgxW_UmUzhLlI8l82eN4AaABAg.8g60e6grQER8rY40vnlNDg,@DharminderSingh,UgxW_UmUzhLlI8l82eN4AaABAg,2,z_xiwjEdAC4,0,4,2019-02-19T17:13:16Z,"I&#39;ll try to explain, In the back propagation step, you&#39;re trying to figure out the difference in L with respect to w1, w2 and b. You can use the chain rule to figure this out. So, the first step is to figure out the difference in L with respect to z. To figure this out, you calculate the derivative of the function L = -(ylog a).... after you figure this out, you calculate the derivative of z with respect to w1. In this case, the the derivative is simply x1. After simplifying both derivatives, the end result is you have the derivative of L with respect to w1. This is what you use to carry out the gradient descent. So you use the newly calculated dW1 and calculate a new w1 (ie newW1 = oldW1 - (learning rate Alpha * dW1)). Then you feed the newW1 back into the algorithm for the forward propagation step. Hope this helps.",2019-02-20T06:32:30Z
Ugz3waEuY8dOPH8b8WZ4AaABAg,@dijkstra4678,,1,KKfZLXcF-aE,0,0,2022-03-18T19:05:10Z,Amazing!,2022-03-18T19:05:10Z
UgzeZ_j4Z6on1LVsq414AaABAg,@HimanshuMauryadesigners,,1,KKfZLXcF-aE,0,0,2021-06-03T03:46:41Z,Why is this statement in the loop :<br>    J += -[yloga + (1-y)log(1-a)]<br>&amp; J/=m outside the loop.<br>first of all we are not using it anywhere and it doesn&#39;t makes any sense. Or Am I  missing something?,2021-06-03T03:46:41Z
Ugyvh_G6nPcdtSkjUuZ4AaABAg,@hummuswithpitta,,1,KKfZLXcF-aE,1,2,2021-05-01T11:43:35Z,makes me dz,2021-05-01T11:43:35Z
Ugyvh_G6nPcdtSkjUuZ4AaABAg.9MnZoxygzKd9wNqYJdzAeR,@DanielRamBeats,Ugyvh_G6nPcdtSkjUuZ4AaABAg,2,KKfZLXcF-aE,0,0,2023-10-27T18:00:32Z,with respect to w1? :D,2023-10-27T18:00:32Z
Ugw_zQuHTvm1sGtak5F4AaABAg,@junkmail75034,,1,KKfZLXcF-aE,0,1,2021-01-29T18:18:44Z,Where did w1 and w2 get initialized?,2021-01-29T18:18:44Z
UgzeOyhvwsY0_9bFKk14AaABAg,@samuelkristen7931,,1,KKfZLXcF-aE,1,0,2020-11-06T22:34:10Z,This is very very wrong! Does he really know mathematics? I thought he has a PhD.,2020-11-06T22:34:10Z
UgzeOyhvwsY0_9bFKk14AaABAg.9FjYN-ivhTs9NEBc_vQR1y,@rohan9545,UgzeOyhvwsY0_9bFKk14AaABAg,2,KKfZLXcF-aE,0,0,2021-05-12T05:10:54Z,@n1tr0z3n and cant teach for shit. no sane person can comprende this shit,2023-11-03T07:12:06Z
UgwnOtWDgVmjGhsAr8R4AaABAg,@kihongkim8726,,1,KKfZLXcF-aE,1,0,2020-08-21T10:05:25Z,where is programming assignment?,2020-08-21T10:05:25Z
UgwnOtWDgVmjGhsAr8R4AaABAg.9CbwTfsrprr9F4TedMwE_F,@Zzanney,UgwnOtWDgVmjGhsAr8R4AaABAg,2,KKfZLXcF-aE,0,3,2020-10-21T14:24:55Z,"There&#39;s a GitHub with all the assignments: <a href=""https://github.com/DoDuy/Deep-Learning-Specialization"">https://github.com/DoDuy/Deep-Learning-Specialization</a>",2020-10-21T14:24:55Z
Ugz435CbOz_jFAuRM-94AaABAg,@praveenbhatt3127,,1,KKfZLXcF-aE,2,1,2020-06-26T19:48:48Z,"Can anyone help me out here! <br>Why we took the average slope of the dJ/dw, why didn&#39;t we took the slop in every iteration and changed weight ?",2020-06-26T19:48:48Z
Ugz435CbOz_jFAuRM-94AaABAg.9ANmiUoE5gP9BHdnczItJf,@pranayreddy9041,Ugz435CbOz_jFAuRM-94AaABAg,2,KKfZLXcF-aE,0,1,2020-07-19T07:06:49Z,"If you change it for every iteration, it has a gradient of that particular training example and other examples might have different attributes and the gradient you have trained on is gone in each iteration. So it has to learn over a group of examples.",2020-07-19T07:06:49Z
Ugz435CbOz_jFAuRM-94AaABAg.9ANmiUoE5gP9Dw0Sf8xpQ5,@wifi-YT,Ugz435CbOz_jFAuRM-94AaABAg,2,KKfZLXcF-aE,0,4,2020-09-23T01:45:11Z,"You could do that Praveen, and that would be stochastic gradient descent (where all parameters are updated after EACH training example is fed to network), rather than full batch gradient descent (where entire training set is fed to network before parameters are updated one time).  Andrew is showing us full batch gradient descent.",2020-09-23T01:46:46Z
UgzciGuuVgfD_JfZkiZ4AaABAg,@NguyenTuanAnhTN,,1,KKfZLXcF-aE,0,0,2019-10-24T14:48:46Z,"why update dw1=dJ/dw1 in right column? if need to update as right column, so updated dw1 in left column has not meaning?<br><a href=""https://youtu.be/KKfZLXcF-aE?list=PLkDaE6sCZn6Ec-XTbcX1uRg2_u4xOEky0&amp;t=330"">https://youtu.be/KKfZLXcF-aE?list=PLkDaE6sCZn6Ec-XTbcX1uRg2_u4xOEky0&amp;t=330</a>",2019-10-24T14:48:46Z
UgxkMdZc2auRqoprxip4AaABAg,@habibmrad8116,,1,KKfZLXcF-aE,0,0,2019-04-20T13:17:24Z,well explained!! thank Andrew Ng from BEIRUT,2019-04-20T13:17:24Z
Ugz9SRX1AiyoM2fIwl14AaABAg,@PradeepKumar-qs3he,,1,KKfZLXcF-aE,2,2,2019-03-11T20:01:57Z,"Isn&#39;t the z^(i) at <a href=""https://www.youtube.com/watch?v=KKfZLXcF-aE&amp;t=0m38s"">0:38</a> supposed to be   (w1 * x1^(i) + w2 * x2^(i) + b)    instead of  (w * x^(i) + b)  ??",2019-03-11T20:01:57Z
Ugz9SRX1AiyoM2fIwl14AaABAg.8sLsDvhLvwG8t1iqvmGiDB,@xiaodong46,Ugz9SRX1AiyoM2fIwl14AaABAg,2,KKfZLXcF-aE,0,0,2019-03-28T20:46:37Z,wT here is the transpose of vector w,2019-03-28T20:46:37Z
Ugz9SRX1AiyoM2fIwl14AaABAg.8sLsDvhLvwG9Zvc39MsfS2,@sandeepnjois9812,Ugz9SRX1AiyoM2fIwl14AaABAg,2,KKfZLXcF-aE,0,0,2022-03-23T17:33:55Z,"Yes, I think the same",2022-03-23T17:33:55Z
UgwFCifixQoZZDxTKNZ4AaABAg,@greenblock1000,,1,KKfZLXcF-aE,0,0,2019-02-18T18:21:12Z,thank you,2019-02-18T18:21:12Z
Ugw5pWrt6cKi-YBg9ql4AaABAg,@giorgikochiashvili6947,,1,KKfZLXcF-aE,1,1,2018-07-21T17:09:30Z,Are not we supposed to calculate J after we updated the weights? And are not we supposed to add one more outer for loop to calculate J to make sure that it is converging?<br>These lectures are GREAT!,2018-07-21T17:09:30Z
Ugw5pWrt6cKi-YBg9ql4AaABAg.8iybGxnNP3Y8qndvDyD5nl,@myongian,Ugw5pWrt6cKi-YBg9ql4AaABAg,2,KKfZLXcF-aE,0,1,2019-02-01T07:12:07Z,we do update J in outer for loop...,2019-02-01T07:12:07Z
UgwR5J6GQRxki6DQhTt4AaABAg,@vaibhav8941,,1,KKfZLXcF-aE,2,3,2017-10-02T13:59:20Z,"There&#39;s no need to calculate J,  I guess.",2017-10-02T13:59:39Z
UgwR5J6GQRxki6DQhTt4AaABAg.8YDOOfVONJF8aWDQ-9R4gK,@kunhongyu5053,UgwR5J6GQRxki6DQhTt4AaABAg,2,KKfZLXcF-aE,0,6,2017-12-23T11:03:09Z,In order to tell whether your model is converging,2017-12-23T11:03:09Z
UgwR5J6GQRxki6DQhTt4AaABAg.8YDOOfVONJF8aeRQmAOdXI,@vaibhav8941,UgwR5J6GQRxki6DQhTt4AaABAg,2,KKfZLXcF-aE,0,0,2017-12-27T00:58:45Z,Kunhong YU Thanks.,2017-12-27T00:58:45Z
Ugytg9LSt3ek2xP_DTB4AaABAg,@PramodShetty,,1,qsIrQi0fzbY,0,0,2023-08-07T21:20:45Z,"Sorry, but you didn&#39;t explain what vectorization means? Or did you? I think you explained that vectorization is fast, but what is it actually?",2023-08-07T21:20:45Z
Ugxf1yNVSP3yGf1lzV54AaABAg,@elgs1980,,1,qsIrQi0fzbY,0,0,2022-07-01T08:27:02Z,"So what&#39;s the magic? I don&#39;t think loop is avoidable down to the bottom. It must be c vs python if not gpu vs cpu, right?",2022-07-01T08:27:02Z
UgyizN5qy3WeAk53HzV4AaABAg,@koponstanley4,,1,qsIrQi0fzbY,1,2,2022-05-16T17:55:46Z,Being taught by Andrew is really fun.,2022-05-16T17:55:46Z
UgyizN5qy3WeAk53HzV4AaABAg.9b5hUVAhXuM9sfXo7rHeO8,@xspydazx,UgyizN5qy3WeAk53HzV4AaABAg,2,qsIrQi0fzbY,0,0,2023-07-27T14:08:04Z,oh gosh no ... he is a night mare !,2023-07-27T14:08:04Z
Ugw6j8zSt_LABaRsPxN4AaABAg,@ayushjangid,,1,qsIrQi0fzbY,2,0,2021-08-02T03:39:19Z,but isn&#39;t dot product itself implemented by a for loop?,2021-08-02T03:39:19Z
Ugw6j8zSt_LABaRsPxN4AaABAg.9QXAKTIEmKH9THSwp5kktu,@noammanakermorag9538,Ugw6j8zSt_LABaRsPxN4AaABAg,2,qsIrQi0fzbY,0,1,2021-10-09T14:48:18Z,"Yes, but numpy handles for loops <b>much</b> faster than python, since behind the scenes numpy is running a for loop in c. This video goes more in depth on the subect - <a href=""https://www.youtube.com/watch?v=Qgevy75co8c"">https://www.youtube.com/watch?v=Qgevy75co8c</a>",2021-10-09T14:51:29Z
Ugw6j8zSt_LABaRsPxN4AaABAg.9QXAKTIEmKH9THTF97n-wt,@ayushjangid,Ugw6j8zSt_LABaRsPxN4AaABAg,2,qsIrQi0fzbY,0,0,2021-10-09T14:50:56Z,@@noammanakermorag9538 thanks mate,2021-10-09T14:50:56Z
UgzqtMXzCFPeyaav79F4AaABAg,@karinwiberg2223,,1,qsIrQi0fzbY,0,0,2021-01-20T13:14:42Z,"Great video, thank you!",2021-01-20T13:14:42Z
UgyooD_b6uXz2bJPdl54AaABAg,@rp88imxoimxo27,,1,qsIrQi0fzbY,0,6,2020-10-10T11:15:41Z,"360p gang, Andrew Ng where is u res rescaling NN?",2020-10-10T11:15:41Z
UgzZeqljI-uG6Tl9SNF4AaABAg,@mohammedouallal2,,1,qsIrQi0fzbY,0,0,2020-08-05T08:34:44Z,Donnie Yen face,2020-08-05T08:34:44Z
Ugx-NF3JEkJ2djtx69t4AaABAg,@halildurmaz7827,,1,qsIrQi0fzbY,3,0,2020-07-30T18:51:48Z,"<a href=""https://www.youtube.com/watch?v=qsIrQi0fzbY&amp;t=2m04s"">2:04</a> The first argument within the function should not be &quot;w&quot;; it should be &quot;w.T&quot;<br> <br>Also, I would like to give a feedback. When you have mistakes like this, you can put a note on the video which describes the correct version",2020-07-30T18:51:48Z
Ugx-NF3JEkJ2djtx69t4AaABAg.9BkEDmT2PuV9GOz0i6Hsyg,@HaSongSon123,Ugx-NF3JEkJ2djtx69t4AaABAg,2,qsIrQi0fzbY,0,0,2020-11-23T10:03:53Z,"Not really. In this case, because both W and X are vectors (not matrics) of the same length, so you can use &quot;w&quot; instead of &quot;w.T&quot; in function &quot;np.dot()&quot;. Best regard!",2020-11-23T10:03:53Z
Ugx-NF3JEkJ2djtx69t4AaABAg.9BkEDmT2PuV9GSP6aczqLm,@halildurmaz7827,Ugx-NF3JEkJ2djtx69t4AaABAg,2,qsIrQi0fzbY,0,0,2020-11-24T17:58:20Z,"Since this is a matrix multiplication, how you can multiply for example a (4,1) matrix with (4,1)? You should apply Transpoze for the first matrix, in order to create the required situation",2020-11-24T17:58:20Z
Ugx-NF3JEkJ2djtx69t4AaABAg.9BkEDmT2PuV9THSegsHWD3,@noammanakermorag9538,Ugx-NF3JEkJ2djtx69t4AaABAg,2,qsIrQi0fzbY,0,0,2021-10-09T14:45:50Z,"@@halildurmaz7827 Try it, numpy knows how to do this correctly (notice that numpy creates a seperation between <b>vectors</b> and 1-row <b>matrices</b> for this reason exactly). Also, It is important to remember that while the dot product can be thought of as just a specific case in matrix multiplication, the dot product can also be thought of as it&#39;s own operation, e.g. a multiplication operator for equal sized vectors that returns a scalar.",2021-10-09T14:45:50Z
Ugxw0YO4eGY0acHVY4h4AaABAg,@vinayreddy8683,,1,qsIrQi0fzbY,2,0,2019-12-30T13:17:55Z,"At <a href=""https://www.youtube.com/watch?v=qsIrQi0fzbY&amp;t=1m37s"">1:37</a> shouldn&#39;t be w^t *x[i].<br>Did he missed transpose?",2019-12-30T13:17:55Z
Ugxw0YO4eGY0acHVY4h4AaABAg.93AAgy8_RY193EnB8MjmhM,@user-rk3qr8yd1x,Ugxw0YO4eGY0acHVY4h4AaABAg,2,qsIrQi0fzbY,0,1,2020-01-01T08:19:56Z,"yes, watch (C1W2L13)",2020-01-01T08:19:56Z
Ugxw0YO4eGY0acHVY4h4AaABAg.93AAgy8_RY1945PdPqTmch,@DanMonster97,Ugxw0YO4eGY0acHVY4h4AaABAg,2,qsIrQi0fzbY,0,0,2020-01-22T13:23:42Z,Isn&#39;t that a scalar multiplication?,2020-01-22T13:23:42Z
UgxEdgyNMWQEArDRMRp4AaABAg,@ahmed_nyc,,1,qsIrQi0fzbY,2,10,2019-07-06T04:47:24Z,"<a href=""http://np.dot/"">np.dot</a> in Python is just a fast algorithm in c for calculating the dot product. There is a for loop inside the implementation of <a href=""http://np.dot/"">np.dot</a>, but the algorithm is way faster.",2019-07-06T04:47:30Z
UgxEdgyNMWQEArDRMRp4AaABAg.8x1VZrKKotp907eYe5QDeq,@itssamuelrowe,UgxEdgyNMWQEArDRMRp4AaABAg,2,qsIrQi0fzbY,0,1,2019-10-16T00:15:37Z,"And also, I think <a href=""http://np.dot/"">np.dot</a> runs on the GPU.",2019-10-16T00:15:37Z
UgxEdgyNMWQEArDRMRp4AaABAg.8x1VZrKKotp9TxBDkjIl0M,@theVSORIGINALs,UgxEdgyNMWQEArDRMRp4AaABAg,2,qsIrQi0fzbY,0,0,2021-10-26T05:00:48Z,its not a algorithm its fast because it uses parellism,2021-10-26T05:00:48Z
UgwCUcyEStU2m2c8qGl4AaABAg,@danielchin1259,,1,qsIrQi0fzbY,0,1,2019-06-27T03:03:45Z,%%timeit,2019-06-27T03:03:45Z
UgzLgtGN1DEjNXPjPOh4AaABAg,@goutamkumarghorai6746,,1,qsIrQi0fzbY,0,1,2019-01-10T18:17:54Z,"sir, you are great, presently world learns deep learning from you, it is great. your contribution never forgot the <a href=""http://world.you/"">world.you</a> are just like next to God for those students who are unable to spend huge money on buying course material from different sources.",2019-01-10T18:17:54Z
Ugynn2MWsWKcLFSXwxF4AaABAg,@sbarter,,1,qsIrQi0fzbY,0,6,2018-08-12T03:15:23Z,makes me feel better about how many times I have to hit backspace when i watch Ng&#39;s demo.,2018-08-12T03:15:23Z
UgxoxUZrCjIbyZ5Pm8N4AaABAg,@suharsh96,,1,qsIrQi0fzbY,0,1,2018-04-08T00:34:56Z,great video!,2018-04-08T00:34:56Z
UgzBBFX83hZKmUX9scB4AaABAg,@lennylinus4231,,1,pYWASRauTzs,1,0,2021-01-16T22:58:13Z,dzi = ai (1-ai ).. wasnt it dzi = ai - yi ???,2021-01-16T22:58:13Z
UgzBBFX83hZKmUX9scB4AaABAg.9IaPZE8Bv8R9oEfW-DW7X-,@classicalfandom8219,UgzBBFX83hZKmUX9scB4AaABAg,2,pYWASRauTzs,0,0,2023-04-08T08:19:47Z,It&#39;s the same put in the values and check the equality,2023-04-08T08:19:47Z
Ugx3r771BeiRau3U02l4AaABAg,@shanefeng3215,,1,pYWASRauTzs,1,16,2020-05-04T16:08:07Z,So this video is the only 1080p in all courses?,2020-05-04T16:08:07Z
Ugx3r771BeiRau3U02l4AaABAg.98EvKo12dS19Sex2KE2zvT,@thepresistence5935,Ugx3r771BeiRau3U02l4AaABAg,2,pYWASRauTzs,0,0,2021-09-24T06:30:27Z,May be,2021-09-24T06:30:27Z
UgzBaUgehZxsPoESLe14AaABAg,@Yippie37,,1,pYWASRauTzs,0,2,2019-12-05T02:58:10Z,m,2019-12-05T02:58:10Z
UgyUZGfZSXGVyrbDmDF4AaABAg,@Ezechielpitau,,1,pYWASRauTzs,2,9,2019-01-29T16:58:20Z,"But all this efficiency gain is really just because numpy is a more efficient C implementation, right?<br>Cause at the end of the day, what&#39;s calculated is STILL in some way or other w(i)*x(i) and then summing it all up.",2019-01-29T16:58:20Z
UgyUZGfZSXGVyrbDmDF4AaABAg.8qgycD8vDT89NocnFl72Jh,@ankitraj_23,UgyUZGfZSXGVyrbDmDF4AaABAg,2,pYWASRauTzs,0,2,2021-05-26T18:08:56Z,Parallelism makes it faster I think,2021-05-26T18:08:56Z
UgyUZGfZSXGVyrbDmDF4AaABAg.8qgycD8vDT89oEeZw6I_IS,@classicalfandom8219,UgyUZGfZSXGVyrbDmDF4AaABAg,2,pYWASRauTzs,0,0,2023-04-08T08:11:35Z,He mentioned SIMD in the previous video look it up,2023-04-08T08:11:35Z
UgzLOZ6CHY-mzNlJP7B4AaABAg,@EranM,,1,pYWASRauTzs,0,4,2018-11-07T13:31:25Z,"<a href=""https://www.youtube.com/watch?v=pYWASRauTzs&amp;t=6m15s"">6:15</a> Andrew gets excited of Vectorization! CUTE!!!",2018-11-07T13:31:25Z
Ugw-T2pua6mnyycL1jJ4AaABAg,@MuhammadHamza-jc2ji,,1,pYWASRauTzs,2,1,2018-07-20T11:35:23Z,"I was wondering, if we had to/ or want to know the Big O of our calculation, how do we do that with single Numpy function.",2018-07-20T11:35:23Z
Ugw-T2pua6mnyycL1jJ4AaABAg.8ivREya2beB8p_2wmC9qQI,@OmerJerk,Ugw-T2pua6mnyycL1jJ4AaABAg,2,pYWASRauTzs,0,0,2019-01-01T18:39:31Z,It heavily depends on the architecture you are running your code on. Cannot find the complexity without knowing the architecture and how numpy implements those SIMD instructions.,2019-01-01T18:39:31Z
Ugw-T2pua6mnyycL1jJ4AaABAg.8ivREya2beB92Xc92PuEhc,@legacies9041,Ugw-T2pua6mnyycL1jJ4AaABAg,2,pYWASRauTzs,0,0,2019-12-14T19:17:42Z,Around O(n^2.6) instead of O(n^3) for non vectorized method,2019-12-14T19:17:42Z
Ugx_w71itlRTeY099Gh4AaABAg,@DJmates,,1,pYWASRauTzs,3,9,2017-11-27T17:40:02Z,"Around <a href=""https://www.youtube.com/watch?v=pYWASRauTzs&amp;t=4m04s"">4:04</a>, you show the equations inside the for loop. In these, you wrote that &quot;dz = a(1‚àía)&quot;. However, during course C1W2L10 (Gradient Descent on m Examples), around time <a href=""https://www.youtube.com/watch?v=pYWASRauTzs&amp;t=4m35s"">4:35</a>, we use &quot;dz = a‚àíy&quot;. I could re-derive this last equation (it is indeed &quot;dz = a‚àíy&quot;). I therefore believe there is an error in this course, isn&#39;t it ? Thank you",2017-11-27T17:40:02Z
Ugx_w71itlRTeY099Gh4AaABAg.8_TzA7o2XOV8a3Rj0vneAf,@changyulin47,Ugx_w71itlRTeY099Gh4AaABAg,2,pYWASRauTzs,0,0,2017-12-12T06:50:14Z,"you are right, please check C1W2L14",2017-12-12T06:50:14Z
Ugx_w71itlRTeY099Gh4AaABAg.8_TzA7o2XOV8fAAKAPniBd,@dpacmanh,Ugx_w71itlRTeY099Gh4AaABAg,2,pYWASRauTzs,0,2,2018-04-18T04:09:49Z,(da/dz) = a(1 - a) and (dL/dz) = (a - y),2018-04-18T04:09:49Z
Ugx_w71itlRTeY099Gh4AaABAg.8_TzA7o2XOV95kZr2k6ZTj,@acidtears,Ugx_w71itlRTeY099Gh4AaABAg,2,pYWASRauTzs,0,2,2020-03-03T18:52:26Z,@@dpacmanh Incorrect. da/dz is indeed a(1-a) but we are looking for dz itself. dz = (dl/da = -y/a + 1-y/1-a) * (da/dz = a(1-a)),2020-03-03T18:52:26Z
Ugy3Dq0Dcf0qWpU2hER4AaABAg,@abdullahnasir8535,,1,okpqeEUdEkY,0,0,2023-12-04T08:34:47Z,"For input feature x being a single nx dimensional vector, we have parameters w which is an nx dimensional vector and b which is a real number.<br>While in case of X (capital x) we have an nx by m dimensional matrix which is a matrix consisting of all m input features, x.<br>If for a single input feature, x we have parameters w of equal dimensions and b a real number, then for m input features, we need m parameters w and b.<br>This means our parameter w is actually an nx by m dimensional matrix just like our matrix X. <br>So, transpose of w should be an m by nx dimensional matrix and not a single dimensional row vector. <br><br>I can&#39;t seem to understand why Andrew said that w is a row vector but I get that if w is a nx by 1 dimensional row vector, we could get a matrix multiplication be between a 1 by nx dimensional vector and a nx by m dimensional matrix which would return a 1 by m dimensional row vector and in turn get added to b which is another row vector of equivalent dimensions. The shape of the output vector is not 1 by 1 but 1 by m.<br>Unless x is an nx by 1 dimensional vector, we will not get a 1 by 1 dimensional vector when multiplying it with the transpose of parameter w being 1 by nx dimensions.",2023-12-04T08:34:47Z
UgxQJWbhKDn8fGACtBJ4AaABAg,@SakshiGupta-qc2pq,,1,okpqeEUdEkY,0,0,2023-09-08T16:25:56Z,Should the weight vector be kept as row vector or column vector? How to determine whether we need to use transpose of weight or not?,2023-09-08T16:25:56Z
Ugx6DetL2rQ_l1A90I94AaABAg,@dijkstra4678,,1,okpqeEUdEkY,0,0,2022-03-19T10:26:59Z,Amazing!,2022-03-19T10:26:59Z
UgyqrU7wOrjYUVorSDl4AaABAg,@JustinMasayda,,1,okpqeEUdEkY,0,1,2022-01-03T22:32:30Z,"You describe broadcasting as being a Python feature, but it&#39;s actually a feature of the NumPy library, not intrinsic to Python. Thanks for this great video series!",2022-01-03T22:35:45Z
UgwJtsLKpNOgcsGl46l4AaABAg,@kailasanischal6790,,1,okpqeEUdEkY,1,3,2021-11-12T07:22:02Z,"doesn&#39;t w changes???<br>after each training set,in gradient descent algo w changes...so how can we compute complete z using initial w??",2021-11-12T07:22:02Z
UgwJtsLKpNOgcsGl46l4AaABAg.9UdCu1oNLKU9ZkZKVqNp92,@dijkstra4678,UgwJtsLKpNOgcsGl46l4AaABAg,2,okpqeEUdEkY,0,0,2022-03-19T10:29:41Z,"I believe this is the forward pass, so in other words this simultaneously does a forward pass on every element in the training data which then can be used to calculate the cost for each forward pass and then once again simultaneously use gradient descent on every training example.",2022-03-19T10:29:41Z
Ugyk2iheUf63QM3qPfl4AaABAg,@user-ip2tq8hb7q,,1,okpqeEUdEkY,1,0,2020-02-08T09:01:35Z,Why we divide m at dw and db?,2020-02-08T09:01:35Z
Ugyk2iheUf63QM3qPfl4AaABAg.94li9QrnKfY97fhadp_pFZ,@user-or7ji5hv8y,Ugyk2iheUf63QM3qPfl4AaABAg,2,okpqeEUdEkY,0,3,2020-04-20T14:35:26Z,To get the average of m samples,2020-04-20T14:35:26Z
Ugz8pq8t-xfQ8wDgdKh4AaABAg,@TheAlians07,,1,okpqeEUdEkY,6,1,2019-10-26T02:36:34Z,Why does W-Transpose have x elements? Shouldn&#39;t it have w elements? If I understand correctly W vector is n x 1 consisting weights for all n features of x.<br><br><br>REPLY,2019-10-26T02:36:34Z
Ugz8pq8t-xfQ8wDgdKh4AaABAg.90XeccOR8uc92XiGfxTffS,@legacies9041,Ugz8pq8t-xfQ8wDgdKh4AaABAg,2,okpqeEUdEkY,0,0,2019-12-14T20:11:10Z,"You mean at <a href=""https://www.youtube.com/watch?v=okpqeEUdEkY&amp;t=03m04s"">03:04</a>? W is the vector of nx1 with weight and not with x&#39;s",2019-12-14T20:11:10Z
Ugz8pq8t-xfQ8wDgdKh4AaABAg.90XeccOR8uc92dZIJaA8mR,@kumarsharma3243,Ugz8pq8t-xfQ8wDgdKh4AaABAg,2,okpqeEUdEkY,0,0,2019-12-17T11:58:41Z,because features have their respective weights so W-T.X matrix is 1*1 matrix or one equation i.e. w1x1+w2x2......wnXn.,2019-12-17T11:58:41Z
Ugz8pq8t-xfQ8wDgdKh4AaABAg.90XeccOR8uc92j3HhNOeyg,@royclymer5690,Ugz8pq8t-xfQ8wDgdKh4AaABAg,2,okpqeEUdEkY,0,0,2019-12-19T15:14:26Z,"I agree. It seems to me that the original set of w&#39;s was a 1 by n column of weights to be multiplied with corresponding values of the i&#39;th element of a single training example, x super script i.  So the only way the W-transpose time X equation makes sense to me is if the W matrix is filled with m columns, each of which corresponding to the I&#39;th training example.",2019-12-19T15:14:26Z
Ugz8pq8t-xfQ8wDgdKh4AaABAg.90XeccOR8uc95yKVgNSQLW,@skypickle29,Ugz8pq8t-xfQ8wDgdKh4AaABAg,2,okpqeEUdEkY,0,1,2020-03-09T03:07:41Z,"x has n features for each sample laid out in a column and m samples(# of columns)<br>W also has a weight for each feature(n x 1 matrix). To be able to multiply w and x, W has to be FIRST and it has to be flipped into a row. Remember,  matrix multiplication is not commutative as we have defined it. The whole idea is to get the a whole column of x to get multiplied by the whole column of W.",2020-03-09T03:07:41Z
Ugz8pq8t-xfQ8wDgdKh4AaABAg.90XeccOR8uc95yLdfay-sf,@skypickle29,Ugz8pq8t-xfQ8wDgdKh4AaABAg,2,okpqeEUdEkY,0,0,2020-03-09T03:17:39Z,"Remember our definition of matrix multiplication¬†<br><br>you take the first column of the second matrix , flip it  into a row and stick it on top of the first row of the first matrix- then multiply the terms that line up over each other so you get a whole row of products-then add up the products and stick that sum into a new  matrix.¬†<br><br>then you take the second  column of the second matrix, flip it into a row, stick it on top of the first row of the first matrix-then multiply the terms that line up over each other so you get a whole row of products-then add up the products and stick that sum into the next column of the new matrix (you&#39;re still working on the first row of the new matrix)<br><br><br>So the only way to get this done is to take the nx1 weight matrix, put in in front, and flip it into a row so it is a 1xn matrix. Now you can multiply a 1 x n matrix by the n x m matrix that is your collection of samples.",2020-03-09T03:17:39Z
UgxB9J5UZuj0tEeR9t94AaABAg,@hongsun8768,,1,okpqeEUdEkY,7,2,2018-01-08T05:42:45Z,Why are &quot;b&quot;s the same?  can someone help me?,2018-01-08T05:42:45Z
UgxB9J5UZuj0tEeR9t94AaABAg.8b8qTJpsx7I8b8qdZL3DQw,@hongsun8768,UgxB9J5UZuj0tEeR9t94AaABAg,2,okpqeEUdEkY,0,0,2018-01-08T05:44:17Z,"if we have different b and taking average into the wt dotproduct, are they the same?",2018-01-08T05:44:17Z
UgxB9J5UZuj0tEeR9t94AaABAg.8b8qTJpsx7I8dHKNBUeqPa,@tino3420,UgxB9J5UZuj0tEeR9t94AaABAg,2,okpqeEUdEkY,0,0,2018-03-02T05:49:30Z,b&#39;s are the same because the only thing that changes is which example it&#39;s calculating. WT and b stay the same.,2018-03-02T05:49:30Z
UgxB9J5UZuj0tEeR9t94AaABAg.8b8qTJpsx7I8es-h90e9mf,@redberries8039,UgxB9J5UZuj0tEeR9t94AaABAg,2,okpqeEUdEkY,0,6,2018-04-10T17:31:24Z,I think b is the &#39;bias&#39; applied to a particular node ....that&#39;s the value the result of wT.x has to overcome to activate the node ... it&#39;s the same for the whole wT.x calculation on a particular pass.,2018-04-10T17:31:24Z
UgxB9J5UZuj0tEeR9t94AaABAg.8b8qTJpsx7I92XiU_EzRWW,@legacies9041,UgxB9J5UZuj0tEeR9t94AaABAg,2,okpqeEUdEkY,0,1,2019-12-14T20:13:04Z,"b is just randomly initialized, it also gets updated in the gradient descent step",2019-12-14T20:13:04Z
UgxB9J5UZuj0tEeR9t94AaABAg.8b8qTJpsx7I92thcs31Hq5,@ruchitvithani9953,UgxB9J5UZuj0tEeR9t94AaABAg,2,okpqeEUdEkY,0,3,2019-12-23T18:28:07Z,"This is the case of Logistic regression and remember that not the neural networks. In this case, how do you measure Z? We do it by w1x1 + w2x2 + ... + wnxn + b  right?  And then we predict output probability using sigmoid function. We generally use variable theta instead of w used in this video, but this course is about neural nets, so probably that&#39;s why professor has used w and b everywhere. Imagine Z as w0x0 + w1x1 + w2x2 + ... + wnxn. Where we take x0 = 1 and w0 = b, now replace all w&#39;s by theta&#39;s and you&#39;ll get an expression of logistic regression.",2019-12-23T18:28:07Z
UgwIib1wgshyPjTJxVx4AaABAg,@dantecerron9804,,1,okpqeEUdEkY,2,3,2017-12-27T11:16:00Z,"Thank you for the great video, just a minor thing:<br>Is it more widely accepted to make X a matrix where each example is represented by a row, or by a column?<br>I&#39;m asking because I&#39;m more comfortable with X being a matrix with dimensions &quot;m&quot; x &quot;n_x&quot; instead of &quot;n_x&quot; x &quot;m&quot;<br>The math ends up being the same all you have to do is transpose X, and multiply Xw instead of w^tX, I just wanted to know which one is more commonplace.",2017-12-27T11:17:18Z
UgwIib1wgshyPjTJxVx4AaABAg.8afY3anVSq98pjQbaLX4FT,@VT-ry2wk,UgwIib1wgshyPjTJxVx4AaABAg,2,okpqeEUdEkY,0,1,2019-01-05T19:18:45Z,I&#39;d say m by n_x is more common.  That&#39;s how sklearn treats your X_train and X_test matrices.  Same applies to the y vector (m by 1 is more common than 1 by m).,2019-01-05T19:18:45Z
UgwIib1wgshyPjTJxVx4AaABAg.8afY3anVSq992XiMXlP6ky,@legacies9041,UgwIib1wgshyPjTJxVx4AaABAg,2,okpqeEUdEkY,0,0,2019-12-14T20:11:58Z,It works better that way with neural networks than with logistic regression,2019-12-14T20:11:58Z
UgzrgjDY1ZVZZlTg0ap4AaABAg,@instasol2453,,1,2BkqApHKwn0,1,0,2023-05-05T11:21:29Z,God Level Teacher! Take a bow!,2023-05-05T11:21:29Z
UgzrgjDY1ZVZZlTg0ap4AaABAg.9pKWlK_6Jxj9qTLF5tr_T1,@jambajuice07,UgzrgjDY1ZVZZlTg0ap4AaABAg,2,2BkqApHKwn0,0,0,2023-06-02T18:05:23Z,mid,2023-06-02T18:05:23Z
UgxM9LaBacvdQuCqKiR4AaABAg,@dijkstra4678,,1,2BkqApHKwn0,1,1,2022-03-19T10:52:30Z,"I think the problem at <a href=""https://www.youtube.com/watch?v=2BkqApHKwn0&amp;t=5m21s"">5:21</a> is that what looks like a nxm matrix is actually a 1xm matrix because if you think about what each x(1),x(2) etc were is actually that whole row of input values so I think what he has accidentally done here is abusive notation and what he actually meant by those x(1),x(2) etc in the n,m matrix is no longer the ones on the left but the actual individual input values before he vectorized the dw calculation.",2022-03-19T10:52:56Z
UgxM9LaBacvdQuCqKiR4AaABAg.9Zkawajotn89gEY0KtiSRj,@konradkawka6920,UgxM9LaBacvdQuCqKiR4AaABAg,2,2BkqApHKwn0,0,0,2022-09-21T10:54:24Z,"You&#39;re wrong, these x(1), x(2) are nx1 vectors on both sides. And this matrix on the right is nxm , not 1xm.",2022-09-21T10:54:24Z
UgwDF9b-nbNZFOYH5bJ4AaABAg,@ayushidutt8246,,1,2BkqApHKwn0,4,0,2020-08-24T17:02:16Z,"At <a href=""https://www.youtube.com/watch?v=2BkqApHKwn0&amp;t=5m17s"">5:17</a> for XdZ(t) X has dimension n*m and dZ(t) has dimension m*1, so multiplication would make the resultant matrix to be n*1, but where are the n rows ?",2020-08-24T17:02:16Z
UgwDF9b-nbNZFOYH5bJ4AaABAg.9CkPZOv7eLx9DiNqP-sLL3,@5paceb0i,UgwDF9b-nbNZFOYH5bJ4AaABAg,2,2BkqApHKwn0,0,1,2020-09-17T18:40:10Z,"@Ayushi Dutt , you are right , the resultant matrix is n*1, he has skipped that I think, after getting the n*1 matrix we also need to do the sum of all n elements in the resultant matrix (he has shown that directly in the video i.e addition of terms). Hope this helps. Correct me if I am wrong",2020-09-17T18:40:10Z
UgwDF9b-nbNZFOYH5bJ4AaABAg.9CkPZOv7eLx9DiOfqbiZqb,@ayushidutt8246,UgwDF9b-nbNZFOYH5bJ4AaABAg,2,2BkqApHKwn0,0,0,2020-09-17T18:47:28Z,@@5paceb0i you&#39;re right. I applied the same method which you mentioned. Thanks a bunch !,2020-09-17T18:47:28Z
UgwDF9b-nbNZFOYH5bJ4AaABAg.9CkPZOv7eLx9DiPxwfzB5y,@5paceb0i,UgwDF9b-nbNZFOYH5bJ4AaABAg,2,2BkqApHKwn0,0,0,2020-09-17T18:58:40Z,@@ayushidutt8246 glad I could help,2020-09-17T18:58:40Z
UgwDF9b-nbNZFOYH5bJ4AaABAg.9CkPZOv7eLx9JJ0GNH_vTQ,@NitinVerma-uj3yp,UgwDF9b-nbNZFOYH5bJ4AaABAg,2,2BkqApHKwn0,0,0,2021-02-03T16:02:14Z,x is an n-dimensional vector,2021-02-03T16:02:14Z
UgyofRqje-PI02VV_UF4AaABAg,@halildurmaz7827,,1,2BkqApHKwn0,5,0,2020-07-27T13:06:48Z,"<a href=""https://www.youtube.com/watch?v=2BkqApHKwn0&amp;t=6m50s"">6:50</a> It should be Z = wT.X + [b, b...,b]<br>¬†<br>Also, I would like to give a feedback. When you have mistakes like this, you can put a note on the video which describes the correct version",2020-07-27T13:06:48Z
UgyofRqje-PI02VV_UF4AaABAg.9BbtMC2qrhw9Cka6JOKmHK,@ayushidutt8246,UgyofRqje-PI02VV_UF4AaABAg,2,2BkqApHKwn0,0,0,2020-08-24T18:43:09Z,"Hello, actually here the concept of &quot;broadcasting&quot; is used. In Python, if you simply write wT.X+b the language will lengthen b out into [b b .... b] matrix of m*1 order. I hope that was of help !",2020-08-24T18:43:09Z
UgyofRqje-PI02VV_UF4AaABAg.9BbtMC2qrhw9DfpRKJoO6Q,@halildurmaz7827,UgyofRqje-PI02VV_UF4AaABAg,2,2BkqApHKwn0,0,0,2020-09-16T18:52:17Z,"@@ayushidutt8246 No, it should be Z = wT.X + [b, b...,b]......After this line, he writes the code of this as Z = np.dot(w.T, x) + b, and for the code &quot;+ b&quot; is enough because of broadcasting. Is it clear?",2020-09-16T18:52:17Z
UgyofRqje-PI02VV_UF4AaABAg.9BbtMC2qrhw9DhyRpIjdXt,@deepakrathore1678,UgyofRqje-PI02VV_UF4AaABAg,2,2BkqApHKwn0,0,0,2020-09-17T14:49:29Z,@@halildurmaz7827 Correct,2020-09-17T14:49:29Z
UgyofRqje-PI02VV_UF4AaABAg.9BbtMC2qrhw9DiPLTQCKSU,@ayushidutt8246,UgyofRqje-PI02VV_UF4AaABAg,2,2BkqApHKwn0,0,0,2020-09-17T18:53:17Z,"@@halildurmaz7827 Oh, I got your point ! I think he writes that interchangeably.",2020-09-17T18:53:17Z
UgyofRqje-PI02VV_UF4AaABAg.9BbtMC2qrhw9PPohBKnx_4,@enisten,UgyofRqje-PI02VV_UF4AaABAg,2,2BkqApHKwn0,0,0,2021-07-05T10:35:30Z,Turksun degil mi?,2021-07-05T10:35:30Z
Ugyw2p4gryOI_EjhLXh4AaABAg,@ust977,,1,2BkqApHKwn0,2,0,2020-02-19T11:45:17Z,"At <a href=""https://www.youtube.com/watch?v=2BkqApHKwn0&amp;t=5m16s"">5:16</a> did it not suppose to be (1 ,1) since multiplying ((1 ,m) * (m, 1) equals (1, 1)",2020-02-19T11:46:09Z
Ugyw2p4gryOI_EjhLXh4AaABAg.95DKd3ghrKe95kc5_M1M-3,@acidtears,Ugyw2p4gryOI_EjhLXh4AaABAg,2,2BkqApHKwn0,0,0,2020-03-03T19:20:46Z,"No? Your calculation makes no sense... What are you even referring to? m is the number of examples so the only way to arrive at your result is by using only a single example (m=1). However, this does not happen there at <a href=""https://www.youtube.com/watch?v=2BkqApHKwn0&amp;t=5m16s"">5:16</a>, nor anywhere else.",2020-03-03T19:20:46Z
Ugyw2p4gryOI_EjhLXh4AaABAg.95DKd3ghrKe95kgh47floS,@ust977,Ugyw2p4gryOI_EjhLXh4AaABAg,2,2BkqApHKwn0,0,0,2020-03-03T20:00:59Z,"@@acidtears Hi!  Actually what Professor Ng was referring to is Broadcasting in Python. I did not know that. I discovered it later. And at <a href=""https://www.youtube.com/watch?v=2BkqApHKwn0&amp;t=5m19s"">5:19</a> he writes n*1. So basically he multiplies (1 n)*(n 1). So call my m here n.",2020-03-03T20:33:52Z
Ugz9F3RDMv5bvlcMayd4AaABAg,@prafulbs7216,,1,2BkqApHKwn0,1,0,2020-02-16T10:45:53Z,"Man very confusing dw, db and all....Have explain better. I am just looking into it.",2020-02-16T10:45:53Z
Ugz9F3RDMv5bvlcMayd4AaABAg.955VSQmxel995kbH4HIhU1,@acidtears,Ugz9F3RDMv5bvlcMayd4AaABAg,2,2BkqApHKwn0,0,0,2020-03-03T19:13:36Z,You need to start from the beginning. He is incredibly good at explaining this complex topic.,2020-03-03T19:13:36Z
Ugy01ZuGqfKFC1m8hpR4AaABAg,@ankitdixit6668,,1,2BkqApHKwn0,2,1,2019-09-22T13:27:49Z,"In previous lectures we had dz(i) = a(i)(1-a(i)),  here dz(i) =  a(i) - y(i), which one is correct?",2019-09-22T13:28:10Z
Ugy01ZuGqfKFC1m8hpR4AaABAg.9-BH7mcHQDh9-DMdJDE-xu,@yvesboutellier336,Ugy01ZuGqfKFC1m8hpR4AaABAg,2,2BkqApHKwn0,0,2,2019-09-23T08:54:25Z,"dz was also in previous lectures a(i) - y(i),¬†<br>a(i)(1-a(i)) was da/dz which was multiplied with dL/da (chain rule) which gives dz (=dL/dz) <br>for your I&#39;m referring to C1W2L09",2019-09-23T08:54:25Z
Ugy01ZuGqfKFC1m8hpR4AaABAg.9-BH7mcHQDh98eoXiHZViM,@haohuynhnhat3881,Ugy01ZuGqfKFC1m8hpR4AaABAg,2,2BkqApHKwn0,0,1,2020-05-15T02:48:13Z,"because dz here refer to (dL/da)*(da/dz), which is equal to a(i) - y(i). the term (da/dz) is equal to a(1-a), and the term (dL/da) is equal to (-y/a + (1-y)/(1-a) ).  When you multiply the two term then you will see that it is equal to a - y.",2020-05-15T02:48:13Z
UgydE8nrYdN_sJFKk3d4AaABAg,@rahulkumarjha2404,,1,2BkqApHKwn0,3,1,2019-03-13T14:23:07Z,Is dw a value or a vector after vectorization.,2019-03-13T14:23:07Z
UgydE8nrYdN_sJFKk3d4AaABAg.8sQQ1wopMql9-BHDHOf-2R,@ankitdixit6668,UgydE8nrYdN_sJFKk3d4AaABAg,2,2BkqApHKwn0,0,0,2019-09-22T13:28:33Z,I might be late but vector,2019-09-22T13:28:33Z
UgydE8nrYdN_sJFKk3d4AaABAg.8sQQ1wopMql92ZbUaNFwsA,@udaykadam5455,UgydE8nrYdN_sJFKk3d4AaABAg,2,2BkqApHKwn0,0,0,2019-12-15T13:50:23Z,@@ankitdixit6668 <br><br>Then dw would be (n*1) vector.<br>And how does that subtract from the &#39;w&#39;  which has different dimension.,2019-12-15T13:50:23Z
UgydE8nrYdN_sJFKk3d4AaABAg.8sQQ1wopMql92dsNo-WUyF,@kumarsharma3243,UgydE8nrYdN_sJFKk3d4AaABAg,2,2BkqApHKwn0,0,0,2019-12-17T14:54:12Z,dw is just a notation for gradient of loss function wrt w.....,2019-12-17T14:54:12Z
UgzXOheJRi9MjuLzWZ94AaABAg,@ritapravadutta7939,,1,2BkqApHKwn0,1,0,2019-01-25T16:22:11Z,"We have to calculate dw1, dw2, dw3... how to vectorize that?",2019-01-25T16:22:11Z
UgzXOheJRi9MjuLzWZ94AaABAg.8qXbIvRjaMe8qZPFWh--5l,@ritapravadutta7939,UgzXOheJRi9MjuLzWZ94AaABAg,2,2BkqApHKwn0,0,0,2019-01-26T09:06:36Z,clear now.,2019-01-26T09:06:36Z
Ugy5GjHWk_NTrr2rUSV4AaABAg,@prayushdawda7807,,1,2BkqApHKwn0,1,2,2018-11-04T14:14:49Z,"I&#39;m confused.<br>At <a href=""https://www.youtube.com/watch?v=2BkqApHKwn0&amp;t=5m45s"">5:45</a>, instead of doing X*dz.T, can we alternatively do dz*X.T?",2018-11-04T14:14:49Z
Ugy5GjHWk_NTrr2rUSV4AaABAg.8nEEYLSlIQ88nNew1NqF4N,@EranM,Ugy5GjHWk_NTrr2rUSV4AaABAg,2,2BkqApHKwn0,0,4,2018-11-08T06:07:17Z,"almost the same, but with a different shape: <br>x1 = np.array([[1, 2], [3, 4]])<br>x2 = np.array([[3], [4]])<br><br><br>np.dot(x1.T, x2)<br>Out[59]: <br>array([[15],<br>       [22]])<br>np.dot(x2.T, x1)<br>Out[60]: array([[15, 22]])<br><br><br>And here we Transpose it to the original shape<br>np.dot(x2.T, x1).T<br>Out[61]: <br>array([[15],<br>       [22]])",2018-11-08T06:07:17Z
UgzD8hsi-qdmYH9CRKR4AaABAg,@KshitijBajracharya,,1,2BkqApHKwn0,1,1,2018-07-12T16:32:33Z,Why have we skipped the calculation of J in the vectorized form? Can we convert it into vectorized form with numpy similar to other variables? Or is it not required at all?,2018-07-12T16:32:33Z
UgzD8hsi-qdmYH9CRKR4AaABAg.8ibMtOwRZu98m9wD7SvtdT,@yangli8575,UgzD8hsi-qdmYH9CRKR4AaABAg,2,2BkqApHKwn0,0,2,2018-10-09T01:37:33Z,it is not necessary to calculate J here.,2018-10-09T01:37:33Z
UgxeZaDHoY0AZhW0rZZ4AaABAg,@yasaminkhorramzadeh3905,,1,2BkqApHKwn0,1,1,2018-04-29T15:02:47Z,"It&#39;s very confusing how the notation between column and row convention keeps changing. What is the standard here? For example, dz = A-Y where we know Y is a (mX1 ) column vector and as such I expect dz to be the same. Then in computing dw, dz.Transpose is used which making the matrix multiplication rule means that dz was in fact a row vector (1Xm).",2018-04-29T15:04:50Z
UgxeZaDHoY0AZhW0rZZ4AaABAg.8fcenI9MAwp8kKxVV06Z79,@mahipalsinghsaran8961,UgxeZaDHoY0AZhW0rZZ4AaABAg,2,2BkqApHKwn0,0,2,2018-08-24T15:17:39Z,"@<a href=""https://www.youtube.com/watch?v=2BkqApHKwn0&amp;t=1m33s"">1:33</a> he says &quot;we had defined Y as [y1....ym] stacked horizontally &quot; so here he&#39;s taking Y as 1Xm matrix",2018-08-24T15:17:39Z
UgxExItj141Kd8k4E-p4AaABAg,@arsalan2780,,1,2BkqApHKwn0,5,0,2018-02-15T10:02:36Z,"@<a href=""https://www.youtube.com/watch?v=2BkqApHKwn0&amp;t=5m33s"">5:33</a> matrix multiplication for (Xdz) is against the matrices multiplication rule considering the required output.. <br>try to multiple both and you will get to know why.. <br>if i am wrong please correct me",2018-02-15T10:02:36Z
UgxExItj141Kd8k4E-p4AaABAg.8cg9PlIjVum8eVahpnzAYm,@ShubhamKumar-nz9rl,UgxExItj141Kd8k4E-p4AaABAg,2,2BkqApHKwn0,0,1,2018-04-01T15:21:46Z,"X is nxm matrix whereas dZ-Transpose will be mx1 matrix. When X and dZ are multiplied, resulting matrix will be nx1 [ nxm X mx1 = nx1 ]. So it is according to matrices multiplication rule.",2018-04-01T15:21:46Z
UgxExItj141Kd8k4E-p4AaABAg.8cg9PlIjVum8kPPu9S8FYh,@FalguniDasShuvo,UgxExItj141Kd8k4E-p4AaABAg,2,2BkqApHKwn0,0,1,2018-08-26T08:51:31Z,"[ x1dz1 + x2dz2 + ‚Ä¶. + xndzn ] is a 1x1 matrix ( just a Real number ).<br>I suppose the source of confusion is the &quot; + &quot; signs. <br>I think it is a slip of pen and should be like : [ x1dz1 , x2dz2 , ‚Ä¶.. , xndzn ] (Here, I am using &#39;commas&#39; as  separators ). It is now a n x 1 matrix.",2018-08-26T08:51:31Z
UgxExItj141Kd8k4E-p4AaABAg.8cg9PlIjVum8nmNWEpy61x,@nikhilbansal7664,UgxExItj141Kd8k4E-p4AaABAg,2,2BkqApHKwn0,0,1,2018-11-18T05:46:35Z,@@FalguniDasShuvo this is still a 1 x n matrix as it&#39;s a row vector,2018-11-18T05:46:35Z
UgxExItj141Kd8k4E-p4AaABAg.8cg9PlIjVum8oTgmGiaOkS,@richeshc,UgxExItj141Kd8k4E-p4AaABAg,2,2BkqApHKwn0,0,1,2018-12-05T10:50:16Z,Falguni Das in video he has clearly said +. Moreover then too it‚Äôs 1xn matrix not nx1,2018-12-05T10:50:16Z
UgxExItj141Kd8k4E-p4AaABAg.8cg9PlIjVum9gFSdBSOh5K,@konradkawka6920,UgxExItj141Kd8k4E-p4AaABAg,2,2BkqApHKwn0,0,0,2022-09-21T19:26:40Z,"@@richeshc Nope, it&#39;s nx1",2022-09-21T19:26:40Z
UgzfrymuzzZYUwo0D_V4AaABAg,@markomilenkovic2714,,1,tKcLaGdvabM,0,0,2023-11-19T00:46:11Z,Thank you Andrew!,2023-11-19T00:46:11Z
UgxokbtZKKDDzoBr5op4AaABAg,@codingwithsam4992,,1,tKcLaGdvabM,0,0,2023-09-21T06:56:38Z,"<a href=""https://www.youtube.com/watch?v=tKcLaGdvabM&amp;t=3m40s"">3:40</a> , cal.reshape(1,4) is it not redundant?",2023-09-21T06:56:38Z
UgyDN9grFSREOiKGFvt4AaABAg,@ahmedjamiu9149,,1,tKcLaGdvabM,0,0,2023-05-07T16:00:45Z,andrew is a blessing to folks taking this path on their own,2023-05-07T16:01:06Z
UgxopqOthYA22iu1II54AaABAg,@arjungoud3450,,1,tKcLaGdvabM,0,0,2022-02-17T16:09:27Z,"Does boosting mean, avoiding loops in matrix operations by reshaping matrices, which activates parallel computing?",2022-02-17T16:11:07Z
UgyJfpEl4lpge7DJI5V4AaABAg,@thepresistence5935,,1,tKcLaGdvabM,0,0,2021-09-25T04:16:22Z,"Deep Explanation for Deep Learning, Thanks!",2021-09-25T04:16:22Z
UgyL8cRmNBZtbE5lLJJ4AaABAg,@eashan2405,,1,tKcLaGdvabM,1,2,2021-09-01T07:55:03Z,"PLEASE REPLY üôè<br>Instead of A.sum(axis=0) can we use np.sum(A, axis=0) ??",2021-09-01T08:31:15Z
UgyL8cRmNBZtbE5lLJJ4AaABAg.9RjsRnnhOdB9bNGYvZedrU,@Mehdirose,UgyL8cRmNBZtbE5lLJJ4AaABAg,2,tKcLaGdvabM,0,0,2022-05-23T13:38:02Z,yes,2022-05-23T13:38:02Z
UgzXllmXXgOFuFX6Vep4AaABAg,@BharathinfinityHegde,,1,tKcLaGdvabM,1,0,2021-07-29T17:45:55Z,"<a href=""https://www.youtube.com/watch?v=tKcLaGdvabM&amp;t=4m43s"">4:43</a> i think thats incorrect as cal have shape (4,) and not (1,4)",2021-07-29T17:45:55Z
UgzXllmXXgOFuFX6Vep4AaABAg.9QOO1dF3JD59RTZwO1PBJY,@rishikeshkanabar4650,UgzXllmXXgOFuFX6Vep4AaABAg,2,tKcLaGdvabM,0,0,2021-08-25T14:37:30Z,Nope it is right. It is a 1x4 matrix i.e. 1 row 4 columns.,2021-08-25T14:37:30Z
UgzEQUdpyHQK2pgFMhZ4AaABAg,@cipherxen2,,1,tKcLaGdvabM,2,0,2020-12-07T04:47:07Z,Is it a feature of python or numpy?,2020-12-07T04:47:07Z
UgzEQUdpyHQK2pgFMhZ4AaABAg.9GxStriqYU79GytHMl0Grz,@haakonvt,UgzEQUdpyHQK2pgFMhZ4AaABAg,2,tKcLaGdvabM,0,0,2020-12-07T18:05:38Z,Numpy üòÑ,2020-12-07T18:05:38Z
UgzEQUdpyHQK2pgFMhZ4AaABAg.9GxStriqYU79GyupvaHlno,@cipherxen2,UgzEQUdpyHQK2pgFMhZ4AaABAg,2,tKcLaGdvabM,0,0,2020-12-07T18:19:14Z,@@haakonvt ü§≠,2020-12-07T18:19:14Z
UgwyUP2_xoMaxDve4rR4AaABAg,@petraredemption9138,,1,tKcLaGdvabM,0,0,2020-09-15T02:10:16Z,NICE.. thank you,2020-09-15T02:10:16Z
UgwZCv65YYpFCrAYR0R4AaABAg,@AnkitSharma-is4po,,1,tKcLaGdvabM,0,2,2020-08-16T03:26:18Z,"Been trying to understand the dry run of the fundamental principle of the operation, this video is very helpful in solving my doubts...<br><br>Thanks a lot",2020-08-16T03:26:18Z
Ugw7nptBcLlEGt_cutZ4AaABAg,@shreyansh_jain,,1,tKcLaGdvabM,1,0,2020-08-05T09:06:25Z,Where can I get the Juptyer notebook file for this? (Any github links ?),2020-08-05T09:06:25Z
Ugw7nptBcLlEGt_cutZ4AaABAg.9Byd-VYUGXV9Ce__vJVQ13,@ShivamGupta-hr8sn,Ugw7nptBcLlEGt_cutZ4AaABAg,2,tKcLaGdvabM,0,0,2020-08-22T10:43:09Z,download anaconda,2020-08-22T10:43:09Z
Ugzq6o9rESMcCSoyNVB4AaABAg,@yuchenzhao6411,,1,tKcLaGdvabM,0,0,2020-06-06T06:45:42Z,"If not for broadcasting introduction, might percentage = 100*np.matmul(A, (np.diag(1/cal))) be more intuitive to do matrix multiplication? And would it be a good convention to not use broadcasting since it is implicit?",2020-06-06T06:45:42Z
UgzRdjewkutJY1uIRjV4AaABAg,@MondayMotivations,,1,tKcLaGdvabM,2,1,2020-01-04T04:22:07Z,"I dont think we need to reshape cal because it is already a 1,4 matrix. <br>simply use A/cal.",2020-01-04T04:22:07Z
UgzRdjewkutJY1uIRjV4AaABAg.93M5LvEWGVy93UmYSlisOy,@PiyushShandilya,UgzRdjewkutJY1uIRjV4AaABAg,2,tKcLaGdvabM,0,3,2020-01-07T13:22:13Z,"<a href=""https://www.youtube.com/watch?v=tKcLaGdvabM&amp;t=4m54s"">4:54</a> &quot;That&#39;s actually a little bit redundant&quot; - Andrew Ng",2020-01-07T13:22:13Z
UgzRdjewkutJY1uIRjV4AaABAg.93M5LvEWGVy95kex_amky6,@acidtears,UgzRdjewkutJY1uIRjV4AaABAg,2,tKcLaGdvabM,0,1,2020-03-03T19:45:46Z,He literally said that. Better be safe than sorry. If you handle neural nets with various input and output sizes you can quickly lose track!,2020-03-03T19:45:46Z
UgyHnYIyOEb3PT7q6t94AaABAg,@kumarsharma3243,,1,tKcLaGdvabM,1,0,2019-12-18T10:10:55Z,"<a href=""https://www.youtube.com/watch?v=tKcLaGdvabM&amp;t=8m00s"">8:00</a> what if we have m*(n-1) matrix then can we do it by converting this to copy one¬†column  at last?? what was the column then ??",2019-12-18T10:11:13Z
UgyHnYIyOEb3PT7q6t94AaABAg.92fwknLk_4I97IA_lKm67n,@user-hx1cy3wc3m,UgyHnYIyOEb3PT7q6t94AaABAg,2,tKcLaGdvabM,0,0,2020-04-11T01:56:26Z,"At least one of m or n should be the same, because it should be when calculate elementwise.",2020-04-11T01:56:26Z
UgyfH2Z2O9GeIt-7ol54AaABAg,@lutzruhmann7162,,1,tKcLaGdvabM,0,0,2019-10-23T07:00:19Z,This was a very nice hands on explanation. Thank you!,2019-10-23T07:00:19Z
UgzzZim_NsfQpD1MeG14AaABAg,@shibairui982,,1,tKcLaGdvabM,0,8,2019-06-10T11:27:32Z,Andrew NG is the BEST.,2019-06-10T11:27:32Z
UgzxNpUEl9BQbO94v554AaABAg,@JimmyCheng,,1,tKcLaGdvabM,0,1,2019-01-12T04:44:07Z,"very clear explanation, thumbs up.",2019-01-12T04:44:07Z
UgxC_cCc5r2fZjipWil4AaABAg,@bahar4813,,1,tKcLaGdvabM,0,3,2018-08-04T09:41:19Z,thank you,2018-08-04T09:41:19Z
UgwOcKptlzVJ2nULSMR4AaABAg,@eashan2405,,1,V2QlTmh6P2Y,0,2,2021-09-01T11:34:28Z,Guys can you pls. suggest me some real world projects to do after completing this specialization?,2021-09-01T11:34:28Z
UgxF4c_cOT_iqaiRoaJ4AaABAg,@prismaticspace4566,,1,V2QlTmh6P2Y,0,1,2020-07-30T02:53:40Z,"Thanks for these useful tricks, I find this much more applicable than courses only talking about math.",2020-07-30T02:53:40Z
Ugyo2p270IqmRd-6dfJ4AaABAg,@yuchenzhao6411,,1,V2QlTmh6P2Y,0,2,2020-06-06T07:24:14Z,"Did <a href=""http://np.dot/"">np.dot</a> really equivalent to dot product in linear algebra?",2020-06-06T07:24:14Z
UgwfgCgzto8pWUKMbFJ4AaABAg,@fromthenorthfromthenorth8224,,1,V2QlTmh6P2Y,0,1,2020-02-26T13:34:12Z,Highly useful .... thanks,2020-02-26T13:34:12Z
UgxYuHfs_fBTga2F-j14AaABAg,@danielchin1259,,1,V2QlTmh6P2Y,0,2,2019-06-27T05:58:27Z,This episode is highly helpful,2019-06-27T05:58:27Z
Ugxw001ctLBNTyz0SIx4AaABAg,@thryce82,,1,V2QlTmh6P2Y,0,2,2019-05-16T03:04:25Z,yep i totally had this happen to me 15 mins ago when learning outer product <br>thanks yall!!!!!!!!!,2019-05-16T03:04:25Z
Ugys-voStangqYWY1at4AaABAg,@nitramcontrario,,1,0S9c7nHoDws,1,6,2020-08-11T22:22:53Z,"Guys, here you can see the exercises: <a href=""https://github.com/Kulbear/deep-learning-coursera"">https://github.com/Kulbear/deep-learning-coursera</a>",2020-08-11T22:22:53Z
Ugys-voStangqYWY1at4AaABAg.9CEVvGXYq5S9Rc_yKGF5F7,@Pratapsingh-ng7pr,Ugys-voStangqYWY1at4AaABAg,2,0S9c7nHoDws,0,0,2021-08-29T11:58:55Z,thanks man,2021-08-29T11:58:55Z
Ugz0VJUa7ZKWTGAQFp14AaABAg,@yashbhavsar1392,,1,0S9c7nHoDws,2,0,2018-08-30T14:29:45Z,Is there any that the channel can publish assignments somewhere and then provide a link to those assignments in the bio? If that can be done it&#39;ll be really helpful in learning this course.,2018-08-30T14:29:45Z
Ugz0VJUa7ZKWTGAQFp14AaABAg.8k_JmvZ2Ba88lVNvDo7V3Z,@fromtheleaf3554,Ugz0VJUa7ZKWTGAQFp14AaABAg,2,0S9c7nHoDws,0,2,2018-09-22T13:01:01Z,I think you can find them on some github repositories.,2018-09-22T13:01:01Z
Ugz0VJUa7ZKWTGAQFp14AaABAg.8k_JmvZ2Ba89CEVr3XhgT8,@nitramcontrario,Ugz0VJUa7ZKWTGAQFp14AaABAg,2,0S9c7nHoDws,0,1,2020-08-11T22:22:18Z,"a little bit late but here you have it: <a href=""https://github.com/Kulbear/deep-learning-coursera"">https://github.com/Kulbear/deep-learning-coursera</a>",2020-08-11T22:22:26Z
UgxrbNBqwABeJ9TDkYp4AaABAg,@ayoubrayanemesbah8845,,1,k_S5fnKjO-4,0,0,2023-10-22T22:56:24Z,"to be honest i didn&#39;t understand this approach , but when you explained it a lamp was turned-on in my brain , if y &#39; is a probability for a given x that y = 1 ,and for both y = 1 and  y = 0 we want to make y&#39; respectively 1 -y&#39; accurate then we need to define a equation that encapsulate both of them ,which is the function that you had provided , this function represent the prob y=? for a given x and we don&#39;t care about ? it can be 0 or 1 in both cases we want the prob to be accurate,thus we can take the surprise of the prob which is defined as log(1/p) = -log(p) and we minimize the surprise but this is not enough , because we want to minimize the surprises of all the Xs , so we take the average of the surprise  for all the x and minimize it , by definition the average of the surprise is the entropy , and by minimizing the entropy we make sure that W and b are the best parameters for the sigmoid function such that for all Xi in Xs if Yi == 0 then 1 - Y&#39;i approch zero as much as possible and when Yi == 1 Yi approche 1 as much as possible , sorry for my weak English but please if any one is a mathematics teacher or someone with a good knowledge in this subject correct me or add any information you want , and please assess my explanation not from a mathematical rigor but just as a simple understanding of this topic Thank you for reading",2023-10-22T22:56:24Z
UgwM-Hd4M_JW351HQmh4AaABAg,@MrBlack-cv8qn,,1,k_S5fnKjO-4,0,0,2022-06-02T19:11:39Z,Anybody hear the ultrasound from the video? Kind of blowing my head,2022-06-02T19:11:39Z
UgysQ9Yd4DtByj4gQaJ4AaABAg,@CSBAMBATIPUDIRISHIVINAYAKA,,1,k_S5fnKjO-4,0,1,2021-07-18T23:13:00Z,"For simplicity, what he is trying to say in this video is, there are many possible planes which classify given points, but what we are trying to find is the ORIGINAL PLANE based on which training data points were classified. So what we do is check the probability that given plane was used as original classification plane mentioned above, and we choose the most probable plane. However, there are assumptions, 1st one is that data is identically independently distributed and 2nd is that actually a plane was used to classify the points in the 1st place, that they are not randomly generated labels",2021-07-18T23:13:00Z
Ugzd2h9VHFlzlZeQQqB4AaABAg,@gabrielwong1991,,1,k_S5fnKjO-4,0,0,2021-02-24T01:41:33Z,"We also use MLE in econometrics, very similar for both discipline!",2021-02-24T01:41:33Z
Ugyq9ORVgFaC85lKIlt4AaABAg,@rp88imxoimxo27,,1,k_S5fnKjO-4,1,0,2020-10-10T17:16:02Z,"This guy explains ML principles so easily, and we got only 32k views? Why videos like &quot;Guy shitted himself&quot; gets much more views than this one...",2020-10-10T17:16:02Z
Ugyq9ORVgFaC85lKIlt4AaABAg.9EdSVMVkegq9ShJCTCeLKu,@thepresistence5935,Ugyq9ORVgFaC85lKIlt4AaABAg,2,k_S5fnKjO-4,0,0,2021-09-25T04:31:18Z,Go to coursera and see how much views he have.,2021-09-25T04:31:18Z
UgznqRdJSDSAdGCeRp54AaABAg,@wifi-YT,,1,k_S5fnKjO-4,2,2,2020-09-27T11:07:07Z,"I don‚Äôt understand why Andrew says at <a href=""https://www.youtube.com/watch?v=k_S5fnKjO-4&amp;t=3m37s"">3:37</a> that our goal is to maximize the probability of y, given x (or, at <a href=""https://www.youtube.com/watch?v=k_S5fnKjO-4&amp;t=4m16s"">4:16</a>, that our goal is to ‚Äúmake probabilities large‚Äù). I get why the log formulas do turn out to achieve our goal of minimizing the loss (as y hat approaches 1 when y=1, and approaches 0 when y=0).  But what does maximizing the probability of y given x have to do with anything?",2020-09-27T11:17:22Z
UgznqRdJSDSAdGCeRp54AaABAg.9E6Jwty5PfC9KOjd2cHGW5,@yashwanths2622,UgznqRdJSDSAdGCeRp54AaABAg,2,k_S5fnKjO-4,0,2,2021-03-02T17:55:02Z,"&#39;y&#39; here is the true label of a training example. So when he says &quot;maximize the probability of y&quot;, he means maximize the model-predicted probability of the example belonging to the class y.",2021-03-02T17:55:02Z
UgznqRdJSDSAdGCeRp54AaABAg.9E6Jwty5PfC9KPcV6ZAqJQ,@wifi-YT,UgznqRdJSDSAdGCeRp54AaABAg,2,k_S5fnKjO-4,0,0,2021-03-03T02:11:53Z,@@yashwanths2622 Thanks!,2021-03-03T02:29:59Z
UgzC3mLzQEh6VK_Kx-p4AaABAg,@evanparshall1323,,1,k_S5fnKjO-4,0,1,2020-06-23T03:56:14Z,Extremely well done. I&#39;ve wondered why this cost function is the way it is for a while and this video cleared it up completely,2020-06-23T03:56:14Z
Ugzy-rWONFFNdxa5QCh4AaABAg,@prattzencodes7221,,1,k_S5fnKjO-4,1,1,2020-06-13T22:08:10Z,So binary classification is essentially estimating a Bernoulli Distribution üòç,2020-06-13T22:08:10Z
Ugzy-rWONFFNdxa5QCh4AaABAg.99rZKp1tO3e9ShJMBwlh7F,@thepresistence5935,Ugzy-rWONFFNdxa5QCh4AaABAg,2,k_S5fnKjO-4,0,1,2021-09-25T04:32:37Z,"Man you&#39;re great, you correlated exactly. you&#39;re good in relating  deep up man",2021-09-25T04:32:37Z
UgwVnxbE2p5ceSuNk0J4AaABAg,@MegaAntimason,,1,k_S5fnKjO-4,0,8,2019-12-24T23:18:55Z,This guys explains MLE so easily and clearly,2019-12-24T23:18:55Z
Ugz-npvEs0zwCJY7lO14AaABAg,@edwinvarghese,,1,k_S5fnKjO-4,4,2,2018-03-16T12:34:01Z,Can anyone tell me how P(y|x) became loss function at the last line. I lost it there !,2018-03-16T12:34:01Z
Ugz-npvEs0zwCJY7lO14AaABAg.8dr5nBGxJbv8e4o9SQArfT,@PabloHernandez-ym4xk,Ugz-npvEs0zwCJY7lO14AaABAg,2,k_S5fnKjO-4,0,0,2018-03-22T05:39:47Z,"The previous slide states that P(y|x) = (y^y) * (1 - y)^(1 - y). Take the log of that and you get the loss function (you only need to apply laws of logs and algebra to get to the exact equation). So, in the last slide, log(P(y|x)) becomes the loss function.",2018-03-22T05:39:47Z
Ugz-npvEs0zwCJY7lO14AaABAg.8dr5nBGxJbv8hAvqVXQ6G8,@swapnilwalke4732,Ugz-npvEs0zwCJY7lO14AaABAg,2,k_S5fnKjO-4,0,2,2018-06-07T04:16:35Z,"I am not sure but will try. P(y|x) if used can give us a loss that whether our network is able to classify things properly. and I think we could have used P(y|x) as a loss function as it is. But as said by Andrew, we need our lost function to be convex and strictly monotonic, that makes us to add Log there, Which is monotonic and negative sign makes it convex. Correct me if I am wrong.",2018-06-07T04:16:35Z
Ugz-npvEs0zwCJY7lO14AaABAg.8dr5nBGxJbv8hgJtR4vAWz,@4abhishekagarwal,Ugz-npvEs0zwCJY7lO14AaABAg,2,k_S5fnKjO-4,0,0,2018-06-19T18:11:08Z,"Yes, you&#39;re right. P(y|x), because of the way it is defined, incentivizes our model to maximize it. So, the greater the value of P(y|x), the greater is the model performance. The negative log of P(y|x) is a good choice for the loss function.",2018-06-19T18:11:08Z
Ugz-npvEs0zwCJY7lO14AaABAg.8dr5nBGxJbv8kjVsAdRTVY,@igorrizhyi5572,Ugz-npvEs0zwCJY7lO14AaABAg,2,k_S5fnKjO-4,0,1,2018-09-03T13:27:43Z,"i will try to explain but im not sure i understand all these details as this is new material for me too. so when it comes to logical regression we mostly interested on calculating probabilities of TRUE/FALSE (classification problem) cases depending on features, presented in our dataset = P(y|x). the probability of all examples will be a product of all discrete probabilities presented in our dataset. as this product is combination of a bunch of probabilities depends on feature values we may call this function as likelihood function. all we do on this video trying to wrap this function into log is about Log-likelihood which is a common way of finding the point on this function where likelihood reaches its maximum using maximum likelihood estimation technique. when we will get these parameters which gets likelihood function to its maximum it mean that we will have such curve which will cover all our examples with maximum probability. it turns out that we may call our likelihood function as loss function because for example in terms of linear regression it almost do the same (trying to find the curve which will be as close as possible to our dataset values)",2018-09-03T13:27:43Z
UgwAWrVupWh3rNRuIaJ4AaABAg,@user-oj4hr5rh6i,,1,fXOsFF95ifk,0,0,2022-06-10T06:34:11Z,This actually looks like least squared stochastic model,2022-06-10T06:34:11Z
Ugy0wXb5mUdZH58jh4R4AaABAg,@kayaba_atributtion2156,,1,fXOsFF95ifk,3,51,2020-09-24T02:59:46Z,Who else is studying for the tensorflow certificate? :),2020-09-24T02:59:46Z
Ugy0wXb5mUdZH58jh4R4AaABAg.9DyimrOW4mu9I-rLFB_gwO,@Xisiqomelir,Ugy0wXb5mUdZH58jh4R4AaABAg,2,fXOsFF95ifk,0,0,2021-01-02T08:58:34Z,Day 1 (RL) Week 2 (syllabus) brah,2021-01-02T08:58:34Z
Ugy0wXb5mUdZH58jh4R4AaABAg.9DyimrOW4mu9g-5byrTUuK,@husanturdiev,Ugy0wXb5mUdZH58jh4R4AaABAg,2,fXOsFF95ifk,0,0,2022-09-15T10:57:40Z,did you get the idea of neural networks?,2022-09-15T10:57:40Z
Ugy0wXb5mUdZH58jh4R4AaABAg.9DyimrOW4mu9s3DI6692R2,@SupashAgarwal,Ugy0wXb5mUdZH58jh4R4AaABAg,2,fXOsFF95ifk,0,0,2023-07-12T07:38:25Z,@@husanturdiev not me but did you?,2023-07-12T07:38:25Z
Ugy3ElbRszxIsm_91Ql4AaABAg,@chavezutajara,,1,fXOsFF95ifk,0,10,2020-09-09T00:07:15Z,I&#39;ve just gotten more out of this 4 minute video than from a semester-long class with some self-pompous a~hole. GO ANDREW!,2020-09-09T00:07:15Z
UgxfN4Xl30pCI6CA_uN4AaABAg,@maratimus,,1,fXOsFF95ifk,0,0,2020-05-14T13:55:36Z,"Yeah, very good and clear",2020-05-14T13:55:36Z
UgztXBoWSAdq3lN_89J4AaABAg,@slavrine,,1,fXOsFF95ifk,0,5,2019-11-08T21:58:42Z,best explanation of NN I have seen,2019-11-08T21:58:42Z
UgwYWW1b9qgQM3-jSQh4AaABAg,@ibrahimyldrm2427,,1,fXOsFF95ifk,3,1,2019-10-13T18:11:37Z,"are x1,x2 and x3 features or different samples?  please explain",2019-10-13T18:11:37Z
UgwYWW1b9qgQM3-jSQh4AaABAg.901rIkIV_7A99S8q7Iaun3,@KumarAbhishek123,UgwYWW1b9qgQM3-jSQh4AaABAg,2,fXOsFF95ifk,0,0,2020-06-03T15:56:23Z,"x1, x2, x3 are features.",2020-06-03T15:56:23Z
UgwYWW1b9qgQM3-jSQh4AaABAg.901rIkIV_7A99SC6Xu0-I6,@ibrahimyldrm2427,UgwYWW1b9qgQM3-jSQh4AaABAg,2,fXOsFF95ifk,0,1,2020-06-03T16:24:59Z,Kumar Abhishek Sir:) this question was from my noob times. What a innocent me. Thnx for replying,2020-06-03T16:24:59Z
UgwYWW1b9qgQM3-jSQh4AaABAg.901rIkIV_7A9Pjch91NCm3,@prajwalchoudhary4824,UgwYWW1b9qgQM3-jSQh4AaABAg,2,fXOsFF95ifk,0,0,2021-07-13T12:34:41Z,@@ibrahimyldrm2427 lol,2021-07-13T12:34:41Z
UgxmEONt2SusAqiil_h4AaABAg,@nijhumreza9878,,1,fXOsFF95ifk,0,5,2019-09-05T18:31:53Z,don&#39;t worry about it :/,2019-09-05T18:31:53Z
UgxtlPYnXX-5kFwdIqN4AaABAg,@averkij,,1,fXOsFF95ifk,0,24,2019-06-22T09:03:04Z,Came from coursera.,2019-06-22T09:03:04Z
UgzQYREZvRUjUmzJBuZ4AaABAg,@vedantjoshi1487,,1,fXOsFF95ifk,2,0,2019-04-18T05:43:55Z,"at <a href=""https://www.youtube.com/watch?v=fXOsFF95ifk&amp;t=1m36s"">1:36</a> please explain how for 3 neurons in first layer....we have only one Z[1]...?..........should we not have Z[1][1]+Z[1][2]+Z[1][3] for 3 neurons?",2019-04-18T05:43:55Z
UgzQYREZvRUjUmzJBuZ4AaABAg.8trBElZVxH38yVUamPy3wA,@dhirajupadhyay01,UgzQYREZvRUjUmzJBuZ4AaABAg,2,fXOsFF95ifk,0,0,2019-08-11T16:47:31Z,"What you are saying is correct. However, Ng has used matrix notation which succinctly described what you were saying.",2019-08-11T16:47:31Z
UgzQYREZvRUjUmzJBuZ4AaABAg.8trBElZVxH38yyPUektukr,@vigneshwarilango7866,UgzQYREZvRUjUmzJBuZ4AaABAg,2,fXOsFF95ifk,0,0,2019-08-23T07:40:05Z,"@@dhirajupadhyay01 The notations are for layers, Vedant is asking about the different neurons in the same layer",2019-08-23T07:40:05Z
UgythzG99qVVG7nmpKV4AaABAg,@user-vk6ee8xv9m,,1,fXOsFF95ifk,0,2,2018-09-12T08:53:08Z,"‰∏™‰∫∫Â≠¶‰π†Á¨îËÆ∞Ôºå‰∏ÄËµ∑Â≠¶‰π†ÔºÅ<a href=""http://fangzh.top/categories/AI/Deep-Learning/"">http://fangzh.top/categories/AI/Deep-Learning/</a>",2018-09-12T08:53:08Z
UgyFsH1HA3-oLgVhLtZ4AaABAg,@isaacgreen9495,,1,CcRkHl75Z-Y,0,0,2022-03-01T20:31:23Z,This was a helpful visual. Thanks!,2022-03-01T20:31:23Z
Ugwm81WY64boqYln9uF4AaABAg,@sheemakhan4738,,1,CcRkHl75Z-Y,0,0,2021-06-22T20:45:34Z,Thnx,2021-06-22T20:45:34Z
Ugza_Qwj6mP-G1X0Nsd4AaABAg,@codewebsduh2667,,1,CcRkHl75Z-Y,0,1,2020-10-26T08:18:52Z,"Good method to understand this is using tensor notations:<br><br>let b(1,j,....,i) represent superscript  1 and all the following variables be subscripts on tensor b:<br><br><br>Then a(1,i)  = w(1,j,i)x(0,j) where x(0,j) is the jth input and w(1,j,i) is the j and ith input from weight 1.<br><br>and a(2,0) = w(2,i)a(1,i)<br><br>Thus: a(1,i)  = w(1,j,i)x(0,j)<br>and  a(2,0) = w(2,i)a(1,i) represent everything we need to know.<br><br>For dimensions of the nth layer weights all we have to do is know that:<br>dimension of current weight = number of nodes in current layer X dimension of previous weight.",2020-10-26T08:18:52Z
UgyUWlUo3ZhMHp-MaRt4AaABAg,@EranM,,1,CcRkHl75Z-Y,0,19,2018-11-13T12:25:42Z,"<a href=""https://www.youtube.com/watch?v=CcRkHl75Z-Y&amp;t=0m00s"">0:00</a> - <a href=""https://www.youtube.com/watch?v=CcRkHl75Z-Y&amp;t=0m07s"">0:07</a> aliens overtake the Video.",2018-11-13T12:26:07Z
Ugypfob8Os4-SYCTHS14AaABAg,@giuseppevaleriogramazio3594,,1,CcRkHl75Z-Y,1,1,2018-06-16T15:02:53Z,"Then can we say that the input layer has associated w and b with shapes, respectively, (1,3) and (1,1) and that they are fixed to, respectively, [1,1,1] and 0?",2018-06-16T15:02:53Z
Ugypfob8Os4-SYCTHS14AaABAg.8hZFxxkGqtV8iZuARNEM4s,@mufeili4350,Ugypfob8Os4-SYCTHS14AaABAg,2,CcRkHl75Z-Y,0,0,2018-07-11T17:34:22Z,"w is a matrix of shape (3,3) where all its elements on the diagonal are 1 and the rest are 0. This is also called a 3-dimensional identity matrix. b is a vector of shape (3,1) where all the elements are 0.",2018-07-11T17:34:22Z
UgzTrF1V-Nnz7RogYXh4AaABAg,@dengpan8086,,1,CcRkHl75Z-Y,0,0,2017-10-30T17:56:34Z,ÂæàÂ•ΩÁêÜËß£,2017-10-30T17:56:34Z
UgwI9im_CTPUUdNfLXV4AaABAg,@divyachopra2369,,1,rMOdrD61IoU,1,0,2023-03-03T05:38:11Z,I have difficulty understanding what exactly are these W and B vectors and how do we determine it for each neuron in the hidden layer ?,2023-03-03T05:38:11Z
UgwI9im_CTPUUdNfLXV4AaABAg.9mmgOmMwVzu9qgaX2uGGOv,@jambajuice07,UgwI9im_CTPUUdNfLXV4AaABAg,2,rMOdrD61IoU,0,0,2023-06-08T06:57:00Z,w is weight and b is bais . we use gradient descent to get this values,2023-06-08T06:57:00Z
Ugz8hcrmw7bzWLzt9Kx4AaABAg,@sandipansarkar9211,,1,rMOdrD61IoU,0,0,2021-01-20T08:00:38Z,nice explanation,2021-01-20T08:00:38Z
UgzAhKHsSzuikXiC-pp4AaABAg,@iOSGamingDynasties,,1,rMOdrD61IoU,1,0,2020-12-31T05:08:33Z,What is W[2] and how is it calculated?,2020-12-31T05:08:33Z
UgzAhKHsSzuikXiC-pp4AaABAg.9HvIQpvYQsH9KukJUJbKVF,@anren7445,UgzAhKHsSzuikXiC-pp4AaABAg,2,rMOdrD61IoU,0,0,2021-03-15T13:35:53Z,"it&#39;s the second weight vector, between layer[1] and layer[2]",2021-03-15T13:35:53Z
Ugxn8ccDBzzkJjT8Tfl4AaABAg,@armitosmt5753,,1,rMOdrD61IoU,0,1,2020-12-15T20:57:22Z,"what are other elements in your matrix wT , you have a row vector that you only wrtote <i>__w1[1]T__</i> ,_<i>_w2[1]T__</i> , ..... , what are before and after each w? are those representing w&#39;s for other nodes?",2020-12-15T21:06:16Z
UgzF9QSRELwlBJdyla94AaABAg,@rp88imxoimxo27,,1,rMOdrD61IoU,0,2,2020-10-11T11:07:15Z,"Too much easy to understand for my genius mind, now I need something much more harder like Transformers or CNN",2020-10-11T11:07:15Z
UgwXIivXiJ4dbhO2LJ54AaABAg,@prismaticspace4566,,1,rMOdrD61IoU,1,4,2020-07-30T03:24:18Z,"This is the most detailed explanation I‚Äôve ever seen, reduced to the most intuitive parts.",2020-07-30T03:24:18Z
UgwXIivXiJ4dbhO2LJ54AaABAg.9Bi_4Tzw2HC9DFja5R2DS1,@harshitgupta5053,UgwXIivXiJ4dbhO2LJ54AaABAg,2,rMOdrD61IoU,0,0,2020-09-06T06:21:42Z,Do read haykin book on neural networks,2020-09-06T06:21:42Z
UgyEcD4BQNRCVJETeIB4AaABAg,@chs2613,,1,rMOdrD61IoU,1,0,2020-06-07T06:55:09Z,"if W[1] is a (4, 3) matrix, then wouldn&#39;t W[1]i be a (1,3) row vector, which is compatible with the  (3, 1) column vector x or a[0].<br>Why do we still need to transpose W[1]i to become a column vector?",2020-06-07T07:00:43Z
UgyEcD4BQNRCVJETeIB4AaABAg.99aU4RitfHt9BXyXAAGh6w,@srujohn652,UgyEcD4BQNRCVJETeIB4AaABAg,2,rMOdrD61IoU,0,0,2020-07-25T15:15:46Z,"W[1]weights will be (3,4) and inputs (3,1). so you need to transpose W, wT*x. otherwise multiplication will not be valid",2020-07-25T15:15:46Z
UgxtsQlHQo85k0zBBcJ4AaABAg,@acousticIndie,,1,rMOdrD61IoU,1,0,2020-05-10T17:01:47Z,W and B here represents weight and Bias ? in the eqn Wt*X+b,2020-05-10T17:01:47Z
UgxtsQlHQo85k0zBBcJ4AaABAg.98UTF759L5j9BXxe5Paett,@srujohn652,UgxtsQlHQo85k0zBBcJ4AaABAg,2,rMOdrD61IoU,0,1,2020-07-25T15:08:07Z,yes,2020-07-25T15:08:07Z
Ugxs8dj-qrMWE0eITNV4AaABAg,@joostthissen8667,,1,rMOdrD61IoU,0,0,2019-12-21T16:57:11Z,Excellent explanation. Very clear.,2019-12-21T16:57:11Z
Ugw1KeJY-8OMoLfbCW54AaABAg,@williamzheng5918,,1,rMOdrD61IoU,1,1,2019-12-17T16:53:26Z,"Each seemingly identical neuron in a layer takes the same input differently, this is quite fascinating from a layman&#39;s view.",2019-12-17T16:53:26Z
Ugw1KeJY-8OMoLfbCW54AaABAg.92e514PnlI89K75e34q19c,@sethpai,Ugw1KeJY-8OMoLfbCW54AaABAg,2,rMOdrD61IoU,0,0,2021-02-23T21:29:49Z,"Interesting insight, I think it is analogous to how two people (or two brains) can receive the same input (like see the same image) and process/respond differently, and this is due to the differences in connections and connection strengths of neurons between the two brains. <br><br>Also, as discussed later in the course, the training of these networks is based on the fine tuning of those connections between neurons to achieve a goal. In neuroscience, a theory is that our brains also tune our neuron connections to achieve changes in behavior, form memories, etc. (known as plasticity), yet each neuron by itself at its core is the same.",2021-02-23T21:29:49Z
Ugx6aQ0lgqTcwe6gD914AaABAg,@shrutigoyal6472,,1,rMOdrD61IoU,1,1,2019-08-27T16:58:00Z,why is W[1] is 4√ó3 matrix??? instead of 4√ó1matrix,2019-08-27T16:58:00Z
Ugx6aQ0lgqTcwe6gD914AaABAg.8z8hWRqcNom8zgUVH3D44Q,@hedgehogist,Ugx6aQ0lgqTcwe6gD914AaABAg,2,rMOdrD61IoU,0,4,2019-09-10T05:08:55Z,"Because there are 3 features: x1, x2, and x3, W[1] assigns a weight to each feature of the input.",2019-09-10T05:08:55Z
UgxL1TX4fNkQSyY7-K94AaABAg,@partyplay2010,,1,rMOdrD61IoU,1,0,2019-05-03T11:49:22Z,"I thought W was a vector that is updated constantly based on the training and learning. Why do we have w1, w2 etc. operating at the same time on the same m training examples ?",2019-05-03T11:49:22Z
UgxL1TX4fNkQSyY7-K94AaABAg.8uTSzYE6neb92YXzt6vFF2,@legacies9041,UgxL1TX4fNkQSyY7-K94AaABAg,2,rMOdrD61IoU,0,0,2019-12-15T03:51:52Z,"In neural networks we have hidden layers, w is a vector only when you are in logistic regression due to having only one neuron/unit as an output. But here we have multiple units per layer. You can also use w as a vector if you choose but you will have to use for-loop which would be more computational expensive.",2019-12-15T03:51:52Z
UgxmIR1x7__EF4K20O54AaABAg,@chitralalawat8106,,1,rMOdrD61IoU,5,4,2019-03-18T07:23:42Z,Very difficult to understand..  :(,2019-03-18T07:23:42Z
UgxmIR1x7__EF4K20O54AaABAg.8sbY0SFNUTp8skbmV6TGSJ,@canucoar,UgxmIR1x7__EF4K20O54AaABAg,2,rMOdrD61IoU,0,2,2019-03-21T19:58:31Z,I thought it was just me :0),2019-03-21T19:58:31Z
UgxmIR1x7__EF4K20O54AaABAg.8sbY0SFNUTp8tP6MyAfoje,@drexiya221,UgxmIR1x7__EF4K20O54AaABAg,2,rMOdrD61IoU,0,7,2019-04-06T22:43:22Z,"Its not easy stuff, but this is probably the best explanation, by the best teacher that you are ever likely to come across :) he certainly helped my understanding..",2019-04-06T22:43:22Z
UgxmIR1x7__EF4K20O54AaABAg.8sbY0SFNUTp8uR7MylpQeW,@frankwxu,UgxmIR1x7__EF4K20O54AaABAg,2,rMOdrD61IoU,0,0,2019-05-02T14:01:59Z,He explained well.,2019-05-02T14:01:59Z
UgxmIR1x7__EF4K20O54AaABAg.8sbY0SFNUTp9-47_-umueh,@RealMcDudu,UgxmIR1x7__EF4K20O54AaABAg,2,rMOdrD61IoU,0,4,2019-09-19T18:49:36Z,"if you finish the original ML course, and then move to this specialization, it will become much much easier :-) (sometimes the tortoise can outbeat the hare)",2019-09-19T18:49:36Z
UgxmIR1x7__EF4K20O54AaABAg.8sbY0SFNUTp92YX0PYJnlg,@legacies9041,UgxmIR1x7__EF4K20O54AaABAg,2,rMOdrD61IoU,0,4,2019-12-15T03:43:20Z,Please take the first machine learning course from him first and then come back here,2019-12-15T03:43:20Z
UgxzQDIHmVWWPTBzY-14AaABAg,@jambajuice07,,1,xy5MOQpx3aQ,0,0,2023-06-08T06:59:32Z,how W[2] will be calculated ?,2023-06-08T06:59:32Z
UgwFYAfiX3xu40gNcDt4AaABAg,@sandipansarkar9211,,1,xy5MOQpx3aQ,0,0,2021-01-23T19:48:03Z,nice explanation,2021-01-23T19:48:03Z
UgwrZx1hUbDFH5mvzb14AaABAg,@karanrana5023,,1,xy5MOQpx3aQ,1,2,2019-07-19T02:35:00Z,The video is stuck after 42 seconds of play.  Could you pls fix....,2019-07-19T02:35:00Z
UgwrZx1hUbDFH5mvzb14AaABAg.8xYjkYNRV599RUxgN3gGPS,@rishikeshkanabar4650,UgwrZx1hUbDFH5mvzb14AaABAg,2,xy5MOQpx3aQ,0,3,2021-08-26T03:33:01Z,"Your internet, amigo :)",2021-08-26T03:33:01Z
UgzYjWc-Ht8DhoyTqCB4AaABAg,@saanvisharma2081,,1,xy5MOQpx3aQ,3,2,2019-01-06T07:09:02Z,Z1 =[ ] matrix constitutes training examples up to M. What is Z2= [ ] matrix then!!!<br>Any help is highly appreciated.,2019-01-06T07:09:02Z
UgzYjWc-Ht8DhoyTqCB4AaABAg.8pkgtwoPsut8pkjTsNky3f,@ameyatathavadkar2743,UgzYjWc-Ht8DhoyTqCB4AaABAg,2,xy5MOQpx3aQ,0,2,2019-01-06T07:31:33Z,Z1 matrix corresponds to training examples upto m for the first hidden layer...so Z2 will correspond to the matrix for m training examples for the 2nd hidden layer and so on...,2019-01-06T07:31:33Z
UgzYjWc-Ht8DhoyTqCB4AaABAg.8pkgtwoPsut8pkmj3Vrh7I,@saanvisharma2081,UgzYjWc-Ht8DhoyTqCB4AaABAg,2,xy5MOQpx3aQ,0,1,2019-01-06T07:59:59Z,@@ameyatathavadkar2743 thank you very much ‚ò∫,2019-01-06T07:59:59Z
UgzYjWc-Ht8DhoyTqCB4AaABAg.8pkgtwoPsut8pkqHETPacS,@ameyatathavadkar2743,UgzYjWc-Ht8DhoyTqCB4AaABAg,2,xy5MOQpx3aQ,0,0,2019-01-06T08:31:00Z,@@saanvisharma2081 anytime :),2019-01-06T08:31:00Z
UgxKCc_JYvXSLIjh6dV4AaABAg,@EranM,,1,xy5MOQpx3aQ,0,6,2018-11-14T10:42:40Z,"<a href=""https://www.youtube.com/watch?v=xy5MOQpx3aQ&amp;t=3m42s"">3:42</a> &quot;Neaty Pretty :&gt;",2018-11-14T10:42:40Z
Ugw280IHHem0qNfsaQ94AaABAg,@magzhankambar1607,,1,xy5MOQpx3aQ,0,6,2018-08-13T11:03:52Z,Thanks,2018-08-13T11:03:52Z
UgzyDnARSkRJ96UBXAB4AaABAg,@eashan2405,,1,kkWRbIb42Ms,0,6,2021-09-05T13:01:06Z,Is there anyone watching this video in 2021?,2021-09-05T13:01:06Z
UgxZuSI1xXWmue9Eon94AaABAg,@sandipansarkar9211,,1,kkWRbIb42Ms,0,0,2021-01-24T20:06:31Z,nce explanation,2021-01-24T20:06:31Z
UgxBi-V_Ndsdkp_HaEd4AaABAg,@haohuynhnhat3881,,1,kkWRbIb42Ms,1,4,2020-05-16T02:58:03Z,"this would be easy to understand if y&#39;all have take a linear algebra course before. I recommend y&#39;all to take a linear algebra course free on Youtube of MIT, Professor Strang, after that these matrix multiplication will as easy as cake.",2020-05-16T02:58:03Z
UgxBi-V_Ndsdkp_HaEd4AaABAg.98hPSaJhi9Z9D2e416WMHA,@DC-cc4qg,UgxBi-V_Ndsdkp_HaEd4AaABAg,2,kkWRbIb42Ms,0,0,2020-09-01T04:23:22Z,This is absolutely true... I actually got stuck and then did a detour to Linear Algebra. Now it makes a lot more sense..,2020-09-01T04:23:22Z
UgyRNCHIvD7wbr3rFZN4AaABAg,@pratikbudruk8921,,1,kkWRbIb42Ms,2,1,2019-06-21T15:26:18Z,What is size of W ? is it 4 * Nx,2019-06-21T15:26:18Z
UgyRNCHIvD7wbr3rFZN4AaABAg.8wS0lCnc-Oz8wjbbmOjl5r,@rabieamelad1513,UgyRNCHIvD7wbr3rFZN4AaABAg,2,kkWRbIb42Ms,0,2,2019-06-28T20:43:23Z,"yse 4*Nx if you have 4 hidden units so number of rows depends on how many hidden units you have,for EX:lets say the hidden layer has 10 hidden units so W (10,Nx)",2019-06-28T20:43:23Z
UgyRNCHIvD7wbr3rFZN4AaABAg.8wS0lCnc-Oz9RuiQKM4ULp,@eashan2405,UgyRNCHIvD7wbr3rFZN4AaABAg,2,kkWRbIb42Ms,0,1,2021-09-05T12:59:07Z,"Size of W will always be (no. of hidden units in that layer, no. of inputs coming from previous layer) <br><br>Eg1 : In the first layer of this 2-layered NN, W[1] had dimension (4,3) cause 4 is the no. of nodes in 1st layer, and 3 is the no. of inputs coming from previous layer i.e. a[0] i.e. x1, x2, x3.<br><br>Eg2 : In the second layer of this 2-layered NN, W[2] had dimension (1,4) cause 1 is the no. of nodes in 2nd layer, and 4 is the no. of inputs coming from previous layer i.e. a[1] i.e. a1, a2, a3, a4.",2021-09-05T12:59:07Z
UgzCgPhLTTejs1UuLZB4AaABAg,@aimecesairemusangamfura884,,1,kkWRbIb42Ms,2,0,2018-08-01T19:07:41Z,is x(1) different to x(2) and x(3) ? i would like to know the difference between x1 and x(1)?,2018-08-01T19:10:35Z
UgzCgPhLTTejs1UuLZB4AaABAg.8jQ8YF8CD2C8kIEAQ0rBJM,@mahmoudgamalabdalnasser,UgzCgPhLTTejs1UuLZB4AaABAg,2,kkWRbIb42Ms,0,13,2018-08-23T13:54:20Z,"x1 refer to input feature like (size of house )...x2   refer to input feature like (number of bedroom )<br> .......x(1) refer to the first training example in this features [size =50 m ,bedroom 4]....x(2) the second training example in this features [size =60 m ,bedroom =5]",2018-08-23T13:54:20Z
UgzCgPhLTTejs1UuLZB4AaABAg.8jQ8YF8CD2C8wjcaBzzJyN,@rabieamelad1513,UgzCgPhLTTejs1UuLZB4AaABAg,2,kkWRbIb42Ms,0,1,2019-06-28T20:51:54Z,"x superscript 1 or 2 or 3 denote to number of training example,so if your training set&#39;s size (m)=1000 , then you have 1000 training examples,but if you see x with subscripts 1 or 2 or 3 that is denote to your features like (size of house, Nobedroom, NO of floors,......etc)",2019-06-28T20:51:54Z
Ugz0mol9KlwMldHdval4AaABAg,@user-rv9pt2hx5n,,1,kkWRbIb42Ms,1,11,2018-05-30T00:57:26Z,Is there anyone watching this video?,2018-05-30T00:57:26Z
Ugz0mol9KlwMldHdval4AaABAg.8gqygtCfXCN8ibsRNHbElk,@GilangD21,Ugz0mol9KlwMldHdval4AaABAg,2,kkWRbIb42Ms,0,1,2018-07-12T21:16:56Z,hey,2018-07-12T21:16:56Z
UgyUYGzigCGr_WyH9UZ4AaABAg,@videos4mydad,,1,Xvg00QnyaIY,0,0,2023-02-18T07:27:14Z,"I am beginning to see math notation is simply just really poorly named variables in programming.  Its too bad that the &quot;one letter&quot; variable naming in math notation has such deep roots.  In programming we would call it &quot;sigmoid()&quot; but in math even when you run out of letters of the alphabet, we go to different alphabets...",2023-02-18T07:27:14Z
UgyJcDdbqbK9szBpy4R4AaABAg,@user-uy6gv8hi5b,,1,Xvg00QnyaIY,0,0,2022-04-12T13:54:04Z,Why we need an activation function in hidden layers?,2022-04-12T13:54:04Z
UgxKA4DY0cKDx4xhQPd4AaABAg,@thepresistence5935,,1,Xvg00QnyaIY,0,2,2021-09-25T05:30:23Z,"I use always Leaky Relu, it gives good results while doing the model building.",2021-09-25T05:30:23Z
UgzkhK5v1nJ54axguXp4AaABAg,@anirudhsharma2003,,1,Xvg00QnyaIY,0,0,2021-08-23T06:19:52Z,Can we make the parameter we apply at Relu function a part of hidden learning parameters like the weights and bias?,2021-08-23T06:19:52Z
Ugwxhi0hN10w9nEYXZF4AaABAg,@istvanbenedek3578,,1,Xvg00QnyaIY,0,0,2021-07-13T21:53:24Z,"Hey Andrew, I really like your videos, the reason why I&#39;ve just written this feedback is to contribute to the improvement. <br>at <a href=""https://www.youtube.com/watch?v=Xvg00QnyaIY&amp;t=1m45s"">1:45</a>: you say &quot;tanh is shifted version of the Sigmoid function&quot; which is a little bit underdefined as the value domain of tanh(x) is larger than the value domain of the sigmoid, simple shift does make tanh from the sigmoid.<br>at <a href=""https://www.youtube.com/watch?v=Xvg00QnyaIY&amp;t=8m23s"">8:23</a>: horizontal axis of the tanh(z) labeled with X, and tanh has a typo.",2021-07-13T21:54:37Z
UgzR8_Zwr6NSdxisuWh4AaABAg,@sandipansarkar9211,,1,Xvg00QnyaIY,0,0,2021-01-24T20:22:19Z,very very clear explanation,2021-01-24T20:22:19Z
Ugy6AEeb2rMInxTbe114AaABAg,@manuel783,,1,Xvg00QnyaIY,0,0,2021-01-18T19:34:03Z,"Clarification: Activation Function<br><br>From <a href=""https://www.youtube.com/watch?v=Xvg00QnyaIY&amp;t=7m58s"">7:58</a>, this visual comparison of 4 activation functions.  All 4 should have &quot;z&quot; as the horizontal axis.  The top right chart in the slide shows &quot;x&quot;, which should be &quot;z&quot;.",2021-01-18T21:07:35Z
UgwxNPwWFGxHTiB92d54AaABAg,@rp88imxoimxo27,,1,Xvg00QnyaIY,1,2,2020-10-11T13:01:56Z,"But ReLU or even Leaky ReLU still are linear functions(but more complex ofc) which means they cant fit some complex classification problems, isn&#39;t it?",2020-10-11T13:01:56Z
UgwxNPwWFGxHTiB92d54AaABAg.9Ef_D4_d7ik9HDzJr0gHV2,@olifsun948,UgwxNPwWFGxHTiB92d54AaABAg,2,Xvg00QnyaIY,0,2,2020-12-14T00:06:15Z,"<a href=""https://datascience.stackexchange.com/questions/26475/why-is-relu-used-as-an-activation-function"">https://datascience.stackexchange.com/questions/26475/why-is-relu-used-as-an-activation-function</a>",2020-12-14T00:06:15Z
UgyUz2sP4NEIxyJdxgZ4AaABAg,@prismaticspace4566,,1,Xvg00QnyaIY,0,6,2020-07-31T02:41:09Z,"So I finally understand why certain activation functions are chosen, it&#39;s because we usually use them..",2020-07-31T02:41:09Z
Ugx276zvQ-4k707ZRJl4AaABAg,@pivasmilos,,1,Xvg00QnyaIY,1,1,2020-04-12T15:34:56Z,"Can&#39;t we reassign the 0 labels to -1, and then use tanh() for the output layer?",2020-04-12T15:34:56Z
Ugx276zvQ-4k707ZRJl4AaABAg.97MD2TByaEg9RNXCNZo8B2,@anirudhsharma2003,Ugx276zvQ-4k707ZRJl4AaABAg,2,Xvg00QnyaIY,0,0,2021-08-23T06:18:10Z,"Most of it is a convention based thing, 0 represents &quot;off&quot; and 1 represents &quot;on&quot;.<br><br>However, a more mathematical explanation can be ;- 0 has a diminishing effect, if a number is multiplied with the output which tends to zero, the result will become negligible in further calculation*. And -1 has a reversing effect, a number multiplied with minus 1 reverses it&#39;s sign, and thus, can have a major effect later.<br><br>* Well, that matters if there actually are some calculations ahead (like other models depending on results from current)",2021-08-23T06:18:10Z
UgxShhiJuJIf0rfzJIx4AaABAg,@hectorgarces5383,,1,Xvg00QnyaIY,1,3,2020-03-13T14:29:17Z,"A sigmoid function is one that have a &quot;S&quot; curve, is not a synonym of log√≠stic regression, in fact tanh func is a type of a a sigmoid function, so min <a href=""https://www.youtube.com/watch?v=Xvg00QnyaIY&amp;t=2m58s"">2:58</a> is kind of incorrect the explaining. Apart of that nice vid.",2020-03-13T14:29:17Z
UgxShhiJuJIf0rfzJIx4AaABAg.968qgJbvLLM978W_CyWOHa,@acidtears,UgxShhiJuJIf0rfzJIx4AaABAg,2,Xvg00QnyaIY,0,1,2020-04-07T07:56:12Z,Logistic regression also  has an S curve... The terms are used as synonyms in machine learning.,2020-04-07T07:56:12Z
UgwxS4i8KZzN4QOmBWt4AaABAg,@saanvisharma2081,,1,Xvg00QnyaIY,0,3,2019-01-13T10:29:45Z,"At <a href=""https://www.youtube.com/watch?v=Xvg00QnyaIY&amp;t=9m01s"">9:01</a> coordinates of tanh graph should be Z not X ????",2019-01-13T10:29:45Z
Ugzbauz9fpJreE8d9DJ4AaABAg,@xerocool2109,,1,Xvg00QnyaIY,3,1,2018-11-29T05:14:43Z,what about Softmax ? is it better than RELU?,2018-11-29T05:14:43Z
Ugzbauz9fpJreE8d9DJ4AaABAg.8oDdbMdjFkK8onWMTu-ull,@chaitanyakrishnadukkipaty9825,Ugzbauz9fpJreE8d9DJ4AaABAg,2,Xvg00QnyaIY,0,7,2018-12-13T12:54:32Z,"I am relatively new to the field, but according to me softmax is preferably used in the final layer when we have a multi-class classification. And in hidden layers we preferably stick to relu or leaky relu in most cases",2018-12-13T12:54:32Z
Ugzbauz9fpJreE8d9DJ4AaABAg.8oDdbMdjFkK8waKWZlXDG_,@abhimanyutiwari100,Ugzbauz9fpJreE8d9DJ4AaABAg,2,Xvg00QnyaIY,0,3,2019-06-25T06:12:05Z,ReLU is used in the hidden layer only and softmax applies to the output (basically it calculate the probability of the classes).,2019-06-25T06:12:05Z
Ugzbauz9fpJreE8d9DJ4AaABAg.8oDdbMdjFkK9NDSZvYbxMz,@angelaju6327,Ugzbauz9fpJreE8d9DJ4AaABAg,2,Xvg00QnyaIY,0,0,2021-05-11T22:19:43Z,I think you mean softplus? softplus is an activate function which is similar with ReLU,2021-05-11T22:19:43Z
Ugz2XDDWg6R7UZ4cNSZ4AaABAg,@EranM,,1,Xvg00QnyaIY,0,1,2018-11-18T14:26:48Z,"<a href=""https://www.youtube.com/watch?v=Xvg00QnyaIY&amp;t=5m15s"">5:15</a> the 0 button got stuck :&gt;",2018-11-18T14:26:48Z
UgyNvXWviquG0nTHoah4AaABAg,@sreemantokesh3999,,1,Xvg00QnyaIY,3,1,2018-10-24T06:58:42Z,Do we need an activation function when in case of regression problems where output is continuous values????,2018-10-24T06:58:42Z
UgyNvXWviquG0nTHoah4AaABAg.8mm7tUm2JN18mxHkgQms_T,@siddhartha8886,UgyNvXWviquG0nTHoah4AaABAg,2,Xvg00QnyaIY,0,0,2018-10-28T14:56:31Z,i think no,2018-10-28T14:56:31Z
UgyNvXWviquG0nTHoah4AaABAg.8mm7tUm2JN18pkl2jetegG,@ameyatathavadkar2743,UgyNvXWviquG0nTHoah4AaABAg,2,Xvg00QnyaIY,0,0,2019-01-06T07:45:19Z,no....for continuous value prediction you use linear regression which does not actually require neural nets to exec...so no need of act funct,2019-01-06T07:45:19Z
UgyNvXWviquG0nTHoah4AaABAg.8mm7tUm2JN192Yy1pIM5nb,@legacies9041,UgyNvXWviquG0nTHoah4AaABAg,2,Xvg00QnyaIY,0,3,2019-12-15T07:48:11Z,"In the case of linear regression, You will use activations functions also except for the output, no activation function there",2019-12-15T07:48:11Z
Ugww3TT65gpJbnQihph4AaABAg,@abekang3623,,1,Xvg00QnyaIY,1,13,2018-01-18T19:17:20Z,"The tanh definition is not correct at <a href=""https://www.youtube.com/watch?v=Xvg00QnyaIY&amp;t=9m01s"">9:01</a>.  The denominator should be exp(z) + exp(-z).  So the whole function should be tanh = (exp(z) - exp(-z)) / (exp(z) + exp(-z))",2018-01-18T19:17:20Z
Ugww3TT65gpJbnQihph4AaABAg.8b_2dGflO8N8ddYeb3FYPb,@nands4410,Ugww3TT65gpJbnQihph4AaABAg,2,Xvg00QnyaIY,0,0,2018-03-11T06:16:53Z,thanks Abe Kang,2018-03-11T06:16:53Z
UgxRh4VBDo3Iuuf3IdF4AaABAg,@mario1ua,,1,NkOv_k7r6no,0,1,2023-10-31T18:00:45Z,"I needed this, thank you!",2023-10-31T18:00:45Z
UgyuM9Lm8xN2sqG757R4AaABAg,@tonyflow6244,,1,NkOv_k7r6no,0,3,2023-04-04T18:22:29Z,"As a layman clicking buttons to try get a better understanding of large language models I thought I was making some progress, then I watched this video, now I think I should go back to primary school üò¢",2023-04-04T18:22:29Z
Ugzwct0m1Il4_7SOa9B4AaABAg,@techanddroid1164,,1,NkOv_k7r6no,0,0,2021-12-14T21:04:00Z,"This person has a lot of knowledge, he picks one thing and then starts explaining other and other. this disease is called explainailibalible sorry",2021-12-14T21:04:00Z
UgzjhhM-mTpVYeEnQKp4AaABAg,@TheThunderSpirit,,1,NkOv_k7r6no,5,1,2021-05-07T09:13:27Z,I got a question - does the use of non-linear activation increase model capacity?,2021-05-07T09:13:27Z
UgzjhhM-mTpVYeEnQKp4AaABAg.9N1kPa5QB6h9Nob4wwMqBj,@imdb6942,UgzjhhM-mTpVYeEnQKp4AaABAg,2,NkOv_k7r6no,0,3,2021-05-26T17:54:00Z,"Exactly my thoughts, came here to gain insight as to how non linear functions like ReLU drastically change usefulness of hidden layers. Instead it&#39;s just re-iterated common knowledge of linear functions producing no value when used on hidden layers.",2021-05-26T17:54:00Z
UgzjhhM-mTpVYeEnQKp4AaABAg.9N1kPa5QB6h9P8DUhBqLih,@almoni127,UgzjhhM-mTpVYeEnQKp4AaABAg,2,NkOv_k7r6no,0,1,2021-06-28T14:34:31Z,Definitely yes.<br>Without non-linearity you can only express linear functions.<br>With non-linearities such as ReLU and sigmoid you can approximate any continuous function on a compact set (search &quot;Universal approximation theorem&quot; for more information).,2021-06-28T14:34:31Z
UgzjhhM-mTpVYeEnQKp4AaABAg.9N1kPa5QB6h9P9_T-Qq9dS,@TheThunderSpirit,UgzjhhM-mTpVYeEnQKp4AaABAg,2,NkOv_k7r6no,0,0,2021-06-29T03:14:30Z,"@@almoni127 Sure, but look at that statement and tell me if that always true, even for a single layer network. How can we claim that model capacity has increased after using a non-linear activation instead of linear activation, since it is not quantifiable. How much capacity has increased?",2021-06-29T03:14:30Z
UgzjhhM-mTpVYeEnQKp4AaABAg.9N1kPa5QB6h9P9woa66pyr,@almoni127,UgzjhhM-mTpVYeEnQKp4AaABAg,2,NkOv_k7r6no,0,0,2021-06-29T06:38:34Z,"@@TheThunderSpirit<br>A good analogue is Boolean circuits.<br>With no hidden layers you don&#39;t have much expressiveness.<br>Already with one hidden layer you have universality, albeit the required hidden layer size might be too large.<br>With arbitrarily deep networks you can approximate all polynomial computations.",2021-06-29T06:38:34Z
UgzjhhM-mTpVYeEnQKp4AaABAg.9N1kPa5QB6h9PEE2mzcM2_,@imdb6942,UgzjhhM-mTpVYeEnQKp4AaABAg,2,NkOv_k7r6no,0,1,2021-06-30T22:34:53Z,@@almoni127 Thank you,2021-06-30T22:34:53Z
Ugwg5Te7VFncYVspptd4AaABAg,@sandipansarkar9211,,1,NkOv_k7r6no,0,1,2021-01-24T21:02:04Z,nice explanation,2021-01-24T21:02:04Z
UgzFEqZedcbDe7g4RZV4AaABAg,@anirudhsriram2125,,1,NkOv_k7r6no,0,27,2020-11-18T09:00:44Z,These lectures deserve to be recognized as the bible of machine learning,2020-11-18T09:00:44Z
Ugy47t7FSg4OyReRlnx4AaABAg,@ysun5125,,1,NkOv_k7r6no,0,0,2020-09-20T04:38:11Z,superb,2020-09-20T04:38:11Z
Ugw1UbDV3DMdN7AIqtl4AaABAg,@chitralalawat8106,,1,NkOv_k7r6no,8,0,2019-03-18T09:37:01Z,"From the videos above, I got to understand that RELu is a linear function... Rest are non linear functions.. But how can consider sigmoid function as binary?? Because a binary function always give output in the form of 0 or 1 but the sigmoid function varies between -ve infinity to +infinity &amp; touching y axis at 0.5?",2019-03-18T09:37:18Z
Ugw1UbDV3DMdN7AIqtl4AaABAg.8sbmGsq400c8tGD8FHV7c_,@Mats-Hansen,Ugw1UbDV3DMdN7AIqtl4AaABAg,2,NkOv_k7r6no,0,4,2019-04-03T11:49:22Z,"ReLU is NOT a linear function, just like the sigmoid function or tanh f.ex.<br>Also. The sigmoid function does not vary between -inf, +inf, its output is in the range (0, 1).",2019-04-03T11:49:22Z
Ugw1UbDV3DMdN7AIqtl4AaABAg.8sbmGsq400c8tGtI293uUf,@saurabhshubham4448,Ugw1UbDV3DMdN7AIqtl4AaABAg,2,NkOv_k7r6no,0,0,2019-04-03T18:06:26Z,@@Mats-Hansen How you are saying relu as non-linear function? Its combination of two linear function.,2019-04-03T18:06:26Z
Ugw1UbDV3DMdN7AIqtl4AaABAg.8sbmGsq400c8tHJkj1OEl7,@Mats-Hansen,Ugw1UbDV3DMdN7AIqtl4AaABAg,2,NkOv_k7r6no,0,3,2019-04-03T22:06:25Z,@@saurabhshubham4448 Yes it is. But a combination of two linear functions doesn&#39;t need to be linear.,2019-04-03T22:06:25Z
Ugw1UbDV3DMdN7AIqtl4AaABAg.8sbmGsq400c8tHhbLkED7R,@saurabhshubham4448,Ugw1UbDV3DMdN7AIqtl4AaABAg,2,NkOv_k7r6no,0,0,2019-04-04T01:43:36Z,"@@Mats-Hansen but whenever you apply it on input, it&#39;s output will be linear, and thus relu don&#39;t help in adding non linearity to the model.",2019-04-04T01:43:36Z
Ugw1UbDV3DMdN7AIqtl4AaABAg.8sbmGsq400c8tIMPbV8eXi,@Mats-Hansen,Ugw1UbDV3DMdN7AIqtl4AaABAg,2,NkOv_k7r6no,0,4,2019-04-04T07:48:52Z,"@@saurabhshubham4448 The output is linear yes, but as far as I understand you lose the linear dependencies between the weights. Let&#39;s take two weights w1 = -0.2 and w2 = 0.5, and a linear function like lets say f(x) = 3x+0.2. Then f(w1) = -0.4 and f(w2) = 1.7. This function preserves the difference (up to a linear factor) between the two weights (w2-w1 = 0.7, and  f(w2)-f(w1) = 3* (w2-w1)=2.1. You will always have this with linear functions, but with a function like ReLU you will not (only interesting of course if at least one of the weights are negative). Now maybe this math is just nonsense, but I think I got a point here somewhere. In a sense you cannot write old weights as a &quot;linear combination&quot; of new weights.",2019-04-04T07:48:52Z
UgxjYQTzkflF0huX6e54AaABAg,@moeinhasani8718,,1,NkOv_k7r6no,1,23,2019-02-21T19:24:09Z,it was like i was blind about lin activation function but now im gifted with vision :),2019-02-21T19:24:09Z
UgxjYQTzkflF0huX6e54AaABAg.8rcSaGPHPSu9e0lY8J2bzJ,@gpietra,UgxjYQTzkflF0huX6e54AaABAg,2,NkOv_k7r6no,0,0,2022-07-28T09:29:12Z,*computer vision,2022-07-28T09:29:12Z
Ugya_aHixmy6T2zGiAx4AaABAg,@darshild5853,,1,NkOv_k7r6no,0,11,2018-12-11T19:25:17Z,Prof Ng is the man!,2018-12-11T19:25:17Z
UgzUJ3ieNiyD7pxKDix4AaABAg,@ttxiton9622,,1,NkOv_k7r6no,2,2,2018-11-30T14:54:51Z,It&#39;s so ridiculous that a video whose speaker is a Chinese but we only got Korean subtitle!!,2018-11-30T14:54:51Z
UgzLmDnhFfJTBUIQsMZ4AaABAg,@Charles-rn3ke,,1,NkOv_k7r6no,3,16,2018-07-19T09:24:26Z,Grandpa telling bedtime story.........,2018-07-19T09:24:26Z
Ugxon1hlYqg5Vdci44l4AaABAg,@banipreetsinghraheja8529,,1,NkOv_k7r6no,0,0,2018-06-02T12:04:51Z,"Refer <a href=""https://towardsdatascience.com/activation-functions-and-its-types-which-is-better-a9a5310cc8f"">https://towardsdatascience.com/activation-functions-and-its-types-which-is-better-a9a5310cc8f</a> , for a better explaination, at least I think so......",2018-06-02T12:04:51Z
UgxVZC-kmDbONGNSY9l4AaABAg,@aqwkpfdhtla9018,,1,NkOv_k7r6no,7,5,2018-05-25T20:41:30Z,Your English is difficult to understand. I keep going back to figure out what you mean by some words.,2018-05-25T20:41:30Z
Ugy2nbVj4YYoqhIx8wx4AaABAg,@SantoshGupta-jn1wn,,1,NkOv_k7r6no,5,6,2017-11-06T21:51:25Z,"Great video!!! I am still confused about why Relu works when it&#39;s properties are quite linear. I mean, I know it&#39;s a piece-wise linear function, therefore does not meet the mathematical definition of linear function. But by using Relu, the output is still just a linear combination. Perhaps some neurons don&#39;t &#39;contribute&#39;, but the output is still a mathematical result of a linear combination of numbers.",2017-11-06T21:51:54Z
UgxLzdU_K5EhhF6ZWNx4AaABAg,@swfsql,,1,6by6Xas_Kho,0,0,2023-08-27T12:29:00Z,"I have noted that my models would not converge nicely (last assignment from C1W4, 3 ReLU + 1 sigmoid layers) when comparing to a notebook reference that I&#39;m following. <br>If I just initialized my weights from a normal distribution, the cost would get stuck at a high value. I&#39;ve tried scaling the weights, changing to a uniform distribution, changing the learning rate to various values, nothing worked.<br>Then following your code, I saw that if I divided the weights for each layer according to the sqrt of the number of features to that layer, then it would start converging beautifully. Would be interesting to know why!<br><br><br>Thanks for your lessons!",2023-08-27T12:32:43Z
UgxDd9wsYK4yYi8sc7F4AaABAg,@arthurkalb1817,,1,6by6Xas_Kho,0,0,2022-04-24T02:30:16Z,It seems like the most general statement of the solution is that the coefficients must form full rank matrices.,2022-04-24T02:30:16Z
UgwI1V8MI_Q0lToddqV4AaABAg,@sakshipathak1855,,1,6by6Xas_Kho,0,0,2021-07-10T17:04:13Z,from where can we access the practice questions?,2021-07-10T17:04:13Z
UgxwyPuseVznqPRHjIt4AaABAg,@shubhamsaha7887,,1,6by6Xas_Kho,3,0,2020-06-04T12:33:02Z,"If W = 0, B = 0, then A = 0. Similarly all vectors should be zero. Isn&#39;t it?",2020-06-04T12:33:02Z
Ugw6H7qbFj5f2iH33Nt4AaABAg,@jessicajiang3781,,1,6by6Xas_Kho,1,0,2020-01-05T10:22:33Z,can anyone explain why gradient descent study slow when the slope is 0 (flat)? arent we are trying to find the max and min in this function? thanks,2020-01-05T10:22:33Z
UgyXz5DyJvenlyuSsBV4AaABAg,@RealMcDudu,,1,6by6Xas_Kho,0,0,2019-09-20T15:13:37Z,"If you use tanh activation function you have an even bigger problem - the gradients will always be equal to zero, and no learning is feasible (not even a disabled - all weights go in the same direction - learning).",2019-09-20T15:13:37Z
Ugysf8Ys2YsEXceQzAR4AaABAg,@sangwoohan1177,,1,6by6Xas_Kho,0,5,2019-07-31T14:32:53Z,That random korean subtitle tho...,2019-07-31T14:32:53Z
UgxIzc5kUoWu9SVf_-B4AaABAg,@shahbazquraishy143,,1,6by6Xas_Kho,0,0,2019-07-23T17:17:21Z,Could have been a shorter video....,2019-07-23T17:17:21Z
UgzT6_21tzRqa0RwsTJ4AaABAg,@danielchin1259,,1,6by6Xas_Kho,0,0,2019-07-01T05:59:45Z,<b>*UNSTABLE EQUILIBRIUM*</b>,2019-07-01T05:59:45Z
UgxiEdaCc3_oJS8qHCd4AaABAg,@saanvisharma2081,,1,6by6Xas_Kho,1,0,2019-01-23T16:06:38Z,Best activation function???,2019-01-23T16:06:38Z
UgwIkJ5uomNq2q_vLsR4AaABAg,@jagadeeshkumarm3333,,1,6by6Xas_Kho,2,1,2018-02-05T13:41:32Z,what is the best choice for learning rate(alpha)...?,2018-02-05T13:41:32Z
UgyoWSPle5ftxMG49794AaABAg,@X_platform,,1,6by6Xas_Kho,9,5,2017-11-17T08:09:20Z,"Since we are using leaky ReLU for most cases now, should we initiate weights as extreme as possible so when back propagation take place, they will have higher chance to land in different local extremas?",2017-11-17T08:09:20Z
UgyoWSPle5ftxMG49794AaABAg.8_3CuRLztMZ8cEWiSHd9jq,@wolfisraging,UgyoWSPle5ftxMG49794AaABAg,2,6by6Xas_Kho,0,0,2018-02-04T07:08:17Z,"kiryu nil, what do u mean by &#39;as extreme&#39;??",2018-02-04T07:08:17Z
UgyoWSPle5ftxMG49794AaABAg.8_3CuRLztMZ8cFKs9KtCam,@X_platform,UgyoWSPle5ftxMG49794AaABAg,2,6by6Xas_Kho,0,0,2018-02-04T14:44:00Z,"Using tf.random_normal, to set high standard deviation*",2018-02-04T14:44:00Z
UgyoWSPle5ftxMG49794AaABAg.8_3CuRLztMZ8cFLA2PhCTa,@wolfisraging,UgyoWSPle5ftxMG49794AaABAg,2,6by6Xas_Kho,0,1,2018-02-04T14:46:34Z,"kiryu nil, well I think the best way to initialize the weights is by using xaveir initializer, from my observations, its the best way, i think that is why the default initializer in tensorflow is this",2018-02-04T14:46:51Z
UgyoWSPle5ftxMG49794AaABAg.8_3CuRLztMZ8yinSfVLcPJ,@dhirajupadhyay01,UgyoWSPle5ftxMG49794AaABAg,2,6by6Xas_Kho,0,0,2019-08-17T06:10:25Z,@@wolfisraging But why? (if you could explain),2019-08-17T06:10:25Z
UgyoWSPle5ftxMG49794AaABAg.8_3CuRLztMZ8yiroryCrbG,@wolfisraging,UgyoWSPle5ftxMG49794AaABAg,2,6by6Xas_Kho,0,0,2019-08-17T06:48:32Z,"@@dhirajupadhyay01 , In short, it helps signals reach deep into the network.<br><br>If the weights in a network start too small, then the signal shrinks as it passes through each layer until it‚Äôs too tiny to be useful.<br><br>If the weights in a network start too large, then the signal grows as it passes through each layer until it‚Äôs too massive to be useful.<br><br>Xavier initialization makes sure the weights are ‚Äòjust right‚Äô, keeping the signal in a reasonable range of values through many layers.",2019-08-17T06:48:32Z
